<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HashMap Vs. ConcurrentHashMap Vs. SynchronizedMap – 如何在Java中同步HashMap]]></title>
    <url>%2F2017%2F10%2F10%2FHashMap-Vs-ConcurrentHashMap-Vs-SynchronizedMap-%E2%80%93-%E5%A6%82%E4%BD%95%E5%9C%A8Java%E4%B8%AD%E5%90%8C%E6%AD%A5HashMap%2F</url>
    <content type="text"><![CDATA[原文 HashMap 在Java中是一种非常强大的数据结构。我们会经常使用它并且在绝大多数的应用中都会使用到它。这里有一些我之前写的例子: 如何实现线程安全的缓存 , 如何转换 HashMap 为 ArrayList? 在上面的例子中，我们都使用了 HashMap，但这些是相当简单的 HashMap 的用法。 HashMap 是一个非同步 的集合类。 你有过以下的问题吗？ ConcurrentHashMap 和 Collections.synchronizedMap(Map) 之间的区别是什么？ ConcurrentHashMap 和 Collections.synchronizedMap(Map) 之间的性能差别如何？ ConcurrentHashMap vs Collections.synchronizedMap() 常见的 HashMap 和 ConcurrentHashMap 的面试题 这本教程中，我们将覆盖以上所有的疑问以及为什么和如何同步 HashMap 的原因？ Why ?Map 对象是一个存储元素的关联的容器，通过唯一标识的 key 和映射的 value 组成。如果你有一个非常高并发的应用，你可能想在不同的线程中修改或读取键值，那么理想的情况下是使用并发的 HashMap 。最典型的例子就是生产者和消费者的读写处理。 所以，线程安全的 Map 意味着什么？如果 多线程 并发地访问一个 hash map，并且至少有一条线程修改 map 的结构，它 必须在外部被同步，以免视图内容不一致。 How ？有两种方式可以同步 HashMap Java 中的 Collections.synchronizedMap() 方法 使用 ConcurrentHashMap HashMap Vs. synchronizedMap Vs. ConcurrentHashMap 12345678//HashtableMap&lt;String, String&gt; normalMap = new Hashtable&lt;String, String&gt;(); //synchronizedMapsynchronizedHashMap = Collections.synchronizedMap(new HashMap&lt;String, String&gt;()); //ConcurrentHashMapconcurrentHashMap = new ConcurrentHashMap&lt;String, String&gt;(); ConcurrentHashMap 当在你的项目中需要非常高并发的时候，你应该使用 ConcurrentHashMap 它是线程安全的，并且不需要同步整个 Map 读是非常快的，而写是通过锁的 没有在 object 级别的锁 锁在 HashMap 的 bucket 级别具有更精细的粒度 如果一个线程尝试修改 ConcurrentHashMap，而另一个线程正在迭代它，则 ConcurrentHashMap 不会抛出 ConcurrentModificationException 异常。 ConcurrentHashMap 使用多个锁 SynchronizedHashMap 在 Object 级别的锁 每次的 读/写 操作都要求获得锁 锁定整个集合是一个性能的开销 这本质上只允许一条线程访问整个 Map 并且会阻塞所有其他的线程 它可能会引起争议 SynchronizedHashMap 返回 Iterator ，它会在并发修改时失败 现在让我们看一下代码 创建类 CrunchifyConcurrentHashMapVsSynchronizedHashMap.java 为每个 HashTable 、SynchronizedMap 和 CrunchifyConcurrentHashMap 创建一个对象 从 Map 中添加和检索 500K 个条目 压测开始和结束时间并用毫秒显示 我们将使用 ExecutorService 来并行地执行5条线程 CrunchifyConcurrentHashMapVsSynchronizedMap.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package crunchify.com.tutorials; import java.util.Collections;import java.util.HashMap;import java.util.Hashtable;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit; /** * @author Crunchify.com * */ public class CrunchifyConcurrentHashMapVsSynchronizedMap &#123; public final static int THREAD_POOL_SIZE = 5; public static Map&lt;String, Integer&gt; crunchifyHashTableObject = null; public static Map&lt;String, Integer&gt; crunchifySynchronizedMapObject = null; public static Map&lt;String, Integer&gt; crunchifyConcurrentHashMapObject = null; public static void main(String[] args) throws InterruptedException &#123; // Test with Hashtable Object crunchifyHashTableObject = new Hashtable&lt;String, Integer&gt;(); crunchifyPerformTest(crunchifyHashTableObject); // Test with synchronizedMap Object crunchifySynchronizedMapObject = Collections.synchronizedMap(new HashMap&lt;String, Integer&gt;()); crunchifyPerformTest(crunchifySynchronizedMapObject); // Test with ConcurrentHashMap Object crunchifyConcurrentHashMapObject = new ConcurrentHashMap&lt;String, Integer&gt;(); crunchifyPerformTest(crunchifyConcurrentHashMapObject); &#125; public static void crunchifyPerformTest(final Map&lt;String, Integer&gt; crunchifyThreads) throws InterruptedException &#123; System.out.println("Test started for: " + crunchifyThreads.getClass()); long averageTime = 0; for (int i = 0; i &lt; 5; i++) &#123; long startTime = System.nanoTime(); ExecutorService crunchifyExServer = Executors.newFixedThreadPool(THREAD_POOL_SIZE); for (int j = 0; j &lt; THREAD_POOL_SIZE; j++) &#123; crunchifyExServer.execute(new Runnable() &#123; @SuppressWarnings("unused") @Override public void run() &#123; for (int i = 0; i &lt; 500000; i++) &#123; Integer crunchifyRandomNumber = (int) Math.ceil(Math.random() * 550000); // Retrieve value. We are not using it anywhere Integer crunchifyValue = crunchifyThreads.get(String.valueOf(crunchifyRandomNumber)); // Put value crunchifyThreads.put(String.valueOf(crunchifyRandomNumber), crunchifyRandomNumber); &#125; &#125; &#125;); &#125; // Make sure executor stops crunchifyExServer.shutdown(); // Blocks until all tasks have completed execution after a shutdown request crunchifyExServer.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS); long entTime = System.nanoTime(); long totalTime = (entTime - startTime) / 1000000L; averageTime += totalTime; System.out.println("2500K entried added/retrieved in " + totalTime + " ms"); &#125; System.out.println("For " + crunchifyThreads.getClass() + " the average time is " + averageTime / 5 + " ms\n"); &#125;&#125; 结果1234567891011121314151617181920212223Test started for: class java.util.Hashtable500K entried added/retrieved in 1432 ms500K entried added/retrieved in 1425 ms500K entried added/retrieved in 1373 ms500K entried added/retrieved in 1369 ms500K entried added/retrieved in 1438 msFor class java.util.Hashtable the average time 1407 ms Test started for: class java.util.Collections$SynchronizedMap500K entried added/retrieved in 1431 ms500K entried added/retrieved in 1460 ms500K entried added/retrieved in 1387 ms500K entried added/retrieved in 1456 ms500K entried added/retrieved in 1406 msFor class java.util.Collections$SynchronizedMap the average time 1428 ms Test started for: class java.util.concurrent.ConcurrentHashMap500K entried added/retrieved in 413 ms500K entried added/retrieved in 351 ms500K entried added/retrieved in 427 ms500K entried added/retrieved in 337 ms500K entried added/retrieved in 339 msFor class java.util.concurrent.ConcurrentHashMap the average time 373 ms &lt;== Much faster]]></content>
      <tags>
        <tag>java</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中假泛型导致的一个坑]]></title>
    <url>%2F2017%2F09%2F21%2FJava-%E4%B8%AD%E5%81%87%E6%B3%9B%E5%9E%8B%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91%2F</url>
    <content type="text"><![CDATA[情景公司里一位程序员，写了段代码: 123456789101112131415161718192021 @Override public Set&lt;Integer&gt; getUserId() &#123; Set&lt;Integer&gt; userIdSet; Object value = LocalCache.getValue(CacheConstants.USERID_KEY); if (value != null) &#123; userIdSet = (Set&lt;Integer&gt;) value; &#125; else &#123; userIdSet = redisTemplate.opsForSet().members(CacheConstants.USERID_KEY); LocalCache.putValue(CacheConstants.USERID_KEY, userIdSet, 300); &#125; return userIdSet; &#125;然后判断Set&lt;Integer&gt; userIdSet = taskService.getUserId();if (task != null &amp;&amp; userIdSet.contains(task.getUserId())) &#123; //do somehting&#125; else &#123; Loggers.RUNNING_LOG.info("unmatch, &#123;&#125;, &#123;&#125;", userIdSet.toString(), task.getUserId());&#125; 发现它输出了的日志: 1unmatch, [2, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 1000], 60 看这样子的数据， Set 里的集合，是有 60 这个值的。那为什么它是 unmatch 呢？这就很奇怪。 原因1234redisTemplate.opsForSet().members()该方法返回的是泛型数据，它的接口声明为:Set&lt;V&gt; members(K key); 而且由于 redisTemplate 并没有添加泛型信息（项目中的 redis 操作，全是 string 来进行编码和解码的）: 123@Autowired@Qualifier("redisTemplate")private RedisTemplate redisTemplate; 所以，导致 1userIdSet = redisTemplate.opsForSet().members(CacheConstants.USERID_KEY); 这里的赋值，直接通过了编译（因为目前Java对泛型的支持，仅仅是通过编译器级别来实现的，而在运行时 runtime 中并没有真正支持。 所以，在实际上, userIdSet 里的是 String 类型，而不是 Integer 类型。 这样子的结果就是使用 String 的 Set 去调用 contains(Integer) ，肯定就会导致 false 啦，然后就出现了上面的日志的打印。 解决知道原因，那就可以进行相应的完善啦 RedisTemplate 注入里，要加上泛型信息，即修改为 123@Autowired@Qualifier("redisTemplate")private RedisTemplate&lt;String, String&gt; redisTemplate; 然后就可以看到相关的地方会报相应的编译时错误了，然后就可以按错误信息的提示来进行修改了。 教训：在一个有泛型的类或方法中，一定要添加泛型的信息！！以免出Bug或掉进坑。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Erlang趣学指南》读书笔记]]></title>
    <url>%2F2017%2F08%2F26%2F%E3%80%8AErlang%E8%B6%A3%E5%AD%A6%E6%8C%87%E5%8D%97%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章查找帮助1erl -man 模块名 变量名Erlang 中，变量名不能以小写字符开头。 原子原子是字面量，这意味着原子是常量，唯一的值就是自己的名字。换句话说，你看到的，就是你能得到的——别想太多。 写法： 以小写字母开头 如果原子不以小写字母开头或者其中包含有除字母、数字、下划线、以及@符号 之外 的其他字符，那么必须被放到两个单引号 (‘’) 之间。 注意千万不要动态生成原子！！！ 因为原子表不被垃圾回收，所以原子会一直累积，直到系统因为内存耗尽或者创建的原子数超过了 1048577 而发生崩溃。 有些原子是保留字，这些原子不能使用。 非短路布尔操作符 and 和 or注意： 这两个操作符，会对两边的参数都会去求值。 短路布尔操作符 andalso 和 orelse比较精确=:= : 精确相等性比较 （严格区分浮点数和整数）=/= : 精确不等性比较 （严格区分浮点数和整数） 非精确== : 非精确相等性比较（非严格区分浮点数和整数）/= : 非精确不等性比较（非严格区分浮点数和整数） 小于等于=&lt; ：注意，它与其他编程语言是不一样的！！！ 不同类型比较Erlang 语言的发明者把实用性的优先级排在理论前面，觉得如果能简单地写出像排序算法那样的程序，可以对任意数据排序，岂不是很棒！做出这个决定是为了简化编程工作！ 1number &lt; atom &lt; reference &lt; fun &lt; port &lt; pid &lt; tuple &lt; list &lt; bit string Erlang 语言发明者之一 Joe Armstrong 说过：具体的顺序不重要，重要是定义明确的全局顺序。 元组1&#123;E1, E2, E3&#125; 带标记的元组如果一个元组中包含一个原子，原子后面只跟着一个元素，那么这样子的元组就称为带标记的元组。 列表1[E1, E2, E3] 注意在 Erlang 中，字符串就是列表！！！ ++，–它们都是 右结合 的操作符。即操作是从右向左进行的！！ hd, tlhd: 获取列表的第一个元素tl: 获取列表除第一个元素外的所有元素 列表模式匹配1[Head | Tail] cons 操作符 |1[Term1 | [Term2 | [.. | [TermN]]]] 非良构列表 improper list1[1 | 2] 像这种就是非良构列表。 非良构列表，虽然可以用于模式匹配，但在 Erlang 标准函数（如 length()) 中使用会失败。这是因为 Erlang 期待的是良构列表。 良构列表这种列表的最后一个元素是 空列表 如: 12[2][1 | [2]] 列表推导式 list comprehension用来构建或修改列表。如： 1231&gt; [ 2 * N || N &lt;- [1,2,3,4]].[2,4,6,8]2&gt; 语法： 1NewList = [Expression || Pattern &lt;- List, Condition1, Condition2, ... ConditionN] Pattern &lt;- List 称为 生成器表达式, generator expression 最完整的语法： 1NewList = [Expression || GeneratorExp1, GeneratorExp2, Condition1, Condition2, ... ConditionN] 位语法1&lt;&lt;&gt;&gt; 在这括号里，可以用逗号，将区段之间分隔。一个区段，就是一个二进制的位序列。如: 12Color = 16#F09A29Pixel = &lt;&lt;Color:24&gt;&gt; 匹配模式： 1&lt;&lt;Pattern, Rest/binary&gt;&gt; 它与列表模式匹配中的 1[Head | Tail] 是一样的。 二进制字符串1&lt;&lt;"Hello word"&gt;&gt; 二进制推导式1&lt;&lt; &lt;&lt;X&gt;&gt; || &lt;&lt;X&gt;&gt; &lt;= &lt;&lt;1,2,3,4,5&gt;&gt;, X rem 2 == 0 &gt;&gt;. 与列表推导式类似！ Erlang 适用和不适用的场景Erlang 历来不擅长数值密集型计算。 对于不需要数值计算的应用，如：事件响应、消息传递等, Erlang 通常是非常快的。 第二章模块1-module(name). 注意, name 是一个 原子 ，并且要跟文件名相同（除开后缀） 导出函数 1-export([Function1/Arity, Function2/Arity,...,FunctionN/Arity]). 导入函数（不太建议这样子使用） 1-import(Module, [Function1/Arity, Function2/Arity,...,FunctionN/Arity]). 函数1name(Args) -&gt; Body. name 必须是一个 原子 , Body 可以是一个或多个用逗号分隔的 Erlang 表达式。函数以一个句点结束。注意，和许多命令式语言不同，Erlang 中没有 return 关键字。return 毫无用处，无需显式说明，函数中最后一个表达式的执行结果会自动被作为返回值传递给调用者。 注释1% 这是注释 宏1-define(Macro, some_value). 使用宏: 1?Macro 条件判断: 12345-ifdef(Macro).-else.-endif. 元数据查看元数据： 1moduleName:module_info(). 注意关于模块设计：一定要避免环形依赖。 第三章模式匹配Erlang 中，函数中的模式匹配，会同时完成函数选择和变量绑定两件事。无需先绑定变量，然后再去比较它们。 其中，每一条函数声明都被称为一个函数子句(function clause) 。函数子句之间必须用分号(;)分隔，所有函数子句形成一个完整的函数定义。最后一个函数子句以句点结束。 绑定变量和自由变量变量绑定：就是将一个值附着到一个未绑定的变量上。 在 Erlang 中，如果给一个已绑定的变量赋值，除非这个新值和变量原有的值相同，否则就会引发错误。 卫语句 guard它是附加在函数头中的语句，能够让模式匹配更具表达力。如: 12old_enough(X) when X &gt;= 16 -&gt; true;old_enough(_) -&gt; false. 在卫表达式中，逗号(,) 的作用和操作符 andalso 类似，分号(;) 和 orelse 类似（不过要注意短路的问题） 不过，卫语句中不能使用用户自定义函数。 if 表达式也称为 卫模式 guard pattern 1234if X &gt; 1 -&gt; io:format("~p &gt; 1~n", [X]); true -&gt; okend. case … of 表达式1234case lists:memeber(X, Set) of true -&gt; Set; false -&gt; [X | Set]end. 第四章类型Erlang 是一门强类型的动态语言。 类型转换1erlang:TypeA_to_TypeB(). 检测数据类型123is_xxxx().type_of(X). 第五章递归编写递归: 基本情形 调用自己的函数 用于测试的列表 例子：计算列表的长度: 1234len([]) -&gt; 0;len([_ | T]) -&gt; 1 + len(T). 尾递归普通的递归，会进行操作的叠加，而尾递归，则旨在消除这个叠加，方法是在它们出现时，就对其进行归约。 第六章高阶函数如果一个函数的参数，是以另一个函数来传递的话，则这个函数称为 高阶函数(higher-order function) 匿名函数和闭包又称为 funs ，除了不能递归调用自己（因为它是匿名，所以。。。） 注意：不管匿名函数在哪里，被继承的作用域会一直跟随着它！即使把这个匿名函数传递给另外一个函数。 闭包：可以让函数引用到它所携带的带些环境（作用域中的值部分）。 第七章错误 编译期错误 逻辑错误 运行时错误 异常 出错 error : 调用 erlang:error(Reason) . 它会结束当前进程的执行，引发运行时错误。 退出 exit : 内部退出: exit/1 ； 外部退出: exit/2 ，在多进程环境中使用。 抛出 throw : 抛出异常: throw(permission_denied). 处理异常1234567891011121314try Expression of SuccessfulPattern1 [Guards] -&gt; Expression1; SuccessfulPattern2 [Guards] -&gt; Expression2catch TypeOfError:ExceptionPattern1 -&gt; Expression3; TypeOfError:ExceptionPattern2 -&gt; Expression4after Expression5 end. after 类似其他语言的 finally 第八章第九章记录 record它只是元组的一种语法糖。 定义： 1-record(name, &#123;property1, property1....&#125;). 使用： 1#recordName&#123;property1=value1, property2=value2...&#125;. 读取 123RecordVar = #recordName&#123;property1=v1, property2=v2...&#125;.RecordVar#recordName.property1. 共享记录: 通过使用 Erlang 的头文件来实现。(xxx.hrl) 123在 xxx.hrl 文件中定义：-record(记录名, &#123;属性1，属性2 ...&#125;). 然后在其他的 erl 文件中包含进来: 1-include("xxx.hrl"). K-V 存储属性列表 proplists:形如: 1[&#123;Key, Value&#125;] 的元组列表。 有序字典 orddict:1&#123;Key, Value&#125; 字典(dict:)和通用平衡树(gb_trees:)（大量数据存储）字典的读取性能最好，其他的话，可以用 gr_trees 集合 ordsets : 有序集合（底层实现为有序列表）。主要用于小集合，是最慢、也是最简单的一种。 sets : 擅长读密集型的处理。 gb_sets : sofs : 集合的集合。 有向图digraph 模块 和 digraph_utils 模块。 队列queue 模块 第十章创建进程spawn/1 123F = fun() -&gt; 2 + 2 end.spawn(F). 发送消息1Pid ! 'hello world'. 向多个进程同发送同样的消息: 1Pid1 ! Pid2 ! Pid3 ! 'hello world'. 接收消息receive 表达式 1234567receive Pattern1 [when guard1] -&gt; Exp1; Pattern2 [when guard2] -&gt; Exp2; Pattern3 -&gt; Exp3[after Delay(超时时间，单位是毫秒) -&gt; AfterExpend. 第十一章第十二章链接 link当两个进程建立这种关系后，如果其中一个进程由于意外的抛出、出错或退出而死亡时，另外一个进程，也会死亡，把这两个进程独立的生存期绑定成一个关联在一起的生存期。 它们是双向的，并且是不可以叠加的 123456785&gt; self().&lt;0.72.0&gt;6&gt; link(spawn(fun() -&gt; timer:sleep(5000), io:format("link退出~n"), exit(reason) end)).truelink退出** exception error: reason7&gt; self().&lt;0.76.0&gt; 注意， link 并不是一个原子操作。可以使用: 1spawn_link/1-3 来实现它们的原子操作 捕获退出信息1process_flag(trap_exit, true). 监控器 monitor1erlang:monitor(process, Pid). 第一个参数永远是 process ，第二个参数是 Pid 原子版: 1spawn_monitor/1-3 命名进程1register(name, Pid). 获取命名进程的Pid: 1Pid = whereis(name). 第十三章第十四章 OTP init 函数它负责初始化服务器的状态，并完成服务器需要的所有一次性任务。 它可以返回: 123456789&#123;ok, State&#125;&#123;ok, State, TimeOut&#125;&#123;ok, State, hibernate&#125;&#123;stop, Reason&#125;ignore State 会直接传递给进程的主循环，并作为进程的状态一直保存在那里。 handle_call 函数handle_call/3 用于处理同步消息。它有三个参数： Request, From, State 用于同步消息的处理 它可以有8种返回值: 123456789101112131415&#123;reply, Reply, NewState&#125;&#123;reply, Reply, NewState, TimeOut&#125;&#123;reply, Reply, NewState, hibernate&#125;&#123;noreply, NewState&#125;&#123;noreply, NewState, TimeOut&#125;&#123;noreply, NewState, hibernate&#125;&#123;stop, Reason, Reply, NewState&#125;&#123;stop, Reason, NewState&#125; handle_cast 函数它有两个参数：Message 和 State . 用于异步消息的处理。 它可以返回: 1234567&#123;noreply, NewState&#125;&#123;noreply, NewState, TimeOut&#125;&#123;noreply, NewState, hibernate&#125;&#123;stop, Reason, NewState&#125; handle_info 函数它和 handle_cast/2 相似，返回值也完全一样。区别在于： 这个回调函数只用来处理直接通过 ! 操作符发送的消息，以及如 init/1 中的 timeout 、监控器通知或 EXIT 信号之类的特殊消息。 terminate 函数它有两个参数： Reason, State ，分别对应 stop 元组中的同名字段。 注意，所有在 init/1 中的动作都应在 terminate/2 中有对应的取消动作。 code_change 函数code_change/3 用于代码升级。调用： 1code_change(PreviousVersion, State, Extra) gen_server 实践在相应的模块中加入: 1-behavior(gen_server). 然后直接编译该模块，可以看到它会报: 1234567$erlc demo.erl demo.erl:11: Warning: undefined callback function handle_call/3 (behaviour 'gen_server')demo.erl:11: Warning: undefined callback function handle_cast/2 (behaviour 'gen_server')demo.erl:11: Warning: undefined callback function init/1 (behaviour 'gen_server')# 第十五章 Erlang 中的有限状态机： 被实现为一个进程，运行一组给定的函数（状态）、接收一些消息（事件）以驱动状态迁移。 即 gen_fsm 行为(finite-state machine, FSM) init 函数它和 gen_server 的 init/1 使用方式一样。返回值可以为: 1234567&#123;ok, StateName, Data&#125;&#123;ok, StateName, Data, Timeout&#125;&#123;ok, StateName, Data, hibernate&#125;&#123;stop, Reason&#125; 注意，StateName 它是原子类型。 StateName 函数函数 StateName/2 （参数分别为 Event ，StateData）和 StateName/3 (参数分别为: Event, From, StateData) 是占位名字，由你来决定它们的内容。假设 init/1 函数返回 1&#123;ok, sitting, dog&#125; 这意味着FSM会处于 sitting 状态。 这时，sitting/2 （异步事件）或 sitting/3 (同步事件) 会被调用。 StateName/2 可以返回: 1234567&#123;next_state, NextStateName, NewStateData&#125;&#123;next_state, NextStateName, NewStateData, Timeout&#125;&#123;next_state, NextStateName, hibernate&#125;&#123;stop, Reason, NewStateData&#125; StateName/3 可以返回: 12345678910&#123;reply, Reply, NextStateName, NewStateData&#125;&#123;reply, Reply, NextStateName, NewStateData, Timeout&#125;&#123;reply, Reply, NextStateName, NewStateData, hibernate&#125;&#123;next_state, NextStateName, NewStateData&#125;&#123;next_state, NextStateName, NewStateData, Timeout&#125;&#123;next_state, NextStateName, NewStateData, hibernate&#125;&#123;stop, Reason, Reply, NewStateData&#125;&#123;stop, Reason, NewStateData&#125; handle_event 函数无论当前在哪个状态，全局事件都会触发一个特定反应。（就是这个函数） 参数分别是： Event, StateName, Data 它的返回值和 StateName/2 一样。 handle_syn_event 函数handle_syn_event/4 和 StateName/3 的关系，类似于 handle_event/2 和 StateName/2 的关系一样。 这个函数处理同步全局事件。参数和返回值都和 StateName/3 一样。 code_change 和 terminate 函数它们和 gen_server 中完全一样。 第十六章Erlang 中的 事件处理器，它也是OTP中一种行为： gen_event gen_event 行为运行这个接受并回调函数的事件管理器进程，而你只需要提供包含这些回调函数的模块即可。 事件处理器的回调函数： init 和 terminate 函数它与上面的 gen_server 和 gen_fsm 行为中的类似。 handle_event 函数handle_event(Event, State) ，它是异步处理的。返回值: 1234567&#123;ok, NewState&#125;&#123;ok, NewState, hibernate&#125;remove_handler&#123;swap_handler, Args1, NewState, NewHandler, Args2&#125; 返回 remove_handler 会导致事件处理器从事件管理器中删除。 最后一个返回值 {swap…} ，这表示移除当前事件处理器，并用一个新的替代它。 handle_call 函数它与 gen_server 中的 handle_call 回调类似。可返回: 1234567&#123;ok, Reply, NewState&#125;&#123;ok, Reply, NewState, hibernate&#125;&#123;remove_handler, Reply&#125;&#123;swap_handler, Reply, Args1, NewState, Handler2, Args2&#125; 使用 gen_event:call/3-4 可以发起该调用。 handle_info 函数它只处理带外消息，如退出信号或使用 ! 操作符直接向事件管理器进程发送消息。 与 gen_server 中的 handle_info 使用场景类似。 code_change 函数参数： OldVsn, State, Extra 第十七章基本概念： 工作者、监督者、监督树 使用监督者只要提供一个回调函数： init/1 ，它的返回值为: 1&#123;ok, &#123;&#123;RestartStrategy, MaxRestart, MaxTime&#125;, [ChildSpec]&#125;&#125;. 重启策略 RestartStrategy可以为 one_for_one ，one_for_all ，rest_for_one 和 simple_one_for_one one_for_one : 当监督者监督了很多工作者，当其中一个工作者失败时，只需要重启这个工作者即可。 one_for_all : 这些工和者必须互相依赖才能正常工作时，就使用这个策略。 rest_for_one : 当需要启动一组进程，而这些进程互相依赖形成一条链时，可以使用该策略。（A -&gt; B, B-&gt;C, C-D) 。即，如果一个进程死了，那么所有在这个进程之后启动的进程，都将被重启。反之不然。 simple_one_for_one : 当希望以动态的方式向监督者增加子进程，而不是静态启动子进程时，可以使用这种策略。 MaxRestart 和 MaxTime意思是在 MaxTime （单位为秒） 指定的时间内，重启次数超过了 MaxRestart 指定的数字，而么监督者会放弃重启，并终止所有子进程，然后自杀，永远停止运行。 ChildSpec 说明抽象形式: 1&#123;ChildId, StartFunc, Restart, Shutdown, Type, Modules&#125; ChildId : 只是监督者内部使用的一个名称。除了调试或想获取监督者所有子进程列表时，这个名字会比较有用之外，其他基本没什么用了。 StartFunc : 是一个元组，用来指定子进程的启动方式。它采用了 {M, F, A} 的标准格式。 Restart: 指定了监督者在某个特定的子进程死后的处理方式。可以为 permanent （一直要重启）, temporary （绝不应该被重启）, transient （正常终止就不会重启，异常死亡，比如非 normal 、shutdown、{shutdown, Reason} 就会重启）。 Shutdown: 用来指定终止进程的超时期限 或 是一个原子： brutal_kill ，它表示无条件终止。 Type: 可以让监督者知道子进程是一个监督者(supervisor)还是一个工作者(worker)。 Modules: 一个列表，其中只有一个元素: 子进程行为使用的回调模块名。 第十八章第十九章OTP 应用结构12345ebin/include/priv/src/test/ 应用资源文件这个文件要放在 ebin/ 目录下。命名通常是 appName.app 基本结构: 1&#123;application, ApplicationName, Properties&#125;. ApplicationName 是一个原子， Properties 是一个 {Key, Value} 元组列表。 属性子集{description, “some description of your application”} {vsn, “1.2.3”} {modules, ModuleList} {registered, AtomList} 应用中进程注册名 {env, [Key, Va]} {maxT, Milliseconds} 应用最长运行时间，默认为 infinity {applications, AtomList} 依赖其他应用的列表。在自己的应用被加载/启动之前，Erlang的应用管理系统会确保这些被依赖的应用先被加载或启动。 {mod, {CallbackMod, Args}} 启动应用时，会调用 CallbackMod:start(normal, Args) ,停止时，会调用 CallbackMod:stop(Args) 启动应用application:start(AppName, temporary) =&gt; 正常结束，则不处理，只有这个应用停止运行。如果异常结束，则报告出错消息，这个应用被终止，不再重启。 application:start(AppName, transient) =&gt; 正常结束，则不处理，只有这个应用停止运行。如果异常结束，则报告出错消息，其他所有应用会被停止，VM也会被关闭。 application:start(AppName, permanent) =&gt; 正常结束或异常结束，其他所有应用都会被停止，VM也会被关闭。]]></content>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 高负载CPU排查]]></title>
    <url>%2F2017%2F08%2F24%2FRabbitMQ-%E9%AB%98%E8%B4%9F%E8%BD%BDCPU%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[问题12 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND16285 user 20 0 6188812 1.465g 5992 S 197.7 9.3 4418:21 beam.smp 线上的 DSP 系统要用到 RabbitMQ 作为进程间消息通信的中间件，但是发现它的CPU使用率时很高，时而又比较低(60%~230%之间波动) 排查方法最直接的是使用 top 命令，这样子可以看到 beam.smp 进程总体的 CPU 使用率 然后，要细分到 RabbitMQ 里的哪些进程要花费高CPU，则可以直接使用 RabbitMQ 自带的插件： rabbitmq_top 12345678910111213141516171819202122232425262728293031323334$./sbin/rabbitmq-plugins list Configured: E = explicitly enabled; e = implicitly enabled | Status: * = running on rabbit@iZ2ze5o5txbjcf4ecbmhunZ |/[e*] amqp_client 3.6.9[e*] cowboy 1.0.4[e*] cowlib 1.0.2[ ] rabbitmq_amqp1_0 3.6.9[ ] rabbitmq_auth_backend_ldap 3.6.9[ ] rabbitmq_auth_mechanism_ssl 3.6.9[ ] rabbitmq_consistent_hash_exchange 3.6.9[ ] rabbitmq_event_exchange 3.6.9[ ] rabbitmq_federation 3.6.9[ ] rabbitmq_federation_management 3.6.9[ ] rabbitmq_jms_topic_exchange 3.6.9[E*] rabbitmq_management 3.6.9[e*] rabbitmq_management_agent 3.6.9[ ] rabbitmq_management_visualiser 3.6.9[ ] rabbitmq_mqtt 3.6.9[ ] rabbitmq_recent_history_exchange 3.6.9[ ] rabbitmq_sharding 3.6.9[ ] rabbitmq_shovel 3.6.9[ ] rabbitmq_shovel_management 3.6.9[ ] rabbitmq_stomp 3.6.9[E*] rabbitmq_top 3.6.9[ ] rabbitmq_tracing 3.6.9[ ] rabbitmq_trust_store 3.6.9[e*] rabbitmq_web_dispatch 3.6.9[ ] rabbitmq_web_mqtt 3.6.9[ ] rabbitmq_web_mqtt_examples 3.6.9[ ] rabbitmq_web_stomp 3.6.9[ ] rabbitmq_web_stomp_examples 3.6.9[ ] sockjs 0.3.4 启用 rabbitmq_top 插件: 123456$./sbin/rabbitmq-plugins enable rabbitmq_topThe following plugins have been enabled: rabbitmq_topApplying plugin configuration to rabbit@iZ2ze5o5txbjcf4ecbmhunZ... started 1 plugin. 查看: 在上面的统计图表中，则可以直接看到 RabbitMQ 内部哪些进程消耗的CPU比较多，然后则可以进一步优化了。 原因在线上的系统中，导致这CPU大波动的原因，是我们 DSP 系统中，使用了定时从队列中获取数据，然后进行批量处理导致的。 我们线上的业务逻辑是这样子的： DSP 系统产生的竞价日志 -&gt; RabbitMQ -&gt; 消费者每分钟批量处理一轮队列消息（处理业务逻辑，然后再批量插入到DB。 主动 pull 消息，而不是监听） 不过，关于这一块，暂时还没有想好有更好的处理方式。因为我们是想批量处理日志到DB的，这样子可以大幅度提高DB的处理性能，不然一条一条地处理日志的话，还是很费时间的。 关于RabbitMQ批量处理的问题，有更好的处理方式，也欢迎告诉一下我 ^_^]]></content>
      <tags>
        <tag>rabbitmq</tag>
        <tag>cpu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alfred3 自定义 workflow]]></title>
    <url>%2F2017%2F08%2F21%2FAlfred3-%E8%87%AA%E5%AE%9A%E4%B9%89-workflow%2F</url>
    <content type="text"><![CDATA[本人习惯用 Golang 来写些小工具什么的，所以，这里以 Golang 为例子 方式Alfred 的 workflow ，个人的理解就是在 Alfred 中输入，然后它会调用其他程序，将你的输入作为程序的输入，然后程序就负责处理并输出数据。 1keyworkd input -&gt; program with [input] paratemer -&gt; result 例子：毫秒转换为 YYYY-MM-dd HH:mm:ss 的输出123456789101112131415161718192021222324252627282930313233343536package mainimport ( "time" "strconv" "github.com/emacsist/alfred3/utils")const DATE_FORMAT = "2006-01-02 15:04:05"func main() &#123; query := utils.GetQuery() response := utils.NewAlfredResponse() timestampInMillis, err := strconv.ParseInt(query, 10, 64) if err == nil &#123; //毫秒转换为时间 Jan 2 15:04:05 2006 MST t := time.Unix(0, timestampInMillis*int64(time.Millisecond)) dateTimeString := t.Format(DATE_FORMAT) response.AddDefaultItem("时间: " + dateTimeString) &#125; else &#123; // 时间 转换为毫秒 t, err := time.Parse(DATE_FORMAT, query) if err == nil &#123; seconds := t.Unix() ms := int64(t.Nanosecond()) / int64(time.Millisecond) response.AddDefaultItem("时间戳:" + strconv.FormatInt(int64(seconds), 10)) response.AddDefaultItem("毫秒:" + strconv.FormatInt(ms, 10)) &#125; else &#123; response.AddDefaultItem("输入的数据格式不对. 毫秒或 YYYY-MM-DD HH:mm:ss") &#125; &#125; response.WriteOutput()&#125; 解释query: 就是我们的输入，这里对于各种编程语言应该是通用的，就是读取 main 函数的 argv 的参数出来。Alfred 会自动将我们的输入作为参数来调用我们这个程序的。 输出从 Alfred3 开始，官方建议使用 JSON 的数据结构作为输出，则不是XML了。 输出的JSON数据结构: 1234567891011121314&#123;"items": [ &#123; "uid": "desktop", "type": "file", "title": "Desktop", "subtitle": "~/Desktop", "arg": "~/Desktop", "autocomplete": "Desktop", "icon": &#123; "type": "fileicon", "path": "~/Desktop" &#125; &#125;]&#125; 字段解释 items: 表示输出的每一个元素的数组。最直观的，就是每一个项，就代表 Alfred 中输出的每一行。 uid: 每一行中，唯一的标识ID。只要唯一就可以了。type: 表示类型title: 标题subtitle: 子标题arg: 参数（这个要特别注意，这个最好要设置一下。该参数是传递给 output 链的。比如，将结果再输出到粘贴板、输出到通知中心，这时 Alfred 就会将 arg 参数的值传递给它们）autocomplete: 自动补全icon: 图标 参考资料https://www.alfredapp.com/help/workflows/inputs/script-filter/json/]]></content>
      <tags>
        <tag>mac</tag>
        <tag>alfred</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis 源码分析及学习]]></title>
    <url>%2F2017%2F07%2F21%2FMyBatis-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[搭建环境本要将相应的工程，放在 github 了，这个是最小的 MyBatis 应用了，导入工程到自己喜欢的IDE里，就可以开始一步一步调试了。 github emacsist mybatis-hello-world 概要12345678910111213public static void main(String[] args) throws IOException &#123; String resource = "com/github/emacsist/mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try &#123; PersonMapper mapper = session.getMapper(PersonMapper.class); Person person = mapper.selectOne(1); System.out.println(person.getName()); &#125; finally &#123; session.close(); &#125;&#125; 可以看到，整个流程就是： 创建配置 -&gt; 初始化配置并创建 SqlSessionFactory -&gt; 获取 SqlSession -&gt; 执行 Mapper 的方法 -&gt; 获取返回结果 MyBatis 的配置 Configuration对应的类为: org.apache.ibatis.session.Configuration 总体: Environmentorg.apache.ibatis.mapping.Environment 这个可以根据不同的环境，来设置不同的DB及连接信息。 这个对应的XML配置是： 1234567891011&lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://10.0.0.40:3308/test?useUnicode=true"/&gt; &lt;property name="username" value="uniweibo"/&gt; &lt;property name="password" value="uniweibo.com"/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; transactionManager 有两种: JDBC 和 MANAGEDdataSource : 数据源，类型可以为 UNPOOLED : 即每次都创建一个新的连接，用完后关闭 POOLED : 使用数据连接池来管理连接 JNDI : 使用 JNDI 来管理 properties这个可以直接引用外部的 properties 文件，并且可以替换它现有的值 1234&lt;properties resource="org/mybatis/example/config.properties"&gt; &lt;property name="username" value="dev_user"/&gt; &lt;property name="password" value="F2Fa3!33TYyg"/&gt;&lt;/properties&gt; settings这些是用于 Environment 常规字段配置的。 123456&lt;settings&gt; &lt;!-- changes from the defaults for testing --&gt; &lt;setting name="cacheEnabled" value="false" /&gt; &lt;setting name="useGeneratedKeys" value="true" /&gt; &lt;setting name="defaultExecutorType" value="REUSE" /&gt;&lt;/settings&gt; 这里重点说一下 defaultExecutorType defaultExecutorTypeExecutor 层次图 SIMPLE如果不显式指定的话，那这个是默认值。 REUSEBATCHtypeAliases为Java类型设置别名 typeHandlers类型处理器. MyBatis 已经自带了不少类型处理器了，在包 org.apache.ibatis.type 下面: databaseIdProvider MyBatis 会加载不带 databaseId 属性和带有匹配当前数据库 databaseId 属性的所有语句。 如果同时找到带有 databaseId 和不带 databaseId 的相同语句，则后者会被舍弃。 为支持多厂商特性只要像下面这样在 mybatis-config.xml 文件中加入 databaseIdProvider 即可 12345&lt;databaseIdProvider type="DB_VENDOR"&gt; &lt;property name="SQL Server" value="sqlserver"/&gt; &lt;property name="DB2" value="db2"/&gt; &lt;property name="Oracle" value="oracle" /&gt;&lt;/databaseIdProvider&gt; DB_VENDOR 的获取: 1System.out.println(session.getConnection().getMetaData().getDatabaseProductName()); databaseId 可以在 Mapper 文件中的语句加上该属性。 123&lt;select id="selectOne" resultType="com.github.emacsist.pojo.Person" databaseId="db2"&gt; select * from person where id = #&#123;id&#125;&lt;/select&gt; 这样子，就可以根据不同的数据库提供商，去选择不同的语句了。 mappers这个配置就是指示 mybatis 如何查找我们的 Mapper 文件的。详情看下面的参考资料。通过配置文件的配置，它会解析及加载到 Configuration 的： 1protected final MapperRegistry mapperRegistry = new MapperRegistry(this); 对象中，这时，就可以通过 SqlSession.getMapper(Class) 方法，来获取不同的 Mapper 。 加载及解析配置文件将 mybatis-config.xml 读取并解析为 org.apache.ibatis.session.Configuration 对象 123InputStream inputStream = Resources.getResourceAsStream(resource);XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, null, null);Configuration config = parser.parse(); 参考资料MyBatis 官方文档 XML 映射配置文件 初始化并创建 SqlSessionFactory12// 这个 inputStream 对象，就是上面读取 mybatis-config.xml 后转换成的输入流SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 经过上面的解析后可知，inputStream 最终转换为的是 Configuration 对象，然后利用该对象来构建 SqlSessionFactory 1234567public class DefaultSqlSessionFactory implements SqlSessionFactory &#123; private final Configuration configuration; public DefaultSqlSessionFactory(Configuration configuration) &#123; this.configuration = configuration; &#125; 获取 SqlSessionSqlSessionFactory 负责与DB的一次会话机制，以及打开会话时设置的会话级别的配置（比如事务级别、是否自动提交、选择 Executor 的类型等） 12345678910111213141516public interface SqlSessionFactory &#123; SqlSession openSession(); SqlSession openSession(boolean autoCommit); SqlSession openSession(Connection connection); SqlSession openSession(TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType); SqlSession openSession(ExecutorType execType, boolean autoCommit); SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType, Connection connection); Configuration getConfiguration();&#125; 通过 SqlSessionFactory 的不同方法，可以选择不同的 SqlSession 的配置。 执行 Mapper 的方法通过 SqlSession.getMapper(Class) 方法获取要执行的 Mapper 。执行到这里，就已经可以决定一条SQL是如何执行的了。之前的 SqlSession 构建完成后，就可以知道它的属性了: 1234this.configuration = configuration;this.executor = executor;this.dirty = false;this.autoCommit = autoCommit; 其中最重要的，就是它的 Executor 的类型（执行器的类型）。 这个 Mapper ，它使用了动态代理的机制： 1234567891011public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException("Type " + type + " is not known to the MapperRegistry."); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException("Error getting mapper instance. Cause: " + e, e); &#125;&#125; 可以看到，它使用了 MapperProxyFactory 代理工厂方法的设计模式，它的代理类就是: org.apache.ibatis.binding.MapperProxy 可以看到，这个就是整个执行时，MyBatis 为我们代理的统一抽象的DB处理。 调用代理方法时，它首先从 MapperMethod 缓存中查找是否已经存在，否则加入本地缓存后再返回（加快查找及构造对象），然后执行 MapperMethod.execute() 方法来执行相应的 CRUD 操作，以及自动映射结果集为我们为 mapper 语句定义的返回类型。 杂项MyBatis 是如何处理动态SQL的? 这在在解析配置文件为 Configuration 对象时，所有的 Mapper 文件，以及它对应的 SQL 文本，都已经被解析为相应的对象了。而动态SQL，则是通过 DynamicSqlSource 对象来保存它的表达式及该表达式所对应的 SQL 语句。 表达式的 eval 是通过 org.apache.ibatis.scripting.xmltags.ExpressionEvaluator 类来进行表达式解析的。 组装动态SQL完成后，就到了解析SQL了。因为我们在写SQL的时候，一般是使用 #{} 的命名参数的形式，但是对于JDBC来说，参数它是必须 ? 的形式的，然后以相应的 value 来进行替换。所以，这里 MyBatis 又要进行一些转换了 SqlSourceBuilder.parse() 方法，就是用来进行SQL解析的。逻辑如下: 判断动态SQL满足的条件的分支，生成最终版的命名的参数 SQL -&gt; #{} 这些的占位符进行分词 -&gt; 将 #{} 替换为 ? -&gt; 将参数对象按顺序，再将 ? 进行 PrepareStatement （防SQL注入）来替换值，这时就形成了最终的可执行的 SQL 语句了。 注意，如果使用的是 ${} 而不是 #{} ，则不会进行将 ${} 转换为 ? ，而是直接将 ${} 替换为相应的值（这可能会造成SQL注入） 性能优化开启SQL压缩 可以看到，我们在 XML 文件格式化的换行、空格等这些符号，在保留后的SQL里还是存在的，但这些了占了额外的大小，在数据传输时，也要占用一定的数据大小（或者许多人觉得，这个影响并不大，但如果你在执行批量处理的时候，这个放大的倍数就比较可观了） 这时，可以在 JDBC 连接里，加上 useCompression=true ，添加个压缩选项。 指量处理的SQL 导致的性能问题在 MyBatis 执行批量操作时，过多的命名参数的话，MyBatis 要进行解析，然后转换为 PrepareStatement ，这需要花费不少的时间的，可参考另一篇 Blog: 记录一次 MySQL 批量插入的优化 在 MyBatis / JDBC ，批量处理的情况为: 开启事务，执行多条 SQL ，然后提交事务。即 insert …values (xxx); insert …values(yyyy) 或 执行一条 insert … values (xxx), (yyy) 这个建议使用第二种，因为可以大量减少数据的传输。 可能在 JDBC 连接上，加上 rewriteBatchedStatements=true 这个改写的选项。开启后，它会将第一种的SQL语句，改写为第二种的SQL语句后，再进行发送到DB。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的 finally 与 return]]></title>
    <url>%2F2017%2F07%2F17%2FJava%E4%B8%AD%E7%9A%84-finally-%E4%B8%8E-return%2F</url>
    <content type="text"><![CDATA[实验代码12345678910111213141516171819package org.agoncal.sample.jmh;/** * Created by emacsist on 2017/7/14. */public class TestFinallyClass &#123; public static void main(String[] args) &#123; System.out.println(testFinally(10)); &#125; public static int testFinally(int i) &#123; try &#123; return i + 1; &#125; finally &#123; i+=10; return i + 2; &#125; &#125;&#125; 字节码12345678910111213141516171819202122232425Code: stack=2, locals=3, args_size=1 0: iload_0 将 LocalVariableTable 中 slot 为 0 的变量压入栈 1: iconst_1 将常量 int 类型的 1 压入栈 2: iadd 将栈顶的两个 int 弹出，并相加，最后将结果压入栈 (即 i+1) 3: istore_1 将栈顶的 int 弹出，并保存到局部变量表中 slot 为 1 的局部变量（这个是编译器处理生成的） 4: iinc 0, 10 将局部变量 slot 为0的变量，增加10，即 (i+=10) 7: iload_0 将 slot 为0的变量（即 i）压入栈 8: iconst_2 将常量 int 类型的 2 压入栈 9: iadd 将栈顶的两个 int 弹出并相加，最后将结果压入栈 10: ireturn 将栈顶的结果，放到返回值的存储位置中 11: astore_2 从栈顶弹出一个对象引用，并保存到 slot 为2(这个是编译器处理生成的) 中 12: iinc 0, 10 将局部变量 slot 为0的变量，增加10，即 (i+=10) 15: iload_0 将 slot 为0的变量（即 i）压入栈 16: iconst_2 将常量 int 类型的 2 压入栈 17: iadd 将栈顶的两个 int 弹出并相加，最后将结果压入栈 18: ireturn 将栈顶的结果，放到返回值的存储位置中 Exception table: from to target type 0 4 11 any 从指令位置0到4之间（不包括4，即 0&lt;=pc&lt;4），执行完后，无条件跳转到指令11位置处。 LocalVariableTable: Start Length Slot Name Signature 0 19 0 i I 伪代码: 1234567int tmpVar = i + 1;(tmpVar 就是编译器生成的 slot 为1 的变量，slot 0是变量 i)执行完这一行，后，它就要跳转到指令11处开始执行了。即:i+=10;return i+2;但是，可以看到由于编译器执行了优化，它直接复制了 finally 的语句，拼接在指令 4-10 处了。可以看到 4-10 的指令，与 11-18 处的指令是完全一样的。 所以，对于编译后真正执行的代码如下: 123int tmpVar = i+1;i+=10;return i+2; finally 没 return 的情况123456789101112131415161718192021stack=2, locals=3, args_size=1 0: iload_0 1: iconst_1 2: iadd 3: istore_1 4: iinc 0, 10 7: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 10: iload_0 11: invokevirtual #4 // Method java/io/PrintStream.println:(I)V 14: iload_1 15: ireturn 16: astore_2 17: iinc 0, 10 20: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 23: iload_0 24: invokevirtual #4 // Method java/io/PrintStream.println:(I)V 27: aload_2 28: athrowException table: from to target type 0 4 16 any 伪代码:（通过字节码可以看到，它也是优化后的字节码的，它将 finally 语句的部分，复制在上面了） 1234int tmpVar = i + 1;i+=10;System.out.println(i);return tmpVar;]]></content>
      <tags>
        <tag>Java</tag>
        <tag>finally</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]Cookie 中的 domain 是如何工作的？]]></title>
    <url>%2F2017%2F07%2F11%2F%E7%BF%BB%E8%AF%91-Cookie-%E4%B8%AD%E7%9A%84-domain-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[原文 虽然现在有 RFC 2965 规范（Set-Cookie2，已经废弃了 RFC 2109），但大多数浏览器并不完全支持，只是遵守 Netscape 的原始规范 Domain 属性值和有效域之间的区别是：前者是 Set-Cookie 头字段，后者是该属性值的解释。根据 RFC 2965 规范，应适用于以下情况： 如果 Set-Cookie 头部字段没有 domain 属性，则有效域是请求的域 如果存在 Domain 属性，则其值将被用作有效域（如果该值不以 . 开头，则该值将由客户端添加） 拥有有效域，它还必须与当前请求的域进行域匹配才可以设置；否则 cookie 将被修改。同样的规则适用于选择 在请求中发送的 Cookie 。 将这些知识映射到你的问题上，则如下: 带有 Domain=.example.com 的将可用于 www.example.com 带有 Domain=.example.com 的将可用于 example.com 带有 Domain=example.com 的将会被转换为 .example.com ，因此，也可用于 www.example.com 带有 Domain=example.com 的不可用于 anotherexample.com www.example.com 能为 example.com 设置 cookie www.example.com 不能为 www2.example.com 设置 cookie www.example.com 不能为 .com 设置 cookie 要通过 www.example.com 和 example.com 读取或设置一个 cookie，请分别为 .www.example.com 和 .example.com 设置。但是，第一个 .www.example.com 只能在该域下面的其他域(例如 foo.www.example.co 或 bar.www.example.com) 访问，其中 .example.com 也可以被任何 example.com 下的其他域(如 foo.example.com 或 bar.example.com) 访问。]]></content>
      <tags>
        <tag>http</tag>
        <tag>cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中私有字段的继承问题]]></title>
    <url>%2F2017%2F07%2F11%2FJava-%E4%B8%AD%E7%A7%81%E6%9C%89%E5%AD%97%E6%AE%B5%E7%9A%84%E7%BB%A7%E6%89%BF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[父类中的私有字段会不会被子类继承？父类(没有 get , set) 12345package org.agoncal.sample.jmh;public class Test &#123; private int age;&#125; 子类: 12345678package org.agoncal.sample.jmh;/** * Created by emacsist on 2017/7/10. */public class Test2 extends Test &#123; private String name;&#125; 反射获取 agegetField12345678910111213141516package org.agoncal.sample.jmh;import java.lang.reflect.Field;/** * Created by emacsist on 2017/7/11. */public class App &#123; public sntatic void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; Test2 t = new Test2(); Field field = t.getClass().getField("age"); field.setAccessible(true); int age = (int)field.get(t); System.out.println(age); &#125;&#125; 发现它报: 123Exception in thread "main" java.lang.NoSuchFieldException: age at java.lang.Class.getField(Class.java:1703) at org.agoncal.sample.jmh.App.main(App.java:11) getDeclaredField12345678910111213141516package org.agoncal.sample.jmh;import java.lang.reflect.Field;/** * Created by emacsist on 2017/7/11. */public class App &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; Test2 t = new Test2(); Field field = t.getClass().getDeclaredField("age"); field.setAccessible(true); int age = (int)field.get(t); System.out.println(age); &#125;&#125; 发现它报: 123Exception in thread "main" java.lang.NoSuchFieldException: age at java.lang.Class.getDeclaredField(Class.java:2070) at org.agoncal.sample.jmh.App.main(App.java:11) getField VS getDeclaredFieldgetField : 它获取的是所有继承层次上的所有 public 的字段（自身的，以及父类的）getDeclaredField : 它获取的是 当前类声明 的所有字段（不管访问性如何） 结论如果父类仅仅是一个私有字段，而不提供任何访问或修改的接口话，对于子类是完全不可见的，也没有提供其他方式可以间接访问或修改（比如反射），所以可以认为，父类的私有字段是不能被继承的。 参考资料stackoverflow]]></content>
      <tags>
        <tag>Java</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中关于局部变量位置及其对应的字节码]]></title>
    <url>%2F2017%2F07%2F07%2FJava-%E4%B8%AD%E5%85%B3%E4%BA%8E%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E4%BD%8D%E7%BD%AE%E5%8F%8A%E5%85%B6%E5%AF%B9%E5%BA%94%E7%9A%84%E5%AD%97%E8%8A%82%E7%A0%81%2F</url>
    <content type="text"><![CDATA[局部变量位置12345678910111213141516171819package org.agoncal.sample.jmh;public class Test &#123; public void t1() &#123; Object a; for (int i = 0; i &lt; 100; i++) &#123; a = new Object(); System.out.println(a.getClass()); &#125; &#125; public void t2() &#123; for (int i = 0; i &lt; 100; i++) &#123; Object a = new Object(); System.out.println(a.getClass()); &#125; &#125;&#125; 看资料网上大多说倾向 t1 更好，因为它重用了变量，而不是必每次都分配。 字节码上的区别t112345678910111213141516 0 iconst_0 将常量 int 型的 0 压入栈 1 istore_2 从栈顶弹出一个 int 的数据，并保存到 LocalVariableTable 的 slot 为 2的局部变量中（在这里，即为 int i = 0) 2 iload_2 从 slot 为 2 的局部变量中，将它的值压入栈（即将 i 的值又压入栈） 3 bipush 100 将字节型 byte 的 100 数值压入栈 5 if_icmpge 32 弹出栈顶两个 int 并比较，如果 &gt;= ，则跳到行 32（即 return），这里的意思就是 if (i&gt;=100) &#123;goto 第32行&#125; 8 new #2 &lt;java/lang/Object&gt; 创建一个对象 Object，这时一个 object 的引用压入栈11 dup 弹出栈顶一个字，并压入2次，（这时，即是有2个 object 引用了）12 invokespecial #1 &lt;java/lang/Object.&lt;init&gt;&gt; 弹出一个 object引用，并调用它的 init 方法，即初始化对象15 astore_1 从栈顶弹出一个对象引用，并保存到 slot 为 1 局部变量中（这里即为 a = new Object())16 getstatic #3 &lt;java/lang/System.out&gt; 获取静态域 System.out 对象，并压入栈19 aload_1 将局部变量 slot 为1 的值又压入栈（a)20 invokevirtual #4 &lt;java/lang/Object.getClass&gt; 弹出对象a，并调用 a.getClass() 方法，最的将结果压入栈23 invokevirtual #5 &lt;java/io/PrintStream.println&gt; 弹出对象 System.out ，并调用 PrintStream.println() 方法（因为该方法并没返回值，所以不用压栈）26 iinc 2 by 1 将局部变量表中 slot 为 2 局部变量，增加 129 goto 2 跳转到 pc 为 2的地方32 return 返回 12345LocalVariableTable: Start Length Slot Name Signature 16 16 1 a Ljava/lang/Object; 2 30 2 i I 0 33 0 this Lorg/agoncal/sample/jmh/Test; t212345678910111213141516 0 iconst_0 将常量 int 型的 0 压入栈 1 istore_1 从栈顶弹出一个 int 的数据，并保存到 LocalVariableTable 的 slot 为 1的局部变量中（在这里，即为 int i = 0) 2 iload_1 从 slot 为 1 的局部变量中，将它的值压入栈（即将 i 的值又压入栈） 3 bipush 100 将字节型 byte 的 100 数值压入栈 5 if_icmpge 32 弹出栈顶两个 int 并比较，如果 &gt;= ，则跳到行 32（即 return），这里的意思就是 if (i&gt;=100) &#123;goto 第32行&#125; 8 new #2 &lt;java/lang/Object&gt; 创建一个对象 Object，这时一个 object 的引用压入栈11 dup 弹出栈顶一个字，并压入2次，（这时，即是有2个 object 引用了）12 invokespecial #1 &lt;java/lang/Object.&lt;init&gt;&gt; 弹出一个 object引用，并调用它的 init 方法，即初始化对象15 astore_2 从栈顶弹出一个对象引用，并保存到 slot 为 2 局部变量中（这里即为 a = new Object())16 getstatic #3 &lt;java/lang/System.out&gt; 获取静态域 System.out 对象，并压入栈19 aload_2 将局部变量 slot 为2 的值又压入栈（a) 20 invokevirtual #4 &lt;java/lang/Object.getClass&gt; 弹出对象a，并调用 a.getClass() 方法，最的将结果压入栈23 invokevirtual #5 &lt;java/io/PrintStream.println&gt; 弹出对象 System.out ，并调用 PrintStream.println() 方法（因为该方法并没返回值，所以不用压栈）26 iinc 1 by 1 将局部变量表中 slot 为 2 局部变量，增加 1 29 goto 2 跳转到 pc 为 2 的地方32 return 返回 12345LocalVariableTable: Start Length Slot Name Signature 16 10 2 a Ljava/lang/Object; 2 30 1 i I 0 33 0 this Lorg/agoncal/sample/jmh/Test; LocalVariableTable 中的 start， length, slot 说明start: 表示以相对于该方法的起始位置的字节数偏移值length: 表示该局部变量的可见性长度（即从相对于 start 的位置开始可见，到 length 个字节数为止）slot：局部变量的存储单元位置（1个 slot 可以存储除 double, long 之外的任何类型的数据，比如 int ,byte , short，对象引用等） 结论通过对比它们的字节码，可以看到它们的唯一区别，就是 Object a 在 LocalVariableTable 中 slot 的位置不同而已，其他的就没有任何区别了。 所以，这两者的代码效率是一样的。（包括内存分配的效率） 个人倾向于将将变量的作用域范围，缩小到最小的风格。即: 123for (int i=0;i&lt;100;i++)&#123; Object a = new Object()&#125;]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中 的 synchronized 与 Atomic]]></title>
    <url>%2F2017%2F07%2F04%2FJava-%E4%B8%AD-%E7%9A%84-synchronized-%E4%B8%8E-Atomic%2F</url>
    <content type="text"><![CDATA[123456789101112131415// 代码1public class Sample &#123; private static int count = 0; synchronized public static void increment() &#123; count++; &#125;&#125;// 代码2public class Sample &#123; private static AtomicInteger count = new AtomicInteger(0); public static void increment() &#123; count.getAndIncrement(); &#125;&#125; 虽然它们都可以实现相同的功能，那它们的区别到底是哪里呢？ synchronized这个是最底层的锁的功能，是Java语言层次的关键字，用来进行同步操作。在使用了 synchronized 的代码块中，所有的线程在执行这段代码的时候，都会变成 串行 ，所以也就解决了多线程的问题。 Atomic这种类型使用的是 CAS(Compare And Swap) 机制来进行修改的。这种类型的操作，不会使用锁来进行同步，它只是进行比较然后交换。想象下这种情况: 线程A：调用 get() ，假设它返回 1线程A：计算它将要修改为新的值，这时期望它变成新值 2（即原值为1，期望值为2）同一时间线程B：调用 get() ，假设它返回 1线程B：计算它将要修改为新的值，这时期望它变成新值 2（即原值为1，期望值为2） CAS 只有在原值与原来的内存位置的值一样的时候，才会将原来内存位置的值设置为期望值（并且，这一个操作是原子性的，这个是由CPU保证它的原子的） 由于 atomic 的特特性，它只会允许一条线程设置成功，然后另一线设置失败，设置失败的线程，它会继续循环下一轮，直到成功为止。 假设这一轮是线程A设置成功了，线程B设置失败，所以线程B会继续 get() -&gt; 比较 -&gt; 设置为新的值 ，直到成功为止。所以，这种一般会有个死循环在这里一直尝试直至成功。 这种 CAS 是由CPU硬件提供的（如果所在平台的CPU并没有提供这种指令的话，那么Java会自行使用自旋来实现它，以达到平台独立的特性） wikipedia]]></content>
      <tags>
        <tag>Java</tag>
        <tag>atomic</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 之 ArrayList 和 LinkedList 源码阅读笔记]]></title>
    <url>%2F2017%2F07%2F04%2FJDK-%E4%B9%8B-ArrayList-%E5%92%8C-LinkedList-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[类声明123public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializablepublic class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 其中 1public abstract class AbstractSequentialList&lt;E&gt; extends AbstractList&lt;E&gt; 可以看到，它们的共同点是 都继承 AbstractList 类 都实现了 List 接口 都实现了 Cloneable 接口 都实现了 Serializable 接口 区别 ArrayList 实现了 RandomAccess 接口，因为它底层是使用数组（会自动 resize）来维护的，而数组是可随机访问的。LinkedList 实现了 Deque 接口，该接口是一个支持两端元素插入和移除的线性集合。它是英文 double ended queue 的简写。 共同点 它们都不是线程安全的，因为它们的方法并没有任何同步语义 它们都是 List 这个数据结构的实现（有序列表） 区别 实现上不同。ArrayList 使用的是动态数组来维护该列表，而 LinkedList 使用的是双向链表来实现 根据实现的不同，就决定了它们各自的特点：ArrayList 读取性能快(O(1))，而 LinkedList 修改（插入或删除）性能快(O(1)) 内存占用不同因为链表是使用前后指针来进行维护的，所以要占用一些额外的内存占用，而数组实现的方式则不需要。 注意点因为 ArrayList 使用的是动态数组来维护，所以为了避免频繁地进行数组的内存分配与复制，最好要事先估算它的大小，然后提供足够的容量大小因子(这个参数只有在 ArrayList 才会有)来初始化它。 扩容的触发条件: 1234567private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; 即 minCapacity - elementData.length &gt; 0 时，就需要扩容了。扩容源码: 1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 首先，将大小扩大为原内部维护的数组大小的 oldCapacity + (oldCapacity&gt;&gt;1)，即 1.5 倍（右移一位，相当于除以2，即 oldCapacity + oldCapacity/2）如果扩大后的大小，还是小于 minCapacity ，则 newCapacity = minCapacity，否则是扩大后1.5倍的大小为基准将再 newCapacity 与 MAX_ARRAY_SIZE 比较，判断是不是超大数组，如果是超大数组，则以 Integer.MAX_VALUE 为最终的扩大大小。 注意，initCapacity 是在一开始的时候，就会 new Object[initCapacity] 大小的Object数组引用的了。 删除元素如果想在循环里删除元素，一定要用 Iterator 来进行 remove ，而不要使用 List.remove() ！！ 同步的 List1List list = Collections.synchronizedList(new ArrayList()); 通过源码注释可知，这种 List ，在进行迭代的时候，需要手动同步(其他的通过 Collections.synchronizedXXXX() 返回的对象也一样): 123456789* &lt;pre&gt;* List list = Collections.synchronizedList(new ArrayList());* ...* synchronized (list) &#123;* Iterator i = list.iterator(); // Must be in synchronized block* while (i.hasNext())* foo(i.next());* &#125;* &lt;/pre&gt; Vector1public class Vector&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 可以看到它和 ArrayList 实现的接口和继承的类都是一样的。最最主要的区别就是，这个类是线程安全的，因为它的所有涉及线程安全的方法，都添加了 synchronized 关键字来进行同步了。 它和 ArrayList 的扩容大小不同: 1int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); capacityIncrement 可以通过构造函数来提供，默认为0，即如果不提供 capacityIncrement 参数，则以2倍的大小来进行扩容。 Vector 还是 Collections.synchronizedList ?这个问题，首先要考虑你之前是否已经有了 List 的数据。因为如果之前已经有了数据的，但想转换为同步的数据，这时它们的区别是: Vector ： 虽然它有个构造函数，提供以另一个 Collection 类型为参数来进行初始化，不过，这会 导致复制数据，即完全是以 Vector 为基准了 1234567public Vector(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); elementCount = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, elementCount, Object[].class);&#125; Collections.synchronizedList ： 这种方式，只是一种包装，即它不会进行数据复制，底层还是引用了相同的数据结构，只是在方法上提供了同步的语义（synchronized） 12345678910final List&lt;E&gt; list;SynchronizedList(List&lt;E&gt; list) &#123; super(list); this.list = list;&#125;SynchronizedList(List&lt;E&gt; list, Object mutex) &#123; super(list, mutex); this.list = list;&#125; 参考资料When to use LinkedList over ArrayList?]]></content>
      <tags>
        <tag>Java</tag>
        <tag>ArrayList</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 之 ThreadLocal 源码阅读笔记]]></title>
    <url>%2F2017%2F07%2F04%2FJDK-%E4%B9%8B-ThreadLocal-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ThreadLocal 类声明1public class ThreadLocal&lt;T&gt; 可以看到，它只是单纯的一个泛型类，没有其他特别的修饰符。 看注释可以看到，它通常的使用方式是在类字段添加: 1private static final ThreadLocal... 属性 private final int threadLocalHashCode = nextHashCode(); ThreadLocal 的 hashCode 变量 private static AtomicInteger nextHashCode = new AtomicInteger(); 原子计数器 private static final int HASH_INCREMENT = 0x61c88647; 每个哈希值之间的间距值 可以看到，这三个东西共同控制每一轮的哈希值，而且hash 值的规律为: 1234500x61c886470x61c88647 * 20x61c88647 * 30x61c88647 * 4 即 下一轮的 hashCode - 上一轮的 hashCode = 0x61c88647 构造函数只有一个 12public ThreadLocal() &#123;&#125; 方法 protected T initialValue(); 这个方法是用来进行初始化的。可以看到，它的默认值为 null public T get(); 获取当前线程持有的ThreadLocal的泛型 T 的值。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 通过该方法的源码可知：上面的 initialValue() 方法，是在第一次 get 的时候，并且 ThreadLocalMap 还没有被初始化的时候调用的（ initialValue() 仅在 get 方法被调用 ）注意，它的 key 为 this 因为可能会有多个 ThreadLocal 对象，this 就保证了，每个 ThreadLocal 都是从它自身获取相应的类型的值。 public void set(T value); 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 可以看到，set 方法也会进行 null 的判断，如果还没有初始化的话，则直接以参数中的值来进行初始化，而不会调用 initialValue() 方法，如果要依赖于 initialValue() 方法进行某种业务逻辑操作的话，这点要特别注意。 public void remove(); 删除当前线程所拥有的 ThreadLocal 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; void createMap(Thread t, T firstValue); 创建 ThreadLocalMap 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 可以看到， threadLocals 它是 Thread 对象的属性来的。正是用它来为每个 Thread 保存各自的 线程私有的局部变量 1ThreadLocal.ThreadLocalMap threadLocals = null public static ThreadLocal withInitial(Supplier&lt;? extends S&gt; supplier); 这个静态初始化方法，提供了另一种初始化值的方式。（从 JDK 1.8 才开始），参数是接口 Supplier ，它的接口为: 12345678910@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; /** * Gets a result. * * @return a result */ T get();&#125; 内部类SuppliedThreadLocal它的构造函数参数为 Supplier 接口，提供了另一种 ThreadLocal 初始化值的方式，用在 ThreadLocal 的静态方法 public static ThreadLocal withInitial(Supplier&lt;? extends S&gt; supplier) 。 它的作用相当于: 123456private static final ThreadLocal&lt;Integer&gt; thread = new ThreadLocal&lt;Integer&gt;()&#123; @Override protected Integer initialValue() &#123; return super.initialValue(); &#125;&#125;; 只是，它将获取初始值的方法，以接口的形式来提供，方便进行一些较复杂的初始化方式。 ThreadLocalMap这个就是真正的 ThreadLocal 持有类。 Entry123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 每一个元素实体类，用于持有 ThreadLocal 所对应的值（key 为 ThreadLocal， value 为 ThreadLocal 所对应的泛型的类型）。 属性及说明 private static final int INITIAL_CAPACITY = 16; 初始值容量，必须为2的倍数 private Entry[] table; Entry 类的数组，维护各个ThreadLocal及其拥有的 value private int size = 0; 实际的元素个数 private int threshold; 重新安排 table 表的 entry 位置。可以通过方法 setThreshold ，但实际上的 threshold 是参数的 2/3 123private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125; 方法 rehash() ; 123if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); 可以看到 size &gt;= threshold 是必要非充分的 rehash 条件. resize(); 扩容 12if (size &gt;= threshold - threshold / 4) resize(); 条件是 size &gt;= threshold - threshold/4 以上这些并不能由我们自行干扰的，而是 JDK 开发者处理的（当然，也可以自己修改 JDK 源码，然后自行编译～） 总结ThreadLocal 类，主要就是维护每个 Thread 中的 ThreadLocal.ThreadLocalMap threadLocals = null; 属性的值及状态。 即每一条线程，都有一份自己的 threadLocals, ThreadLocal 只是提供了一个统一的 API，让你 get, set, init 等操作。其中 key 就是 this 对象（即每一个当前的 ThreadLocal 对象自身），value 就是当前 this 对象所持有的对应的 ThreadLocal 的泛型类型。 比如下面代码 1234567891011121314151617181920212223242526package org.agoncal.sample.jmh;public class Test &#123; private static final ThreadLocal&lt;Integer&gt; thread = new ThreadLocal&lt;Integer&gt;()&#123; @Override protected Integer initialValue() &#123; return super.initialValue(); &#125; &#125;; private static final ThreadLocal&lt;String&gt; thread2 = new ThreadLocal&lt;String&gt;()&#123; @Override protected String initialValue() &#123; return super.initialValue(); &#125; &#125;; public static void main(String[] args) &#123; System.out.println(thread.get()); System.out.println(thread2.get()); &#125;&#125; 这里有两个 ThreadLocal 对象，所以 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; ThreadLocalMap 的大小就是2，key 就是 this，this 就是指当前调用 api 的 ThreadLocal 对象。value 就是当前 ThreadLocal 对应的泛型的类型的值。 以上面的代码为例子: 1thread.get() 在调用的时候，Thread.currentThread() 来获取当前线程 t，然后通过 t来获取该当前线程持有的 ThreadLocalMap （它包含了 thread 和 thread2 为 key 的对象，value 就分别就是它们各自对应的值）。 在这里，this 就是指 thread 对象，它的 value 就是 Integer 类型。 同理，如果是 thread2 调用的话，this 就是指 thread2 ，它的 value 就是 String 类型。 因为该对象表示的是每一条线程自身的数据，并不涉及多线程的共享问题，所以这里是没有同步之类的要求。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 之 Enum 源码阅读笔记]]></title>
    <url>%2F2017%2F07%2F03%2FJDK-%E4%B9%8B-Enum-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Enum 类声明1public abstract class Enum&lt;E extends Enum&lt;E&gt;&gt; implements Comparable&lt;E&gt;, Serializable 可以看到，它是一个抽象类，实现的 Comparable 和 Serializable 接口 Enum 类的属性 private final String name; 所代表的名称（即 enum 的名称,也即是枚举字段的变量的字面量所表示的字符串，这个并不能改变的，因为它是 final 的） private final int ordinal; 所代表的顺序（即 enum 声明的顺序，从0开始，这个并不能改变的，因为它是 final 的） Enum 类的方法 protected Enum(String name, int ordinal); 构造函数 public final String name(); 获取它的 name public final int ordinal(); 获取它的 ordinal public static]]></content>
      <tags>
        <tag>Java</tag>
        <tag>enum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 之 Integer 源码阅读笔记]]></title>
    <url>%2F2017%2F07%2F03%2FJDK-%E4%B9%8B-Integer-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[虽然这里只是以 Integer 为例，但是其他的 primitive 包装类，原理也是一样的，就不再多解释了。 Integer 类声明1public final class Integer extends Number implements Comparable&lt;Integer&gt; 其中, Number 类的修饰: 1public abstract class Number implements java.io.Serializable 通过源码可以看到，Java中 primitive 的类型（byte, short, int, long, float, double）所代表的对象类型(Byte, Short, Integer, Long, Float, Double)，都是 final, Serializable , Comparable 的。 Number 抽象类可以看到，它提供了对各个Number子类的统一各种基础类型的抽象表示接口。 123456789101112131415public abstract int intValue();public abstract long longValue();public abstract float floatValue();public abstract double doubleValue();public byte byteValue() &#123; return (byte)intValue();&#125;public short shortValue() &#123; return (short)intValue();&#125; 属性 public static final int MIN_VALUE = 0x80000000; 表示 Integer 的最小值 public static final int MAX_VALUE = 0x7fffffff; 表示 Integer 的最大值 public static final Class TYPE = (Class) Class.getPrimitiveClass(“int”); 底层表示 int 的类型的Class public static final int SIZE = 32; 表示 int 是32位的 public static final int BYTES = SIZE / Byte.SIZE; 表示 int 占用多少字节数 private final int value; 它内部表示的 int 的value 内部Integer缓存类 IntegerCache看类的注解可知：JLS规范（Java Language Specification）要求，至少 要缓存 -128 &lt;= N &lt;= 127 范围的 Integer 对象（注意，最低的下限是 -128，这个值是不变修改的，只允许修改上限，而且上限必须 &gt;= 127） 可以通过VM参数来控制它的大小 1234-XX:AutoBoxCacheMax=&lt;size&gt;或通过系统属性来配置:-Djava.lang.Integer.IntegerCache.high=&lt;size&gt; 设置参数后，它的范围就是 [-128, &amp;&amp; &gt;= 127] 了（当然,size可以设置得比 127 小，如果比 127 小的话，它会忽略你设置的这个值，而是使用 127 这上限了）: 123i = Math.max(i, 127);// Maximum array size is Integer.MAX_VALUEh = Math.min(i, Integer.MAX_VALUE - (-low) -1); 而且，上限最大为 (Integer.MAX_VALUE-(-low) -1，即是 2147483518) 注意12345java -XX:+PrintFlagsFinal -version | grep AutoBoxCacheMax intx AutoBoxCacheMax = 128 &#123;C2 product&#125;java version "1.8.0_74"Java(TM) SE Runtime Environment (build 1.8.0_74-b02)Java HotSpot(TM) 64-Bit Server VM (build 25.74-b02, mixed mode) 可以看到，AutoBoxCacheMax 这个参数，是在 C2 product 中才会生效的（即以 -server 启动的VM) 64位的JDK只会以 server 来启动，32位的，可以才可以选择 -client 或者 -server IntegerCache 属性123static final int low = -128;static final int high;static final Integer cache[]; 可以看到，cache 字段缓存了所设置的 Integer 对象。 缓存池大小的影响默认情况12345public static void main(String[] args) &#123; Integer a = 300; Integer b = 300; System.out.println(a == b);&#125; 它返回的是 false 修改参数后的影响123-XX:AutoBoxCacheMax=300或-Djava.lang.Integer.IntegerCache.high=300 这样子的话，上面的代码就会返回 true Integer缓存池的作用 它的作用就是在调用 valueOf 时，尽可能地返回缓存池中的 Integer 所代表的 int 的对象。 在缓存池中的对象之间的比较，就可以直接用 == 来比较了。 == 之间的比较，肯定是比通过方法调用 equals 来得更快。 返回缓存对象valueOf() 方法12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 可以看到，当 i 的值在缓存范围之内，它会返回所缓存的对象，而不是创建新的对象。 valueOf() VS parseInt()注意，valueOf() 返回的是 Integer，而 parseInt() 返回的是 int 所以，一定要清楚地知道自己到底需要的是什么数据类型，然后去选择适当的方法。 原则上，能用 primitive 类型，就不要用对象类型，但实际还要根据代码的业务逻辑需要去选择。 虽然 valueOf() 有缓存对象，但对象毕竟还是重量级的（无论它是不是有缓存），通常它的性能都要比 primitive 类型低。 equals()所有 primitive 类的包装类，都已经覆盖了 Object 的这个方法(Object里的 equals 方法是用 == 来比较的)，它表示的是包装类所代表对应的 primitive 的值是否相等。 123456public boolean equals(Object obj) &#123; if (obj instanceof Integer) &#123; return value == ((Integer)obj).intValue(); &#125; return false;&#125; 修改内部表示的 int 值12345678910111213public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; Integer a = 127; Field field = Integer.class.getDeclaredField("value"); field.setAccessible(true); field.set(a, -99999); System.out.println(a); Integer b = 127; System.out.println(b); Integer aa = new Integer(127); System.out.println(aa);&#125; 输出的是 123-99999-99999127 可以看到，因为 127 在 Integer 缓存池的范围内，所以所有 Integer 的字面值（即不是通过 new 来创建的）其实指向的是同一个对象，那我们通过反射修改了它的运行时表示，那么修改后的表示会反映到所有之后的指向同一个对象的引用了。 Integer 与 int 进行比较时会发生什么？12345678910package org.agoncal.sample.jmh;public class Test &#123; public static void main(String[] args) &#123; Integer a = 12342; System.out.println(a == 12342323); &#125;&#125; 相对应的字节码: 123456789101112131415Code: stack=3, locals=2, args_size=1 0: sipush 12342 3: invokestatic #2 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 6: astore_1 7: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 10: aload_1 11: invokevirtual #4 // Method java/lang/Integer.intValue:()I 14: ldc #5 // int 12342323 16: if_icmpne 23 19: iconst_1 20: goto 24 23: iconst_0 24: invokevirtual #6 // Method java/io/PrintStream.println:(Z)V 27: return 通过字节码，可以看到上面的源码被编译后的伪代码: 123456Integer a = Integer.valueOf(12342);boolean result = false;if (a.intValue() == 12342323) &#123; result = true;&#125;System.out.println(result); 即 Integer 与 int （其他的 primitive 类型与对应的包装类型一样）比较时， Integer 会调用 intValue() 方法（注意，如果这时 Integer 对象为 null，会发生 NullPointerException）转换为 int 之后再进行比较。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>integer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 之 String 源码阅读笔记]]></title>
    <url>%2F2017%2F07%2F01%2FJDK-%E4%B9%8B-String-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本文基于 JDK 1.8 ，所有代码都有 Mac 环境下， JDK 1.8 中测试 String 类的修饰1public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence 首先，它是一个 final 类，这表明：该类是不能被继承的。 Why is String class declared final in Java? 实现了 Serializable 接口，表明它是可序列化的实现了 Comparable 接口，表示它是可比较的实现了 CharSequence 接口，看该接口的说明，表示：它是一个可读取的 char 值的序列。该接口提供了不同的 char 序列的统一的形式和只读访问 String 类的属性 private final char value[]; 这个存储的是 string 的值，用字符数组来保存 private int hash; // Default to 0 这个表示该 string 的 哈希码 private static final long serialVersionUID = -6849794470754667710L; 这个表示该 string 的序列化版本 private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; 这个用来保存要进行序列化的字段。默认情况下，所有的非 transient 非 static 修饰的字段都会被序列化，但可以用这个来进行选择性序列化的字段。 其中 serialPersistentFields 主要是被 java.io.ObjectStreamClass.getDeclaredSerialFields 方法处理: 123456789101112131415ObjectStreamField[] serialPersistentFields = null; try &#123; Field f = cl.getDeclaredField("serialPersistentFields"); int mask = Modifier.PRIVATE | Modifier.STATIC | Modifier.FINAL; if ((f.getModifiers() &amp; mask) == mask) &#123; f.setAccessible(true); serialPersistentFields = (ObjectStreamField[]) f.get(null); &#125; &#125; catch (Exception ex) &#123; &#125; if (serialPersistentFields == null) &#123; return null; &#125; else if (serialPersistentFields.length == 0) &#123; return NO_FIELDS; &#125; 看它的注释可知：它返回给定的 class 显式声明的 serialPersistentFields 字段定义的可序列化的字段。如果没有适当地定义这个字段的话，就返回 null 。 transient VS serialPersistentFieldstransient ：用该关键字修改的字段，表示 不序列化 该字段serialPersistentFields : 表示只序列化这里指定的字段。注意，这里的优先级，高于 transient 。即，只要这里指定了序列化的，即使在该字段里用了 transient 来修饰，该字段也会进行序列化 测试代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136package org.agoncal.sample.jmh;import java.io.*;/** * Created by emacsist on 2017/6/30. */public class Test &#123; public static void main(String[] args) &#123; write(); read(); &#125; private static final void read() &#123; try &#123; PersonA personA = new PersonA(); FileInputStream fileIn = new FileInputStream("/tmp/personA.bin"); ObjectInputStream in = new ObjectInputStream(fileIn); personA = (PersonA) in.readObject(); in.close(); fileIn.close(); System.out.println(personA); &#125; catch (IOException i) &#123; i.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; try &#123; PersonB personB = new PersonB(); FileInputStream fileIn = new FileInputStream("/tmp/personB.bin"); ObjectInputStream in = new ObjectInputStream(fileIn); personB = (PersonB) in.readObject(); in.close(); fileIn.close(); System.out.println(personB); &#125; catch (IOException i) &#123; i.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125; private static final void write() &#123; try &#123; PersonA personA = new PersonA(); FileOutputStream fileOut = new FileOutputStream("/tmp/personA.bin"); ObjectOutputStream out = new ObjectOutputStream(fileOut); out.writeObject(personA); out.close(); fileOut.close(); &#125; catch (IOException i) &#123; i.printStackTrace(); &#125; try &#123; PersonB personB = new PersonB(); FileOutputStream fileOut = new FileOutputStream("/tmp/personB.bin"); ObjectOutputStream out = new ObjectOutputStream(fileOut); out.writeObject(personB); out.close(); fileOut.close(); &#125; catch (IOException i) &#123; i.printStackTrace(); &#125; &#125; public static class PersonA implements Serializable &#123; private String hello = "Hello World"; transient private Integer age = 18; public String getHello() &#123; return hello; &#125; public void setHello(String hello) &#123; this.hello = hello; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "personA[" + hello + ", " + age + "]"; &#125; &#125; public static class PersonB implements Serializable &#123; private String hello = "Hello World"; transient private Integer age = 18; private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[1]; static &#123; serialPersistentFields[0] = new ObjectStreamField("age", Integer.class); &#125; public String getHello() &#123; return hello; &#125; public void setHello(String hello) &#123; this.hello = hello; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "personB[" + hello + ", " + age + "]"; &#125; &#125;&#125; 输出如下: 12personA[Hello World, null]personB[null, 18] 可以看到，PersonB 的 age 字段用了 transient 修饰，但它是在 serialPersistentFields 里，但它还是被序列化了。 常用的方法length()它返回的是内部表示的 char 数组的长度 1value.length equals()它判断是否是相同的对象，然后再判断是否是 String 的实例，如果是String实例，就从头到尾进行每一个字符的比较，直到有没的字符为止。 处理 String 的方法通过看源码可知，所有处理 String 的方法，都是通过返回一个新的 String 对象的，而不是在原有的 String 对象上面进行字符 value 数组的修改。 看到网上一些源码分析的文章，说是因为 value 被定义为 final ，所以不能修改。 1private final char value[]; 一个字段被定义为 final ，它的不能 修改 是指不能指向其他的对象了，而只能一直指向当前这个 value 的对象。但 value 对象自身，还是可以修改的，比如下面的代码: 123456public static void main(String[] args) &#123; final char[] hello = "hello world".toCharArray(); System.out.println(hello); hello[0] = 'H'; System.out.println(hello);&#125; 输出为 12hello worldHello world 但如果这样子的话，就不能被编译通过了: 12char[] newHello = "new hello world".toCharArray();hello = newHello; String 不能被修改？网上大多资料，一直在说什么 String 是不可变的。但这种说法，我不知道其实说这些话的人，是不是真的理解了其实的本质。反正，我个人理解起来，是挺费劲的。所以，今天才抽点空来详细看看 String 的源码。 final 的类：表示不能被继承。仅此而已final 字段：如果是对象类型，则表示对象的引用不可变（但对象自身的状态还是可变的）；如果是基础类型，表示一旦初始化了，就不能再修改它的值了。final 方法：表示不能被子类覆盖。 通过源码我们知道 value 是 String 内部持有的真正的对象，String 是用它来保存它表示其值的，我们知道数组在Java中是对象的一种，也就是说 final char value[] 仅仅表示它不能指向其他的 char[] 对象引用了，而 char valuel[] 自身的内容，其实是可以改变的。那为什么大家都在说，String 是不可变的类型呢，因为 String 类中，根本没有提供 API 给你修改 char valuel[] 的内容. String 中的所有的修改方法，都是复制一个新的 char value[] 的值然后作为 String 对象返回的。（为什么呢？这里涉及的比较多了，简单说一下，就是Java的团队认为，字符串复用的好处，大于坏处，所以就使用了字符串复用的方式：即通过 Constant Pool 来维护字符串常量池） 比如有两个字段: 12String hello = "abc123";String hello2 = "abc123"; 在Java内部， hello 与 hello2 其实都是指向同一个字符串 “abc123” 的内存区域的。比如下面的代码，可以看到: 123456789101112public static void main(String[] args) &#123; String hello = "abc123"; String hello2 = "abc123"; String helloNew = new String("abc123"); String hello2New = new String("abc123"); System.out.println("hello 的地址 =&gt; " + Integer.toHexString(System.identityHashCode(hello))); System.out.println("hello2 的地址 =&gt; " + Integer.toHexString(System.identityHashCode(hello2))); System.out.println("helloNew 的地址 =&gt; " + Integer.toHexString(System.identityHashCode(helloNew))); System.out.println("hello2New 的地址 =&gt; " + Integer.toHexString(System.identityHashCode(hello2New)));&#125; 在我的 Mac 上输出如下: 1234hello 的地址 =&gt; 6f94fa3ehello2 的地址 =&gt; 6f94fa3ehelloNew 的地址 =&gt; 5e481248hello2New 的地址 =&gt; 66d3c617 可以看到 hello 与 hello2 的地址是一样的，也就说明 hello == hello2 ，helloNew 与 hello2New 的地址是不一样的，也就说明 helloNew != hello2New 让我们来改变 String 的值！12345678910111213public class Test &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; String hello = "abc"; System.out.println(Integer.toHexString(System.identityHashCode(hello))); System.out.println(Integer.toHexString(System.identityHashCode("abc"))); Field valueField = String.class.getDeclaredField("value"); valueField.setAccessible(true); valueField.set(hello, "newValue".toCharArray()); System.out.println("现在 hello 的值为 =&gt;" + hello); System.out.println(Integer.toHexString(System.identityHashCode(hello))); &#125;&#125; 输出如下: 12346f94fa3e6f94fa3e现在 hello 的值为 =&gt;newValue6f94fa3e 什么！两个 String “不同”，竟然 == 时返回 true ?1234567891011121314151617181920package org.agoncal.sample.jmh;import java.lang.reflect.Field;/** * Created by emacsist on 2017/6/30. */public class Test &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; String hello = "abc"; Field valueField = String.class.getDeclaredField("value"); valueField.setAccessible(true); valueField.set(hello, "newValue".toCharArray()); String hello2 = "abc"; System.out.println("hello =&gt;" + hello); System.out.println("hello == hello2 =&gt; " + (hello == hello2)); &#125;&#125; 输出结果: 12hello =&gt;newValuehello == hello2 =&gt; true 虽然我们 看到 hello2 的值为 “abc”，但其实在JVM内部，并不是 “abc”，而是 “newValue” 了，所以输出为 true这是一个陷阱，因为我们通过反射，修改了 JVM 对字符串 “abc” 的内部表示了（即，对于JVM来说，”abc” 就表示是 “newValue” 了，你可以认为 “abc” 是 “newValue” 的别名！）比如: 1System.out.println("abc"); JVM 就会输出 1newValue 所以，你永远输出不了 “abc” 这个常量字符串了！ 注意，这里说的是常量字符串，通过下面的变换，也是可以输出的，但这样子就不是常量字符串”abc”了, 而是对象内容输出的拼接了～: 1System.out.println(new String("a") + new String("bc")); 从字节码级别看1234526: ldc #2 // String abc28: astore_329: getstatic #10 // Field java/lang/System.out:Ljava/io/PrintStream;32: aload_333: invokevirtual #11 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 为什么在字节码里，常量池表项的索引 #2，内容是 “abc”，但输出来的还是 “newValue” 呢？ 可以推论：这是因为我们通过反射，修改了JVM的运行时对 “abc” 字符串常量的表示形式了。虽然字节码中反编译时，它显示的是 “abc”，这是静态的，而显示的时候，是运行时动态的内容了，所以才会出现这种情况。 结论所以，为什么一般说 String 不可变？其实只是 API 本身并没有提供让你修改 value 字符数组的接口，而且 String 类，是 final 的，也就是说，它也不允许你通过继承来修改它。 因为 JVM 使用了常量池这个东东（注意，常量池并不仅仅只有字符串常量，Class 文件中的方法符号，字段符号等这些，也是常量池的一部分！） ，所以才要求 String 是不可变的，它们是互为表里关系，一脉相乘的。 通过上面的例子，你就可以知道，如果JVM内部是使用常量池复用的规则，但又允许你修改的话，就会出现上面的问题了。”abc” 输出的不是 “abc” ～ 你不是你，我也不是我了，然后就会有另一个问题了： 1Who are you ? 注意：在 Java 里，任何通过 new 出来的对象，都是唯一的！（即物理地址上是唯一的， 即用 == 来比较的，只要 System.identityHashCode() 输出来的值是相等的，那么 == 一定会返回 true） 正因为如此，所以，Java 里有个 equals 的方法，允许我们判断两个对象的 逻辑相等 ，比如我们定义：只要属性中年龄相同的两个对象就是 相等 的，那么我们就可以通过实现自定义的 equals 方法，来进行逻辑上的相等。 String.intern() 注意，该方法是属于本地方法。它的声明如下: 1public native String intern(); 它的作用是：如果从常量池中，没有与该 String equals（即内容相同）的 String 的话，则将该 String 放进常量池中，然后返回该 String 在常量池中的引用；如果常量池已经存在该 String 的话，则直接返回常量池中的引用。 即：该方法保证返回的是从常量池中返回的唯一的引用。 对于普通的 Java 字符串字面量，Java会自动进行 intern() 操作。 例如: 12345678910package org.agoncal.sample.jmh;public class Test &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InterruptedException &#123; String hello = "hello"; String hello2 = new String("hello"); System.out.println(hello == hello2); System.out.println(hello.intern() == hello2.intern()); &#125;&#125; 它会输出: 12falsetrue intern() 在 字符串拼接时的注意事项！ 注意，是在拼接时才有，非拼接的情况，与假设常量池中已经有该字符串的情况下样，即它返回的是常量池中的地址，但它不会与堆中的地址相同。 在JDK 1.8 中（其他JDK没实验过），经验证，当执行字符串拼接时（即使两个拼接的是变量，而不是字符串字面量），拼接后的字符串的情况： 如果常量池中，还没有该字符串的话，则会把它从堆内存的地址， 提升为常量池中的地址如果常量池中，已经有该字符串的话，则 intern() 方法只是返回常量池中的地址，但该对象原地址不变 证明代码： 12345678910111213141516171819package org.agoncal.sample.jmh;public class Test &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InterruptedException &#123; System.out.println("第一次常量池中没有相同的字符串的情况"); String name = new String("emac") + new String("sist"); System.out.println("name 变量的地址:" + Integer.toHexString(System.identityHashCode(name))); System.out.println("name 代表的常量池的地址:" + Integer.toHexString(System.identityHashCode(name.intern()))); System.out.println("emacsist 常量的地址:" + Integer.toHexString(System.identityHashCode("emacsist"))); System.out.println(); System.out.println("第一次常量池中已经有相同的字符串的情况"); String name2Interned = "emacsist2";//Java会自动将它放入常量池，模拟常量池已经有的情况 String name2 = new String("emacsist2"); System.out.println("name 变量的地址:" + Integer.toHexString(System.identityHashCode(name2))); System.out.println("name 代表的常量池的地址:" + Integer.toHexString(System.identityHashCode(name2.intern()))); System.out.println("emacsist2 常量的地址:" + Integer.toHexString(System.identityHashCode("emacsist2"))); &#125;&#125; 输出结果 123456789第一次常量池中没有相同的字符串的情况name 变量的地址:6f94fa3ename 代表的常量池的地址:6f94fa3eemacsist 常量的地址:6f94fa3e第一次常量池中已经有相同的字符串的情况name 变量的地址:5e481248name 代表的常量池的地址:66d3c617emacsist2 常量的地址:66d3c617 JDK 1.6, JDK 1.7, JDK 1.8 之间的区别&lt;=JDK 1.6 : intern() 的字符串，它会放在 Java 堆中的 Permanent Generation 内存区域&gt;= JDK 1.7 : intern() 的字符串，它分配在普通的 Java 堆中，即 Young 和 Old Generation 内存区域( Oracle JDK 7 changes ) (这意味着可以被GC) 常量池相关的JVM参数12345[12:23:10] emacsist:~ $ java -XX:+PrintFlagsFinal -version | grep StringTable bool PrintStringTableStatistics = false &#123;product&#125; uintx StringTableSize = 60013 &#123;product&#125;Java(TM) SE Runtime Environment (build 1.8.0_74-b02)Java HotSpot(TM) 64-Bit Server VM (build 25.74-b02, mixed mode) -XX:+PrintStringTableStatistics : 在JVM退出时，打印当前JVM的常量池统计信息 -XX:StringTableSize=N : 设置 StringTable 的大小 字符中常量池的大小范围: 1StringTable size of 1000 is invalid; must be between 1009 and 2305843009213693951 输出例子:(-XX:+PrintStringTableStatistics -XX:StringTableSize=1009) 123456789101112131415161718SymbolTable statistics:Number of buckets : 20011 = 160088 bytes, avg 8.000Number of entries : 12127 = 291048 bytes, avg 24.000Number of literals : 12127 = 468448 bytes, avg 38.629Total footprint : = 919584 bytesAverage bucket size : 0.606Variance of bucket size : 0.607Std. dev. of bucket size: 0.779Maximum bucket size : 6StringTable statistics:Number of buckets : 1009 = 8072 bytes, avg 8.000Number of entries : 865 = 20760 bytes, avg 24.000Number of literals : 865 = 58048 bytes, avg 67.108Total footprint : = 86880 bytesAverage bucket size : 0.857Variance of bucket size : 0.814Std. dev. of bucket size: 0.902Maximum bucket size : 5 参考资料： java-performance.info 美团-深入解析String#intern 什么时候该用 String.intern() ？一般情况下，我们使用字符串的比较，一般是使用 String.equals() ，极少见到 String.intern() == String.intern() 。透过源码可知，equals 是逐个逐个字符从头开始进行比较的，但是 inter() 它是直接比较两个引用的。 所以，通常来说，直接比较引用会比一个一个字符地来比较的性能更高。（即 == 比 equals() 这种方法调用来得更快） 注意，如果决定使用 intern() 来进行字符串的比较，请记得将所有字符串都要进行 intern() 之后再进行比较～ 1234567891011121314151617181920212223242526package org.agoncal.sample.jmh;public class Test &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InterruptedException &#123; String hello = "hello world hello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello world"; String hello2 = new String("hello world hello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello world"); final int N = 100000; long start = System.currentTimeMillis(); for (int i = 0; i &lt; N; i++) &#123; if (!hello.equals(hello2)) &#123; System.out.println("not equals"); &#125; &#125; System.out.println("equals cost " + (System.currentTimeMillis() - start) + " ms"); start = System.currentTimeMillis(); String hello2Intern = hello2.intern(); for (int i = 0; i &lt; N; i++) &#123; if (hello != hello2Intern) &#123; System.out.println("not equals"); &#125; &#125; System.out.println("== cost " + (System.currentTimeMillis() - start) + " ms"); &#125;&#125; 输出结果: 12equals cost 62 ms== cost 1 ms 注意，不要在循环中一直调用 intern() ，因为它是本地方法的调用，在循环里调用的话，这样子会比在循环里调用普通的 Java 的方法更耗时。（调用本地方法比较昂贵） 参考资料： stackoverflow Is it good practice to use java.lang.String.intern()? String s = new String() + new String()或者 123String hello = "hello";String world = "world";String s = hello + world; 因为Java编译器的原因，这种代码，在编译的时候，会被编译为: 1String s = new StringBuilder().append(new String()).append(new String()).toString(); 或 1String s = new StringBuilder().append(hello).append(world).toString(); 所以： 1String hello = new String("hello") + new String("world"); 会被编译为: 1String hello = new StringBuilder().append(new String("hello")).append(new String("world")).toString(); 被编译后的字节码如下: 1234567891011121314151617stack=4, locals=2, args_size=1 0: new #2 // class java/lang/StringBuilder 3: dup 4: invokespecial #3 // Method java/lang/StringBuilder."&lt;init&gt;":()V 7: new #4 // class java/lang/String 10: dup 11: ldc #5 // String hello 13: invokespecial #6 // Method java/lang/String."&lt;init&gt;":(Ljava/lang/String;)V 16: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 19: new #4 // class java/lang/String 22: dup 23: ldc #8 // String world 25: invokespecial #6 // Method java/lang/String."&lt;init&gt;":(Ljava/lang/String;)V 28: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 31: invokevirtual #9 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 34: astore_1 35: return String s = “hello” + “world”它会直接被编译器进行优化为: String s = “helloworld” 并且会将它(“helloworld”)放入常量池中（注意不是 “hello” 和 “world” 分别放入常量池，而是 “helloworld” 一个） 编译后的字节码: 12345Code: stack=1, locals=2, args_size=1 0: ldc #2 // String helloworld 2: astore_1 3: return switch 与 String从JDK 1.7开始，switch 可以用 String 了 1234567891011121314public static final void s(String hello) &#123; switch (hello) &#123; case "world": System.out.println("world"); case "hello": System.out.println("hello"); break; case "hello2": System.out.println("hello2"); break; default: System.out.println("default"); &#125;&#125; 可以看到，它的字节码如下: 1234567891011120: aload_01: astore_12: iconst_m13: istore_24: aload_15: invokevirtual #8 // Method java/lang/String.hashCode:()I8: lookupswitch &#123; // 3 -1220935264: 72 99162322: 58 113318802: 44 default: 83 &#125; 伪代码： 12345678910111213141516171819202122232425262728293031323334String tmp = hello; //aload_0 表示将第0个参数，即 hello 压入栈，astore_1 表示将栈顶的元素弹出，保存到第一个局部变量中，这里假设为 tmpint tmp_i = -1; // iconst_m1 表示将 -1 压入栈，所以这里的伪代码是这样子，tmp_i 就表示是 第1个局部变量// 即第0个局部变量为 String hello(xx_0的局部变量指令就是它)， 第1个局部变量为 String tmp = hello（xx_1的局部变量就是它），第2个局部变量为 int tmp_i = -1;（xx_2的局部变量指令就是它）然后根据 tmp.hashCode() 的结果，查找 lookupswitch 表，左边的是 hashCode 的值，右边为要跳转到的代码位置。那么它们是如何比较的？（这里仅以一个为例，假设与 "world" 这个分支比较的情况： 44: aload_1 45: ldc #9 // String world 47: invokevirtual #10 // Method java/lang/String.equals:(Ljava/lang/Object;)Z 50: ifeq 83 53: iconst_0 54: istore_2 55: goto 83 这段代码的伪代码如下:(在Java字节码中，0 表示 false, 1 表示 true)if (!tmp.equals("world"))&#123; goto 83行;&#125;tmp_i = 0goto 83 行; 83: iload_2 84: tableswitch &#123; // 0 to 2 0: 112 1: 120 2: 131 default: 142 &#125; 如果 !tmp.equals("world")，则 tmp_i = -1, 否则 tmp_i = 0，在这里时，就已经是普通的 swith int 类型的代码了（因为 iload_2 就表示的是 tmp_id 这个 int 的值） 总结在 swith 中使用 String 时，它步骤如下: 调用 swith 变量中的String 的 hashCode 的方法，返回一个 int 值，保存到一个编译器生成的临时变量中，假设为 tmp_i 根据 hashCode 的结果，跳转到相应的，由Java编译器生成的代码 ，它的伪代码就是字符串之间的 equals 的方法。（因为单纯地靠 HashCode 并不能决定两个字符串是否真的相同） 然后根据 equals 的结果，再设置相应的 tmp_i 的值（每个结果，从上到下依次是从 0 开始递增） 最后，切换为普通的 int 的 swith 代码了～（即直接比较 tmp_i 与 swith 表中各个项的 int 的值是否相等，然后再跳转到相应的代码）]]></content>
      <tags>
        <tag>java</tag>
        <tag>jdk</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java程序员的自我修养]]></title>
    <url>%2F2017%2F06%2F28%2FJava%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB%2F</url>
    <content type="text"><![CDATA[Java 内存模型及规范ifeve-Java内存模型FAQ-中译版 The Java Memory Model The JSR-133 Cookbook for Compiler Writers JVM 架构https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-2.html 根据规范可知, 运行时的数据区域有 PC 寄存器(program counter register)（线程私有） JVM 栈(JVM stack)，以前也称为 Java栈（线程私有，即不可能在一个栈帧之中引用另一个线程的栈帧）=&gt; 它保存的是 栈帧 。它持有本地变量、中间结果，并且在方法的调用和返回中起着重要的作用。 堆(heap) =&gt; 即GC所管理的各种对象（线程共享） 方法区(method area) =&gt; 类似操作系统进程的 TEXT 段（文本段，即只读段），它是堆的逻辑组成部分，不同的JVM实现，可以将它实现为不需要进行GC的。（线程共享） 运行时常量池(runtime constant pool) =&gt; 注意，这个不一定只是编译期的常量池，也可以是运行时解析后生成的，它在方法区中分配。表示了 class 文件中的 constant_pool 表。 本地方法栈(native method stack) =&gt; 执行本地方法（例如C语言的方法）时创建的栈 栈帧用来存储数据、中间结果，也用来处理动态链接、方法返回值和异常分发。每一个栈帧都有： 本地变量表（在编译时确定） 操作数栈（在编译时确定） 指向当前方法所在类的运行时常量池的引用 本地变量表 注意，参数与是本地变量的一部分。 一个本地变量可以保存一个类型为 boolean, byte, char, short, int, float, reference 或 returnAddress 。 long 和 double 要占用两个本地变量。 它通过 索引 来进行定位和访问，从 0 开始（如果是实例方法，则第0个变量，一定是 this，其他参数，则按顺序推算）。 操作数栈字节码指令的操作数必须是在 操作数栈 的（我个人理解，类似CPU的寄存器，因为JVM是基于栈的，所以，这里的操作数栈就可以认为等同于CPU的寄存器） 注意，操作数栈，是在栈之内的。 JVM栈 包含 栈帧， 而栈帧包含 操作数栈 动态链接它的作用就是将指向常量池的符号转换为实际方法的直接引用。 方法正常结束即没有抛出任何异常。这时当前方法返回一个值给它的调用者，然后还要进行恢复调用者状态（即JVM里，它是由被调用者进行上下文恢复的，即要恢复调用者的局部变量表、操作数栈、PC等） 方法异常结束这种情况下，一定不会有方法返回值给调用者的 参考资料深入理解JVM-周志明Java虚拟机规范-周志明等译http://docs.oracle.com/javase/specs/ JVM 各种参数参考本博客的 [翻译]Java -XX:+PrintFlagsFinal命令行参数详解 一般的调优都是从 内存、GC类型 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[11:17:44] emacsist:~ $ java -X -Xmixed 混合模式执行 (默认) -Xint 仅解释模式执行 -Xbootclasspath:&lt;用 : 分隔的目录和 zip/jar 文件&gt; 设置搜索路径以引导类和资源 -Xbootclasspath/a:&lt;用 : 分隔的目录和 zip/jar 文件&gt; 附加在引导类路径末尾 -Xbootclasspath/p:&lt;用 : 分隔的目录和 zip/jar 文件&gt; 置于引导类路径之前 -Xdiag 显示附加诊断消息 -Xnoclassgc 禁用类垃圾收集 -Xincgc 启用增量垃圾收集 -Xloggc:&lt;file&gt; 将 GC 状态记录在文件中 (带时间戳) -Xbatch 禁用后台编译 -Xms&lt;size&gt; 设置初始 Java 堆大小 -Xmx&lt;size&gt; 设置最大 Java 堆大小 -Xss&lt;size&gt; 设置 Java 线程堆栈大小 -Xprof 输出 cpu 配置文件数据 -Xfuture 启用最严格的检查, 预期将来的默认值 -Xrs 减少 Java/VM 对操作系统信号的使用 (请参阅文档) -Xcheck:jni 对 JNI 函数执行其他检查 -Xshare:off 不尝试使用共享类数据 -Xshare:auto 在可能的情况下使用共享类数据 (默认) -Xshare:on 要求使用共享类数据, 否则将失败。 -XshowSettings 显示所有设置并继续 -XshowSettings:all 显示所有设置并继续 -XshowSettings:vm 显示所有与 vm 相关的设置并继续 -XshowSettings:properties 显示所有属性设置并继续 -XshowSettings:locale 显示所有与区域设置相关的设置并继续-X 选项是非标准选项, 如有更改, 恕不另行通知。以下选项为 Mac OS X 特定的选项: -XstartOnFirstThread 在第一个 (AppKit) 线程上运行 main() 方法 -Xdock:name=&lt;应用程序名称&gt;" 覆盖停靠栏中显示的默认应用程序名称 -Xdock:icon=&lt;图标文件的路径&gt; 覆盖停靠栏中显示的默认图标[11:27:06] emacsist:~ $ Java 自带工具 Mac 上查看Java安装目录： 123[18:37:34] emacsist:~ $ /usr/libexec/java_home/Library/Java/JavaVirtualMachines/jdk1.8.0_74.jdk/Contents/Home[18:37:37] emacsist:~ $ 1234567891011121314151617181920212223242526272829303132333435363738394041424344appletviewer =&gt; applet 查看器，开发 applet 才会用到extcheck =&gt; 用于检测 Jar 包与当前JDK是否有冲突，这个极少用到，一般是JDK更新扩展 ext 包时使用idlj =&gt; 为Java语言来使用 CORBA 功能的 .java 文件进行生成代码用到的。jar =&gt; jar 文件处理工具。类似 zip ，虽然 jar 本质上也是一个 zip 文件jarsigner =&gt; jar 文件签名工具java =&gt; Java 程序启动器javac =&gt; Java源码编译器javadoc =&gt; JavaDoc 处理工具javafxpackager =&gt; 开发 JavaFX javah =&gt; 开发本地代码，如 C 时用来处理头文件的javap =&gt; Java 类文件反编译器javapackager =&gt; 执行与Java和 JavaFX程序打包和签名相关的任务。比如可以将你的应用捆绑JRE，然后打包发布～jcmd =&gt; JVM诊断命令工具，发送诊断命令请求到一个正在运行的JVM(比如导出内存信息，栈信息等，jmap)jconsole =&gt; 基于 JMX 的图形化监控JVM的工具jdb =&gt; Java调试器jdeps =&gt; Java 类依赖分析器jhat =&gt; 查看 Java 堆 dump 文件的jinfo =&gt; 查看Java进程的配置信息jjs =&gt; 运行 Nashorn （JVM上的JavaScript解释器） 命令行脚本 Shelljmap =&gt; 获取Java进程的内存映像jmc =&gt; The Java Mission Control (JMC) ，Java 程序的性能监控和分析工具jps =&gt; 列出Java进程jrunscript =&gt; Java的脚本 shelljsadebugd =&gt; Javar 调试守护服务代理者，类似一个远程的 debug 服务器jstack =&gt; 获取Java进程当前所有线程栈jstat =&gt; 获取 Java 进程的状态信息jstatd =&gt; jstat 的守护进程jvisualvm =&gt; 可视化的VM工具keytool =&gt; 密钥工具native2ascii =&gt; 将文本文件转换为 Unicode Latin-1 编码orbd =&gt; CORBA 相关的工具。pack200 =&gt; 将 jar 文件转换为 pack200 类型的文件（高度压缩版的 jar 文件，可减少带宽和下载时间等）policytool =&gt; 策略工具rmic =&gt; RMI 编译器rmid =&gt; RMI 守护进程rmiregistry =&gt; RMI注册器schemagen =&gt; XML schema 生成器serialver =&gt; 序列化版本查看器。即查看 serialVersionUID 的值servertool =&gt; 不太明了。。tnameserv =&gt; 不太明了。。unpack200 =&gt; 解压缩 pack200 文件的工具wsgen =&gt; 生成 JAX-WS 相关的工具wsimport =&gt; 导入 JAX-WS 相关的工具xjc =&gt; 根据 XML schema 生成 Java 类 JDK Tools and Utilities 各种性能工具 TProfiler-alibaba crashub greys 个人强烈推荐使用这个 分析 core dump 文件 MAT JDK自带的 jvisualvm 各种 OutOfMemory, StackoverflowStackoverflow 的代码JVM 参数:（将栈调小点，让它快点出现问题） 1-Xss170k 123456789101112package com.github.emacsist.memory;public class StackoverFlow &#123; public static void main(String[] args) &#123; hello(); &#125; public static void hello() &#123; hello(); &#125;&#125; 然后它就会报: 1234Exception in thread "main" java.lang.StackOverflowError at com.github.emacsist.memory.StackoverFlow.hello(StackoverFlow.java:10) at com.github.emacsist.memory.StackoverFlow.hello(StackoverFlow.java:10) at com.github.emacsist.memory.StackoverFlow.hello(StackoverFlow.java:10) HeapOutOfMemory 的代码JVM参数:（调小堆大小，让它早点出现异常） 1-Xms5m -Xmx5m 12345678910111213141516package com.github.emacsist.memory;import java.util.ArrayList;import java.util.List;/** * Created by emacsist on 2017/6/29. */public class HeapOutOfMemory &#123; public static void main(String[] args) &#123; List&lt;Object&gt; container = new ArrayList&lt;&gt;(); while (true) &#123; container.add(new Object()); &#125; &#125;&#125; 输出 12345678Exception in thread "main" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:261) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227) at java.util.ArrayList.add(ArrayList.java:458) at com.github.emacsist.memory.HeapOutOfMemory.main(HeapOutOfMemory.java:13) Young OutOfMemory 的代码JVM参数:（ -Xmn 是控制 Young 区的内存大小的） 1-Xms10m -Xmx10m -Xmn6m 1234567891011package com.github.emacsist.memory;/** * Created by emacsist on 2017/6/29. */public class YoungOutOfMemory &#123; public static void main(String[] args) &#123; byte[] _10MB = new byte[1024 * 1024 * 10]; System.out.println("OK =&gt; " + _10MB.length); &#125;&#125; 输出 12Exception in thread "main" java.lang.OutOfMemoryError: Java heap space at com.github.emacsist.memory.YoungOutOfMemory.main(YoungOutOfMemory.java:8) 关于常量池异常代码的问题因为它在不同版本的JDK的实现不同。可以参考: String.intern in Java 6, 7 and 8 – string pooling DirectMemory 的代码JVM参数:（默认为0，即无限） 1-XX:MaxDirectMemorySize=8m 查看: 12345[12:32:36] emacsist:~ $ java -XX:+PrintFlagsFinal -version | grep MaxDirectMemorySize uintx MaxDirectMemorySize = 0 &#123;product&#125;java version "1.8.0_74"Java(TM) SE Runtime Environment (build 1.8.0_74-b02)Java HotSpot(TM) 64-Bit Server VM (build 25.74-b02, mixed mode) 123456789101112package com.github.emacsist.memory;import java.nio.ByteBuffer;/** * Created by emacsist on 2017/6/29. */public class MaxDirectOutOfMemory &#123; public static void main(String[] args) &#123; ByteBuffer _10MB = ByteBuffer.allocateDirect(1024 * 1024 * 10); &#125;&#125; 输出 12345Exception in thread "main" java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:693) at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311) at com.github.emacsist.memory.MaxDirectOutOfMemory.main(MaxDirectOutOfMemory.java:10) 个人关于对内存问题分析思路一般都是先将当前JVM的堆栈 dump 出来、获取当前JVM的内存配置，然后使用 MAT 分析内存占用，看看有没有异常，对比内存的配置是否合理。 使用 jstat 输出GC的统计，查看各种GC的收集程度及其统计信息。 然后再看看具体出现的是哪种 OutOfMemory ，结合上面MAT的内存分析（如果代码有问题，完善代码） 然后再合理配置相应的内存区域大小。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>自我修养</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat脚本 catalina.sh 注释]]></title>
    <url>%2F2017%2F06%2F27%2FTomcat%E8%84%9A%E6%9C%AC-catalina-sh-%E6%B3%A8%E9%87%8A%2F</url>
    <content type="text"><![CDATA[解释器1#!/bin/sh 为什么用 sh 而不是 bash ？因为它要兼容其他的OS环境。 sh vs bash 协议使用的是 apache licenses2 环境变量脚本里也说明了，它建议你不要在该脚本(catalina.sh)中设置环境这些环境变量。 应该将设置环境变量的操作，放在 CATALINA/bin 目录下的 setenv.sh 文件中（如果没有，可以创建一个），这样子可以隔离Tomcat的脚本，与你自定义个性化的脚本。 注意， setenv.sh 里不要设置 CATALINA_HOME 或 CATALINA_BASE 因为 setenv.sh 也是通过它们的环境变量来查找 setenv.sh 的。 CATALINA_HOME可能是指向你的 Catalina 构建的目录。 在多Tomcat实例时，它表示的是一些 Common 的信息 CATALINA_BASE可选。 它用于一个 Catalina 实例的动态部分（即这些信息是该实例自身私有的，而 CATALINA_HOME 是所有实例信息仅有的） 如果没有的话，它的值与 CATALINA_HOME 相同 CATALINA_OUT可选。 stdout 和 stderr 被重定向到的文件的全路径。 默认为 $CATALINA_BASE/logs/catalina.out CATALINA_OPTS可选。 当执行 start, run 或 debug 命令时，用于 Java 运行时(Java Runtime，即JVM)的选项。 包含在这里而不在 JAVA_OPTS 的所有选项，应该仅仅用于 Tomcat 自身，而不应该用于停止进程（stop process)，或 version 命令等。 在这里设置的选项有： heap 大小， GC 日志， JMX CATALINA_TMPDIR可选。 目录路径，JVM 用它 (java.io.tmpdir) 作为临时目录的路径。 默认为 $CATALINA_BASE/temp JAVA_HOME必须指向你的 JDK 安装目录。 当运行 debug 参数时，它是必须的。 JRE_HOME必须指向你的 JRE 安装目录。 如果为空的话，则默认与 JAVA_HOME 相同。 注意！！如果 JRE_HOME 和 JAVA_HOME 同时设置的话，则会使用 JRE_HOME JAVA_OPTS可选。 用于执行任何命令时的 Java 运行时选项。 包含在这里而不在 CATALINA_OPTS 的所有选项，它会被用于 Tomcat ，也被用于停止进程(stop process)、 version 等命令中。 绝大部分的选项，都应该放在 CATALINA_OPTS 里 JPDA_TRANSPORT可选。 当执行 jpda start 命令时被使用的 JPDA transport 。 默认为 “dt_socket” JPDA_ADDRESS可选。 当执行 jpda start 命令时使用的 Java 运行时选项。 默认为 localhost:8000 JPDA_SUSPEND可选。 当执行 jpda start 命令时使用的 Java 运行时选项。 用于指示 JVM 在启动之后，是否立即挂起执行。 默认是 “n” JPDA_OPTS可选。 当执行 jpda start 命令时使用的 Java 运行时选项。 当使用这个选项时， JDPA_TRANSPORT ， JPDA_ADDRESS ， JPDA_SUSPEND 都会被忽略。 因此，所有要求的 jpda 选项，必须要指定。默认为: 1-agentlib:jdwp=transport=$JPDA_TRANSPORT,address=$JPDA_ADDRESS,server=y,suspend=$JPDA_SUSPEND JSSE_OPTS可选。 当 JSSE 启用时，该选项用来控制 Java 运行时的 TLS 的实现。默认为: 1"-Djdk.tls.ephemeralDHKeySize=2048" CATALINA_PID可选。 包含 catalina 启动 Java 进程的 PID 的文件路径。 LOGGING_CONFIG可选。 覆盖 Tomcat 的日志配置文件。 例子（所有都在同一行）： 1LOGGING_CONFIG="-Djava.util.logging.config.file=$CATALINA_BASE/conf/logging.properties" LOGGING_MANAGER可选。 覆盖 Tomcat 的日志管理 例子（所有都在同一行）： 1LOGGING_MANAGER="-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager" UMASK可选。 覆盖 Tomcat 默认的 UMASK （0027） USE_NOHUP可选。 如果设置为字符串的 “true” ，则 start 命令将会使用 nohup ，这样子 Tomcat 进程将会忽略任何的 hangup 信号了。默认是 “false” ，除了在 HP-UX 上运行（它默认就是 “true” ） 判断OS使用 uname 命令。 解析命令软链接的真实位置 =&gt; PRG1234567891011PRG="$0"while [ -h "$PRG" ]; do ls=`ls -ld "$PRG"` link=`expr "$ls" : '.*-&gt; \(.*\)$'` if expr "$link" : '/.*' &gt; /dev/null; then PRG="$link" else PRG=`dirname "$PRG"`/"$link" fidone 获取命令所在的目录 =&gt; PRGDIR1PRGDIR=`dirname "$PRG"` 设置 CATALINA_HOME如果环境变量 CATALINA_HOME 还没有设置的话，则设置它为 $PRGDIR/.. 因为 PRGDIR 通常是在 CATALINA_HOME/bin 目录下，所以，它要返回上一级目录(..)。 设置 CATALINA_BASE如果环境变量 CATALINA_BASE 还没有设置的话，则设置它为 CATALINA_HOME 设置 CLASSPATH首先清空所有用户自定义的 CLASSPATH ，然后加载 setenv.sh (优先从 CATALINA_BASE/bin/setenv.sh 查找，如果有则使用它；否则继续在 CATALINA_HOME/bin/setenv.sh 里查找 ) 里的脚本内容（你也可以将 CLASSPATH 的内容添加到 setenv.sh 里，让 Tomcat 来加载） 对于特殊的 Cygwin 环境，则重新为它设置相应的环境变量. 1234567if $cygwin; then [ -n "$JAVA_HOME" ] &amp;&amp; JAVA_HOME=`cygpath --unix "$JAVA_HOME"` [ -n "$JRE_HOME" ] &amp;&amp; JRE_HOME=`cygpath --unix "$JRE_HOME"` [ -n "$CATALINA_HOME" ] &amp;&amp; CATALINA_HOME=`cygpath --unix "$CATALINA_HOME"` [ -n "$CATALINA_BASE" ] &amp;&amp; CATALINA_BASE=`cygpath --unix "$CATALINA_BASE"` [ -n "$CLASSPATH" ] &amp;&amp; CLASSPATH=`cygpath --path --unix "$CLASSPATH"`fi 输出 CATALINA_HOME 和 CATALINA_BASE 的信息12345678910case $CATALINA_HOME in *:*) echo "Using CATALINA_HOME: $CATALINA_HOME"; echo "Unable to start as CATALINA_HOME contains a colon (:) character"; exit 1;esaccase $CATALINA_BASE in *:*) echo "Using CATALINA_BASE: $CATALINA_BASE"; echo "Unable to start as CATALINA_BASE contains a colon (:) character"; exit 1;esac 加载 setclasspath.sh它主要用来确保以及设置 JAVA_HOME 或 JRE_HOME 的。 以及为不同的命令行参数，来判断使用哪个。（比如使用 debug 选项的话，它要求必须是 JDK） 添加 bootstrap.jar 到 CLASSPATH1CLASSPATH="$CLASSPATH""$CATALINA_HOME"/bin/bootstrap.jar 这个 jar 包是整个 Tomcat 的启动核心 设置默认的 CATALINA_OUT 和 CATALINA_TMPDIR添加 tomcat-juli.jar 到 CLASSPATH这个 jar 包是 Tomcat 内部用来处理日志相关的 设置 LOGGING_CONFIG123456789# Set juli LogManager config file if it is present and an override has not been issuedif [ -z "$LOGGING_CONFIG" ]; then if [ -r "$CATALINA_BASE"/conf/logging.properties ]; then LOGGING_CONFIG="-Djava.util.logging.config.file=$CATALINA_BASE/conf/logging.properties" else # Bugzilla 45585 LOGGING_CONFIG="-Dnop" fifi 这时的 JAVA_OPTS12345JAVA_OPTS="$JAVA_OPTS $JSSE_OPTS"# Register custom URL handlers# Do this here so custom URL handles (specifically 'war:...') can be used in the security policyJAVA_OPTS="$JAVA_OPTS -Djava.protocol.handler.pkgs=org.apache.catalina.webresources" 设置 LOGGING_MANAGER123if [ -z "$LOGGING_MANAGER" ]; then LOGGING_MANAGER="-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager"fi 命令行参数判断根据不同的命令行参数来设置不同的环境变量以及它们各自特有的参数。 比如 是否有 tty是否以 jpda 来启动是否以 debug 来启动是否以 run 来启动是否以 start 来启动是否是 stop 命令（可以添加 -force) Tomcat 的用法 注意，等等进程结束并使用 -force 选项的话，前提要求设置了 CATALINA_PID 环境变量 12345678910111213141516171819202122232425./catalina.sh debug ：（要 OS400 中不可用）启动 catalina 的 调试器（类似 GDB 那样）./catalina.sh debug -security ：同上，但带有一个 security manager 来启动调试器./catalina.sh jpda start ：在 JPDA Debugger 下启动 catalina（远程调试）./catalina.sh run ：在当前窗口中启动 catalina./catalina.sh run -security ：在当前窗口中启动带有 security manager 的 catalina./catalina.sh start ：在一个分隔的窗口中启动 catalina./catalina.sh start -security ：在一个分隔的窗口中启动带有 security manager 的 catalina./catalina.sh stop ：停止 catalina ，并为进程等待 5 秒后结束./catalina.sh stop n ：停止 catalina ，并为进程等待 n 秒后结束./catalina.sh stop -force ：停止 catalina ，并为进程等待 5 秒后结束，如果该进程还存活的话，再使用使用 kill -KILL 来终止进程./catalina.sh stop n -force ：停止 catalina ，并为进程等待 n 秒后结束，如果该进程还存活的话，再使用使用 kill -KILL 来终止进程./catalina.sh configtest ：检测 server.xml 是否有错误./catalina.sh version ：检测 tomcat 的版本]]></content>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty实战》读书笔记]]></title>
    <url>%2F2017%2F06%2F25%2F%E3%80%8ANetty%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Netty 核心组件 Channel : 传入或传出数据的载体 回调 : 一个被提供给另一个方法的方法引用 Future : 提供了另一种在完成时通知应用程序的方式 事件 和 ChannelHandler : Netty 使用不同的事件来通知我们状态的改变或者是操作的状态。 EeventLoop : Netty 在内部会为每个 Channel 分配一个 EventLoop，用以处理所有事件 123入站事件 -&gt; 入站处理器 -&gt; 入站事件 -&gt; 入站处理器 -&gt; ...... &lt;- 出站处理器 &lt;- 出站事件 &lt;- 出站处理器 &lt;- 出站事件 echo 服务器github emacsist nett-echo 纯手工输入~自己输入一次，加深下印象 server 端代码Handler123456789101112131415161718192021222324252627282930313233package com.github.emacsist.echo.server;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.util.CharsetUtil;/** * Created by emacsist on 2017/6/25. */@ChannelHandler.Sharablepublic class EchoServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf in = (ByteBuf)msg; System.out.println("Server received: " + in.toString(CharsetUtil.UTF_8)); ctx.write(in); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.writeAndFlush(Unpooled.EMPTY_BUFFER).addListener(ChannelFutureListener.CLOSE); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; Bootstrap 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.github.emacsist.echo.server;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import java.net.InetSocketAddress;/** * Created by emacsist on 2017/6/25. */public class EchoServer &#123; private final int port; public EchoServer(int port) &#123; this.port = port; &#125; public void start() throws InterruptedException &#123; final EchoServerHandler serverHandler = new EchoServerHandler(); EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(eventLoopGroup).channel(NioServerSocketChannel.class).localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(serverHandler); &#125; &#125;); ChannelFuture f = b.bind().sync(); f.channel().closeFuture().sync(); &#125; finally &#123; eventLoopGroup.shutdownGracefully().sync(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; if (args.length != 1 )&#123; System.err.println("Usage: " + EchoServer.class.getSimpleName() + " &lt;port&gt;"); return; &#125; int port = Integer.parseInt(args[0]); new EchoServer(port).start(); &#125;&#125; client 端代码Handler 代码1234567891011121314151617181920212223242526272829package com.github.emacsist.echo.client;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.util.CharsetUtil;/** * Created by emacsist on 2017/6/25. */@ChannelHandler.Sharablepublic class EchoClientHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.writeAndFlush(Unpooled.copiedBuffer("Netty rocks!", CharsetUtil.UTF_8)); &#125; protected void channelRead0(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf) throws Exception &#123; System.out.println("Client received: " + byteBuf.toString(CharsetUtil.UTF_8)); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; Bootstrap 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.github.emacsist.echo.client;import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import java.net.InetSocketAddress;/** * Created by emacsist on 2017/6/25. */public class EchoClient &#123; private final String host; private final int port; public EchoClient(String host, int port)&#123; this.host = host; this.port = port; &#125; public void start() throws InterruptedException &#123; EventLoopGroup group = new NioEventLoopGroup(); try&#123; Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class).remoteAddress(new InetSocketAddress(host, port)) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new EchoClientHandler()); &#125; &#125;); ChannelFuture f = b.connect().sync(); f.channel().closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully().sync(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; if (args.length != 2 )&#123; System.err.println("Usage: " + EchoClient.class.getSimpleName() + " &lt;host&gt; &lt;port&gt;"); return; &#125; String host = args[0]; int port = Integer.parseInt(args[1]); new EchoClient(host, port).start(); &#125;&#125; 运行及结果server1234567891011121314[13:35:16] emacsist:echo-server $ mvn exec:java[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building echo-server 1.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO][INFO] &gt;&gt;&gt; exec-maven-plugin:1.2.1:java (default-cli) &gt; validate @ echo-server &gt;&gt;&gt;[INFO][INFO] &lt;&lt;&lt; exec-maven-plugin:1.2.1:java (default-cli) &lt; validate @ echo-server &lt;&lt;&lt;[INFO][INFO][INFO] --- exec-maven-plugin:1.2.1:java (default-cli) @ echo-server ---Server received: Netty rocks! client12345678910111213141516171819202122[13:35:05] emacsist:echo-client $ mvn exec:java[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building echo-client 1.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO][INFO] &gt;&gt;&gt; exec-maven-plugin:1.2.1:java (default-cli) &gt; validate @ echo-client &gt;&gt;&gt;[INFO][INFO] &lt;&lt;&lt; exec-maven-plugin:1.2.1:java (default-cli) &lt; validate @ echo-client &lt;&lt;&lt;[INFO][INFO][INFO] --- exec-maven-plugin:1.2.1:java (default-cli) @ echo-client ---Client received: Netty rocks![INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 4.327 s[INFO] Finished at: 2017-06-25T13:35:28+08:00[INFO] Final Memory: 9M/155M[INFO] ------------------------------------------------------------------------[13:35:28] emacsist:echo-client $ Netty 网络抽象 Channel – Socket EmbeddedChannel LocalServerChannel NioDatagramChannel NioSctpChannel NioSocketChannel EventLoop – 控制流、多线程处理、并发。它是Netty的核心抽象，用于处理连接的生命周期中所发生的事件。 一个 EventLoopGroup 包含一个或多个 EventLoop 一个 EventLoop 在它的生命周期内只和一个 Thread 绑定 所有由 EventLoop 处理的 I/O 事件都将在它专的 Thread 上被处理 一个 Channel 在它的生命周期内只注册一个 EventLoop 一个 EventLoop 可能会被分配给一个或多个 Channel ChannelFuture – 异步通知 ChannelHandler – 它充当了所有处理入站和出站数据的应用程序逻辑的容器。（ChannelInboundHandler 它处理入站的数据， ChannelOutboundHandler 它处理出站的数据） ChannelPipeline – 提供了 ChannelHandler 链的容器。 ChannelHandlerContext – 当 ChannelHandler 被添加到 ChannelPipeline 时，它将会被分配一个 ChannelHandlerContext ，其代表了 ChannelHandler 和 ChannelPipeline 之间的绑定。虽然这个对象可以被用于获取其底层的 Channel，但是它主要还是被用于写出站数据。 Netty 两种发送消息方式 直接写到 Channel =&gt; 这导致消息从 ChannelPipeline 的 尾端开始流动 写到和 ChannelHandler 相关联的 ChannelHandlerContext =&gt; 导致消息从 ChannelPipeline 中的下一个 ChannelHandler 开始流动 编码器与解码器Netty 接收或发送一个消息时，会发生一次数据转换 入站：解码 byte -&gt; object 出站：编码 object -&gt; byte 内置的传输 NIO : 使用 java.nio.channels 包作为基础(支持的协议有 TCP, UDP, SCTP, UDT) Epool : 使用 io.netty.channel.epoll ，由 JNI 驱动的 epoll() 和 非阻塞IO 。这个传输支持只有在Linux上可用的多种特性，如: SO_REUSEPORT，比NIO更快，而且是完全非阻塞的。（仅Linux，支持的协议有 TCP, UDP） OIO : 使用 java.net 包作为基础，使用阻塞流（支持的协议有 TCP，UDP，SCTP， UDT） Local : 使用 io.netty.channel.local ，可以在VM内部通过管道进行通信的本地传输 Embedded : 使用 io.netty.channel.embedded ，允许使用 ChannelHandler 而又不需要一个真正的基于网络的传输。这在测试你的 ChannelHandler 实现时非常有用。 ByteBuf —— Netty的数据容器它维护了两个不同的索引：一个用于读取，一个用于写入。 当你从 ByteBuf 读取时，它的 readerIndex 将会被递增(以 read 开头的API)已经被读取的字节数。同样地，当你写入 ByteBuf 时，它的 writerIndex 也会被递增（以 write 开头的API）。以 set, get 开头的API 不会改变这两个索引。 使用模式 堆缓冲区：这种模式称为 backing array，类似 JDK 的 ByteBuffer 的用法。它将数据存储在 JVM 的堆空间中。 直接缓冲区：它的数据存储在 JVM 的堆外空间，主要缺点是：它的分配和释放都比较昂贵。 复合缓冲区：它为多个 ByteBuf 提供了一个聚合视图（比如HTTP的头部+HTTP的Body）。（CompositeByteBuf，它可以同时包含直接内存分配和非直接内存分配的 ByteBuf） 派生缓冲区创建方法： duplicate() slice() slice(int, int) Unpooled.unmodifiableBuffer() order(ByteOrder) readSlice(int) 每个这些方法都将返回一个新的ByteBuf 实例，它具有自己的读索引，写索引和标记索引。 其内部存储和JDK的ByteBuffer一样，也是共享 （注意，内容是共享的！！！） ByteBufHolder 接口除了实际的数据之外，还要存储各种属性值，如HTTP，字节的内容、状态码、cookie等。 content() ： 返回这个 ByteBufHolder 所持有的 ByteBuf copy() : 返回这个 ByteBufHolder 的一个深拷贝 duplicate() : 返回这个 ByteBufHolder 的一个浅拷贝 Channel 的生命周期1ChannelRegistered -&gt; ChannelActive -&gt; ChannelInactive -&gt; ChannelUnregistered ChannelHandler 的生命周期123handlerAdded : 添加到 ChannelPipeline 中时被调用handlerRemoved : 从 ChannelPipeline 中移除时被调用handlerCaught : 当处理过程中在 ChannelPipeline 中有错误产生时调用 资源管理调用 ChannelInboundHandler.channelRead() 或者 ChannelOutboundHandler.write() 处理数据时，必须要保证没有任何的资源泄漏。（因为Netty是使用引用计数来处理池化的 ByteBuf 的） 为了检测资源泄漏的问题，Netty 提供了 class ResourceLeakDetector 来检测。 检测级别有: DISABLED : 禁用泄漏检测 SIMPLE : 使用 1% 的默认采样率检测并报告。（这是默认级别） ADVANCED : 使用默认的采样率，报告所发现的任何的泄漏以及对应的消息被访问的位置 PARANOID : 类似 ADVANCED ，但是会对每一次（对消息的）访问都采样。（这应该只是在调试阶段使用） 使用： 1java -Dio.netty.leakDetectionLevel=ADVANCED 异常处理 ChannelHandler.execeptionCaught() 默认实现是简单地将当前异常转发给 ChannelPipeline 中的下一个 ChannelHandler 如果异常到达了 ChannelPipeline 的尾端，它将会被记录为未被处理 要想定义自定义的处理逻辑，你需要重写 exceptionCaught() 方法。然后你需要决定是否需要将该异常传播出去 JDK 5 线程模型池化，它的思想： 从池中空闲线程列表中选择一个 Thread，并且派它去运行一个已经提交的任务（Runnable的实现） 当任务完成时，将该Thread返回给该列表，使其可被重用 这虽然减少了每个任务线程的创建和销毁，但它并不能消除由 上下文切换 所带来的开销，随着线程数量的增加很快变得明显，并且在高负载下，愈演愈烈。 EventLoop 接口123456while(!terminated) &#123; List&lt;Runnable&gt; readyEvents = blockUntilEventsReady() for (Runnable ev : readyEvents) &#123; ev.run() &#125;&#125; 在这个线程模型中，一个 EventLoop 由一个永不变的 Thread 驱动。可根据可用核心不同，可能会创建多个 EventLoop 实例用以优化资源的使用，并且单个 EventLoop 可能会被指派用于服务多个 Channel Netty 4 中的 I/O 和事件处理在 Netty 4 中，所有的 I/O 操作和事件都已经被分配给了 EventLoop 的那个 Thread 来处理（注意，是处理，而不是触发哦） Netty 3 中的 I/O 操作这个模型只保证了入站（上游）事件会在所谓的 I/O 线程（对应 Netty 4 中的 EventLoop ）执行。所有的出站（下游）事件都由调用线程处理，其可能是 I/O 线程也可能是别的线程。 主要问题是：该模型不可能保证多个线程不会在同一时刻尝试访问出站事件。（例如，在不同的线程中调用 Channel.write() ，针对同一个 Channel 同时触发出站的事件，就会发生这种情况） 线程管理取决于当前执行的 Thread 的身份的确定(EventLoop的 inEvenLoop(Thread) 来确定) 。 如果是支撑的 EventLoop 的线程，那么所提交的代码将会被（直接）执行。否则 EventLoop 将调度该任务以便稍后执行，并将它放入到内部队列中。 ！！！！永远不要将一个长时间运行的任务放入到执行队列中，因为它将阻塞需要在同一线程上执行的任何的其他任务。 EventLoop 的线程分配NIO 中这种模型中，它们可能会被多个 Channel 所共享，这样可以通过尽可能少的 Thread 来支撑大量的 Channel ，而不是每个 Channel 分配一个 Thread 。EventLoopGroup 负责为每个新创建的 Channel 分配一个 EventLoop。在当前实现中，使用顺序循环（round-robin) 的方式进行分配以获取一个均衡的分布，并且相同的 EventLoop 可能会被分配给多个 Channel 。 OIO 中这里每个 Channel 都将被分配一个 EventLoop（以及它的Thread） 导引123 &lt;-- Bootstrap（客户端）Cloneable &lt;- AbstractBootstrap &lt;-- &lt;-- ServerBootstrap（服务器端） 为什么引导类是 Cloneable 的？ 你有时可能会需要创建多个具有类似配置或者完全相同配置的 Channel 。为了支持这种模式而又不需要为每个 Channel 都创建并配置一个新的引导类实例，AbstractBootstrap 被标记为了 Cloneable 。在一个已经配置完成的引导类实例上调用 clone() 方法将返回一个可以立即使用的引导类实例。 注意，这种方式只会创建引导类实例的 EventLoopGroup 的一个浅拷贝，所以，后者将在所有克隆的 Channel 实例之间共享。 Bootstrap内置编/解码器123456789101112131415161718192021222324252627282930313233/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/base64/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/bytes/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/compression/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/dns/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/haproxy/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http/cookie/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http/cors/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http/multipart/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http/websocketx/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http/websocketx/extensions/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http/websocketx/extensions/compression/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/http2/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/json/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/marshalling/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/memcache/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/memcache/binary/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/mqtt/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/protobuf/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/redis/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/rtsp/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/sctp/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/serialization/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/smtp/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/socks/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/socksx/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/socksx/v4/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/socksx/v5/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/spdy/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/stomp/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/string/Users/emacsist/.m2/repository/io/netty/netty-all/4.1.12.Final/netty-all-4.1.12.Final.jar!/io/netty/handler/codec/xml]]></content>
      <tags>
        <tag>java</tag>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/O模型知识收集整理]]></title>
    <url>%2F2017%2F06%2F23%2FI-O%E6%A8%A1%E5%9E%8B%E7%9F%A5%E8%AF%86%E6%94%B6%E9%9B%86%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[同步、异步 与 阻塞、非阻塞What’s the differences between blocking with synchronous, nonblocking and asynchronous? stackoverflow 里的是线程的同步与阻塞，我翻译了一下: 阻塞的意思可能与同步相同，也可能是不同，这取决于上下文。当我们谈论方法调用时，一个同步的调用，也可以称为阻塞的（在稍候将返回），因为线程调用方法时不能继续向前了，直到方法返回。反义词就是，在这种情况下可以是异步的。 在 锁 的术语中，如果等待获取的线程被处于挂起模式，直到锁可用（或者超时），这种情况下，锁就称为阻塞。这种情况下的反义词是非阻塞锁，这意味着线程即使无法获得锁也会立即返回。这可以用于实现所谓的自旋锁，你可以保持线程处于活动状态的同时轮询锁的状态。 说到这里，你可以推断出这些概念间的区别了：同步通常意味着一个活动在线程向前移动之前，必须等待回复。 阻塞是指：线程处于等待状态（通常意味着它不会被调度执行，直到发生某些事件为止）。从这里可以得出结论：同步调用可能涉及阻塞行为，也可能不依赖于底层实现（即它也可能是在自旋，这意味着你正在使用异步调用模拟同步行为） 这时引用知乎上面的一个 回答 可以参考一下。 123456789101112131415161718192021222324老张爱喝茶，废话不说，煮开水。出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。1 老张把水壶放到火上，立等水开。（同步阻塞）老张觉得自己有点傻2 老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞）老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。3 老张把响水壶放到火上，立等水开。（异步阻塞）老张觉得这样傻等意义不大4 老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞）老张觉得自己聪明了。所谓同步异步，只是对于水壶而言。普通水壶，同步；响水壶，异步。虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。所谓阻塞非阻塞，仅仅对于老张而言。立等的老张，阻塞；看电视的老张，非阻塞。情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。——来源网络，作者不明。作者：愚抄链接：https://www.zhihu.com/question/19732473/answer/23434554来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 这样子理解就清楚好多了。我觉得一个人能用普通人都能理解的思维来表达知识的，一定是对知识掌握得非常透彻的，哈哈。 I/O 模型单线程阻塞多线程阻塞##]]></content>
      <tags>
        <tag>IO模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 1.x 协议笔记整理]]></title>
    <url>%2F2017%2F06%2F22%2FHTTP-1-x-%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[请求报文123456请求方法(GET,POST等) 空格 URL 空格 协议版本\r\n字段名: 字段值\r\n...字段名: 字段值\r\n\r\n请求体的内容 比如: 123456789GET /2017/06/02/Golang-%E6%B1%87%E7%BC%96%E6%9D%82%E9%A1%B9/ HTTP/1.1Host: emacsist.github.ioConnection: keep-alivePragma: no-cacheCache-Control: no-cacheUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Referer: https://emacsist.github.io/tags/golang/ 响应报文123456协议及版本 空格 状态码 空格 描述\r\n字段: 字段值\r\n...字段: 字段值\r\n\r\n响应体的内容 比如: 123456789101112131415161718192021HTTP/1.1 200 OKServer: GitHub.comContent-Type: text/html; charset=utf-8Last-Modified: Fri, 16 Jun 2017 13:44:31 GMTAccess-Control-Allow-Origin: *Expires: Thu, 22 Jun 2017 07:41:06 GMTCache-Control: max-age=600Content-Encoding: gzipX-GitHub-Request-Id: F682:28F28:E2E8C4:F13E12:594B7239Content-Length: 6688Accept-Ranges: bytesDate: Thu, 22 Jun 2017 07:31:06 GMTVia: 1.1 varnishAge: 0Connection: keep-aliveX-Served-By: cache-nrt6120-NRTX-Cache: MISSX-Cache-Hits: 0X-Timer: S1498116666.909413,VS0,VE213Vary: Accept-EncodingX-Fastly-Request-ID: aadc9ce160db1f0a3d9b123dede2dcc2e311b549 HTTP1.1 协议规范http rfc2616]]></content>
      <tags>
        <tag>http</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM字节码学习与理解]]></title>
    <url>%2F2017%2F06%2F19%2FJVM%E5%AD%97%E8%8A%82%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[aconst_null 压特殊的 null 对象引用入栈。 iconst_ 作用压整型数字0，1，2，3，4，5 入栈 注意压入栈的指令还有： bipush 0;sipush 0;idc 0; 但这些指令相对于等同的 iconst_ 指令，效率更低，并且在 class 文件中占用更加多的字节 iconst_m1 将 -1 压入操作数栈 lconst_lconst_0 或 lconst_1 压长整型 long integer 0 或 1 入栈 注意也可以用 ldc2_w 0 尽管这条指令占用更多的字节以及效率更低 fconst_fconst_0 或 fconst_1 或 fconst_2 压单精度浮点数 0.0， 1.0 或 2.0 入栈 注意你也可以用 ldc 0.0 尽管这条指令占用更多的字节以及效率更低 dconst_dconst_0 或 dconst_1 压双精度浮点数 0.0 或 1.0 入栈 注意你也可以用 ldc2_w 0.0 尽管这条指令占用更多的字节以及效率更低 bipushbipush n 是一个 -128 &lt;= n &lt;= 127 的整数。压 1字节 有符号整数入栈。 注意bipush 通常比 ldc 更高效。并且它在class文件中占用的字节数更少。 sipushsipush n 是一个 -32768 &lt;= n &lt;= 32767 的有符号整数。压 2字节 有符号整数入栈。 ldcldc 是一个int，或 floag，或 引号的 string。压一个字大小的常量入栈。 在字节码中， ldc 操作码后接着一个 8位 无符号的整数，这个整数是当前 class 的常量池项的索引。项是被标识为 CONSTRANT_Integer 或 CONSTRANT_Float 或 CONSTRANT_String 。 注意当可能时，使用 bipush 或 sipush 或 const 指令之一来代替 ldc ，因为它们通常更高效。 ldc_wldc_w 是一个 int, 或 float 或 引号的 string。压一个字大小的常量入栈（wide index) 注意ldc_w 与 ldc 是相同的。区别在于: ldc_w 使用的是 16-bit 索引，而 ldc 使用的是 8-bit 索引 ldc2_wldc2_w 是一个 long integer 或 double 数字。 在字节码中， ldc2_w 操作码后接着一个 16-bit 无符号的整数。这个整数是一个常量池中的索引项。项是标识为 CONSTRANT_Double 或 CONSTRANT_Long 的项。 iloadiload =&gt; 这种是无符号整数，范围为 0~0xFF，即 0~255或wide iload =&gt; 这种是无符号整数，范围为 0~0xFFFF，即 0～65535 从本地变量 (local variable) (varnum是本地变量的号码) 获取 integer。即将本地变量 varnum 的值压入栈。 iload_它等同于 iload ，但通常，它比 iload 更高效，并且在class文件中占用更少的字节数。 lloadlload =&gt; 这种是无符号整数，范围为 0~0xFF或wide lload =&gt; 这种是无符号整数，范围为 0~0xFFFE 从本地变量（local variable) 获取一个 long integer，然后将它压入栈 lload_它等同于 lload ，但通常，它比 lload 更高效，并且在class文件中占用更少的字节数 注意由于 long integer 是 64-bit 的，并且每一个本地变量最多持有32-bit，所以Java使用了连续2个本地变量， 和 + 1 来保存一个 long 。因此， lload 通常是将 和 + 1 的本地变量压入栈。 floadfload =&gt; 这是一个无符号数，范围为 0~0xFF或wide fload =&gt; 这是一个无符号数，范围为 0~0xFFFF 从本地变量 (local variable) (varnum是本地变量的号码) 获取 float。即将本地变量 varnum 的值压入栈。 fload_它等同于 fload ，但通常，它比 fload 更高效，并且在class文件中占用更少的字节数 dloaddload =&gt; 这是一个无符号数，范围为 0~0xFF或wide dload =&gt; 这是一个无符号数，范围为 0~0xFFFE 从本地变量 (local variable) (varnum是本地变量的号码) 获取 double。即将本地变量 varnum 的值压入栈。 注意由于 double 是 64-bit 的，并且每一个本地变量最多持有32-bit，所以Java使用了连续2个本地变量 和 + 1 来保存 double 。 因此, dload 通常是将 和 + 1 压入栈。 dload_它等同于 dload ，但通常，它比 dload 更高效，并且在class文件中占用更少的字节数 aloadaload =&gt; 这是一个无符号数，范围为 0~0xFF或wide aload =&gt; 这是一个无符号数，范围为 0~0xFFFF 从本地变量(local variable)获取一个对象的引用，然后将它压入栈。 aload_它等同于 aload ，但通常，它比 aload 更高效，并且在class文件中占用更少的字节数 aaload 从一个对象数组(array of objects)中获取一个对象引用(object reference)，然后将它压入栈 aaload 之前，栈顶应该为: index：数组索引arrayref：数组对象的引用 aaload 之后，栈顶为: arrayref[index]的值 所以，aaload之前，通常要准备好arrayref 和 index 的值压入栈。 iaload 从一个int数组（integer array)中获取一个int，然后将它压入栈。 laload 从一个long数组（long array)中获取一个long，然后将它压入栈。 daload 从一个double数组（double array)中获取一个double，然后将它压入栈。 baload 从一个字节数组（byte array)中获取一个字节，然后扩展它为一个 integer ，最后压它入栈。 它也用作从布尔数组中接收值。（Sun的实现中，boolean array 通常也是保存为 byte array的，每一个字节代表一个布尔值） caload 从一个字符数组中获取一个字符，然后将它压入栈。 saload 从一个 short 数组中获取一个 short 。 istoreistore =&gt; 这是一个无符号数，范围为 0~0xFF或wide istore =&gt; 这是一个无符号数，范围为 0~0xFFFF 从栈顶弹出(pop)一个int，并且将它保存到本地变量 (local variable) 中。 istore_istore_0 , istore_1 ， istore_2 ，istore_3 它等同于 istore ，通常该指令比 istore 更高效，并且在class文件中占用更少的字节数。 lstorelstore =&gt; 这是一个无符号数，范围为 0~0xFF或wide lstore =&gt; 这是一个无符号数，范围为 0~0xFFFE 从栈顶弹出(pop)一个int，并且将它保存到本地变量 (local variable) 中。 注意long 是 64-bit 的，并且每个本地变量最多只能拥有 32-bit，由于Java使用2个连续的本地变量 和 + 1 来表示一个 long。 因此, lstore 通常修改了 和 + 1 的值。 lstore_lstore_0, lstore_1, lstore_1, lstore_2, lstore_3 它等同于 lstore ，通常该指令比 lstore 更高效，并且在class文件中占用更少的字节数。 fstorefstore =&gt; 这是一个无符号数，范围为 0~0xFF或wide store =&gt; 这是一个无符号数，范围为 0~0xFFFF 从栈顶弹出(pop)一个float，并且将它保存到本地变量 (local variable) 中。 fstore_fstore_0, fstore_1, fstore_1, fstore_2, fstore_3 它等同于 fstore ，通常该指令比 fstore 更高效，并且在class文件中占用更少的字节数。 dstoredstore =&gt; 这是一个无符号数，范围为 0~0xFF或wide dstore =&gt; 这是一个无符号数，范围为 0~0xFFFE 从栈顶弹出(pop)一个double，并且将它保存到本地变量 (local variable) 中。 注意double 是 64-bit 的，并且每个本地变量最多只能拥有 32-bit，由于Java使用2个连续的本地变量 和 + 1 来表示一个 long。 因此, dstore 通常修改了 和 + 1 的值。 dstore_dstore_0, dstore_1, dstore_1, dstore_2, dstore_3 它等同于 dstore ，通常该指令比 dstore 更高效，并且在class文件中占用更少的字节数。 astoreastore =&gt; 这是一个无符号数，范围为 0~0xFF或wide astore =&gt; 这是一个无符号数，范围为 0~0xFFFF 从栈顶弹出(pop)一个对象引用，并且将它保存到本地变量 (local variable) 中。 astore_astore_0, astore_1, astore_1, astore_2, astore_3 它等同于 astore ，通常该指令比 astore 更高效，并且在class文件中占用更少的字节数。 iastore 从栈中获取一个 int，并且将它保存到一个 int 数组对象中。 iastore 指令执行之前的栈:valueindexarrayrefxxx 执行完之后：xxx lastore 从栈中获取一个双字，long integer ，并且将它保存到一个 long integer 数组中。 lastore 指令执行之前的栈：value-word1value-word2indexarrayrefxxx 执行完之后：xxx fastore与 iastore 类似 dastore与 lastore 类似 aastore与 iastore 类似 castore与 iastore 类似。 c 表示 character sastore与 iastore 类似. s 表示 short pop从栈顶中丢弃一个字(single-word)大小的数据。 pop2从栈顶中丢弃两个字(two words)大小的数据。 dup复制栈顶一个字（single-word)的数据，然后压它入栈。 即 pop 一次，push 两次 dup_x1复制栈顶一个字（single-word)的数据，然后插入到原栈顶下面第二项中。 执行指令之前，栈顶：word1word2xxxx 执行完指令之后：word1word2word1xxxx dup_x2复制栈顶一个字（single-word)的数据，然后插入到原栈顶下面第三项中。 执行指令之前，栈顶：word1word2word3xxxx 执行完指令之后：word1word2word3word1xxxx dup2复制栈顶两个字（two-words)的数据，然后压它入栈。（比如2个int, 1个int和object引用，又或者是一个 double ，或一个 long） dup2_x1复制栈顶两个字（two-words)的数据，然后将复制的那个字(two-word)插入到原前一个字(previous single word)前面。 比如 dup2_x1 指令之前的栈为:word1word2word3xxxx 执行完指令之后，栈为:word1word2word3word1word2xxxx dup2_x2复制栈顶两个字（two-words)的数据，然后将复制的那个字(two-word)插入到原前两个字(previous two word)前面。 比如 dup2_x1 指令之前的栈为:word1word2word3word4xxxx 执行完指令之后，栈为:word1word2word3word4word1word2xxxx swap交换栈顶两个字的数据 指令执行之前:word1word2xxxx 指令执行完后:word2word1xxxx iadd, isub, imul, idiv, irem 将栈顶两个数弹出(pop)，然后将它们相加（减，乘，除，取模）的结果压入栈 ladd，lsub, lmul, ldiv, lrem 将栈顶两个 long integer 弹出，然后将它们相加（减，乘，除，取模）的结果压入栈。 指令前的栈:value1-word1value1-word2value2-word1value2-word2xxxx 指令执行后的栈:result-word1result-word2xxxx fadd, fsub, fmul, fdiv， frem 将栈顶两个单精度浮点数弹出，然后将它们相加（减，乘，除，取模）的结果压入栈。 dadd, dsub, dmul, ddiv, drem 将栈顶两个双精度浮点数弹出，然后将它们相加（减，乘，除，取模）的结果压入栈。 指令前的栈:value1-word1value1-word2value2-word1value2-word2xxxx 指令后的栈:result-word1result-word2xxxx ineg, lneg, fneg, dneg将栈顶 int, long, float, double 弹出，取负后，再压入栈 ishl, lshl, ishr, lshr将 int, long 左移或右移指定位数（有符号）。 栈前:value1 =&gt; 要位移的个数value2 =&gt; 要进行位移的数xxxx 栈后resultxxxx 例如， ishr ，它等同于 x / (2^n) ，n 就是 value1，x 就是 value2 iushr, lushr它是无符号位移 iand, land, ior, lor, ixor, lxor将栈顶两个 int 或 两个long 的值进行位与（或、异或）操作。 栈前:value1value2xxxx 栈后resultxxxx iinciinc =&gt; varnum 是一个无符号数，范围为 0~0xFF, n 是一个有符号整数，范围为 -128~127或wide iinc =&gt; varnum 是一个无符号数，范围为 0~0xFFFF, n 是一个有符号整数，范围为 -32768 ~ 32767 表示将本地变量 (local variable) 序号为 varnum 的变量，增加 n （注意，n可以为负的，即减的意义） i2l将 int 转换为 long 。 栈前:intxxxx 栈后long-word1long-word2xxxx i2f栈前 intxxxx 栈后 floatxxxx i2d栈前intxxxx 栈后double-word1double-word2xxxx l2i栈前 long-word1long-word2xxxx 栈后 intxxxx l2f栈前long-word1long-word2xxxx 栈后floatxxxx l2d栈前 long-word1long-word2xxxx 栈后 double-word1double-word2xxxx f2i栈前 floatxxxx 栈后 intxxxx f2l栈前 floatxxxx 栈后 long-word1long-word2xxxx f2d栈前 floatxxxx 栈后 double-word1double-word2xxxx d2i栈前 double-word1double-word2xxxx 栈后 intxxxx d2l栈前 double-word1double-word2xxxx 栈后 long-world1long-world2 d2f栈前 double-word1double-word2xxxx 栈后 floatxxxx i2b从栈顶中弹出一个 int，然后转换为有符号的字节（前8位保留，后24位丢弃，即后24位设置为0），然后将结果进行有符号扩展，最后将结果压入栈 注意：它可能会导致符号（正负）改变。 i2c从栈顶中弹出一个 int，然后转换为一个 16位无符号字符。（后16位设置为0），然后将结果压入栈 i2s从栈顶中弹出一个 int，然后转换为一个有符号的 short 。（后16位设置为0），然后将结果进行有符号扩展，最后将结果压入栈。 注意：它可能会导致符号（正负）改变。 lcmp将栈顶两个 long 值弹出，然后比较它们的大小。如果相等，则将 0 压入栈。如果 value2 &gt; value 1 ，则将 1 压入栈；如果 value1 &gt; value 2 ，则将 -1 压入栈。 栈前:value1-word1value1-word2value2-word1value2-word2xxxx 栈后：int-resultxxxx fcmpl单精度浮点数比较。（如果任一数字是 NaN，则压-1入栈） 栈前value1value2xxxx 栈后int-resultxxxx 如果相等，则将 int 0 压入栈。如果 value2 &gt; value 1 ，则将 1 压入栈； 如果 value1 &gt; value2，则将 -1 压入栈。 fcmpg与 fcmpl 相同。但如果任一数字是 NaN，则压1入栈。 dcmpl双精度浮点比如（如果任一数字是 NaN，则压-1入栈） 栈前:value1-word1value1-word2value2-word1value2-word2xxxx 栈后int-resultxxxx 如果相等，则将 int 0 压入栈。如果 value2 &gt; value 1 ，则将 1 压入栈； 如果 value1 &gt; value2，则将 -1 压入栈。 dcmpg与 dcmpl 相同。但如果任一数字是 NaN，则压1入栈。 ifeqifeq 如果栈顶的 int 为0，则跳转到 label 的位置。（弹出栈顶） ifneifne 如果栈顶的 int 不为0，则跳转到 label 的位置。（弹出栈顶） ifgeifge 如果栈顶的 int 大于等于 0，则跳转到 label 的位置。（弹出栈顶） ifgtifgt 如果栈顶的 int 大于 0，则跳转到 label 的位置。（弹出栈顶） ifleifle 如果栈顶的 int 小于等于 0，则跳转到 label 的位置。（弹出栈顶） if 与 cmp 指令结合它们都是以 int 来比较（弹出栈顶两个 int) if_icmpeq =&gt; 比较，如果等于0（即相等），则跳转if_icmpneif_icmpltif_icmpgeif_icmpgtif_icmple if_acmpeq =&gt; 比较两个引用型，如果相等，则跳转if_acmpne =&gt; 比较两个引用型，如果不相等，则跳转 gotogoto 跳转到 label jsr jump to subroutine jsr 栈前：xxx 栈后return-addressxxx 它通常用来实现 Java 中的 finally 子句。 retret =&gt; 它是一个无符号整数，范围为 0~0xFF或wide ret =&gt; 它是一个无符号整数，范围为 0~0xFFFF 它用于从 subroutine （即用 jsr 指令调用的）返回。 tableswitch 用于执行计算比较跳转 tableswitch [] … default : 栈前:valxxxx 栈后xxxx low 是一个有符号 32-bit 整数。 lookupswitch 用于执行高效的 比较-然后-跳转。通常是 switch 语句。 lookupswitch : : … : default : key1, key2 都是 32-bit 整数 栈前:itemxxxx 栈后xxxx ireturn从方法中返回 integer 结果。 栈前:return-valuexxxx 栈后xxxx 它从栈顶中弹出一个 int ，然后将它压入调用者（例如，使用 invokevirtual, invokespecial, invokestatic or invokeinterface 来调用当前正执行的方法）的操作数栈中。当前正执行的方法的其他操作数栈都会被丢弃。 lreturn与 ireturn 相同。只是它返回的是 long (注意，它要占用2个32-bit) freturn与 ireturn 相同。只是它返回的是 float dreturn与 ireturn 相同。只是它返回的是 double areturn与 ireturn 相同。只是它返回的是 对象引用. 栈前:objectrefxxxx 栈后xxxx return从方法中返回。方法的返回类型为 void。 getstatic 获取静态域 static field getstatic 它会从栈顶中的 objectref 引用弹出，然后从 objectref 中获取以 field-spec 标识的静态域，最后将这个值压入栈（一个字或双字，双字的情况，比如 double, long 类型） 栈前:xxxx 栈后valuexxxx 或value-word1value-word2xxxx putstaticputstatic 为静态域设置值（值是从栈顶中的一个字或双字获取） 栈前：valuexxxx 栈后xxxx 或 栈前:value-word1value-word2xxxx 栈后:xxxx getfieldgetfield 例如:getfield java/lang/System/out Ljava/io/PrintStream; 从栈顶中弹出对象的引用(objectref)，然后获取它的指定字段，最后将字段的值（一个字或双字）压入栈。 栈前:objectrefxxxx 栈后valuexxxx 或 栈前:objectrefxxxx 栈后：value-word1value-word2xxxx putfieldputfield 为实例对象设置值。 栈前:valueobjectrefxxxx 栈后:xxxx 或 栈前:value-word1value-word2objectrefxxxx 栈后:xxxx invokevirtual 调用实例方法 invokevirtual 栈前:arg1arg2…argNobjectrefxxxx 栈后:resultxxxx invokespecialinvokespecial 调用属于指定 class 的方法（比如构造函数， this 的私有方法， this 父类的方法等） 栈前: argN…arg2arg1objectrefxxxx 栈后:[result]xxxx invokestaticinvokestatic 调用一个类的静态方法 栈前:argN…arg2arg1objectrefxxxx 栈后:[result]xxxx invokeinterface调用一个接口方法 invokeinterface 栈前:argN…arg2arg1objectrefxxxx 栈后:[result]xxxx newnew 创建一个对象 栈前:xxxx 栈后:objectrefxxxx newarraynewarray type 可以是以下之一: boolean, char, float, double, byte, short, int, long 栈前:nxxxx 栈后:arrayrefxxxx anewarrayanewarray type 是一个 class 或 interface 名。 栈前:sizexxxx 栈后:arrayrefxxxx arraylength获取数组长度 栈前:arrayrefxxxx 栈后:lengthxxxx athrow抛出一个异常。 栈前:objectref[这是一个异常类型对象, throwable 或它的子类]xxxx 栈后:xxxx checkcast检查对象或数组的类型 checkcast 栈前:objectrefxxxx 栈后:objectrefxxxx 检查栈顶的操作数（一个对象或数组的引用）是否可以转换为指定的类型。 instanceofinstanceof 测试一个对象是否某个类的实例 栈前:objectrefxxxx 栈后:int-resultxxxx 如果是，则int-result为1，否则为0 monitorenter进入一个同步的代码区域 栈前:objectrefxxxx 栈后:xxxx monitorexit离开一个同步的代码区域 栈前:objectrefxxxx 栈后:xxxx nop 这个条指令并不会做任何事。编译器有时会有了调试，测试或时序的目的而生成 nop 参考资料cs.au.dk]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>bytecode</tag>
        <tag>字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang中关于逃逸分析以及变量与堆栈的分配问题]]></title>
    <url>%2F2017%2F06%2F18%2FGolang%E4%B8%AD%E5%85%B3%E4%BA%8E%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E5%8F%98%E9%87%8F%E4%B8%8E%E5%A0%86%E6%A0%88%E7%9A%84%E5%88%86%E9%85%8D%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[变量是如何分配今天看到 《Go程序设计语言– 艾伦 A. A. 多诺万 》 （看的是中译版，P26, P27)有句话： 编译器可以选择使用堆或栈上的空间来分配，令人惊奇的是，这个选择不是基于使用 var 或 new 关键字来声明变量。 任何情况下，逃逸的概念使你不需要额外费心来写正确的代码，但要记住它在性能优化的时候是有好处的，因为每一次变量逃逸都需要一次额外的内存分配过程。 什么是逃逸分析维基百科 逃逸分析是一种确定指针动态范围的方法——分析在程序的哪些地方可以访问到指针 作用域与生命周期 不要将作用域和生命周期混淆。声明的作用域是声明在程序文本中出现的区域，它是一个编译时的属性。变量的生命周期是变量在程序执行期间能被程序的其他部分所引用的起止时间，它是一个运行时属性。 参考资料Golang逃逸分析]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于StringBuilder中设置初始容量对性能的测试]]></title>
    <url>%2F2017%2F06%2F16%2F%E5%85%B3%E4%BA%8EStringBuilder%E4%B8%AD%E8%AE%BE%E7%BD%AE%E5%88%9D%E5%A7%8B%E5%AE%B9%E9%87%8F%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[被测试代码12345678910111213141516171819202122package org.agoncal.sample.jmh;/** * Created by emacsist on 2017/6/16. */public class StringAppend &#123; public static String defaultBuilder(int len) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; len; i++) &#123; sb.append(i); &#125; return sb.toString(); &#125; public static String bufferBuilder(int len) &#123; StringBuilder sb = new StringBuilder(len); for (int i = 0; i &lt; len; i++) &#123; sb.append(i); &#125; return sb.toString(); &#125;&#125; 基准测试代码12345678910111213141516171819202122232425262728293031323334353637package org.agoncal.sample.jmh;import org.openjdk.jmh.annotations.*;import org.openjdk.jmh.runner.Runner;import org.openjdk.jmh.runner.RunnerException;import org.openjdk.jmh.runner.options.Options;import org.openjdk.jmh.runner.options.OptionsBuilder;import java.util.concurrent.TimeUnit;/** * Created by emacsist on 2017/6/9. */@BenchmarkMode(Mode.All)@OutputTimeUnit(TimeUnit.MILLISECONDS)@State(Scope.Thread)public class Main &#123; @Benchmark public void benchmark()&#123; StringAppend.defaultBuilder(10000); &#125; @Benchmark public void benchmarkFinal()&#123; StringAppend.bufferBuilder(10000); &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(Main.class.getSimpleName()) .forks(1) .measurementIterations(10) .warmupIterations(20) .build(); new Runner(opt).run(); &#125;&#125; 测试结果123456789101112131415161718192021222324252627# Run complete. Total time: 00:40:59Benchmark Mode Cnt Score Error UnitsMain.benchmark thrpt 200 2.720 ± 0.089 ops/msMain.benchmarkFinal thrpt 200 3.133 ± 0.119 ops/msMain.benchmark avgt 200 0.387 ± 0.017 ms/opMain.benchmarkFinal avgt 200 0.343 ± 0.016 ms/opMain.benchmark sample 529790 0.377 ± 0.001 ms/opMain.benchmark:benchmark·p0.00 sample 0.303 ms/opMain.benchmark:benchmark·p0.50 sample 0.324 ms/opMain.benchmark:benchmark·p0.90 sample 0.534 ms/opMain.benchmark:benchmark·p0.95 sample 0.541 ms/opMain.benchmark:benchmark·p0.99 sample 0.606 ms/opMain.benchmark:benchmark·p0.999 sample 2.408 ms/opMain.benchmark:benchmark·p0.9999 sample 4.810 ms/opMain.benchmark:benchmark·p1.00 sample 13.386 ms/opMain.benchmarkFinal sample 621482 0.322 ± 0.001 ms/opMain.benchmarkFinal:benchmarkFinal·p0.00 sample 0.254 ms/opMain.benchmarkFinal:benchmarkFinal·p0.50 sample 0.289 ms/opMain.benchmarkFinal:benchmarkFinal·p0.90 sample 0.452 ms/opMain.benchmarkFinal:benchmarkFinal·p0.95 sample 0.499 ms/opMain.benchmarkFinal:benchmarkFinal·p0.99 sample 0.523 ms/opMain.benchmarkFinal:benchmarkFinal·p0.999 sample 2.230 ms/opMain.benchmarkFinal:benchmarkFinal·p0.9999 sample 3.307 ms/opMain.benchmarkFinal:benchmarkFinal·p1.00 sample 93.323 ms/opMain.benchmark ss 10 5.305 ± 0.391 ms/opMain.benchmarkFinal ss 10 5.324 ± 0.278 ms/op 个人结论测试环境 12345678910111213java -versionjava version "1.8.0_92"Java(TM) SE Runtime Environment (build 1.8.0_92-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.92-b14, mixed mode)lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 12.04 LTSRelease: 12.04Codename: precise 可以看到，它们几乎是没有什么区别的。不过，不知道是不是自己写的测试代码有问题，如果是，还请指教。 网上大多资料显示说，它之间有性能区别，是因为它动态扩容，导致内存频率分配回收的问题。这个虽然说理论上会是这样子，但我认为，最终还是要看测试的结果。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>performance</tag>
        <tag>StringBuilder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请不要再说Java中final方法比非final性能更好了]]></title>
    <url>%2F2017%2F06%2F16%2F%E8%AF%B7%E4%B8%8D%E8%A6%81%E5%86%8D%E8%AF%B4Java%E4%B8%ADfinal%E6%96%B9%E6%B3%95%E6%AF%94%E9%9D%9Efinal%E6%80%A7%E8%83%BD%E6%9B%B4%E5%A5%BD%E4%BA%86%2F</url>
    <content type="text"><![CDATA[无继承有 static 修饰static final123456789101112131415161718// 生成随机数字和字母,public static final String getStringRandomFinal(int length) &#123; String val = ""; Random random = new Random(); // 参数length，表示生成几位随机数 for (int i = 0; i &lt; length; i++) &#123; String charOrNum = random.nextInt(2) % 2 == 0 ? "char" : "num"; // 输出字母还是数字 if ("char".equalsIgnoreCase(charOrNum)) &#123; // 输出是大写字母还是小写字母 // int temp = random.nextInt(2) % 2 == 0 ? 65 : 97; val += (char) (random.nextInt(26) + 97); &#125; else if ("num".equalsIgnoreCase(charOrNum)) &#123; val += String.valueOf(random.nextInt(10)); &#125; &#125; return val;&#125; static 非 final123456789101112131415161718// 生成随机数字和字母,public static String getStringRandom(int length) &#123; String val = ""; Random random = new Random(); // 参数length，表示生成几位随机数 for (int i = 0; i &lt; length; i++) &#123; String charOrNum = random.nextInt(2) % 2 == 0 ? "char" : "num"; // 输出字母还是数字 if ("char".equalsIgnoreCase(charOrNum)) &#123; // 输出是大写字母还是小写字母 // int temp = random.nextInt(2) % 2 == 0 ? 65 : 97; val += (char) (random.nextInt(26) + 97); &#125; else if ("num".equalsIgnoreCase(charOrNum)) &#123; val += String.valueOf(random.nextInt(10)); &#125; &#125; return val;&#125; 结果这里使用了 OpenJDK 的 JMH 基准测试工具来测试的，结果如下: 123456789101112131415161718192021222324252627282930313233343536373839# JMH 1.4.1 (released 903 days ago, please consider updating!)# VM invoker: /srv/jdk1.8.0_92/jre/bin/java# VM options: &lt;none&gt;# Warmup: 20 iterations, 1 s each# Measurement: 20 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: org.agoncal.sample.jmh.Main.benchmark中间忽略了预热及测试过程，这里只显示结果Result: 206924.113 ±(99.9%) 7746.446 ops/s [Average] Statistics: (min, avg, max) = (132107.466, 206924.113, 267265.397), stdev = 32798.937 Confidence interval (99.9%): [199177.667, 214670.559]# JMH 1.4.1 (released 903 days ago, please consider updating!)# VM invoker: /srv/jdk1.8.0_92/jre/bin/java# VM options: &lt;none&gt;# Warmup: 20 iterations, 1 s each# Measurement: 20 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: org.agoncal.sample.jmh.Main.benchmarkFinal中间忽略了预热及测试过程，这里只显示结果Result: 210111.568 ±(99.9%) 8486.176 ops/s [Average] Statistics: (min, avg, max) = (133813.368, 210111.568, 267525.228), stdev = 35931.001 Confidence interval (99.9%): [201625.392, 218597.744] # Run complete. Total time: 00:13:54Benchmark Mode Samples Score Error Unitso.a.s.j.Main.benchmark thrpt 200 206924.113 ± 7746.446 ops/so.a.s.j.Main.benchmarkFinal thrpt 200 210111.568 ± 8486.176 ops/s 总结：你说final的性能比非final有没有提升呢？可以说有，但几乎可以忽略不计。如果单纯地追求性能，而将所有的方法修改为 final 的话，我认为这样子是不可取的。而且这性能的差别，远远也没有网上有些人说的提升 50% 这么恐怖（有可能他们使用的是10年前的JVM来测试的吧^_^，比如 《35+ 个 Java 代码性能优化总结》这篇文章。雷总：不服？咱们来跑个分！） 分析字节码级别的差别StringKit.javaStringKitFinal.java 它们在字节码上的差别: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[18:52:08] emacsist:target $ diff /tmp/stringkit.log /tmp/stringkit-final.log1,5c1,5&lt; Classfile /Users/emacsist/Documents/idea/logging/target/classes/org/agoncal/sample/jmh/StringKit.class&lt; Last modified 2017-6-15; size 1098 bytes&lt; MD5 checksum fe1ccdde26107e4037afc54c780f2c95&lt; Compiled from "StringKit.java"&lt; public class org.agoncal.sample.jmh.StringKit---&gt; Classfile /Users/emacsist/Documents/idea/logging/target/classes/org/agoncal/sample/jmh/StringKitFinal.class&gt; Last modified 2017-6-15; size 1118 bytes&gt; MD5 checksum 410f8bf0eb723b794e4754c6eb8b9829&gt; Compiled from "StringKitFinal.java"&gt; public class org.agoncal.sample.jmh.StringKitFinal24c24&lt; #15 = Class #52 // org/agoncal/sample/jmh/StringKit---&gt; #15 = Class #52 // org/agoncal/sample/jmh/StringKitFinal32,33c32,33&lt; #23 = Utf8 Lorg/agoncal/sample/jmh/StringKit;&lt; #24 = Utf8 getStringRandom---&gt; #23 = Utf8 Lorg/agoncal/sample/jmh/StringKitFinal;&gt; #24 = Utf8 getStringRandomFinal47c47&lt; #38 = Utf8 StringKit.java---&gt; #38 = Utf8 StringKitFinal.java61c61&lt; #52 = Utf8 org/agoncal/sample/jmh/StringKit---&gt; #52 = Utf8 org/agoncal/sample/jmh/StringKitFinal75c75&lt; public org.agoncal.sample.jmh.StringKit();---&gt; public org.agoncal.sample.jmh.StringKitFinal();87c87&lt; 0 5 0 this Lorg/agoncal/sample/jmh/StringKit;---&gt; 0 5 0 this Lorg/agoncal/sample/jmh/StringKitFinal;89c89&lt; public static java.lang.String getStringRandom(int);---&gt; public static final java.lang.String getStringRandomFinal(int);91c91&lt; flags: ACC_PUBLIC, ACC_STATIC---&gt; flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL187c187&lt; SourceFile: "StringKit.java"---&gt; SourceFile: "StringKitFinal.java" 可以看到除了方法名和方法修饰符不同之外，其他的没有什么区别了。 在调用者上面的字节码差别1234567891011121314151617181920212223242526272829303132333435public void benchmark(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: bipush 32 2: invokestatic #2 // Method org/agoncal/sample/jmh/StringKit.getStringRandom:(I)Ljava/lang/String; 5: pop 6: return LineNumberTable: line 21: 0 line 22: 6 LocalVariableTable: Start Length Slot Name Signature 0 7 0 this Lorg/agoncal/sample/jmh/Main; RuntimeVisibleAnnotations: 0: #26()public void benchmarkFinal(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: bipush 32 2: invokestatic #3 // Method org/agoncal/sample/jmh/StringKitFinal.getStringRandomFinal:(I)Ljava/lang/String; 5: pop 6: return LineNumberTable: line 26: 0 line 27: 6 LocalVariableTable: Start Length Slot Name Signature 0 7 0 this Lorg/agoncal/sample/jmh/Main; RuntimeVisibleAnnotations: 0: #26() 可以看到，它们在调用者上面的字节码也没有什么区别，只是方法名不一样之外。 对于 JVM 来说，它是只认字节码的，既然字节码除了方法名和修饰符一样，其他都一样，那就可以大概推测它们的性能几乎可以忽略不计了。因为调用 static final 和 static 非 final 的JVM指令是一样。 无 static 修饰方法体是一样的，只是将它们删除了 static 的修饰。 结果123456789101112131415161718192021222324252627282930313233343536373839# JMH version: 1.19# VM version: JDK 1.8.0_92, VM 25.92-b14# VM invoker: /srv/jdk1.8.0_92/jre/bin/java# VM options: &lt;none&gt;# Warmup: 20 iterations, 1 s each# Measurement: 20 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: org.agoncal.sample.jmh.Main.benchmark中间忽略了预热及测试过程，这里只显示结果Result "org.agoncal.sample.jmh.Main.benchmark": 201306.770 ±(99.9%) 8184.423 ops/s [Average] (min, avg, max) = (131889.934, 201306.770, 259928.172), stdev = 34653.361 CI (99.9%): [193122.347, 209491.193] (assumes normal distribution)# JMH version: 1.19# VM version: JDK 1.8.0_92, VM 25.92-b14# VM invoker: /srv/jdk1.8.0_92/jre/bin/java# VM options: &lt;none&gt;# Warmup: 20 iterations, 1 s each# Measurement: 20 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: org.agoncal.sample.jmh.Main.benchmarkFinal中间忽略了预热及测试过程，这里只显示结果Result "org.agoncal.sample.jmh.Main.benchmarkFinal": 196871.022 ±(99.9%) 8595.719 ops/s [Average] (min, avg, max) = (131182.268, 196871.022, 265522.769), stdev = 36394.814 CI (99.9%): [188275.302, 205466.741] (assumes normal distribution) # Run complete. Total time: 00:13:35Benchmark Mode Cnt Score Error UnitsMain.benchmark thrpt 200 201306.770 ± 8184.423 ops/sMain.benchmarkFinal thrpt 200 196871.022 ± 8595.719 ops/s 分析字节码级别的差别12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[19:20:17] emacsist:target $ diff /tmp/stringkit.log /tmp/stringkit-final.log1,5c1,5&lt; Classfile /Users/emacsist/Documents/idea/logging/target/classes/org/agoncal/sample/jmh/StringKit.class&lt; Last modified 2017-6-15; size 1110 bytes&lt; MD5 checksum f61144e86f7c17dc5d5f2b2d35fac36d&lt; Compiled from "StringKit.java"&lt; public class org.agoncal.sample.jmh.StringKit---&gt; Classfile /Users/emacsist/Documents/idea/logging/target/classes/org/agoncal/sample/jmh/StringKitFinal.class&gt; Last modified 2017-6-15; size 1130 bytes&gt; MD5 checksum 15ce17ee17fdb5f4721f0921977b1e69&gt; Compiled from "StringKitFinal.java"&gt; public class org.agoncal.sample.jmh.StringKitFinal24c24&lt; #15 = Class #52 // org/agoncal/sample/jmh/StringKit---&gt; #15 = Class #52 // org/agoncal/sample/jmh/StringKitFinal32,33c32,33&lt; #23 = Utf8 Lorg/agoncal/sample/jmh/StringKit;&lt; #24 = Utf8 getStringRandom---&gt; #23 = Utf8 Lorg/agoncal/sample/jmh/StringKitFinal;&gt; #24 = Utf8 getStringRandomFinal47c47&lt; #38 = Utf8 StringKit.java---&gt; #38 = Utf8 StringKitFinal.java61c61&lt; #52 = Utf8 org/agoncal/sample/jmh/StringKit---&gt; #52 = Utf8 org/agoncal/sample/jmh/StringKitFinal75c75&lt; public org.agoncal.sample.jmh.StringKit();---&gt; public org.agoncal.sample.jmh.StringKitFinal();87c87&lt; 0 5 0 this Lorg/agoncal/sample/jmh/StringKit;---&gt; 0 5 0 this Lorg/agoncal/sample/jmh/StringKitFinal;89c89&lt; public java.lang.String getStringRandom(int);---&gt; public final java.lang.String getStringRandomFinal(int);91c91&lt; flags: ACC_PUBLIC---&gt; flags: ACC_PUBLIC, ACC_FINAL169c169&lt; 0 125 0 this Lorg/agoncal/sample/jmh/StringKit;---&gt; 0 125 0 this Lorg/agoncal/sample/jmh/StringKitFinal;188c188&lt; SourceFile: "StringKit.java"---&gt; SourceFile: "StringKitFinal.java" 可以看到，字节码上除了名字和 final 修饰符差别外，其余的是一样的。 在调用者上面的字节码差别1234567891011121314151617181920212223242526272829303132333435363738394041public void benchmark(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: new #2 // class org/agoncal/sample/jmh/StringKit 3: dup 4: invokespecial #3 // Method org/agoncal/sample/jmh/StringKit."&lt;init&gt;":()V 7: bipush 32 9: invokevirtual #4 // Method org/agoncal/sample/jmh/StringKit.getStringRandom:(I)Ljava/lang/String; 12: pop 13: return LineNumberTable: line 21: 0 line 22: 13 LocalVariableTable: Start Length Slot Name Signature 0 14 0 this Lorg/agoncal/sample/jmh/Main; RuntimeVisibleAnnotations: 0: #30()public void benchmarkFinal(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: new #5 // class org/agoncal/sample/jmh/StringKitFinal 3: dup 4: invokespecial #6 // Method org/agoncal/sample/jmh/StringKitFinal."&lt;init&gt;":()V 7: bipush 32 9: invokevirtual #7 // Method org/agoncal/sample/jmh/StringKitFinal.getStringRandomFinal:(I)Ljava/lang/String; 12: pop 13: return LineNumberTable: line 26: 0 line 27: 13 LocalVariableTable: Start Length Slot Name Signature 0 14 0 this Lorg/agoncal/sample/jmh/Main; RuntimeVisibleAnnotations: 0: #30() 可以看到，它们除了名字不同之外，其他的JVM指令都是一样的。 总结对于是否有 final 修饰的方法，对性能的影响可以忽略不计。因为它们生成的字节码除了 flags 标志位是否有 final 修饰不同之外，其他所有的JVM指令，都是一样的（对于方法本身，以及调用者本身的字节码都一样）。对于JVM来说，它执行的就是字节码，如果字节码都一样的话，那对于JVM来说，它就是同一样东西的了。 有继承无 final 修饰123456789101112131415161718192021222324252627package org.agoncal.sample.jmh;import java.util.Random;/** * Created by emacsist on 2017/6/15. */public abstract class StringKitAbs &#123; // 生成随机数字和字母, public String getStringRandom(int length) &#123; String val = ""; Random random = new Random(); // 参数length，表示生成几位随机数 for (int i = 0; i &lt; length; i++) &#123; String charOrNum = random.nextInt(2) % 2 == 0 ? "char" : "num"; // 输出字母还是数字 if ("char".equalsIgnoreCase(charOrNum)) &#123; // 输出是大写字母还是小写字母 // int temp = random.nextInt(2) % 2 == 0 ? 65 : 97; val += (char) (random.nextInt(26) + 97); &#125; else if ("num".equalsIgnoreCase(charOrNum)) &#123; val += String.valueOf(random.nextInt(10)); &#125; &#125; return val; &#125;&#125; 有 final 修饰123456789101112131415161718192021222324252627package org.agoncal.sample.jmh;import java.util.Random;/** * Created by emacsist on 2017/6/15. */public abstract class StringKitAbsFinal &#123; // 生成随机数字和字母, public final String getStringRandomFinal(int length) &#123; String val = ""; Random random = new Random(); // 参数length，表示生成几位随机数 for (int i = 0; i &lt; length; i++) &#123; String charOrNum = random.nextInt(2) % 2 == 0 ? "char" : "num"; // 输出字母还是数字 if ("char".equalsIgnoreCase(charOrNum)) &#123; // 输出是大写字母还是小写字母 // int temp = random.nextInt(2) % 2 == 0 ? 65 : 97; val += (char) (random.nextInt(26) + 97); &#125; else if ("num".equalsIgnoreCase(charOrNum)) &#123; val += String.valueOf(random.nextInt(10)); &#125; &#125; return val; &#125;&#125; 测试代码写一个类来继承上面的抽象类，以此来测试在继承中 final 有否对多态中的影响 12345678package org.agoncal.sample.jmh;/** * Created by emacsist on 2017/6/15. */public class StringKitFinal extends StringKitAbsFinal &#123;&#125; 123456789package org.agoncal.sample.jmh;/** * Created by emacsist on 2017/6/15. */public class StringKit extends StringKitAbs &#123;&#125; 然后在基准测试中: 123456789@Benchmarkpublic void benchmark() &#123; new StringKit().getStringRandom(32);&#125;@Benchmarkpublic void benchmarkFinal() &#123; new StringKitFinal().getStringRandomFinal(32);&#125; 测试结果非 final 结果 1234567891011121314151617# JMH version: 1.19# VM version: JDK 1.8.0_92, VM 25.92-b14# VM invoker: /srv/jdk1.8.0_92/jre/bin/java# VM options: &lt;none&gt;# Warmup: 20 iterations, 1 s each# Measurement: 20 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: org.agoncal.sample.jmh.Main.benchmark中间忽略了预热及测试过程Result "org.agoncal.sample.jmh.Main.benchmark": 213462.677 ±(99.9%) 8670.164 ops/s [Average] (min, avg, max) = (135751.428, 213462.677, 264182.887), stdev = 36710.017 CI (99.9%): [204792.513, 222132.841] (assumes normal distribution) 有 final 结果 1234567891011121314151617# JMH version: 1.19# VM version: JDK 1.8.0_92, VM 25.92-b14# VM invoker: /srv/jdk1.8.0_92/jre/bin/java# VM options: &lt;none&gt;# Warmup: 20 iterations, 1 s each# Measurement: 20 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: org.agoncal.sample.jmh.Main.benchmarkFinal中间忽略了预热及测试过程Result "org.agoncal.sample.jmh.Main.benchmarkFinal": 213684.585 ±(99.9%) 8571.512 ops/s [Average] (min, avg, max) = (133472.162, 213684.585, 267742.236), stdev = 36292.318 CI (99.9%): [205113.073, 222256.097] (assumes normal distribution) 总对比 12345# Run complete. Total time: 00:13:35Benchmark Mode Cnt Score Error UnitsMain.benchmark thrpt 200 213462.677 ± 8670.164 ops/sMain.benchmarkFinal thrpt 200 213684.585 ± 8571.512 ops/s 它们字节码的区别123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[12:12:19] emacsist:classes $ diff /tmp/StringKit.log /tmp/StringKitFinal.log1,5c1,5&lt; Classfile /Users/emacsist/Documents/idea/logging/target/classes/org/agoncal/sample/jmh/StringKit.class&lt; Last modified 2017-6-16; size 317 bytes&lt; MD5 checksum 7f9b024adc7f39345215e3e8490cafe4&lt; Compiled from "StringKit.java"&lt; public class org.agoncal.sample.jmh.StringKit extends org.agoncal.sample.jmh.StringKitAbs---&gt; Classfile /Users/emacsist/Documents/idea/logging/target/classes/org/agoncal/sample/jmh/StringKitFinal.class&gt; Last modified 2017-6-16; size 337 bytes&gt; MD5 checksum f54eadc79a90675d97e95f766ef88a87&gt; Compiled from "StringKitFinal.java"&gt; public class org.agoncal.sample.jmh.StringKitFinal extends org.agoncal.sample.jmh.StringKitAbsFinal10,12c10,12&lt; #1 = Methodref #3.#13 // org/agoncal/sample/jmh/StringKitAbs."&lt;init&gt;":()V&lt; #2 = Class #14 // org/agoncal/sample/jmh/StringKit&lt; #3 = Class #15 // org/agoncal/sample/jmh/StringKitAbs---&gt; #1 = Methodref #3.#13 // org/agoncal/sample/jmh/StringKitAbsFinal."&lt;init&gt;":()V&gt; #2 = Class #14 // org/agoncal/sample/jmh/StringKitFinal&gt; #3 = Class #15 // org/agoncal/sample/jmh/StringKitAbsFinal19c19&lt; #10 = Utf8 Lorg/agoncal/sample/jmh/StringKit;---&gt; #10 = Utf8 Lorg/agoncal/sample/jmh/StringKitFinal;21c21&lt; #12 = Utf8 StringKit.java---&gt; #12 = Utf8 StringKitFinal.java23,24c23,24&lt; #14 = Utf8 org/agoncal/sample/jmh/StringKit&lt; #15 = Utf8 org/agoncal/sample/jmh/StringKitAbs---&gt; #14 = Utf8 org/agoncal/sample/jmh/StringKitFinal&gt; #15 = Utf8 org/agoncal/sample/jmh/StringKitAbsFinal26c26&lt; public org.agoncal.sample.jmh.StringKit();---&gt; public org.agoncal.sample.jmh.StringKitFinal();32c32&lt; 1: invokespecial #1 // Method org/agoncal/sample/jmh/StringKitAbs."&lt;init&gt;":()V---&gt; 1: invokespecial #1 // Method org/agoncal/sample/jmh/StringKitAbsFinal."&lt;init&gt;":()V38c38&lt; 0 5 0 this Lorg/agoncal/sample/jmh/StringKit;---&gt; 0 5 0 this Lorg/agoncal/sample/jmh/StringKitFinal;40c40&lt; SourceFile: "StringKit.java"---&gt; SourceFile: "StringKitFinal.java" 可以看到，除了它们的方法签名和方法名字不同之外其他的都是一样的，包括JVM调用指令也完全是一样的。 总结可以看到它们几乎是一样的。 总结基于上面的基准测试结论，我认为滥用或刻意为了所谓的提升性能，而去为每一个方法尽可能添加 final 的关键字是不可取的。使用 final ，更多的应该是根据Java对 final 的语义来定义，而不是只想着为了提升性能（而且这影响可以忽略不计）而刻意用 final. 使用 final 的情况: final 变量: 表示只读（只初始化一次，但可多次读取）final 方法：表示子类不可以重写。（网上认为 final 比非 final 快，就是认为它是在编译的时候已经静态绑定了，不需要在运行时再动态绑定。这个可能以前的JVM上是正确的，但在现代的JVM上，这个可以认为没什么影响，至少我在基准测试里是这样子）final 类： 它们不能被继承，而且final类的方法，默认也是 final 的。 关于这个 final 的性能问题，我也Google了下，发现 stackoverflow 上，也有类似的问题： 参考资料 stackoverflow]]></content>
      <tags>
        <tag>java</tag>
        <tag>performance</tag>
        <tag>final</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的基准测试JMH简单使用]]></title>
    <url>%2F2017%2F06%2F12%2FJava%E4%B8%AD%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95JMH%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[使用命令行请参考官方网站: openjdk jmh Mavenpom.xml 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-core&lt;/artifactId&gt; &lt;version&gt;1.15&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-generator-annprocess&lt;/artifactId&gt; &lt;version&gt;1.15&lt;/version&gt;&lt;/dependency&gt; 使用示例: 123456789101112131415161718192021222324252627282930313233343536import org.openjdk.jmh.annotations.*;import org.openjdk.jmh.runner.Runner;import org.openjdk.jmh.runner.RunnerException;import org.openjdk.jmh.runner.options.Options;import org.openjdk.jmh.runner.options.OptionsBuilder;import java.util.concurrent.TimeUnit;/** * Created by emacsist on 2017/6/12. */@BenchmarkMode(Mode.Throughput)@OutputTimeUnit(TimeUnit.MICROSECONDS)@State(Scope.Thread)public class BenchmarkTest &#123; @Benchmark public void testJSON()&#123; add(1, 3); &#125; public static int add(int a, int b)&#123; return a + b; &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(BenchmarkTest.class.getSimpleName()) .forks(1) .warmupIterations(5) .measurementIterations(5) .threads(10) .build(); new Runner(opt).run(); &#125;&#125; 说明Mode：表示测试类型，它有 Throughput（吞吐量）， AverageTime（平均时间）， SampleTime（取样时间）， SingleShotTime（测量单次操作），All（前面所有类型）OutputTimeUnit：输出的时间单位 warmupIterations：表示预热，消除JIT的影响measurementIterations：表示测量的次数 输出例子比如上面的代码的输出为 123456789101112131415161718192021222324# Warmup Iteration 1: 2304.433 ops/us# Warmup Iteration 2: 2817.992 ops/us# Warmup Iteration 3: 3895.650 ops/us# Warmup Iteration 4: 3912.852 ops/us# Warmup Iteration 5: 4092.241 ops/usIteration 1: 4133.110 ops/usIteration 2: 4465.652 ops/usIteration 3: 4754.479 ops/usIteration 4: 5023.710 ops/usIteration 5: 4653.248 ops/usResult "testJSON": 4606.040 ±(99.9%) 1280.132 ops/us [Average] (min, avg, max) = (4133.110, 4606.040, 5023.710), stdev = 332.446 CI (99.9%): [3325.908, 5886.172] (assumes normal distribution)# Run complete. Total time: 00:00:12Benchmark Mode Cnt Score Error UnitsBenchmarkTest.testJSON thrpt 5 4606.040 ± 1280.132 ops/usProcess finished with exit code 0]]></content>
      <tags>
        <tag>Java</tag>
        <tag>benchmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DSP系统中JSON解析性能对比Java 与 Golang]]></title>
    <url>%2F2017%2F06%2F12%2FDSP%E7%B3%BB%E7%BB%9F%E4%B8%ADJSON%E8%A7%A3%E6%9E%90%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94Java-%E4%B8%8E-Golang%2F</url>
    <content type="text"><![CDATA[Java中的性能测试代码: 1234567891011121314151617181920212223242526272829303132333435363738```bashpackage com.company.benchmark;import com.fasterxml.jackson.databind.JsonNode;import com.company.util.JsonUtil;import org.openjdk.jmh.annotations.*;import org.openjdk.jmh.runner.Runner;import org.openjdk.jmh.runner.RunnerException;import org.openjdk.jmh.runner.options.Options;import org.openjdk.jmh.runner.options.OptionsBuilder;import java.util.concurrent.TimeUnit;/** * Created by emacsist on 2017/6/12. */@BenchmarkMode(Mode.SingleShotTime)@OutputTimeUnit(TimeUnit.NANOSECONDS)@State(Scope.Thread)public class BenchmarkJSON &#123; @Benchmark public void testJSON()&#123; String json = "&#123;\"id\":\"1\",\"user\":&#123;\"id\":\"426b466fe00e698a2b718079afff962f\"&#125;,\"rule\":[\"50284\",\"56415\",\"56416\",\"56417\",\"56418\",\"56419\",\"56420\",\"56421\",\"56422\",\"56423\",\"57034\",\"57036\",\"9078\"],\"imp\":[&#123;\"bidfloor\":800,\"ext\":&#123;\"repeat\":1&#125;,\"feed\":&#123;\"type\":0&#125;,\"id\":\"25263317556521\",\"bidfloorcur\":\"RMB\",\"tagid\":\"1000000002\"&#125;,&#123;\"bidfloor\":100000,\"ext\":&#123;\"repeat\":1&#125;,\"feed\":&#123;\"type\":0&#125;,\"id\":\"25263317556522\",\"bidfloorcur\":\"RMB\",\"tagid\":\"1000000002\"&#125;],\"app\":&#123;\"name\":\"weibo\",\"id\":\"iamappidinwax\"&#125;,\"device\":&#123;\"geo\":&#123;&#125;,\"carrier\":\"\",\"model\":\"OPPO_OPPO A37t\",\"ua\":\"OPPO-OPPO A37t__weibo__6.11.1__android__android5.1\",\"ip\":\"113.227.98.236\",\"ext\":&#123;&#125;,\"connectiontype\":2,\"os\":\"android\",\"osv\":\"5.1\"&#125;,\"dealid\":\"47cd7e122ade3d12e312c5eb6e68bc6e\",\"at\":2&#125;"; JsonNode node = JsonUtil.readTree(json); &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(BenchmarkJSON.class.getSimpleName()) .forks(1) .warmupIterations(5) .measurementIterations(5) .threads(500) .build(); new Runner(opt).run(); &#125; 结果： 1234567891011Percentiles, ns/op: p(0.0000) = 58682.052 ns/op p(50.0000) = 61242.538 ns/op p(90.0000) = 62028.112 ns/op p(95.0000) = 62028.112 ns/op p(99.0000) = 62028.112 ns/op p(99.9000) = 62028.112 ns/op p(99.9900) = 62028.112 ns/op p(99.9990) = 62028.112 ns/op p(99.9999) = 62028.112 ns/op p(100.0000) = 62028.112 ns/op 单线程版本:即将上面的 threads 删除掉: 1234567891011Percentiles, ns/op: p(0.0000) = 346423.000 ns/op p(50.0000) = 663625.000 ns/op p(90.0000) = 749015.000 ns/op p(95.0000) = 749015.000 ns/op p(99.0000) = 749015.000 ns/op p(99.9000) = 749015.000 ns/op p(99.9900) = 749015.000 ns/op p(99.9990) = 749015.000 ns/op p(99.9999) = 749015.000 ns/op p(100.0000) = 749015.000 ns/op Golang 中的性能测试代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445package testimport ( "encoding/json" "testing" "github.com/pquerna/ffjson/ffjson" "github.com/company/golang-dsp-bid/bean")func BenchmarkJson(b *testing.B) &#123; j := `&#123;"id":"1","user":&#123;"id":"426b466fe00c698a2b718079efff962f"&#125;,"rule":["50284","56415","56416","56417","56418","56419","56420","56421","56422","56423","57034","57036","9078"],"imp":[&#123;"bidfloor":100000,"ext":&#123;"repeat":1&#125;,"feed":&#123;"type":0&#125;,"id":"25263317556521","bidfloorcur":"RMB","tagid":"1000000002"&#125;,&#123;"bidfloor":800,"ext":&#123;"repeat":1&#125;,"feed":&#123;"type":0&#125;,"id":"25263317556522","bidfloorcur":"RMB","tagid":"1000000002"&#125;],"app":&#123;"name":"weibo","id":"iamappidinwax"&#125;,"device":&#123;"geo":&#123;&#125;,"carrier":"","model":"OPPO_OPPO A37t","ua":"OPPO-OPPO A37t__weibo__6.11.1__android__android5.1","ip":"1.1.1.1","ext":&#123;&#125;,"connectiontype":2,"os":"android","osv":"5.1"&#125;,"dealid":"47cd7e122ade3d12e312c5eb6e68bc6e","at":2&#125;` for i := 0; i &lt; b.N; i++ &#123; var bidRequest bean.BidRequest e := json.Unmarshal([]byte(j), &amp;bidRequest) if e != nil &#123; panic(e) &#125; &#125;&#125;func BenchmarkFFJsonFast(b *testing.B) &#123; j := `&#123;"id":"1","user":&#123;"id":"426b466fe00c698a2b718079efff962f"&#125;,"rule":["50284","56415","56416","56417","56418","56419","56420","56421","56422","56423","57034","57036","9078"],"imp":[&#123;"bidfloor":100000,"ext":&#123;"repeat":1&#125;,"feed":&#123;"type":0&#125;,"id":"25263317556521","bidfloorcur":"RMB","tagid":"1000000002"&#125;,&#123;"bidfloor":800,"ext":&#123;"repeat":1&#125;,"feed":&#123;"type":0&#125;,"id":"25263317556522","bidfloorcur":"RMB","tagid":"1000000002"&#125;],"app":&#123;"name":"weibo","id":"iamappidinwax"&#125;,"device":&#123;"geo":&#123;&#125;,"carrier":"","model":"OPPO_OPPO A37t","ua":"OPPO-OPPO A37t__weibo__6.11.1__android__android5.1","ip":"1.1.1.1","ext":&#123;&#125;,"connectiontype":2,"os":"android","osv":"5.1"&#125;,"dealid":"47cd7e122ade3d12e312c5eb6e68bc6e","at":2&#125;` for i := 0; i &lt; b.N; i++ &#123; var bidRequest bean.BidRequest e := ffjson.UnmarshalFast([]byte(j), &amp;bidRequest) if e != nil &#123; panic(e) &#125; &#125;&#125;func BenchmarkFFJson(b *testing.B) &#123; j := `&#123;"id":"1","user":&#123;"id":"426b466fe00c698a2b718079efff962f"&#125;,"rule":["50284","56415","56416","56417","56418","56419","56420","56421","56422","56423","57034","57036","9078"],"imp":[&#123;"bidfloor":100000,"ext":&#123;"repeat":1&#125;,"feed":&#123;"type":0&#125;,"id":"25263317556521","bidfloorcur":"RMB","tagid":"1000000002"&#125;,&#123;"bidfloor":800,"ext":&#123;"repeat":1&#125;,"feed":&#123;"type":0&#125;,"id":"25263317556522","bidfloorcur":"RMB","tagid":"1000000002"&#125;],"app":&#123;"name":"weibo","id":"iamappidinwax"&#125;,"device":&#123;"geo":&#123;&#125;,"carrier":"","model":"OPPO_OPPO A37t","ua":"OPPO-OPPO A37t__weibo__6.11.1__android__android5.1","ip":"1.1.1.1","ext":&#123;&#125;,"connectiontype":2,"os":"android","osv":"5.1"&#125;,"dealid":"47cd7e122ade3d12e312c5eb6e68bc6e","at":2&#125;` for i := 0; i &lt; b.N; i++ &#123; var bidRequest bean.BidRequest e := ffjson.Unmarshal([]byte(j), &amp;bidRequest) if e != nil &#123; panic(e) &#125; &#125;&#125;` 结果: 123456[15:38:13] emacsist:test git:(master*) $ go test -v -bench=.BenchmarkJson-4 50000 31739 ns/opBenchmarkFFJsonFast-4 100000 21533 ns/opBenchmarkFFJson-4 100000 21390 ns/opPASSok github.com/company/golang-dsp-bid/test 6.682s]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Golang</tag>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang优化DSP系统一例]]></title>
    <url>%2F2017%2F06%2F08%2FGolang%E4%BC%98%E5%8C%96DSP%E7%B3%BB%E7%BB%9F%E4%B8%80%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[JSON 解析更新：2017-6-12！！这里有问题，参考下文 因为是与微博WAX那边对接，使用的是JSON序列化协议，但偏偏Golang的标准库里的JSON解析却极慢。然后使用了 ffjson ，到 easyjson ，最后到现在的 jsoniter : 123data, _ := ioutil.ReadAll(request.Body)var bidRequest bean.BidRequesterr := jsoniter.Unmarshal(data, &amp;bidRequest) easyjson 比 ffjson 还快一点（但不是很明显），最后测试用了下 jsoniter ，发现差距还是很大（当然，要检测反序列化出来的结果是一致的，这个库还是有点限制，目前对自定义的 json 接口不友好） 下面是使用 ffjson 时监测到的性能数据 123456. . 20: if request.Method == "POST" &#123;. . 21: s := utils.CurrentMillis(). 140ms 22: data, _ := ioutil.ReadAll(request.Body). . 23: //logrus.Infof("receive body =&gt;%v", string(data)). 20ms 24: var bidRequest bean.BidRequest. 490ms 25: err := ffjson.UnmarshalFast(data, &amp;bidRequest) 下面是使用 jsoniter 时监测到的性能数据 123456. . 21: if request.Method == "POST" &#123;. . 22: s := utils.CurrentMillis(). 110ms 23: data, _ := ioutil.ReadAll(request.Body). . 24: //logrus.Infof("receive body =&gt;%v", string(data)). . 25: var bidRequest bean.BidRequest. 80ms 26: err := jsoniter.Unmarshal(data, &amp;bidRequest) 可以看到，还是提升得很大的。 这个 jsoniter 有内存泄漏的问题 ！！！！！后感：看来以后用国产的东西，真心要注意，打醒十二万精神！！！还是弃用它了，凡是打着高性能的旗号的，极可能写的代码是有问题的！换了这个JSON库后，内存升到 54% 多了（8GB物理内存），一般情况下，该进程占用的内存为 2%, 3 % 左右。 异步获取数据在进行性能监测时，发现有个方法占用了极大的总时间: 123456789101112130 960ms (flat, cum) 24.55% of Total. . 3:import "github.com/company/golang-dsp-bid/bean". . 4:. . 5:// CheckServiceISOk :. . 6:// check ok. . 7:func CheckServiceISOk(task *bean.TaskPostAd, price int32) bool &#123;. 520ms 8: taskMoneyMap := GetTaskMoneyRedis(task). 250ms 9: clientMoneyMap := GetClientMoney(task.UserID, task.ClientID). 190ms 10: userMoneyMap := GetUserMoney(task.UserID). . 11:. . 12: if len(taskMoneyMap) == 0 || len(clientMoneyMap) == 0 || len(userMoneyMap) == 0 &#123;. . 13: return false. . 14: &#125; 这个是检测金额是否OK的，因为这里是串行了，所以时间是累加的，这里的结果是取样时累计的耗时(即30秒内，这个方法累计耗时)为 960ms 。 其实这里是可以分3个 goroutine 来获取，然后再汇总: 12345678910111213141516171819202122232425262728293031323334353637383940414243/Users/emacsist/Documents/go/company/dsp-bid/src/github.com/company/golang-dsp-bid/service/CheckService.go 0 410ms (flat, cum) 9.40% of Total . . 12: . . 13: var taskMoneyMap map[string]string . . 14: wg.Add(1) . . 15: go func(wg *sync.WaitGroup) &#123; . . 16: defer wg.Done() . 370ms 17: taskMoneyMap = GetTaskMoneyRedis(task) . 40ms 18: &#125;(&amp;wg) . . 19: . . 20: var clientMoneyMap map[string]string . . 21: wg.Add(1) . . 22: go func(wg *sync.WaitGroup) &#123; . . 23: defer wg.Done()ROUTINE ======================== github.com/company/golang-dsp-bid/service.CheckServiceISOk.func2 in /Users/emacsist/Documents/go/company/dsp-bid/src/github.com/company/golang-dsp-bid/service/CheckService.go 10ms 170ms (flat, cum) 3.90% of Total . . 17: taskMoneyMap = GetTaskMoneyRedis(task) . . 18: &#125;(&amp;wg) . . 19: . . 20: var clientMoneyMap map[string]string . . 21: wg.Add(1) 10ms 10ms 22: go func(wg *sync.WaitGroup) &#123; . . 23: defer wg.Done() . 160ms 24: clientMoneyMap = GetClientMoney(task.UserID, task.ClientID) . . 25: &#125;(&amp;wg) . . 26: . . 27: var userMoneyMap map[string]string . . 28: wg.Add(1) . . 29: go func(wg *sync.WaitGroup) &#123;ROUTINE ======================== github.com/company/golang-dsp-bid/service.CheckServiceISOk.func3 in /Users/emacsist/Documents/go/company/dsp-bid/src/github.com/company/golang-dsp-bid/service/CheckService.go 0 190ms (flat, cum) 4.36% of Total . . 26: . . 27: var userMoneyMap map[string]string . . 28: wg.Add(1) . . 29: go func(wg *sync.WaitGroup) &#123; . . 30: defer wg.Done() . 180ms 31: userMoneyMap = GetUserMoney(task.UserID) . 10ms 32: &#125;(&amp;wg) . . 33: . . 34: wg.Wait() . . 35: . . 36: if len(taskMoneyMap) == 0 || len(clientMoneyMap) == 0 || len(userMoneyMap) == 0 &#123; . . 37: return false 优化完后，可以看到降低到 410ms 了（因为是异步，所以总时间是最大那个的耗时）]]></content>
      <tags>
        <tag>golang</tag>
        <tag>dsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下源码调试Redis]]></title>
    <url>%2F2017%2F06%2F05%2FMac%E4%B8%8B%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95Redis%2F</url>
    <content type="text"><![CDATA[安装和配置好GDB权限参考下面安装GNU工具集 Mac下安装GNU工具集 然后还要进行 GDB 签名 codesign GDB 重新编译 redisredis 官方文档Debug指南]]></content>
      <tags>
        <tag>redis</tag>
        <tag>gdb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 汇编杂项]]></title>
    <url>%2F2017%2F06%2F02%2FGolang-%E6%B1%87%E7%BC%96%E6%9D%82%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[查看Go源码输出的汇编代码12345678go tool compile -S hello.go或go tool objdump -s "main\.main" hello或go tool compile -N -S hello.go最好用这个，这种是禁止优化的 小例子只有一个返回值1234567891011[22:58:38] emacsist:Desktop $ cat hello.gopackage mainfunc main() &#123; a, b := 3, 4 println(add(a, b))&#125;func add(a, b int) int &#123; return a + b&#125; 输出的汇编代码: 1234567891011"".add t=1 size=19 args=0x18 locals=0x0 0x0000 00000 (hello.go:8) TEXT "".add(SB), $0-24 0x0000 00000 (hello.go:8) FUNCDATA $0, gclocals·54241e171da8af6ae173d69da0236748(SB) 0x0000 00000 (hello.go:8) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (hello.go:9) MOVQ "".b+16(FP), AX 0x0005 00005 (hello.go:9) MOVQ "".a+8(FP), CX 0x000a 00010 (hello.go:9) ADDQ CX, AX 0x000d 00013 (hello.go:9) MOVQ AX, "".~r2+24(FP) 0x0012 00018 (hello.go:9) RET 0x0000 48 8b 44 24 10 48 8b 4c 24 08 48 01 c8 48 89 44 H.D$.H.L$.H..H.D 0x0010 24 18 c3 $.. FP =&gt; 指向栈底（高位内存地址）(Frame pointer)SP =&gt; 指向栈顶（低位内存地址）(Stack pointer) “”.add =&gt; 表示命名空间，这就是上面源码中的 add 函数 t =&gt; 这个我也不知道表示什么意思。。。有知道的，麻烦告知一下 ^_^ size =&gt; 表示这个函数是 19 个字节 args =&gt; 表示参数总占字节数（16进制显示） locals =&gt; 表示局部变量（即在函数内部的变量）的总字节数（16进制显示） TEXT “”.add(SB), $0-24 =&gt; 这表示代码段(TEXT)，SB(Static Base)表示函数 add 的地址，$0：表示局部变量总字节数（十进制显示）, -24：表示参数总占字节数(十进制显示)（包括传入和返回参数的总字节数之和），因为这里一共3个 int, 3*8=24 . 可以这样子输出它的大小: fmt.Printf(&quot;a: %T, %d\n&quot;, a, unsafe.Sizeof(a)) ，我这里输出为: a: int, 8 FUNCDATA =&gt; 这个是与垃圾收集器相关的，这里不理它 MOVQ “”.b+16(FP), AX =&gt; MOVQ表示移动2个字（1字=2字节=16位，所以这里是32位，可以用一个32位的寄存器来保存，这里为AX）。即 FP + 16 (即是变量b的内存数据)， FP + 8 （即是变量a的内存数据）。从这里可以推出，Golang中处理参数是从左到右顺序压入栈的。 ADDQ CX, AX =&gt; 前面已经将变量b的数据放到了 AX， 变量a的数据放到了CX， 这里就将它们相加，然后再保存到 AX 寄存器中。 MOVQ AX, “”.~r2+24(FP) =&gt; 将返回结果（结果保存到了AX）保存到栈的 FP+24 的位置。~r2 表示参数的位置（位置是按从函数左到右的参数顺序开始算起，包括返回参数。 ~r2 表示第2&lt;位置从0开始&gt; 个参数的值为 AX的值。从这里可以推出：返回值的存储地址比参数的存储地址高。 RET =&gt; 函数返回 多个返回值1234567891011package mainfunc main() &#123; a, b, c := 3, 4, 5 a1, s2 := add(a, b, c) println(a1, s2)&#125;func add(a, b, c int) (int, int) &#123; return a + b + c, a + b&#125; 汇编后的代码 1234567891011121314"".add t=1 size=32 args=0x28 locals=0x0 0x0000 00000 (hello.go:9) TEXT "".add(SB), $0-40 0x0000 00000 (hello.go:9) FUNCDATA $0, gclocals·24b0aee1021c20d1590e75b99691b0e0(SB) 0x0000 00000 (hello.go:9) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (hello.go:10) MOVQ "".b+16(FP), AX 0x0005 00005 (hello.go:10) MOVQ "".a+8(FP), CX 0x000a 00010 (hello.go:10) ADDQ CX, AX 0x000d 00013 (hello.go:10) MOVQ "".c+24(FP), CX 0x0012 00018 (hello.go:10) ADDQ AX, CX 0x0015 00021 (hello.go:10) MOVQ CX, "".~r3+32(FP) 0x001a 00026 (hello.go:10) MOVQ AX, "".~r4+40(FP) 0x001f 00031 (hello.go:10) RET 0x0000 48 8b 44 24 10 48 8b 4c 24 08 48 01 c8 48 8b 4c H.D$.H.L$.H..H.L 0x0010 24 18 48 01 c1 48 89 4c 24 20 48 89 44 24 28 c3 $.H..H.L$ H.D$(. 意思和上面的说明大概相同。这里特别说明的是: ~r3 =&gt; 表示第3个参数的值（即返回值）（未命名的情况下）~r4 =&gt; 表示第4个参数的值（即返回值）（未命名的情况下） 如果返回值有命名的话，它是这样子的: 123456789101112131415161718func add(a, b, c int) (d int, e int) &#123; return a + b + c, a + b&#125;"".add t=1 size=32 args=0x28 locals=0x0 0x0000 00000 (hello.go:9) TEXT "".add(SB), $0-40 0x0000 00000 (hello.go:9) FUNCDATA $0, gclocals·24b0aee1021c20d1590e75b99691b0e0(SB) 0x0000 00000 (hello.go:9) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (hello.go:10) MOVQ "".b+16(FP), AX 0x0005 00005 (hello.go:10) MOVQ "".a+8(FP), CX 0x000a 00010 (hello.go:10) ADDQ CX, AX 0x000d 00013 (hello.go:10) MOVQ "".c+24(FP), CX 0x0012 00018 (hello.go:10) ADDQ AX, CX 0x0015 00021 (hello.go:10) MOVQ CX, "".d+32(FP) 0x001a 00026 (hello.go:10) MOVQ AX, "".e+40(FP) 0x001f 00031 (hello.go:10) RET 0x0000 48 8b 44 24 10 48 8b 4c 24 08 48 01 c8 48 8b 4c H.D$.H.L$.H..H.L 0x0010 24 18 48 01 c1 48 89 4c 24 20 48 89 44 24 28 c3 $.H..H.L$ H.D$(. 所以，Go 中多个返回值的实现就是这样子处理的。 函数调用图12345func add(a, b, c int) (d int, e int) &#123; var a1 int = 3 var a2 int = a1 * 3 return a + b + c + a2, a + b + a1&#125; 栈的改变123456789101112131415SP=SP-N，表示是开辟一个空间（进行函数调用）SP=SP+N，表示释放一个空间 （函数调用完毕，返回）低位地址^| | add 函数局部变量2(a2) &lt;------SP| add 函数局部变量1(a1) | main.main 的返回地址 &lt;------FP| add 函数参数1(a) | add 函数参数2(b)| add 函数参数3(c)| add 函数参数返回值1(d)| add 函数参数返回值2(e)高位地址 runtime.main函数返回地址 FP的空间（即所有函数参数和返回值的空间）：它是在调用方进行分配的（即，传入和返回参数的空间，在这个例子里是在 main 函数中分配好的，它属于 main 所在栈的一部分） SP的空间：这个才是 add 的栈 在Go中，每一个 Goroutine 都有它自己的栈空间。 下面是禁用优化后输出的汇编: 1234567891011121314151617181920212223242526272829303132"".add t=1 size=151 args=0x28 locals=0x28 0x0000 00000 (hello.go:9) TEXT "".add(SB), $40-40 0x0000 00000 (hello.go:9) SUBQ $40, SP 0x0004 00004 (hello.go:9) MOVQ BP, 32(SP) 0x0009 00009 (hello.go:9) LEAQ 32(SP), BP 0x000e 00014 (hello.go:9) FUNCDATA $0, gclocals·24b0aee1021c20d1590e75b99691b0e0(SB) 0x000e 00014 (hello.go:9) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 (hello.go:9) MOVQ $0, "".d+72(FP) 0x0017 00023 (hello.go:9) MOVQ $0, "".e+80(FP) 0x0020 00032 (hello.go:9) MOVQ $0, "".e+80(FP) 0x0029 00041 (hello.go:9) MOVQ $0, "".d+72(FP) 0x0032 00050 (hello.go:10) MOVQ $3, "".a1+8(SP) 0x003b 00059 (hello.go:11) MOVQ $9, "".a2(SP) 0x0043 00067 (hello.go:12) MOVQ "".a+48(FP), AX 0x0048 00072 (hello.go:12) MOVQ "".b+56(FP), CX 0x004d 00077 (hello.go:12) MOVQ "".c+64(FP), DX 0x0052 00082 (hello.go:12) ADDQ CX, AX 0x0055 00085 (hello.go:12) LEAQ 9(AX)(DX*1), AX 0x005a 00090 (hello.go:12) MOVQ AX, ""..autotmp_3+24(SP) 0x005f 00095 (hello.go:12) MOVQ "".a+48(FP), AX 0x0064 00100 (hello.go:12) MOVQ "".b+56(FP), CX 0x0069 00105 (hello.go:12) MOVQ "".a1+8(SP), DX 0x006e 00110 (hello.go:12) ADDQ CX, AX 0x0071 00113 (hello.go:12) ADDQ DX, AX 0x0074 00116 (hello.go:12) MOVQ AX, ""..autotmp_4+16(SP) 0x0079 00121 (hello.go:12) MOVQ ""..autotmp_3+24(SP), AX 0x007e 00126 (hello.go:12) MOVQ AX, "".d+72(FP) 0x0083 00131 (hello.go:12) MOVQ ""..autotmp_4+16(SP), AX 0x0088 00136 (hello.go:12) MOVQ AX, "".e+80(FP) 0x008d 00141 (hello.go:12) MOVQ 32(SP), BP 0x0092 00146 (hello.go:12) ADDQ $40, SP 0x0096 00150 (hello.go:12) RET 返回值设置零值: 12340x000e 00014 (hello.go:9) MOVQ $0, "".d+72(FP)0x0017 00023 (hello.go:9) MOVQ $0, "".e+80(FP)0x0020 00032 (hello.go:9) MOVQ $0, "".e+80(FP)0x0029 00041 (hello.go:9) MOVQ $0, "".d+72(FP) 参考资料 Golang汇编命令解读 go语言汇编(学习笔记) Golang中的Plan9汇编器 Go汇编学习 1.进程内存地址与寄存器 解析 Go 中的函数调用]]></content>
      <tags>
        <tag>golang</tag>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《汇编语言》学习笔记]]></title>
    <url>%2F2017%2F05%2F26%2F%E3%80%8A%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章：基础知识汇编语言的组成 汇编指令：机器码助记符，有对应的机器码 伪指令：没有对应的机器码，由编译器执行，计算机并不执行 其他符号：如 +, -, *, / 等，由编译器识别，没有对应的机器码 指令和数据指令和数据，是应用上的概念。在内存或磁盘上，指令和数据没有任何区别，都是二进制信息。CPU在工作的时候，把有的信息看作指令，有的信息看作数据，为同样的信息赋予了不同的意义。 存储单元每个存储单元从0开始顺序编号，这些编号可以看作是存储单元在存储器中的地址。 一个存储单元可以存储一个 Byte(8 bit) CPU 对存储器的读写必须要进行下面3类信息的交互： 存储单元的地址（地址信息）=&gt; 地址总线 器件的选择，读或写的命令（控制信息） =&gt; 控制总线 读或写的数据（数据信息）=&gt; 数据总线 数据的读写 读： CPU -&gt; 地址总线：3号地址 -&gt; 控制总线信息：读 -&gt; 内存则将3号地址上的数据通过数据总线返回给CPU 写： CPu -&gt; 地址总线：3号地址 -&gt; 控制总线信息：写 -&gt; CPU通过数据总线发送要写的数据给内存的3号单元 命令计算机读写即机器码就是驱动CPU来进行读写的，例如： 1MOV AX, [3] 表示传送3号单元的内容到AX 地址总线CPU是通过地址总线来指定存储单元的，可见地址总线上能传送多少个不同的信息，CPU就可以对多少个存储单元进行寻址。（即 CPU 的寻址单位是：一个存储单元，即一个字节） 一个CPU有N根地址线，则可以说这个CPU的地址总线的宽度为N。这样的CPU最多可以寻找2^N次方个内存单元（即 2^N 个字节，注意，不是位） 数据总线数据总线的宽度，决定了CPU与外界的数据传送速度。 控制总线控制总线是一些不同控制线的集合。有多少根控制总线，就意味着CPU提供了外部器件的多少种控制。所以，控制总线的宽度，决定了CPU对外部器件的控制能力。 内存地址空间各类存储器，在物理上是独立的器件，但在以下两点上相同： 都和CPU的总线相连 CPU对它们进行读或写的时候，都通过控制线发出内存读写命令。也就是说，CPU在操控它们的时候，把它们都当作内存对待 ，把它们总的看作一个由若干存储单元组成的逻辑存储器，这个逻辑存储器就是我们所说的 内存地址空间 在汇编中，我们面对的是 内存地址空间 。CPU对这段内存地址空间中读写数据，实际上就是在相应的物理存储器中读写数据。 即，对于CPU来说，系统中所有存储器中的存储单元，都处于一个统一的逻辑存储器中，它的容量受CPU寻址能力的限制。这个逻辑存储器即是我们所说的 内存地址空间 大小内存地址空间的大小，受CPU地址总线宽度的限制。 内存地址空间分配基于一个计算机硬件系统编程时，必须知道这个系统中的内存地址空间分配情况。因为当我们想在某类存储器中读写数据的时候，必须知道它的第一个单元的地址和最后一个单元的地址，才能保证读写操作是在预期的存储器中进行。 不同的计算机系统的内存地址空间的分配情况是不同的。 第二章：寄存器8086 CPU寄存器共14个（16位） 这四个是通用寄存器（存放一般性的数据），为了兼容性，可以分开使用两个独立的8位寄存器（H后缀表示高8位，L后缀表示低8位） AX（AH, AL） BX（BH，BL） CX（CH，CL） DX（DH，DL） SI DI SP BP IP CS SS DS ES PSW 字在寄存器中的存储出于兼容性的考虑，8086CPU一次性处理以下两种尺寸的数据： 字节：byte, 即8 bit ，可以存在8位寄存器中 字：word，即2个byte，这两个字节分别称为这个字的高位字节和低位字节 物理地址所有的内存单元构成的存储空间是一个一维的线性空间，每一个内存单元在这个空间中都有唯一的地址，我们将这个唯一的地址称为 物理地址 。 CPU通过地址总线送入存储器的，必须是一个内存单元的 物理地址 。 在CPU向地址总线上发出物理地址之前，必须要在内部先形成这个物理地址。不同的CPU可以有不同的形成物理地址的方式。 16位的CPU描述了CPU的结构特性： 运算器一次最多可以处理16位的数据 寄存器的最大宽度为16位 寄存器和运算器之间的通路为16位 8086 CPU给出物理地址的方法8086 CPU有20位地址总线，达1MB寻址能力。但 8086CPU又是16位结构的，如果单纯地发出地址的话，那它只能送出16位的地址，表现出的寻址能力只有64KB。 所以，8086CPU 采用一种在内部用两个16位地址合成的方法来形成一个20位的物理地址。 过程： CPU中相关的部件提供两个16位的地址，一个称为 段地址 ，另一个称为 偏移地址 段地址和偏移地址通过内部总线送入一个称为地址加法器的部件 地址加法器将两个16位地址合成为一个20位的物理地址 地址加法器通过内部总线将20位物理地址送入输入输出控制电路 输入输出控制电路将20位物理地址送上地址总线 20位物理地址被地址总线传送到存储器 地址加法器采用： 物理地址=段地址 16 + 偏移地址* (即段地址左移4位) 的方法来合成物理地址。 段地址 * 16 + 偏移地址 = 物理地址 的本质含义即：CPU在访问内存时，用一个基础地址（段地址 16）和一个相对于基础地址的偏移地址相加，给出内存单元的 物理地址* 。即：CPU在访问内存时 1基础地址 + 偏移地址 = 物理地址 为什么需要 段地址 16* 呢？这是因为需要进一位，然后在此基础上再加上偏移地址，这才是正确的物理地址。（这是 8086 CPU 对地址计算的约定） 段寄存器8086 CPU有四个段寄存器： CS, DS, SS, ES 段地址在 8086 CPU中由段寄存器存放 CS 和 IP 是8086 CPU中两个最关键的寄存器，它们指示了CPU当前要读取指令的地址。 CS ：为代码段寄存器IP ：为指令指针寄存器 在 8086 PC机中，任意时刻，假设 CS 中的内容为M， IP中的内容为N，8086CPU将从内存 M*16 + N 单元开始读取一条指令并执行。即任意时刻，CPU将 CS:IP 指向的内容当作指令执行 即8086 CPU的工作过程简要如下： 从 CS:IP 指向的内存单元读取指令，读取的指令进入指令缓冲器 IP=IP+所读取指令的长度，从而指向下一条指令 执行指令。转至步骤1，重复这个过程 在8086CPU加电启动或复位位， CS和IP被设置为 CS=FFFFH， IP=0000H ，即在8086PC机刚启动时，CPU从内存FFFF0H单元中读取指令执行，FFFF0H单元中的指令是8086PC机开机后执行的第一条指令。 修改CS，IP的指令程序员能够用指令读写的部件只有寄存器，可以通过改变寄存器中的内容实现对CPU的控制。CPU从何处执行指令，是由CS，IP中的内容决定的，程序员可以通过改变CS，IP中的内容来控制CPU执行目标指令。 能够改变 CS，IP 的内容的指令被统称为 转移指令 ，比如 JMP 指令。 同时改变CS和IP： 1jmp 段地址:偏移地址 只改变IP： 1jmp 某一合法寄存器 对于CPU来说，它只认为 CS:IP 指向的内存单元中的内容为指令。 Windows下的 Debug 工具 R: 查看、改变CPU寄存器的内容. r 寄存器 回车，然后输入值，再回车即可修改 寄存器 的值 D: 查看内存中的内容. d 段地址:偏移地址 来查看内存内容。或 d 段地址:偏移地址 结尾偏移地址 或 d 段寄存器:偏移地址 E: 改写内存中的内容. e 起始地址 数据1 数据2 数据3 … U: 将内存中的机器翻译为汇编指令。 u 段地址:偏移地址 结尾偏移地址 T: 执行一条机器指令。直接 t 即可，它会执行 CS:IP 指向的指令。 A: 以汇编指令的格式在内存中写入一条机器指令。 a 段地址:偏移地址 后回车，就可以开始以汇编指令的形式，直接向内存写入数据。 注意，要想让CPU执行我们的指令，向内存写好汇编指令后，要将 CS和IP 的值指向相应的内存地址。 第三章：寄存器（内存访问）内存中字的存储CPU中，用16位寄存器来存储一个字。高8位放在高位字节，低8位放在低位字节。在内存中存储时，由于内存单元是字节单元（一个单元存放一个字节），则一个字要用两个地址连续的内存单元来存放，这个字的低字节放在低地址单元中，高位字节放在高位地址单元中。 DS和[address]8086CPU中，内存地址=段地址+偏移地址 组成。 DS 寄存器通常用来存放要访问数据的段地址。[…] 表示一个内存单元、表示内存单元的偏移地址。 8086CPU中，自动取 DS 中的数据为内存单元的段地址。 MOV 指令中的 [] 说明操作对象是一个内存单元。[] 中的0，说明这个内存单元的偏移地址是0，它的段地址默认放在 DS 中。 内存的读写读1MOV 寄存器, [内存单元地址] 写1MOV [内存单元地址]，寄存器 数据段将一段内存当作数据段，是我们在编程时的一种安排，可以在具体操作的时候，用 DS 存放数据段的段地址，再根据需要，用相关指令访问数据段中的具体单元。 栈LIFO（Last In First Out ，后进先出） CPU提供的栈机制8086CPU中提供了相关的指令来以栈的方式访问内存空间。 PUSH（入栈） POP（出栈） 它们都是以 字 为单位进行的。 栈顶8086CPU中，有两个寄存器，段寄存器 SS 和 寄存器 SP，栈顶的段地址放在 SS 中，偏移地址放在 SP 中。 任意时刻， SS:SP 指向栈顶元素。 PUSH 和 POP 指令执行时，CPU从 SS 和 SP 中得到栈顶的地址。 8086CPU中，入栈时， 栈顶从高地址向低地址方向增长 . PUSHPUSH AX 步骤： SP=SP-2 ，SS:SP 指向当前栈顶前面的单元，以当前栈顶前面的单元为新的栈顶 将AX中的内容送入 SS:SP 指向的内存单元。SS:SSP 此时指向新栈顶 空栈以 10000H~1000FH 这段空间看作栈， 此时 SS=1000H，则SP=？ 换个角度看，任意时刻， SS:SP 指向栈顶元素，当栈为空的时候，栈中没有元素，也就不存在栈顶元素，所以 SS:SP 只能指向栈的最底部单元下面的单元，该单元的偏移地址为栈最底部的字单元的偏移地址+2，栈最底部字单元的地址为 1000:000E ，所以栈空时， SP=0010H POPpop ax 过程 将 SS:SP 指向的内存单元处的数据送入 AX SP=SP+2， SS:SP 指向当前栈顶下面的单元，以当前栈顶下面的单元为新的栈顶 注意，POP 之后，只是将 SP 偏移了而已，原数据仍然会在内存中的，但它已经不在栈中了。当再次 PUSH 后，将会写入新的数据。 栈顶超界的问题8086CPU中，并不会保证我们对栈的操作不会超界。这也就是说，8086CPU，只知道栈顶在何处（由 SS:SP 指示），而不知道我们安排的栈空间有多大。这点好像CPU只知道当前要执行的指令在何处（由 CS:IP 指示），而不知道要执行的指令有多少。 我们在编程的时候要自己操心栈顶超界的问题，要根据可能用到的最大栈空间，来安排栈的大小，防止入栈的数据太多而导致超界；执行出栈的操作时也要注意，以防栈空的时候继续出栈而导致的超界。 POP 和 PUSH 指令它们与 MOV 指令不同， CPU执行 MOV 指令只需要一步。而 PUSH，POP 指令却需要两步。 PUSH：先改变 SP，后向 SS:SP 处传送POP：先读取 SS:SP 处的数据，后改变 SP 栈段将一段内存当作栈段，仅仅是我们在编程时的一种安排，CPU并不会由于这种安排，就在执行 PUSH 、POP 等栈操作指令时自动地将我们定义的栈段当作栈空间来访问。它只是简单地访问 SS:SP 指向的地址当作栈段。 这些完全是我们自己安排的： 我们可以用一个段存放数据，将它定义为 “数据段”；（CS:IP）我们可以用一个段存放代码，将它定义为 “代码段”；（DS:[])我们可以用一个段当作栈，将它定义为 “栈段”；(SS:SP) 我们可以这样子安排，但要让CPU按照我们的安排来访问这些段，就要： 对于数据段，将它的段地址放在 DS 中对于代码段，将它的段地址放在 CS 中对于栈段，将它的段地址放在 SS 中，将栈顶单元的偏移地址放在 SP 注意： Debug 中的 T 命令在执行修改寄存器 SS 的指令时，下一条指令也紧接着被执行。 第四章：第一个程序编译默认的源码后缀为 .asm ，非这个后缀的，则要写全文件名，包括后缀。 假设源文件为： c:\hello.asm 1masm c:\hello; 链接1link hello; 调试1debug hello.exe 注意，要 hello.exe 是要全名的，不能省略 .exe 整个过程1编程 -&gt; 1.asm -&gt; 编译（masm) -&gt; 1.obj -&gt; 链接(link) -&gt; 1.exe -&gt; 加载（command) -&gt; 内存中的程序 -&gt; 运行(CPU) DOS 的加载过程 找到一段起始地址为： SA:0000（即起始地址的偏移地址为0）的容量足够的空闲内存区 在这段内存区的前 256 个字节中，创建一个称为程序段前缀（PSP）的数据区， DOS 要利用 PSP 来和被加载程序进行通信 从这段内存区的 256 字节处开始（在PSP后面），将程序装入，程序的地址被设置为 SA + 10H:0 （即 PSP的内容范围就是: SA:0 ~ SA+10H:0 将该内存的段地址存入 DS 中，初始化其他相关寄存器后，设置 CS:IP 指向程序的入口 PSP的内容为： 程序加载后， DS 中存放着程序所在内存区的段地址，这个内存区的偏移地址为0，则程序所在的内存区的地址为 DS:0 这个内存区的前 256 个字节中存放的是 PSP ， DOS 用来和程序进行通信。从 256 字节处向后的空间存放的是程序 所以， 从 DS 中可以得到 PSP 的段地址 SA， PSP 的偏移地址为 0，则物理地址为 SA * 16 + 0因为 PSP 占 256 （100H）字节，所以程序的物理地址为： 1234SA * 16 + 0 + 256 = SA * 16 + 16 * 16 + 0 = (SA+16) * 16 + 0用段地址和偏移地址表示为：SA + 10H:0 单任务执行过程 由其他程序（debug, command或其他程序），将可执行文件中的程序加载入内存 设置 CS:IP 指向程序的第一条要执行的指令（即程序的入口），从而使程序得以运行 程序运行结束后，返回到加载者 第五章：[BX] 和 loop指令要完整地描述一个内存单元，需要两种信息 内存单元的地址：DS 为段地址， [N] N 为偏移地址 内存单元的长度（类型）：可以由具体指令中其他操作对象（比如说寄存器）指出 [BX] 同样也表示一个内存单元，它的偏移地址在 BX 中 loop 指令下面2步是自动CPU处理的 CX = CX - 1 CX 不为0，则转至标号处执行； 如果为0，则向下执行 汇编源程序中，数据不能以字母开头 debug 中的 G 命令它可以让 CPU 一直执行到指定的地址中为止: 1G 0012 即将程序执行到 IP 地址为 0012H 的地方 debug 中的 P 命令它会自动重复执行循环中的指令，直到 CX = 0 为止 。即在 CS:IP 指向 loop xxx 时，输入 p 命令即可。 当然，也可以用 G 命令来间接实现这个目的 debug 和汇编器 masm 对指令的不同处理debug 中: 123mov ax, [0]它表示将 ds:0 处的数据送入 ax 中 masm 源代码中： 1234mov ax,[0]编译后，生成的是 mov ax, 0 所以，在 masm 这样子的要显式出给段地址: 123456mov ax, ds:[0]或mov ax, [bx]这样子它就会默认是 DS:[bx] 了 一段安全的空间不能确定一段内存空间中是否存放着重要的数据或代码的时候，不能随意向其中写入内容。 不要忘记，我们是在操作系统的环境中工作，操作系统管理所有的资源，也包括内存。如果我们需要向内存空间写入数据的话，要使用操作系统给我们分配的空间，而不应直接用地址任意指定内存单元，向里面写入。 在CPU保护模式下的操作系统(Windows 2000, Unix)中，硬件已经被这些操作系统利用CPU保护模式所提供的功能全面而严格地管理了。 第六章：包含多个段的程序程序取得所需空间的方法有两种 在加载程序的时候为程序分配 程序在执行的过程中向系统申请 程序第一条指令这是由可执行文件中描述信息指明的。 可执行文件由描述信息和程序组成 程序来自于源程序中的汇编指令和定义的数据 描述信息则主要是编译、连接程序对源程序中相关伪指令进行处理所得到的信息 只用一个段来写代码1234567891011121314assume cs:codecode segment ... 数据 ...start: ... 代码 ...code endsend start 多段123456789101112131415161718192021222324252627282930313233343536373839404142assume cs:code, ds:data, ss:stackdata segment dw 0123h, 0456h, 0789h, 0abch, 0defh, 0fedh, 0cbah, 0987hdata endsstack segment dw 0,0,0,0,0,0,0,0,0,0stack endscode segmentstart: mov ax, stack mov ss, ax mov sp, 20h mov ax, data mov ds, ax mov bx, 0 mov cx, 8s: push [bx] add bx, 2 loop s mov bx,0 mov cx,8s0: pop [bx] add bx,2 loop s0 mov ax, 4c00 int 21hcode endsend start 第七章：更灵活的定位内存地址的方法and 和 or 指令1234mov al,01100011Badd al,00111011Bor al,00111011B [bx+idata][bx+idata] 表示一个内存单元，它的偏移地址为 [bx] + idata 。也可以写成如下格式: 12345mov ax, [200+bx]或mov ax, 200[bx]或mov ax, [bx].200 SI 和 DI它们和 BX 功能相近。但 SI 和 DI 不能够分成两个8位寄存器来使用。 [bx+si] 和 [bx+di]指明内存单元: [bx(si或di)] [bx(si或di) + idata] 也可以: [bx+si] [bx+di] 表示一个内存单元，它的偏移地址为 [bx] + [si] 或 [bx] + [di] [bx+si+idata] 和 [bx+di+idata]表示一个内存单元，它的偏移地址为： [bx] + [si] + idata 寻址方式 [idata] : 用一个常量来表示地址，可用于直接定位一个内存单元 [bx] : 用一个变量来表示内存地址，可用于间接定位一个内存单元 [bx+idata] : 用一个变量和常量表示地址，可在一个起始地址的基础上，用变量间接定位一个内存单元 [bx+si或di] : 用两个变量表示地址 [bx+si或di+idata] : 用两个变量和一个常量表示地址 第八章：数据处理的两个基本问题 处理的数据在什么地方 要处理的数据有多长 bx, si, di 和 bp 只有这4个寄存器可以在 [..] 中进行内存单元的寻址 在 [..] 中，这4个寄存器可以单个出现，或只能以4种组合出现：bx和si， bx和di， bp和si, bp和di 在 [..] 中使用寄存器 bp, 而指令中没有显性地给出段地址，段地址默认就在 SS 中 机器指令处理的数据在什么地方在机器指令这一层，并不关心数据的值是多少，而关心 指令执行前一刻 ，它将要处理的数据所在的位置。可以在3个地方： CPU 内部 内存 端口 数据位置的表达立即数1mov ax, 1 寄存器1mov ax, bx 段地址（SA）和偏移地址（EA）1mov ax, [0] 寻址方式直接寻址1[idata] 寄存器间接寻址1234[bx][si][di][bp] 寄存器相对寻址1234[bx+idata][si+idata][di+idata][bp+idata] 基址变址寻址1234[bx+si][bx+di][bp+si][bp+di] 相对基址变址寻址1234[bx+si+idata][bx+di+idata][bx+si+idata][bp+di+idata] 要处理数据的长度8086CPU 可以处理两种尺寸的数据： byte 和 word 通过寄存器名指明处理的数据的尺寸 没有寄存器名存在的情况下， 用 X ptr 指明内存单元的长度，X 可以为 word 或 byte 其他方法。有些指令默认访问的是字单元，还是字节单元。比如 push 就只能进行字单元操作 div 指令 除数：8位或16位，在一个寄存器或内存单元中 被除数：默认放在AX或DX和AX中。如果除数为8位，被除数则为16位，默认在AX中存放；如果除数为16位，被除数则为32位，在DX和AX中存放，DX存放高16位，AX存放低16位 结果：如果除数为8位，则AL存储除法操作的商，AH存储除法操作的余数；如果除数为16位，则AX存储除法操作的商，DX存储除法操作的余数 dup123db 重复次数 dup (重复的字节型数据)dw 重复次数 dup (重复的字型数据)dd 重复次数 dup (重复的双字型数据) 第九章：转移指令的原理可以修改 IP 或同时修改 CS 和 IP 的指令统称为 转移指令 只修改IP，称为段内转移，如: jmp ax 短转移: IP 修改的范围为: -128 ~ 127 近转移：IP 修改的范围为: -32768 ~ 32767 同时修改 CS 和 IP 称为段间转移，如: jmp 1000:0 转移指令分类 无条件转移指令，如 jmp 条件转移指令 循环指令， 如 loop 过程 中断 offset它是由编译器处理的符号，功能是： 取得标号的偏移地址 jmp 指令要出给两种信息： 转移的目的地址 转移的距离（段间转移、段内短转移、段内近转移） 依据位移进行转移的 jmp 指令1jmp short 标号 它对IP的修改范围为 -128 ~ 127 ，即向前最多 128 个字节， 向后最多 127 个字节。 注意：CPU 执行 JMP 指令的时候，并不需要转移的目的地址。 1jmp short 标号 并不包含转移的目的地址，而包含的是 转移的位移 。这个位移，是编译器根据汇编指令中的 标号 计算出来的。 转移的目的地址在指令中的 jmp 指令1jmp far ptr 标号 它是段间转移，又称为远转移。它会同时修改 CS 和 IP 转移地址在寄存器中的 jmp 指令1jmp 16位寄存器 功能： IP = 16位寄存器的值 转移地址在内存中的 jmp 指令123jmp word ptr 内存单元地址（段内转移）jmp dword prt 内存单元地址（段间转移） jcxz 指令它是条件转移指令。所有的条件转移指令都是短转移，在对应的机器码中包含转移的位移，而不是目的地址。对IP的修改范围都为： -128 ~ 127 如果 cx = 0 ，则转移到标号处执行，否则程序向下执行。 loop 指令它是循环指令。所有的循环指令都是短转移，在对应的机器码中包含转移的位移，而不是目的地址。对IP的修改范围都为：-128 ~ 127 CX = CX-1，然后 CX != 0 ，则转移到标号处执行。 第十章：CALL 和 RET 指令ret 和 retfret =&gt; 用栈中的数据，修改IP的内容，从而实现近转移 IP = SS * 16 + SP SP = SP + 2 相当于: pop IP retf =&gt; 用栈中的数据，修改CS和IP，从而实现远转移 IP = SS * 16 + SP SP = SP + 2 CS = SS * 16 + SP SP = SP + 2 相当于: pop IPpop CS call 指令 将当前 IP 或 CS 和 IP 压入栈 转移 它不能实现短转移，除此之餐，它和 JMP 指令的原理相同。 依据位移进行转移的 call 指令1call 标号（将当前IP压入栈后，转移到标号处执行指令） SP = SP + 2; SS *16 + SP = IP IP = IP + 16位位移 转移的目的地址在指令中的 call 指令1call far prt 标号 它是段间转移。 SP = SP - 2; SS 16 + SP = CS; SP = SP - 2; SS 16 + SP = IP CS = 标号所在段的段地址； IP = 标号所在段中的偏移地址 相当于: push CSpush IPjmp far prt 标号 转移地址在寄存器中的 call 指令1call 16位寄存器 SP = SP - 2 SS * 16 + SP = IP IP = 16位寄存器的值 转移地址在内存中的 call 指令两种格式： call word prt 内存单元地址 push ipjmp word ptr 内存单元地址 call dword prt 内存单元地址 push cspush ipjmp dword prt 内存单元地址 mul 指令 两个相乘数：要么都是8位，要么都是16位。如果是8位，则一个默认在 AL 中，另一个在 8 位寄存器或内存字节单元中。要么是 16 位，一个默认在 AX 中，另一个在 16 位或内存字节单元中。 结果：8位的话，结果默认在 AX 中； 16 位，则默认高位在 DX 中，低位在 AX 中 12mul 寄存器mul 内存单元 第十一章：标志寄存器特殊的寄存器作用： 存储相关指令的某些执行结果 为CPU执行相关指令提供行为依据 控制CPU的相关工作方式 其他寄存器是用来存放数据的，都是整个寄存具有一个含义。而标志寄存器，是按拉起作用的，也就是说，它的每一位都有专门的含义，记录特定的信息。 0：CF进位标志位。一般情况下，在进行 无符号 运算的时候，它记录了运算结果的最高有效位向更高位的进位值，或从更高位的借位值 2：PF奇偶标志位。它记录相关指令执行后，其结果的所有 bit 位中 1 的个数是否为偶数。如果1的个数为偶数，则 PF = 1， 如果为奇数，则 PF = 0 4：AF6：ZF零标志位。它记录相关指令执行后，结果是否为0.如果为0，ZF=1，否则 ZF=0 7：SF符号标志位。它记录相关指令执行后，其结果是否为负。如果为负，SF = 1， 如果非负， SF = 0 8：TF9：IFIF = 0，在进入中断处理程序后，禁止其他的可屏蔽中断。IF = 0，表示中断处理程序需要处理可屏蔽中断。 12sti ：设置 IF = 1cli : 设置 IF = 0 10：DF方向标志位。在串处理指令中，控制每次操作后 si, di 的增减。 DF = 0 ：每次操作后， si, di 递增DF = 1 : 每次操作后， si，di 递减 12cld 指令：将标志寄存器的 DF 位置0std 指令：将标志寄存器的 DF 位置1 11：OF溢出标志位。一般情况下，OF 记录了 有符号 运算的结果是否发生了溢出。如果溢出了， OF = 1 ，如果没有， OF = 0 注意， OF 是对有符号的。CF 是对无符号的 adc 指令adc 是带进位加法指令。它利用了 CF 位上记录的进位值。 1234adc 操作对象1，操作对象2结果为操作对象1 = 操作对象1 + 操作对象2 + CF 利用它，可以对任意大的数据进行加法运算。 sbb 指令它是带借位减法指令，它利用了 CF 位上记录的借位值。 1234sbb 操作对象1，操作对象2功能操作对象1 = 操作对象1 - 操作对象2 - CF 利用它，可以对任意大的数据进行减法运算。 cmp 指令它相当于减法，只是不保存结果。将对标志寄存器产生影响。 1234cmp 操作对象1， 操作对象2功能操作对象1 - 操作对象2 ，但并不保存结果，仅仅是对标志寄存器进行设置 检测比较结果的条件转移指令下面是常用的根据 无符号 数的比较结果进行转移的条件转移指令 jeequal 等于则转移。检测的是 ZF = 1 jnenot equal 不等于则转移，检测的是 ZF = 0 jbbelow 低于则转移，检测的是 CF = 1 jnbnot below 不低于则转移，检测的是 CF = 0 jaabove 高于则转移。 CF = 0 且 ZF = 0 jnanot above 不高于则转移。 CF = 1 或 ZF = 1 pushf 和 popfpushf ：将标志寄存器的值压栈popf : 从栈中弹出数据，送入标志寄存器 第十二章：内中断中断信息可以来自 CPU 的内部和外部。 中断的产生 除法错误：中断类型码为0 单步执行：中断类型码为1 执行 into 指令：中断类型码为4 执行 int 指令： int N，N为字节型立即数，即提供给CPU的中断类型码 8086CPU用称为中断类型码的数据来标识中断信息的来源。 中断类型码为一个字节型数据，可以表示 256 种中断信息的来源。 中断向量表CPU用8位的中断类型码通过中断向量表，找到相应的中断处理程序的入口地址。 所谓中断向量，就是中断处理程序的入口地址。展开来讲，中断向量表，就是中断处理程序的入口地址的列表。 中断向量表在内存中存放。对于 8086CPU，中断向量表指定放在内存地址 0 处。从内存 0000:0000 到 0000:03FF 的1024个单元中存放着中断向量表。 一个表项存放着一个中断向量，也就是一个中断处理程序的入口地址，对于 8086CPU， 这个入口地址包括段地址和偏移地址，所以，一个表项占两个字，高地址存放段地址，低地址存放偏移地址。 中断过程找到中断入口地址的最终目的是用它设置 CS 和 IP ，使CPU执行中断处理程序。 用中断类型码找到中断向量，并用它设置 CS 和 IP 这个工作是由 CPU 硬件自动完成的。CPU 硬件完成这个工作的过程，称为 中断过程 整个过程如下： 取得中断类型码 N pushf TF = 0, IF = 0 push CS push IP IP = N 4, CS = N 4 + 2 中断处理程序和 iret 指令中断处理程序的常规步骤： 保存用到的寄存器 处理中断 恢复用到的寄存器 用 iret 指令返回 iret 指令用汇编语法表述为： POP IPPOP CSpopf 响应中断的特殊情况举例：CPU在执行完 SS 指令后，不响应中断。 这给连续设置 SS 和 SP 指向正确的栈顶提供了一个时机。 第十三章：int 指令1int n 它的功能是：引发中断号为 N 的中断过程 BIOS 和 DOS 中断例程的安装过程 开机后， CPU一加电，初始化 CS = 0FFFFH， IP=0 ，自动从 FFFF:0 单元开始执行程序。FFFF:0 有一条转跳指令，CPU执行后，转去执行BIOS中的硬件系统检测和初始化程序。 初始化程序将建立 BIOS 所支持的中断向量，即将 BIOS 提供的中断例程的入口地址登记在中断向量表中。注意，对于BIOS所提供的中断例程，只需要将入口地址登记在中断向量表中即可，因为它们是固化到 ROM 中的程序，一直在系统内存中存在。 硬件系统检测和初始化完成后，调用 int 19H 进行操作系统的引导，从此将计算机交由操作系统控制 DOS 启动后，除完成其他工作以外，还将它提供的中断例程装入内存，并建立相应的中断向量 BIOS 和 DOS 提供的中断例程，都是用 AH 来传递 内部子程序的编号 。 第十四章：端口CPU可以直接读写以下3个地方的数据 CPU内部的寄存器 内存单元 端口 端口的读写它和内存地址一样，通过地址总线来传送。在PC中，CPU最多可定位64KB个不同的端口。则端口地址的范围为 0 ~ 65535 它只有两个指令： in ：读out : 写 在 in 和 out 指令中，只能使用 ax 或 al 来存放从端口中读入的数据或要发送到端口中的数据。8位时，使用 AL， 16位时， 使用 AX SHL 和 SHR 指令SHL 的功能： 将一个寄存器或内存单元中的数据向左移位 将最后移出的一位写入 CF 中 最低位用 0 补充 SHR 与 SHR 的操作刚好相反 第十五章：外中断PC系统的接口卡和主板上，装有各种接口芯片。这些外设接口芯片的内部有若干寄存器，CPU将这些寄存器当作端口来访问。 外中断源可屏蔽中断如果 IF = 1，则CPU执行完当前指令后响应中断，引发中断过程；如果 IF = 0，则不响应可屏蔽中断 不可屏蔽中断是CPU必须响应的外中断。对于 8086CPU，不可屏蔽中断的中断类型码固定为 2 ，所以，中断过程中，不需要取中断类型码。 几乎所有由外设引发的外中为，都是 可屏蔽中断 。 PC 机键盘的处理过程按下一个键时产生的扫描码称为 通码松开一个键时产生的扫描码称为 断码 扫描码长度为：一个字节。通码的第7位为0，断码的第7位为1 。即： 断码 = 通码 + 80H 杂项显存的物理地址1B8000~BFFFF ASCII 与 显卡文本模式显示ASCII 是7位代码，只用了一个字节中的低7比特，最高位通常置0 。这意味着，ASCII只包含 128 个字符的编码。 屏幕上的每个字符，对应着显存中的两个连续字节。 前一个字节是字符的ASCII代码，后一个字节是显示属性，包括字符颜色（前景色）和底色（背景色）。 显示属性分为两部分，低4位定义的是前景色，高4位是背景色。RGBK（背景色），其中K是闪烁位，0为不闪烁，1为闪烁。RGBL（前景色），其中L是亮度位，0为正常亮度，1为高亮。 MOV目的操作数不能为立即数，而且目的操作数和源操作数不允许同时为内存单元。 汇编地址它是在源程序编译期间，编译器为每条指令确定的汇编位置，指示该指令相对于程序或段起始处的距离，以字节计算。当编译后的程序装入物理内存后，它又是该指令在内存段内的偏移地址。 jmp near xxxjmp near 的操作数并非目标位置的偏移地址，而是目标位置 相对于当前指令处的偏移量（以字节为单位） 编译器对它的处理：用标号（目标位置）处的汇编地址减去当前指令的汇编地址，再减去当前指令的长度（3)，就得到了 jmp near xxx 指令的实际操作数。 movsb 或 movsw源数据：DS:SI目的地：ES:DI CX: 次数 DF标志位：cld =&gt; 清0，表示传送的是正向（从内存低地址到高地址）std =&gt; 置1，表示传送的是反向（从内存高地址到低地址） MOVSB 或 MOVSW 通常与 rep (表示 repeat) 结合使用。 偏移地址如果要用寄存器来提供偏移地址，只能使用： bx, si, di, bp 不能使用其他寄存器。 cbw 或 cwdcbw =&gt; (convert byte to word)，将 AL 中的有符号数扩展到整个AX。如果AL为 10001101，执行完这指令后，AX为 1111111110001101cbd =&gt; (convert word to double word)，将AX中的有符号数扩展到 DX:AX 。 call 指令相对近调用这个是通过符号或立即数（立即数也要减去当前指令的汇编地址）给出的。 计算过程： 用目标过程的汇编地址送去当前 call 指令的汇编地址，于减去当前 call 以字节为单位的长度（3），保留16位的结果。 1call near xxx near 不是必须的，如果不提供任何关键字，则默认就是 near 绝对近调用这个是通过寄存器或内存单元给出目标地址的。 绝对远调用1call xxxx:yyyy 间接绝对远调用1call far [xxx] 它会使用 xxx 处的2个字（注意是字，第一个字是偏移地址，第二个字是段地址）来分别代替IP和CS的内容。 ret 和 retfret 和 retf 经常用做 call 和 call far 的配对指令。 ret 是近返回：它只做一件事，就是从栈中弹出一个字到指令指针寄存器IP中 retf 是远返回：处理器分别从栈中弹出两个字到指令指针寄存器IP和代码段寄存器CS中 call 和 ret , retf 不会影响任何的标志寄存器 jmp相对短转移jmp short 标号或数值 用目标地址减去当前指令的汇编地址，再减去当前指令的长度（2），保留一个 字节 的结果（结果是有符号数） 16位相对近转移jmp near 标号或数值 用目标地址减去当前指令的汇编地址，再减去当前指令的长度（3），保留一个字（16位）的结果。（结果是有符号数） 16位间接绝对近转移jmp near bx 它也是近转移，即只是段内转移。但目标地址是通过寄存器或内存地址（该地址里的内存内容）给出的 16位直接绝对远转移jmp xxxx:yyyy 16位间接绝对远转移标号 dw yyyy, xxxxjmp far [标号] 注意，第一个字是偏移地址，第二个才是段地址 即相当于转移到 jmp far xxxx:yyyy iret这个是中断返回指令，它会导致处理器依次从栈中弹出（恢复）IP、CS 和 Flags 的原始内容。 CMOS RAM前14个字节分别为： 0x0：秒0x1：闹钟秒0x2：分0x3：闹钟分0x4：时0x5：闹钟时0x6：星期0x7：日0x8：月0x9：年0xa: 寄存器A0xb: 寄存器B0xc: 寄存器C0xd: 寄存器D 访问需要通过两个端口： 0x70或0x74 =&gt; 它是索引端口，用于指定CMOS RAM的内存单元0x71或0x75 =&gt; 它是数据端口，用来读写相应的内存单元 比如下面代码就是读取星期几： MOV al,0x06OUT 0x70, alIN al, 0x71 我现在是星期四（因为我系统设置了每周第一天为星期天），所以下面的数值为05（实际是我们一般人理解的星期四，只是不同的起始计数不同） 执行完后，可以看到al值为 05 （它是以星期天为开始计数的，即星期一～星期天为， 01~07）]]></content>
      <tags>
        <tag>汇编语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang中遇到的[坑]]]></title>
    <url>%2F2017%2F05%2F21%2FGolang%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84-%E5%9D%91%2F</url>
    <content type="text"><![CDATA[匿名函数123456789101112131415161718192021222324package mainimport ( "fmt" "time")func main() &#123; for i := 0; i &lt; 10; i++ &#123; go show(i) &#125; for i := 0; i &lt; 10; i++ &#123; go func() &#123; fmt.Printf("go x =&gt; %v\n", i) &#125;() &#125; time.Sleep(5 * time.Second)&#125;func show(x int) &#123; fmt.Printf("x =&gt; %v\n", x)&#125; 输出的结果: 123456789101112131415161718192021[Running] go run "/Users/emacsist/Documents/go/test/src/t1/main.go"x =&gt; 1x =&gt; 3x =&gt; 2x =&gt; 4go x =&gt; 10x =&gt; 7x =&gt; 8go x =&gt; 10x =&gt; 6go x =&gt; 10go x =&gt; 10x =&gt; 0x =&gt; 5go x =&gt; 10go x =&gt; 10go x =&gt; 10go x =&gt; 10go x =&gt; 10x =&gt; 9go x =&gt; 10 切片的 copy 与 赋值区别123456789101112131415161718192021222324252627282930package mainimport "fmt"func main() &#123; copySlice() fmt.Println("------------") assignlice()&#125;func copySlice() &#123; hello := []string&#123;"你", "好"&#125; c := make([]string, 2, 2) copy(c, hello) fmt.Printf("%v\n", hello) fmt.Printf("%v\n", c) c[0] = "您" fmt.Printf("%v\n", hello) fmt.Printf("%v\n", c)&#125;func assignlice() &#123; hello := []string&#123;"你", "好"&#125; c := hello fmt.Printf("%v\n", hello) fmt.Printf("%v\n", c) c[0] = "您" fmt.Printf("%v\n", hello) fmt.Printf("%v\n", c)&#125; 输出： 12345678910[Running] go run "/Users/emacsist/Documents/go/test/src/t1/main.go"[你 好][你 好][你 好][您 好]------------[你 好][你 好][您 好][您 好] 切片、字典与性能避免循环里使用： 1234var h []stringfor i:=0;i&lt;10;i++ &#123; h = append(h, "你好")&#125; 而应该事先分配好足够的内存，再循环里使用: 1234h := make([]string, 0, 10)for i:=0;i&lt;10;i++ &#123; h = append(h, "你好")&#125; 字典同样。 切片中的使用注意直接访问来修改，与赋值给一个临时变量，然后再修改这个临时变量要千万注意：直接访问修改是会影响原来的，而修改赋值给临时变量的，则只是反映到临时变量里，而不会修改原值（指针的类型除外） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( "fmt")func main() &#123; var bidList []Bid bid1 := Bid&#123;ID: "ID", Impid: "impID", Price: 232, NURL: "http://", Adm: "adm", Crid: "crid"&#125; bid2 := Bid&#123;ID: "ID2", Impid: "impID2", Price: 2322, NURL: "http2://", Adm: "adm2", Crid: "crid2"&#125; bidList = append(bidList, bid1, bid2) fmt.Printf("%v\n", bidList) change(bidList) fmt.Printf("%v\n", bidList) change2(bidList) fmt.Printf("%v\n", bidList)&#125;func change(bidList []Bid) &#123; bid1Copy := bidList[0] bid1Copy.ID = "IDcopy"&#125;func change2(bidList []Bid) &#123; bidList[0].ID = "IDCopy2"&#125;type Bid struct &#123; //DSP 对该次出价分配的ID ID string `json:"id"` //Bid Request 中对应的曝光ID Impid string `json:"impid"` //DSP 出价，单位是分/千次曝光，即CPM Price int32 `json:"price"` //win notice url NURL string `json:"nurl"` //广告物料(博文样式返回mid) Adm string `json:"adm"` //广告创意ID Crid string `json:"crid"`&#125; 输出的结果为: 1234[Running] go run "/Users/emacsist/Documents/go/test/src/t1/main.go"[&#123;ID impID 232 http:// adm crid&#125; &#123;ID2 impID2 2322 http2:// adm2 crid2&#125;][&#123;ID impID 232 http:// adm crid&#125; &#123;ID2 impID2 2322 http2:// adm2 crid2&#125;][&#123;IDCopy2 impID 232 http:// adm crid&#125; &#123;ID2 impID2 2322 http2:// adm2 crid2&#125;] 如果修改为: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( "fmt")func main() &#123; var bidList []Bid bid1 := Bid&#123;ID: "ID", Impid: "impID", Price: 232, NURL: "http://", Adm: "adm", Crid: "crid"&#125; bid2 := Bid&#123;ID: "ID2", Impid: "impID2", Price: 2322, NURL: "http2://", Adm: "adm2", Crid: "crid2"&#125; bidList = append(bidList, bid1, bid2) fmt.Printf("%v\n", bidList) change(bidList) fmt.Printf("%v\n", bidList) change2(bidList) fmt.Printf("%v\n", bidList)&#125;func change(bidList []Bid) &#123; bid1Copy := &amp;bidList[0] bid1Copy.ID = "IDcopy"&#125;func change2(bidList []Bid) &#123; bidList[0].ID = "IDCopy2"&#125;type Bid struct &#123; //DSP 对该次出价分配的ID ID string `json:"id"` //Bid Request 中对应的曝光ID Impid string `json:"impid"` //DSP 出价，单位是分/千次曝光，即CPM Price int32 `json:"price"` //win notice url NURL string `json:"nurl"` //广告物料(博文样式返回mid) Adm string `json:"adm"` //广告创意ID Crid string `json:"crid"`&#125; 即将 change 里的 bid1Copy := bidList[0] 修改为 bid1Copy := &amp;bidList[0] ，那输出的结果为: 1234[Running] go run "/Users/emacsist/Documents/go/test/src/t1/main.go"[&#123;ID impID 232 http:// adm crid&#125; &#123;ID2 impID2 2322 http2:// adm2 crid2&#125;][&#123;IDcopy impID 232 http:// adm crid&#125; &#123;ID2 impID2 2322 http2:// adm2 crid2&#125;][&#123;IDCopy2 impID 232 http:// adm crid&#125; &#123;ID2 impID2 2322 http2:// adm2 crid2]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]RabbitMQ 心跳]]></title>
    <url>%2F2017%2F05%2F16%2F%E7%BF%BB%E8%AF%91-RabbitMQ-%E5%BF%83%E8%B7%B3%2F</url>
    <content type="text"><![CDATA[用心跳检测死TCP连接介绍网络可能会以许多方式失败，有时会很细微（例如高比率的数据包丢失）。中断的TCP连接需要比较长时间（例如，在Linux上默认是大约11分钟）才能被操作系统检测到。AMQP 0-9-1 提供心跳功能，以确保应用层及时发现连接中断（以及完全无响应的对等体）。心跳也可以防御某些网络设备，当一段时间内没有任何活动时，可能会终止空闲的TCP连接。 心跳超时间隔心跳超时值的定义为：在RabbitMQ与客户端之间应该将对等TCP连接视作为无法访问（down）的时间段之后。此值在连接时由客户端和RabbitMQ服务器之间协商。客户端必须配置请求心跳。在RabbitMQ 3.0或更高版本中，Broker 将会默认尝试心跳值（尽管客户端仍可否决）。超时时间的单位为秒，默认值为 60 （在3.5.5之前为 580） 每间隔大约 timeout/2 秒发送一次心跳帧。在两次丢失心跳后，TCP对等体就被认为是无法访问的。不同的客户端对此有不同的显示，但TCP连接将会被关闭。当客户端检测到由于心跳而无法访问 RabbitMQ 节点时，需要重新连接。 任何流量（例如协议操作、发布的消息、确认）会计数有效的心跳数。客户端可以选择发送心跳帧，而不管连接是否有其他流量，但有些只在必要时才进行。 可以通过将超时间隔设置为 0 来禁用心跳。这不是推荐的做法。 Java客户端开启心跳要在 Java 客户端开启心跳超时，请在创建连接之前使用 ConnectionFactory#setRequestedHeartbeat 进行设置。 123ConnectionFactory cf = new ConnectionFactory();// set the heartbeat timeout to 60 secondscf.setRequestedHeartbeat(60); 请注意，如果 RabbitMQ 服务器配置了非零心跳超时值（在 3.6.x 版本开始为默认值），则客户端只能比该值低，而不能比它高。 .NET 客户端开启心跳要在.NET客户端中配置心跳超时，请在创建连接之前使用 ConnectionFactory.RequestedHeartbeat 进行设置： 123var cf = new ConnectionFactory();// set the heartbeat timeout to 60 secondscf.RequestedHeartbeat = 60; 低超时值与错误判断由于瞬时网络拥塞、短时间服务器流量控制等原因，将心跳超时值设置得太低可能导致错误的判断（对等体被认为不可用，但实际上它是可用的）。在选择超时值时，应该考虑这一点。 来自用户和客户端库维护者的这几年有价值的反馈表明，低于5秒的值很可能导致误报，1秒或更低的值则非常可能会这样子做。5到20秒范围内的值对大多数环境是最佳的选择。 在 STOMP 中的心跳STOMP1.2 包含心跳 。在STOMP中，心跳超时可以是不对称的：也就是说，客户端和服务器可以使用不同的值。 RabbitMQ STOMP插件完全支持此功能。 STOMP中的心跳可以选择性加入。要开启它们，请在连接时，使用 heart-beat 头部。参见 STOMP 规范 的一个例子。 在 MQTT 中的心跳MQTT 3.1.1 包含心跳 ，用不同的名称（keepalives)来表示。RabbitMQ MQTT插件完全支持此功能。 MQTT在 Keepalives 可以选择性加入。要开启它们，请在连接时设置 keepalive 间隔。请查看你的 MQTT 客户端文档来获取例子。 Shovel 和 Federation 插件中的心跳Shovel 和 Federation 插件：用来进行 Erlang 客户端连接到 RabbitMQ 节点。因此，它们可以被配置为使用期望的心跳值。 详细请看 AMQP 0-9-1 URI查询参数指引 心跳与TCP keepalivesTCP包含一个类似于心跳的（也称为 keepalive) 的机制，它覆盖上面的消息协议和 net tick 超时之上：TCP keepalives . 由于默认值不足，对于消息传输协议，TCP keepalive 并不适用，甚至是适得其反。然而，通过适当的调整，在不能期望应用程序开启心跳或使用合理值的环境下，它们可以作为额外的防御机制。详情请看 网络指南]]></content>
      <tags>
        <tag>翻译</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]RabbitMQ 生产环境检查列表]]></title>
    <url>%2F2017%2F05%2F15%2F%E7%BF%BB%E8%AF%91-RabbitMQ-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%A3%80%E6%9F%A5%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[原文 介绍数据服务，比如 RabbitMQ，通常有许多可调参数。一些配置对开发环境比较有意义的，但并不真正地适用生产环境。没有单一的配置可以适用于所有用例。因此，在上线到生产环境时，对其配置进行评估是非常重要的。本指南旨在帮你做这件事 虚拟主机、用户、权限虚拟主机例如，在单租户环境中，当你的RabbitMQ集群专用于为生产环境中的单个系统服务时，使用默认虚拟主机 (/) 是完全正常的。 在多租户环境中，为每个 租户/环境 使用单独的虚拟主机。例如： project1_development, project1_production, project2_development, project2_production 等等。 用户对于生产环境，要删除默认用户(guest)。默认情况下，默认用户仅能从 localhost 来连接，因为它是大家都知道的信任凭据。如果要开启远程连接，请考虑使用单独具有带密码的管理员权限的用户。 建议为每个应用使用单独的用户。例如，如果你有一个移动应用，Web应用和一个数据聚合系统，那你应该要有3个独立的用户。这使得一些事情变得简单： 将客户端连接与应用相关联 使用细粒度的权限 取消信任凭证（例如定期或违约的情况下） 如果同一应用有许多实例，则在更好的安全性（每个实例都有一组自己的凭据）和便利的配置（在一些或所有实例之间共享一组凭据）之间要权衡一下。对于涉及许多客户端执行相同或相似功能并具有固定IP地址的 IoT 应用，使用 x509 证书或源IP地址范围进行身份验证比较好。 资源限制当消费者跟不上时，RabbitMQ 会使用 资源驱动警报 来抵制发布者。所以，在投入到生产环境时进行评估资源限制的配置是很重要的。 内存默认情况下，RabbitMQ 将使用高达 40% 的可用 RAM（译注：即物理内存的 40%） 。对于专门用于运行 RabbitMQ 的节点，提高限制通常是比较合理的。但是，应注意OS和文件系统缓存也需要 RAM 来进行操作的。否则由于操作系统进行 swap 的话会导致吞吐量下降，甚至会导致OS终止 RabbitMQ 进程。 以下是一些推荐的 RAM 限制的基本准则： 至少要 128 MB 当有高达 4GB 的RAM时，配置RAM的 65% 的上限 当有高达 4～8 GB的RAM时，配置RAM的 70% 的上限 当有高达 8～16 GB的RAM时，配置RAM的 75% 的上限 当有高达 16 GB以上的RAM时，配置RAM的 80% 的上限 高于 0.85 的值是比较危险的，并且是不建议的。 可用磁盘空间应该有可用的磁盘空间来避免 磁盘空间警报。默认情况下， RabbitMQ 始终需要 50MB 的可用磁盘空间。这可以提高许多流行的 Linux 发行版的开发人员的体验。但是，这并不是一个推荐用于生产环境的值，因为它们可能具有显著更高的 RAM 的限制。以下是建议确定多少可用磁盘空间的基本准则： 至少 2GB 当 RAM 介于 1～8 GB时，它的建议大小为 100% 的RAM内存大小 当 RAM 介于 8～32 GB时，它的建议大小为 90% 的RAM内存大小 当 RAM 超过 32 GB时，它的建议大小为 80% 的RAM内存大小 可以将 rabbit.disk_free_limit 配置设置为 {mem_relative, N} ，以使其计算为操作系统报告的RAM总量的百分比。例如，使用 {mem_relative, 1.0} 为100%， {mem_relative, 1.25} 为 125% 等等。 打开文件句柄限制OS会限制同时打开文件句柄的最大数量，其中包括网络套接字。确保你的限制设置足够高以允许预期的并发连接数和队列数。 确保你的环境允许有效的 RabbitMQ 用户至少 50K 的打开文件描述符，包括在开发环境中。 根据经验，将并发连接数乘2的 95% 并加上总队列数来计算推荐的文件句柄限制。值为 500K 是不足够的，并不会消耗很多硬件资源，因此建议用于生产环境设置。更详细的信息，请查看网络指南 安全注意事项用户和权限参考上面 Erlang cookie在 Linux 和 BSD 系统上，有必要将 Erlang Cookie 访问限制在运行 RabbitMQ 的用户和诸如 rabbitmqctl 之类的工具上 TLS我们建议尽可能地使用 TLS 连接，至少加密流量。同时也建议使用 peer 验证（认证）。开发和QA环境可以使用自签名的TLS证书。当 RabbitMQ 和所有应用程序在受信任的网络上运行或使用 VMware NSX等技术隔离时，自签名证书也可以在生产环境中适用。 虽然RabbitMQ默认尝试提供安全的TLS配置（例如禁用SSLv3），但我们建议你评估启动TLS版本和密码套件。详细信息，请参考 TLS指南 网络配置生产环境可能需要调整网络配置。详情请看 网络指南 自动连接恢复一些客户端，如 Java, .NET 和 Ruby ，支持网络故障后自动连接恢复。如果所使用的客户端提供此功能，建议使用它，而不是开发自己的恢复机制。 集群注意事项集群大小在确定集群大小时，考虑以下几个因素很重要： 预期吞吐量 预期复制（镜像数） 数据位置 由于客户端可以连接到任意节点，所以RabbitMQ可能需要执行消息和内部操作的集群间路由。如果可能的话，尝试使消费者和生产者连接到同一个节点：这将减少节点间的流量。同样有用的是，使消费者连接到当前 master 队列（可使用 HTTP API 判断）。当考虑数据位置时，总体集群吞吐量可以达到非一般的数量级。 对于大多数环境，镜像到一半以上的集群节点就足够了。建议使用具有奇数节点（3，5等）的集群。 分区处理策略在开始投入到生产环境前选择分区的处理策略很重要。如有疑问，请使用 autoheal 策略 节点时间同步RabbitMQ 集群通常可以很好地运行，而不需要同步集群节点间的时钟。然而一些插件，例如, management UI ，利用本地时间戳来进行度量处理，并且当节点的当前时间漂移分开时可能会显示不正确的统计信息。因此，建议服务器使用NTP或类似设备来确保时钟保持同步。]]></content>
      <tags>
        <tag>翻译</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCPCopy的使用]]></title>
    <url>%2F2017%2F05%2F15%2FTCPCopy%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[今天由于某些原因，DSP系统的测试环境不能用了，所以想复制一些正式环境的流量到测试服务器上。查找资料，发现了个 tcpcopy 项目，发现不错。 Github上虽然也有安装和使用手册，但对于第一次环境的人来说，还是有点模糊。经过自己动手设置，终于理解了它的使用方式： 安装就不多介绍了，这里只是描述使用 假设你的测试环境的应用监听的是 9001 ，而且是在 10.0.0.40 启动 intercept假设 intercept 的IP为 10.0.0.40 （ intercept 要与你的测试的应用程序所在的服务器在同一个），而且下面的 9001 也就是测试的应用程序的端口。 1./intercept -i eth0 -F 'tcp and src port 9001' -d 注意，这里的 9001 就是要处理的当前服务器地址的源端口 启动 tcpcopy假设 tcpcopy 的地址为 10.0.0.40 1./tcpcopy -x 80-10.0.0.40:9001 -s 10.0.0.40 -c 10.0.0.40 -x ：表示将本机的 80 端口的流量，copy一份到 10.0.0.40 的 9001 端口。-s ：这个就是 intercept 的地址。-c ：tcpcopy 修改tcp的源IP地址，以免响应给最初的 client。 注意下面是要注意的事项 丢包在测试过程中，发现它会丢包，测试的情况如下: 1239477 - 1000018959 - 2000028351 - 30000 上面是 成功数/总请求数 负载10GB内存，8核的 ab 10W个请求： tcpcopy: 0.4% 的内存，53% 的CPUintercept: 0.4% 的内存， 23% 的CPU]]></content>
      <tags>
        <tag>tcpcpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]How to Interpret the Erlang Crash Dumps]]></title>
    <url>%2F2017%2F05%2F13%2F%E7%BF%BB%E8%AF%91-How-to-Interpret-the-Erlang-Crash-Dumps%2F</url>
    <content type="text"><![CDATA[原文 如何解释 Erlang Crash Dumps本节介绍 Erlang 运行时系统在异常退出时生成的 erl_crash.dump 文件 注意：在 Erlang/OTP R9C 中， Erlang crash dump 有大幅的改变。在本节中的信息不能直接应用到旧的 dumps 文件中。但是，如果你使用了 crashdump_viewer(3) 查看旧的 dumps 文件，则 crash dumps 文件会被转换为与此相类似的格式。 系统将 crash dump 文件写入模拟器（译注：即 Erlang虚拟机，类似JVM）的当前目录（译注：即你在哪个目录中启动 Erlang 虚拟机）或由环境变量 ERL_CRASH_DUMP 指定的文件中（无论是哪种系统都如此）。对于要写入的 crash dump 文件，必须是在一个已经挂载的可写入的文件系统。 主要由于两种原因之一会导致写 crash dump 文件：内置函数 erlang:halt/1 从正在执行的 Erlang 代码中被显式地带有一个 string 参数来调用，或者运行时系统检测到无法处理的错误。最常见的系统无法处理错误的原因是由外部的限制导致的，例如内存不足。由于内部错误引起的 crash dump 可能会由于系统在模拟器自身达到了极限（例如系统中的原子数，或者太多同步ETS表）引起的。通常重新配置模拟器或操作系统可以避免崩溃，因此正确地解释 crash dump 是很重要的。 在支持OS信号的系统上，它也可 以通过发送 SIGUSR1 信号来停止运行时系统和生成 crash dump。 Erlang的 crash dump 是一个可读文本文件，但可能比较难以阅读它。使用在 Observer 应用中的 Crashdump Viewer 工具可以简化该任务。这是一个用于浏览 Erlang crash dumps 的基于 wx-widget 的工具。 一般信息（General Information）Crash dump 的第一部分显示了以下信息： dump 的创建时间 一个 Slogan ，它指明产生 dump 的原因 dump 的源节点的系统版本 源节点正执行的模拟器编译时间 原子表中的原子数 导致 crash dump 的运行时系统线程 Crash Dump 的原因(Slogan)Dump 的原因显示在文件的开头: 1Slogan: &lt;reason&gt; 如果系统是由 BIF erlang:halt/1 停止的话，则 Slogan 是传递给 BIF 的 string 参数，否则它是模拟器或(Erlang)内核生成的描述。通常，该消息足以知道问题所在，但有时只是一些描述一些消息。请注意，认为的 crash 的原因，仅仅只是认为 。具体的错误原因会因本地应用以及所在的操作系统而异。 : Cannot allocate bytes of memory (of type ““)系统内存不足。 是失败分配内存的分配器。 是 试图分配的 字节数 。 是内存需要分配的内存块类型。最常见的情况是进程存储大量的数据。在这种情况下，最常见的导致crash的 是 heap ， old heap , heap_fraq 或 binary 。更多关于分配器的信息，请看 erts_alloc(3) : Cannot reallocate bytes of memory (of type ““)与上述相同，除了内存是重新分配，而不是在系统内存不足时被分配外。 Unexpected op code 编译代码错误， beam 文件损坏或编译器出错。 Module undefined | Function undefined | No function :/1 | No function :start/2内核/STDLIB 应用程序已经损坏或启动脚本已经损坏 Driver_select called with too large file descriptor N套接字的文件描述符数超过 1024 （仅适用于 Unix 系统）。某些 Unix 文件描述符的限制可以设置为超过 1024 ，但 Erlang 只能同时使用 1024 个 套接字/管道（因为 Unix 中 select 调用的限制）。打开常规文件的数量不受此影响。 Received SIGUSR1发送 SIGUSR1 信号给 Erlang 虚拟机（仅适用于 Unix 系统）可以强制生成 crash dump 。这个 Slogan 指明 Erlang 虚拟机的 crash dump 是由于收到该信号导致的 Kernel pid terminated () ()内核监控程序检测到故障，通常 application_controller 已经关闭（ Who = application_controller, Why = shutdown ）。Application Controller 可能由于许多原因而关闭，最常见的原因是分布式 Erlang 节点的节点名已经被使用了。一棵完整的监控树 crash （即，最顶层的监控者已经退出）也会给出同样的结果。该消息来自 Erlang 代码，而不是虚拟机自身。这总是由于应用程序里的一些故障，无论它是在 OTP 还是用户写的应用都如此。可能第一步适当采取的应该是查看你的应用程序日志。 Init terminating in do_boot ()主要的 Erlang 启动顺序已经被终止，最可能是因为启动脚本有错误或无法读取。这通常是配置错误；系统可能使用了错误的 -boot 参数、或从错误的OTP版本中的启动脚本来启动。 Could not start kernel pid () ()内核进程之一无法启动。这可能是因为参数有问题（比如 -config 参数中有错）或配置文件错误。检查所有文件是否在正确的位置，并且检查配置文件（如果有的话）是否有损坏。通常消息也会写入控制终端和/或错误日志中以解释哪里错了。 其他错误除上面外的其他错误也可能会发生，因为 erlang:halt/1 BIF 可以产生任何消息。如果消息不是由 BIF 产生的，并且不在上面的列表之一中，那可能是由于模拟器出现错误了。然而，可能会出现不寻常的消息，即这里没提及到，但仍然是与应用程序故障有关的。有更多可用的信息，所以完整阅读 crash dump 可以披露 crash 的原因。进程的大小， ETS表的数量， 以及每个Erlang进程栈的数据对找出所在问题都是有帮助的。 原子数crash 时系统中的原子数显示为 Atoms: ，好大几W个原子数是完全正常的，但更多地可以表明 BIF erlang:list_to_atom/1 用来动态生成不同的原子，它绝不是一个好方式。 调度器信息（Scheduler Information）在标签 =scheduler 下面，显示了有关运行时系统中调度顺的当前统计的信息。在操作系统中允许暂停其他线程，在本节中的数据反映了当发生 crash 时运行时系统的状态。 进程可以存在以下字段： =scheduler:id标题。说明调度器的ID Scheduler Sleep Info Flags如果为空，表示调度器正在工作中。 如果非空，则调度器正处于某种状态中： sleep 、 suspended 。 该条仅出现在基于 SMP 模拟器中。 Scheduler Sleep Info Aux Work如果不为空，则调度器内部的辅助工作已经调度完成。 Current Port当前由调度器执行的 port 的 port 标识符。（译注：Port 在Erlang中与普通理解的 Port 并不太一样。它是一种 Erlang 与外部程序通信的方式之一） Current Process由当前调度器执行的进程的进程标识符。如果有这样的一个进程，这个条目下面就跟着有：State ， Internal State ， Program Counter 以及 CP 。这些项是描述了 进程信息部分 注意，这些是当 crash dump 开始生成时的一个快照。因此，它们很可能与在 = proc 部分找到的同样进程的条目不太相同（并说明更多）。如果当前没有运行的进程，则仅显示 Current Process Current Process Limited Stack Trace本条目仅在有 Current Process 时显示。类似 =proc_stack ，除了仅显示函数帧（也就是说，省略了栈变量）。此外，仅显示栈的顶部和底部。如果栈足够小的话（ &lt; 512 个 slots ），则会完整显示。否则显示条目 skipping ## slots ， ## 是被忽略的 slots 数量。 Run Queue显示在此调度器上有多少个进程和不同调度优先级的 port 的统计信息 ** crashed **该条目通常是不会显示的。这意味着获取有关此调度器的其余信息由于某些原因而导致失败。 内存信息（Memory Information）在标签 =memory 下面显示的信息类似于在一个存活的节点通过 erlang:memory() 获取的信息。 内部表信息（Internal Table Information）在标签 =hash_table: 和 =index_table: 下面显示了内部表的信息。这是运行时系统开发者最感兴趣的。 分配区域（Allocated Areas）在标签 =allocated_areas 下面显示了在一个存活节点中通过 erlang:system_info(allocated_areas). 获取的信息类似。 分配器（Allocator）在标签 =allocator: 下显示了各种关于分配器 的信息。这些信息类似于在一个存活的节点上通过 erlang:system_info({allocator, }). 获取的信息。更多信息，请参阅 erts_alloc(3) 进程信息（Process Information）Erlang crashdump 包含了每个存活在 Erlang 系统的进程列表。以下字段可以存在于一个进程中： =proc:标题。指示进程的 ID State进程的状态。可以是以下中的一个: Scheduled进程被调度去执行，但它当前并不在运行（“在 Run Queue 中”） Waiting进程正等待某些东西（在接收） Running进程正在运行。如果 BIF erlang:halt/1 被调用，就是该进程调用它的。 Exiting进程正在退出 Garbing这是不幸运的，当写 crash dump 时该进程正在被垃圾收集。该进程的其余信息就有限了。 Suspended进程在 suspended 中，可能是由 BIF erlang:suspend_process/1 调用或它尝试向一个繁忙的 port 写数据导致的。 Registered name该进程的注册名，如果有的话。 Spawned as进程的入口点，即启动进程的 spawn 或 spawn_link 函数的引用。 Last scheduled in for | Current call当前进程的函数。该字段并不是总会存在的。 Spawned by进程的父进程，即执行 spawn 或 spawn_link 的进程。 Started进程启动的日期和时间 Message queue length进程消息队列的长度 Number of heap fragments已分配的堆帧数 Heap fragment data堆帧数据大小。该数据是由发送到该进程的消息或者由 Erlang BIFs 创建的。这个数量取决于该字段完全不感兴趣的事情数。 Link list与此进程相关联的进程ID列表。也可包含 ports 。如果进程用作监视的话，该字段还会告知有效的直接监控。也就是说，一个连到进程的连接，它告诉你 当前 进程正监控其他进程（译注：即 P1 -&gt; P2，这表示P2正监控P1）。一个从进程中的连接，它告诉你其他的进程正监控着当前的进程。（译注：P1 &lt;- P2 ，表示P1正在监控P2） Reductions进程消耗的减少量。 译注：该字段不是很理解。。 Stack+heap栈和堆的大小（它们共享内存段） OldHeapold heap 的大小。Erlang虚拟机使用2代的分代垃圾收集器。有一个用于新数据项的堆，另一个用于两个垃圾收集后还存活的数据。这个假设（这几乎总是正确的）是，两个垃圾收集还存活的数据可以 升级 到一个更少垃圾收集的堆中，因为它们将存活比较长的一段时间。这是虚拟机中常见的技术。堆和栈一起的总和构成了进程的绝大部分分配的内存。 Heap unused, OldHeap unused每个堆上未使用的内存量。它通常是无用的。 Memory该进程总使用内存量。它包括了调用栈、堆和内部结构。与 erlang:process_info(Pid,memory) 相同。 Program counter当前指令指针。仅运行时系统开发者感兴趣。它指向的函数是当前进程的函数。 CPContinuation Pointer，即当前调用的返回地址。对于非运行时系统开发者来说是无用的。可以跟踪 CP 指向的函数，即调用当前函数的函数。 Arity实数参数的寄存器数量。如果有实参的话则紧接着参数寄存器。它可包含函数参数，如果它们还没有迁移到栈的话。 Internal State关于该进程的更多内部状态 其他参看 process data Port 信息这部分列出了打开的 ports ，它们的拥有者，任何连接的进程，它们 driver 或外部进程的名字。 ETS 表这部分包含了系统中的所有关于 ETS 表的信息。以下是每一张表的字段 =ets:标题。指明表的拥有者（一个进程ID） Table表的ID。如果它是一个 named_table ，则是它的名字。 Name表名，不管它是否是一个 named_table Hash table, Buckets是否是一张 hash 表，即，它并不是一张 ordered_set 表 Hash table, Chain Length表是否是一张 hash 表。包含了关于表的统计信息，比如：最大、最小和平均链长度。具有比平均值大得多和远大于预期标准偏差的标准偏差，这表示由于某些原因，terms 的 hash 表现不好。 Ordered set (AVL tree), Elements表是否是 ordered_set 。（元素的数量与表中的对象数相同） Fixed表是否使用 ets:safe_fixtable/2 或一些内部机制修复了。 Objects表中的对象数 Words表中数据被分配的字数（通常4字节为一字） Type表的类型， set , bag , dublicate_bag 或 ordered_set Compressed表是否压缩 Protection表的 protection Write Concurrency表是否开启 write_concurrency Read Concurrency表是否开启 read_concurrency 计时器（Timers）这部分包含了所在关于以 erlang:start_timer/3 和 erlang:send_after/3 启动的计时器信息。以下是每个计时器的字段： =timer:标题。指明 timer 的拥有者（一个进程ID），也就是说，进程接收消息时 timers 过期了。 Message被发送的消息 Time left直到消息将被发送的剩余毫秒数（milliseconds left) 分布式信息（Distribution Information）如果 Erlang 节点存活，即设置了与其他节点进行通信，这部分列出了活动的连接。可以存在以下字段： =node:节点名 no_distribution节点是否并不是分布式的 =visible_node:可视节点的标题，即，一个存活节点连接到一个 crash 的节点。指明了节点的 channel 序号。 =hidden_node:隐藏节点标题。隐藏节点与可视节点相同，除了它是以 -hidden 标识开头。指明了节点的 channel 序号。 =not_connected:早先连接到 crash 节点的节点标题。crash 时存在的未连接节点的引用（即，进程或 port 的标识符）。指明了节点的 channel 序号。 Name远程节点的名字 Controller控制与远程节点通信的 port Creation与节点名标识符一起的一个整数（1-3）来标识特定的节点实例。 Remote monitoring: 在 crash 时，正监控远程进程的本地进程 Remotely monitored by: 在 crash 时，正在监控本地进程的远程进程 Remote link: 在 crash 时，存在于本地进程和远程节点的链接。 已加载模块的信息（Loaded Module Information）这部分包含了关于所有已加载模块的信息 首先是已加载代码的占用内存总述： Current code ： 模块的当前最新版本的代码 Old code : 在系统中存在更新版本的代码，但旧版本还没有被清除的代码 内存占用是以字节为单位的。然后会列出所有已加载的模块。会出现以下字段： =mod:标题。指明模块名 Current size已加载代码的内存占用，单位字节 Old size旧代码的内存占用，单位字节 Current attributes当前代码的模块属性。该字段会在使用 Crashdump Viewer 工具时被解码。 Old attributes旧代码的模块属性，如果有的话。该字段会在使用 Crashdump Viewer 工具时被解码。 Current compilation info当前代码的编译信息（选项）。该字段会在使用 Crashdump Viewer 工具时被解码。 Old compilation info旧代码的编译信息（选项），如果有的话。该字段会在使用 Crashdump Viewer 工具时被解码。 Fun 信息该部分列出所有 funs 。以下字段可出现在每一个 fun 中。 =fun标题 Modulefun 定义所在的模块名 Uniq, Index标识符 Addressfun 代码的地址 Native_address当开启 HiPE 时, fun 代码的本地代码地址 Refc引用 fun 的引用数 进程数据（Process Data）对于每一个进程，至少有一个 =proc_stack 和一个 =proc_heap 标签，后接着的是进程的栈和堆的原始内存信息 对于每一个进程，如果进程的消息队列不为空的话，还会有一个 =proc_messages 标签，如果进程的 dictionary （即 put/2 和 get/1 所做的事）不为空的话，还有一个 proc_dictionary 标签。 原始内存信息可以在使用 Crashdump Viewer 工具时被解码。然后你可以看到栈的dump，消息队列（如果有话），以及 dictionary （如果有话） 栈 dump 是Erlang进程的dump 。大多存活的数据（即，当前使用的变量）会放到栈上；因此可能比较感兴趣。人们可以猜测它是什么，但作为信息来说是符号来的，完整阅读这些信息可能是有用的。例如，我们可以在下面的例子的第5，和第6行中找出 Erlang 基本加载器的变量状态： 1234567(1) 3cac44 Return addr 0x13BF58 (&lt;terminate process normally&gt;)(2) y(0) ["/view/siri_r10_dev/clearcase/otp/erts/lib/kernel/ebin",(3) "/view/siri_r10_dev/clearcase/otp/erts/lib/stdlib/ebin"](4) y(1) &lt;0.1.0&gt;(5) y(2) &#123;state,[],none,#Fun&lt;erl_prim_loader.6.7085890&gt;,undefined,#Fun&lt;erl_prim_loader.7.9000327&gt;,(6) #Fun&lt;erl_prim_loader.8.116480692&gt;,#Port&lt;0.2&gt;,infinity,#Fun&lt;erl_prim_loader.9.10708760&gt;&#125;(7) y(3) infinity 当为进程解释这些数据时，有助于知道匿名函数对象（funs) 是给出以下： 创建它们的函数的名字的名称构造 一个数字（从0开始），表示该函数中的 fun 个数。 原子（Atoms）本节介绍系统中所有的原子。这仅是那些怀疑动态生成原子会是个问题的人感兴趣的部分，否则，这一节可以忽略。 请注意，最后创建的原子反而是最先显示的。 免责声明（Disclaimer）crash dump 文件格式会在 OTP 版本之间演变。此处描述的某些信息可能并不适用于你的版本。这样的描述永不会完整；这意味着，对于 crash dump 的解释是一般的，以及对尝试查找应用程序错误是有帮助的，而不是完整的规范。]]></content>
      <tags>
        <tag>翻译</tag>
        <tag>erlang</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]RabbitMQ中 immediate 和 mandatory 的用法]]></title>
    <url>%2F2017%2F05%2F11%2F%E7%BF%BB%E8%AF%91-RabbitMQ%E4%B8%AD-immediate-%E5%92%8C-mandatory-%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文 immediate 和 mandatory 字段是 AMQP 规范的一部分，并且还包含在 RabbitMQ FAQ 中指出实现者如何解释它们的含义的。 Mandatory 如果消息无法路由到队列，则此标志告诉服务器如何执行。具体来说，如果设置了 mandatory 并且运行绑定消息后（译注：即进行消息路由）放到0个队列中，则该消息返回给发送者（通过 basic.return ）。如果在相同情况下但没有设置 mandatory ，则服务器会静默地删除该消息。 或者用我的话说：把这条消息放到至少一个队列上，如果你无法做到，那就将它返回给我。 immediate 对于发布一条带有 immediate 的消息，如果匹配的队列中已经准备好了消费者，则将消息路由到其中一个队列中。如果消费者刚在 ack 接收信息之前崩溃了，则该消息将被重新进队 和/或 分发到其他该队列上的消费者（如果没有崩溃，那么消息被确认，并且按照正常情况进行）。但是，如果匹配的队列中具有 0 个就绪消费者，那么该消息在随后的队列分发中不会重新进队。只有当所有匹配的队列中都没有就绪的消费者时才会将消息返回给发送者（通过 basic.return ） 或者用我的话说：“如果至少有一个消费者连接到我的队列，并且该消费者现在就可以消费这条消息，则立即分发这条消息给它们。如果没有消费者连接到我的队列，那么我的消息延迟消费是毫无意义的，然后消费者就会一直看不到它。They snooze, they lose.”]]></content>
      <tags>
        <tag>翻译</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]RabbitMQ 的 Management Plugin 插件]]></title>
    <url>%2F2017%2F05%2F11%2F%E7%BF%BB%E8%AF%91-RabbitMQ-%E7%9A%84-Management-Plugin-%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[介绍rabbitmq-management 插件提供了基于 HTTP 的API来管理及监控你的 RabbitMQ 服务器，以及基于浏览器的UI和命令工具 rabbitmqadmin 。功能包括： 声明，列出和删除交换机、队列、绑定、用户、虚拟主机和权限 监控队列长度、全局和每个Channel的消息速率、每条连接的数据速率，等等 监控资源使用，例如：文件描述符、内存使用、可用磁盘空间 管理用户（要求当前用户具有管理员身份的权限） 导出和导入对象定义（虚拟机、用户、权限、队列、交换机、绑定、参数、策略）到 JSON 强制关闭连接(connection)、清除队列消息（purge queues) 发送和接收消息（对于开发环境以及分析解决问题比较有用） 开始management plugin 插件是包含在 RabbitMQ 发行版中的。为了开启它，使用 rabbitmq-plugins: 1rabbitmq-plugins enable rabbitmq_management Web界面的地址在： http://server-name:15672/ 在插件里Web界面同样使用该插件来提供一个 HTTP API 。查看 API 文档可以访问： http://server-host:15672/api/ 或者我们 这里最新的 HTTP API 文档 下载 rabbitmqadmin 的地址为: http://server-name:15672/cli/ 注意，在 RabbitMQ 3.0 版本之前的端口为 55672. 为了使用 Web 界面你需要使用 RabbitMQ 用户来进行身份认证（新安装的时，用户名为 guest，密码为 guest）。在这里，你可以管理交换机、队列、绑定、虚拟主机、用户和权限。希望界面是自解释的。 management 的界面的实现是单个静态HTML页面的，它使用后台查询 HTTP API 。因此，它大量使用 JavaScript。它已经在最近版本的 Firefox、Chromium 和 Safari 测试过了，并且也回归测试过了 IE 6.0 权限 management &lt; policymaker &lt; monitoring &lt; administratormanagement 插件有些扩展了现有的权限模型。在RabbitMQ中，可以给定用户任意标签。 management 插件使用名为 management 、 policymaker 、 monitoring 和 administrator 的标签。下表显示了不同类型的用户可以做些什么： 标签为：空不能访问 management 插件 标签为：management可以做的事有： 列出所有可以通过 AMQP 登录的虚拟主机 在 它们 所在的虚拟主机中，查看所有队列、交换机和绑定 查看和关闭它们各自的 Channel 和 Connections 查看覆盖它们自己所有虚拟主机的 全局 统计信息，包括其他用户在这些虚拟机主内的活动 标签为：policymaker所有 management 可以做的，加上下面： 查看、创建和删除可以通过 AMQP 登录的虚拟主机的策略和参数 标签为: monitoring所有 management 可以做的，加上下面： 队列所有虚拟主机，包括无法通过 AMQP 登录的虚拟机主机 查看其他用户的 connection 和 channel 查看节点级别数据，比如：内存使用和集群 查看所有虚拟主机真实的全局统计信息 标签为: administrator所有 policymaker 和 monitoring 可以做的，加上： 创建和删除虚拟主机 查看、创建和删除用户 查看、创建和删除权限 关闭其他用户的 connection 注意，由于 administrator 可以做所有 monitoring 的事，而 monitoring 可以做所有 management 可做的事，因此你通常只需要为每个用户提供最多一个标签即可。 后续正常的 RabbitMQ 权限仍然适用于 monitors 和 administrators ；只是因为用户是一个 monitor 或 administrator 并不能通过 AMQP 或 management plugin 插件给它们完全访问交换机、队列和绑定。 如果由于只有 non-administrator 用户或根本没有用户而被锁定，你可以使用 rabbitmqctl add_user 来创建一个 non-administrator 用户，然后使用 rabbitmqctl set_user_tags 来提升它为 administrator HTTP APImanagement plugin 插件会创建一个基于 HTTP 的API在 http://server-name:15672/api/ ，浏览该地址可以获取有关API的更多信息。为了方便起见，你可以在 Github 中阅读 最新HTTP API文档 可以在启用了 rabbitmq-management 插件的任何节点上使用 HTTP API 。然后它能够提供在集群节点中一个或所有节点的测量信息。当监视节点集群时，不需要单独通过 HTTP API 与每个节点进行联系。相反，联系随机一个节点或集群中负载均衡器前端即可。 对于多种语言的 HTTP API 客户端，请参阅 开发者工具 rabbitmqadmin 是一个 Python 的与HTTP API 交互的命令行工具。它可以从任意的开启了 management plugin 的RabbitMQ节点中下载，地址为: http://server-name:15672/cli/ 配置这时有几个影响 management plugin 插件的配置选项。它们是通过 RabbitMQ 主配置文件 进行管理的. 启动时加载定义management plugin 插件允许你导出所有包含 Broker 对象（队列、交换机、绑定、用户、虚拟主机、权限和参数）定义的JOSN文件。在某些情况下，确定在启动时都存在这些对象可能是有用的。 为此，请将 rabbitmq_management.load_definitions 的配置项，指向你先前导出的JSON文件的路径： 12345[&#123;rabbitmq_management, [ &#123;load_definitions, "/path/to/definitions/file.json"&#125; ]&#125;]. 注意，文件中的定义将会覆盖现存在 Broker 中的所有内容。使用这个选项并不会删除任何已经存在的内容。但是，如果从完全重置的 Broker 中开始的话，使用这个选项将会阻止创建默认的 用户/虚拟机/权限 。 消息速率默认情况下，management plugin 插件显示全局的消息速率，以及每条队列、每个Channel、每个交换机和虚拟主机。这些被称为 basic 消息速率 它还可以显示所有 channel -&gt; exchange ， exchange -&gt; queue 和 queue -&gt; channel 组合的消息速率。这些被称为 detailed 消息速率。默认情况下是禁用 detailed 消息速率的，因为当存在大量的 channel 、queue 和 exchange 组合时，它们可能会占用大量的内存。 或者，可以完全禁用消息速率。这可以帮助你从绑定的CPU(CPU-bound)中获得最好的性能。 消息速率的模式可以由 rabbitmq_management 中的配置 rates_mode 来控制。它们可以为 basic (默认值)、detailed 或 none 统计间隔默认情况下，服务器将每 5000ms 收集一次统计信息。management plugin 中显示的消息速率值会在此期间进行计算。因此，你可能希望增大此值，以便在较长时间内采样本，或者减少具有大量队列或channel服务器上统计时的负载。 为此，请将 rabbit 应用的 collect_statistics_interval 变量的值设置为所需的间隔（单位为毫秒），然后重启 RabbitMQ HTTP 请求记录为了生成简单的 HTTP API 请求访问日志，请将 rabbit_management 应用程序中的 http_log_dir 变量的值设置为日志所在的目录，然后重启 RabbitMQ 。注意，只有请求的API为 /api 的才会被记录，而不是组成浏览器的GUI的静态文件的请求。 事件积压在高负载下，统计事件的处理会增加内存消耗。为了减少这种情况，可以调节 channel 和 queue 统计信息收集器的最大积压数。在 rabbitmq_management 应用的 stats_event_max_backlog 的变量值可设置它们的最大大小。默认为 250 例子用户切换请求日志记录目录、统计间隔为 10000ms 以及其他显式设置相关参数值为默认值的配置例子如下: 123456[ &#123;rabbit, [ &#123;tcp_listeners, [5672]&#125;, &#123;collect_statistics_interval, 10000&#125; ] &#125;, &#123;rabbitmq_management, [ &#123;http_log_dir, "/tmp/rabbit-mgmt"&#125;, &#123;rates_mode, basic&#125;] &#125;]. 配置 HTTP 监听器可以配置 rabbitmq-web-dispatch 来为 management plugin 监听不同的端口或网卡、开启SSL等。为此，你应该配置 listener 配置项，例如更改端口: 12345[ ... &#123;rabbitmq_management, [&#123;listener, [&#123;port, 12345&#125;]&#125;]&#125;, ...]. 或者为 management plugin 开启HTTPS: 123456789[&#123;rabbitmq_management, [&#123;listener, [&#123;port, 15671&#125;, &#123;ssl, true&#125;, &#123;ssl_opts, [&#123;cacertfile, "/path/to/cacert.pem"&#125;, &#123;certfile, "/path/to/cert.pem"&#125;, &#123;keyfile, "/path/to/key.pem"&#125;]&#125; ]&#125; ]&#125;]. 查看 rabbitmq-web-dispatch 指南来获取更多细节 样本保留策略(sample retention policies)management plugin 会保留一些数据的样本，例如：消息速率和队列长度。你可以配置这些数据保留多长时间。 123456789101112[ ... &#123;rabbitmq_management, [&#123;sample_retention_policies, %% List of &#123;MaxAgeInSeconds, SampleEveryNSeconds&#125; [&#123;global, [&#123;605, 5&#125;, &#123;3660, 60&#125;, &#123;29400, 600&#125;, &#123;86400, 1800&#125;]&#125;, &#123;basic, [&#123;605, 5&#125;, &#123;3600, 60&#125;]&#125;, &#123;detailed, [&#123;10, 5&#125;]&#125;] &#125;] &#125;, ...]. 有三个策略： global : 保留概要和虚拟主机页面的数据的时间 basic : 保留独立连接、channel、交换机和队列数据的时间 detailed : 保留连接、channel、交换机和队列间配对数据的时间 此配置（默认值）将全局数据以固定5秒（即每5秒采样一次）持续10分钟5秒，然后以固定1分钟持续我小时1分钟采样，然后以固定10分钟持续大约8小时。它保留 basic 数据在固定5秒持续1分5秒，然后固定1分持续1小时； detailed 数据仅持续10秒。 所有三个策略是强制性的，并且必须包含至少一个保留对 {MaxAgeInSeconds, SampleEveryNSeconds} 。 跨域资源共享(CROS)management plugin 的API默认情况下不允许访问托管在不同来源的网站。要允许的来源网站必须显式地列出在白名单中: 123456[ ... &#123;rabbitmq_management, [&#123;cors_allow_origins, ["http://rabbitmq.com", "http://example.org"]&#125;]&#125;, ...]. 可以允许任何来源来使用 API 。但是，如果API可以从外部访问的话，则不建议。 123456[ ... &#123;rabbitmq_management, [&#123;cors_allow_origins, ["*"]&#125;]&#125;, ...]. CROS 的 pre-flight 请求会被浏览器缓存。 默认情况下， management plugin 插件定义了超时时间为 30 分钟。你可以在配置文件中修改此值。它的单位为秒。 1234567[ ... &#123;rabbitmq_management, [&#123;cors_allow_origins, ["http://rabbitmq.com", "http://example.org"]&#125;, &#123;cors_max_age, 3600&#125;]&#125;, ...]. 集群注意事项management plugin 插件是会感知集群的。你可以在集群中的一个或多个节点上启用它，并且无论你连接到哪个节点，都可以查看整个集群的信息。 如果要部署一个没有完全开启 management plugin 的集群节点，则仍然需要在每个节点上启用 rabbitmq-management-agent 插件。 当在集群时，management plugin 执行集群范围查询时，这意味着它可能受到各种网络事件（如 分区）的影响。 代理设置可以通过符合 RFC 1738 的任何代理使 Web UI 可用。以下 Apache 配置示例说明了使用Apache作为代理性的最少必须指令。它假定 management plugin 的 Web UI 在默认端口 15672 。 重启统计数据库统计数据库是完全存储在内存中的。应该对待它们的所有内容都是短暂的。在 3.6.7 版本之前，统计数据存储在单个节点上。从 3.6.7 开始，每个节点都有自己的统计数据库，其中包含在该节点上记录的统计数据。可以重启这些统计数据库。 在 RabbitMQ 3.6.2 之前，统计数据库是存储在 stats 进程的内存中的，并且在 RabbitMQ 3.6.2 开始，它们是存储在 ETS 表中的。在 3.6.2 之前的版本中，要重启数据库可以使用: 1rabbitmqctl eval 'exit(erlang:whereis(rabbit_mgmt_db), please_terminate).' 从 RabbitMQ 3.6.2 到 3.6.5 ，可以使用: 1rabbitmqctl eval 'supervisor2:terminate_child(rabbit_mgmt_sup_sup, rabbit_mgmt_sup),rabbit_mgmt_sup_sup:start_child().' 这些命令必须要托管数据库的节点上执行。从 3.6.7 开始，可以使用下面命令来重置每个节点的数据库: 1rabbitmqctl eval 'rabbit_mgmt_storage:reset().' 要重置所有节点的数据库： 1rabbitmqctl eval 'rabbit_mgmt_storage:reset_all().' 也可以通过 HTTP API 端重置整个数据库: 1DELETE /api/reset 重置单个节点: 1DELETE /api/reset/:node 内存管理可以使用 rabbitmqctl 来获取 management database 的内存使用情况： 1rabbitmqctl status 或者通过 HTTP API 发送一个 GET 请求到 /api/nodes/name 统计数据是按照上述统计间隔进行的，或者当某些组件被 创建/声明 时（例如，一条新的 connection 或 channel 被打开，或一个队列被声明）或者 关闭/删除时。消息速率不会直接影响 management database 的内存使用。 统计数据库的内存消耗总量取决于事件的触发间隔，有效的速率模式和保留策略。 将 rabbit.collect_statistics_interval 的值增加到 30-60s （注意，该值应以毫秒为单位来设置，例如： 30000) 将减少具有大量 队列/channel/连接 的系统的内存消耗。调整保留策略以保留较少的数据也将有所帮助。 通过使用参数 stats_event_max_backlog 设置最大积压队列大小可以限制 channel 和统计收集器进程的内存使用情况。如果积压队列已满，则新的 channel 和 队列收集将被丢弃，直到前面的队列处理完毕。 统计间隔也可以在运行时更改。这样做对现有的 连接、channel 或 队列没有影响。只会影响新的统计收集实体。 1rabbitmqctl eval 'application:set_env(rabbit, collect_statistics_interval, 60000).' 统计数据库也可以被重启（见上面），因此它会强制释放所有内存。 译者题外话今天在公司里发现中间件 RabbitMQ 队列数据基本没有，但是还是发现它占用了 9GB 多的内存: 一开始，第一感觉认为它是内存泄漏了。所以就顺便翻译了这篇文章，也方便自己日后查看。通地重启统计数据库，即可完全释放掉这部分的内存。]]></content>
      <categories>
        <category>rabbitmq</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]RabbitMQ中的消费者确认和发布者确认]]></title>
    <url>%2F2017%2F05%2F10%2F%E7%BF%BB%E8%AF%91-RabbitMQ%E4%B8%AD%E7%9A%84%E6%B6%88%E8%B4%B9%E8%80%85%E7%A1%AE%E8%AE%A4%E5%92%8C%E5%8F%91%E5%B8%83%E8%80%85%E7%A1%AE%E8%AE%A4%2F</url>
    <content type="text"><![CDATA[原文 介绍使用消息 Broker 的系统，例如 RabbitMQ 是被定义为分布式的。由于协议的方法（消息）的发送并不能保证到达对应目的地或者被成功地处理掉这些消息，因此，发布者和消费者都需要一个进行分发和处理的确认机制。RabbitMQ 支持的几种消息协议都支持这种特性。本指南介绍了AMQP 0-9-1的功能，但其他协议（STOMP，MQTT等）的思想基本相同。 消费者对RabbitMQ的分发处理确认称为 AMQP 0-9-1 说明中的确认；Broker 对发布者的确认是一种协议扩展，称为发布者确认。 消费者分发确认当 RabbitMQ 分发一条消息给消费者时，它需要知道什么时候认为消息已经被成功发送了。至于是什么样的逻辑优化，取决于系统。因此主要由应用层来决定。在 AMQP 0-9-1 中，它是通过当消费者使用 basic.consume 方法来注册或者通过 basic.get 方法按需获取消息时实现的。 如果你更喜欢采用面向例子并且循序渐进的资料，消费者确认在 RabbitMQ 教程#2 有介绍。 分发标识符(Delivery Identifiers)：分发标签(Delivery Tags)在我们继续讨论其他主题之前，重要的是要解释分发是如何被标识的（并且确认指明他们各自的分发）。当消费者（订阅）注册时，消费将被 RabbitMQ 通过使用 basic.deliver 方法来分发（推送）。该方法携带一个分发标签（devlivery tag)，它唯一地标识了在 Channel 上的分发。分发标签(devlivery tag) 因此是每个 channel 范围私有的。 分发标签(devlivery tag) 是单调递增的正整数，并由客户端库来表示。客户端库中的确认分发的方法，将带上一个分发标签(devlivery tag)作为参数。 确认方法根据所使用的确认模式，RabbitMQ可以在发送（写入TCP套接字）后立即认为消息已经被成功地分发或者当接收到客户端显式（“手动”）确认时才认为它已经被成功地分发。手动发送的确认消息可以为主动或被动，并且使用以下协议方法之一: basic.ack ：用于主动确认 basic.nack ： 用于被动确认（注意，这是一个 RabbitMQ 对 AMQP 0-9-1 的扩展 ） basic.reject : 用于被动确认，但与 basic.nack 比较而言，它有一些限制。 主动确认就简单地指示 RabbitMQ 记录一条消息已经被成功地分发了。 使用 basic.reject 的被动确认也有同样的效果。差异主要在于主义方面：主动确认假设消息已经被成功地处理了，而被动确认对应的是分发的消息并没有被成功处理，但消息仍然应该被删除。 一次性确认多条分发手动确认可以被批量处理，以减少网络传输。这可以通过设置确认方法（参见上面）中的 multiple 字段为 true 来实现。请注意， basic.reject 以前并没有该字段，这就是为什么 basic.nack 被 RabbitMQ 作为一个协议扩展来引入。 当 multiple 字段设置时，RabbitMQ 将确认所有未完成的分发标签 直到并包括 确认中的指定的标签。像其他与确认相关的东西一样，它也是 Channel 私有的。例如，在 Channel ch 中给定了分发标签为 5，6，7，8 是未确认的， 当一个带有 delivery_tag 为8， multiple 为 true 的确认帧到达 channel ch 后，所有从5到8（包括）的标签都会被确认。如果 multiple 为 false ，则分发的 5,6,7将仍然是未确认的。 Channel 的 prefetch 设置（QoS)由于消息发送（推送）到客户端是异步的，因此Channel中，在给定的一瞬间，通常有超过一条消息是 in flight 状态的。此外，从客户端手动确认本质上也是异步的。因此，会有一个没有被确认的分发标签的滑动窗口。开发者通会倾向于限制此窗口的大小，以避免消费者端无限缓冲的问题。这是通过使用 basic.qos 方法设置 预取计数 值来完成的。该值定义了Channel上允许的未确认的分发的最大数值。一旦数量达到配置的计数，RabbitMQ 将停止在该Channel 上分发更多消息，除非至少有一个未确认的消息被确认了。 例如，在给定的Channel ch 上有分发标签为 5,6,7,8 的未确认消息，并且 Channel ch 的 prefetch 计数设置为4，则 RabbitMQ 将不会推送更多的分发给 Channel ch，除非至少有一个未完成的分发被确认了。当该Channel上有一个带有 delivery_tag 为 8的确认帧到达时，RabbitMQ 将通知和分发多一条消息给该Channel。 值得重申的是，分发流程和客户端手动确认完全是异步的。因此，如果 prefetch 的值在分发已经在 in flight 状态时被改变了，则会出现自然竞态条件，并且可能会暂时超过 Channel 上 prefetch 计数的未确认消息。 可以为Channel或消费者设置 QoS 。详情参看 Consumer Prefetch 客户端错误：双重确认以及未知标签(double acking and unknow tags)如果客户端多次对同一个分发标签进行确认，RabbitMQ 将导致一个 Channel 错误，例如 PRECONDITION_FAILED - unknown delivery tag 100 。如果使用了一个未知的分发标签，也会抛出同样的 Channel 异常。 发布者确认使用标准的 AMQP 0-9-1 ，保证消息不丢失的唯一方法是使用事务——用 Channel 事务，发布消息，提交。在这种情况下，事务是不必须的，而且它是重置级的，并且会降低 250 倍左右的吞吐量。为了弥补这一点，引入了确认机制。它模仿了协议中已经存在的消费者确认机制。 为了开启确认机制，客户端发送 confirm.select 方法。根据是否设置 no-wait , Broker 可以使用 confirm.select-ok 来响应。一旦 confirm.select 在Channel上使用了，就被认为处于确认模式。事务Channel 不能进入确认模式，并且一旦Channel处于确认模式，则不能进行事务处理。 一旦Channel处理确认模式， Broker 和 客户端都会计数消息（在第一个 confirm.select 时，从1开始计数）. Broker 通过在同一个Channel上发送一个 basic.ack 来确认消息。 delivery-tag 字段包含已经确认消息的序列号。Broker 也可以在 basic.ack 设置 multiple 以指示所有到达并包含具有序列号的消息已经被处理。 Java中的一个发布大量的消息到一个确认模式的Channel并等待确认的例子，可以在 这里 找到. 被动确认在特殊情况下，当 Broker 无法成功处理消息时，Broker 会发送一个 basic.nack 而不是 basic.ack 。在这种情况下，basic.nack 的字段具有与 basic.ack 相应字段的相同含义，并且 requeue 字段应该被忽略。nack 一条或多条消息时，Broker 指示它无法处理消息，并拒绝为它们承担责任；在这点上，客户端可以选择重新发布消息。 Channel处理确认模式后，所有后续发布的消息将会被确认或 nack 一次。并不保证消息被确认要多久。不会存在消息既是确认又是 nack情况。 如果在负责该队列的Erlang进程中，发生内部错误时，则仅会分发 basic.nack 。 什么时候消息会被确认？对于不可路由的消息，一旦交换机验证一条消息将不会被路由到任何队列（返回一个空的队列列表），Broker 将发出确认。如果消息也被发布为 mandatory 时，则在 basic.ack 之前将发送一个 basic.return 给客户端。被动确认( basic.nack )也如此。 对于可路由的消息，当消息被所有队列接受时，就发送 basic.ack 。对于路由到持久化队列的持久化消息，这意味着已经持久化到磁盘了。对于镜像队列，这意味着所有镜像都已经接受了该消息。 对于持久化消息的 ACK 延迟对于持久化消息路由到一个持久化队列时，将在消息持久化到磁盘后发送 basic.ack 。RabbitMQ 消息存储间隔（几百毫秒）后，将消息分批存储，以最小化调用 fsync(2) 次数，或当队列空间时。这意味着，在一直恒定的负载下， basic.ack 的延迟可以达到几百毫秒。为了提高吞吐量，强烈建议应用程序进行异步处理确认（作为流），或者批量发布消息，并等待未完成的确认。不同的客户端库之间的具体API有所不同。 发布者确认的顺序注意事项在大多数情况下，RabbitMQ 将与发布的相同顺序向发布者确认消息（这适用于在单个Channel上发布的消息。但是，发布者确认是异步发出的，可以确认单条消息或一组消息。发出确认的确切时刻取决于消息的分发模式（ persistent VS transient) 以及消息被路由到队列的属性（见上面）。也就是说，不同的消息可以被认为是准备好在不同的时间进行确认的。这意味着与其各自的消息相比，确认可以以不同的顺序到达。应用程序不应该依赖于确认的顺序。 发布者确认和保证分发如果在所有消息写入磁盘之前崩溃，Broker 将丢失持久的消息。 在某些情况下，这些会导致 Broker 会有意外的行为。 例如，考虑这种情况： 客户端向持久化队列发送一条持久化消息 客户端从队列中消费消息（注意，消息是持久化的，队列也是持久化的），但并没有 ack 它 Broker 挂了，并且重启 客户端重连，并且开始消费消息 在这一点上，客户端可以合理地假设该消息将被再次分发。这并不是以下情况：重启导致 Broker 丢失消息。为了保证持久性，客户端应该使用确认。如果发布者的 Channel 已经处在确认模式，发布者将不会收到丢失的消息的 ACK（因为消息还没有写到磁盘） 限制最大的分发标签(maximum delivery tag) 分发标签是一个 64位的长整型数值，因此它的最大值为 9223372036854775807 。由于分发标签是 Channel 私有的，因此在实践中，发布者或消费者不太可能会运行到这个值。]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Erlang杂项]]></title>
    <url>%2F2017%2F05%2F10%2FErlang%E6%9D%82%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[erlang 启动参数说明+ : 它是 emulator flag 它控制模拟器的行为(即虚拟机)。(emulator flag).可以通过 erlang:system_info(…) 来获取。所有选项名有: system_info - : 这种参数是传递给 runtime system ，特别是 init system 来处理的。可以通过 init:get_argument/1 函数来获取这些参数，init:get_arguments(). 会列出所有。 (flag) plain argument : 它可以出现在第一个 (flag) 之前，或者在 – flag 后面。又或者是 -extra flag 后面。可以通过 init:get_plain_arguments(). 来获取 让 Erlang 接受的信号说明SIGUSR1 ： 它会导致Erlang强制产生一个 crash dump 文件。SIGTERM ： 它会产生一个 stop 的消息给 init 进程。即等同于调用 init:stop/0SIGUSR2 ： 它保留Erlang内部使用。 环境变量ERL_CRASH_DUMP这个是 crash_dump 的文件名。如果没设置，它就是在当前目录下的，crash dump 的文件名为 erl_crash.dump ERL_CRASH_DUMP_NICE当模拟器需要写crash dump文件时，这个值就是该进程的 nice value 。有效范围是 1-39 。数值越大，优先级越低。 ERL_CRASH_DUMP_SECONDS即花费在写 crash dump 文件允许耗时的秒数。当超过了这个秒数，模拟器就会被 SIGALRM 信号终止。 如果它没有设置，或者设置为0( ERL_CRASH_DUMP_SECONDS=0 )，运行时系统甚至不会尝试写 crash dump 文件。它仅仅只是终止掉。如果它为负数，比如 ERL_CRASH_DUMP_SECONDS=-1 ，则运行时系统会无限等待，直到 crash dump 文件已经被写到文件了。 ERL_CRASH_DUMP_BYTEScrash dump 文件最大的字节数，超出时它会被截断。如果没有设置，则表示没有限制。如果设置为0，则不会尝试写 crash dump 文件。 ERL_AFLAGS这个值的内容，会被添加到 erl 命令行的开头。但如果有 -extra 则比较特殊，这部分要放在该值的结尾，然后它会被放到正式命令行的 -extra 后面。 ERL_ZFLAGS and ERL_FLAGS这两个环境变量的值，会被追加到 erl 命令行的结尾。同样，如果是含有 -extra 也会特别处理。（同上） ERL_LIBS它包含额外的库目录，它会被添加到 code path 。 ERL_EPMD_ADDRESS可以设置为逗号分隔的IP地址列表，表示 epmd 进程监听的地址。（loopback 地址是一直会被监听的，无论它有没有显式指明） ERL_EPMD_PORTepmd 进程监听的端口。 注意，在一个集群中的所有节点，它们的 epmd 端口必须是相同的！！！]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDA pro 杂项]]></title>
    <url>%2F2017%2F05%2F08%2FIDA-pro-%E6%9D%82%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[常用工具分类工具 file 命令 PE Tools PEiD 摘要工具 nm ldd objdump otool dumpbin c++filt 深度检测工具 strings 反汇编器（ndisasm, diStorm)]]></content>
      <tags>
        <tag>ida</tag>
        <tag>反汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Erlang程序设计》学习笔记]]></title>
    <url>%2F2017%2F05%2F07%2F%E3%80%8AErlang%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[动态代码载入每当调用 someModule:someFunction(…) 时，调用的总是最新模块里的最新版函数，哪怕当代码在模块里运行时重新编译了该模块也是如此。 在任一时刻，Erlang允许一个模块的 两个版本 同时运行。 保存预处理的输出1erlc -P some_module.erl 它会生成 some_module.P 文件 表达式和表达式序列任何可以执行并生成一个值的事物，都被称为表达式。 表达式序列，是由一系列逗号分隔的表达式。它们在 -&gt; 箭头之后随处可见。表达式序列 E1, E2, E3,…,En 的值，被定义为序列最后那个表达式的值，而该表达式在计算时可以使用 E1, E2 等表达式所创建的绑定。定价于 LISP 里的 progn 函数引用 fun LocalFunc/Arity fun Mod:RemoteFunc/Arity 包含文件1-include(FileName). 包含库的头文件： 1-include_lib(Name). 列表操作++1A ++ B 即 A 列表和 B 列表相加 1231&gt; [1,2,3] ++ [4,5,6].[1,2,3,4,5,6]2&gt; –1A -- B 从列表 A 中移除列表 B 。移除的意思是 B 中所有元素都会从 A 里去除。请注意，如果符号 X 在 B里出现了 K 次，那么A只会移除前K个X。 123452&gt; [1,2,3,4,5,6,1,2] -- [1].[2,3,4,5,6,1,2]3&gt; [1,2,3,4,5,6,1,2] -- [1,1].[2,3,4,5,6,2]4&gt; 短路布尔表达式 Expr1 orelse Expr2 Expr1 andalso Expr2 下面的并不是短路表达式: 12A or BA and B 这种两边的参数总会被执行，即使表达式的真值只需要第一个表达式的值就能确定也是如此。 设置代码搜索路径查看1code:get_path(). 设置 1erl -pa Dir1 -pa Dir2 .... -pz DirK1 -pz DirK2 pa 表示添加到搜索的开头pz 表示添加到搜索的结尾 导出所有函数1-compile(export_all). 系统启动时执行一组命令在用户主目录的 .erlang 文件里的所有命令，都会有 erlang 启动时执行: 12345678[12:41:01] emacsist:~ $ cat ~/.erlangio:format("Hi, I'm in your .erlang file ~n").[12:41:05] emacsist:~ $ erlErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Hi, I'm in your .erlang fileEshell V8.3 (abort with ^G)1&gt; 查看用户主目录位置: 1init:get_argument(home). 在命令提示符里编译和运行12erlc hello.erlerl -noshell -s hello start -s init stop 使用 Escript 运行文件 hello 的内容: 123#!/usr/bin/env escriptmain(Args) -&gt; io:format("hello world~n"). Args 是一个原子列表 执行: 12chmod u+x hello./hello 停止Erlang有时Erlang停不了下来，以下是可能的原因 shell 没反应 Ctrl-C 被禁用 erlang 启动时设置了 -detached 标识 erlang 启动时设置了 -heart Cmd 选项。它会建立一个操作系统进程来监控Eralng的操作系统进程。如果Eralng的操作系统进程崩溃了，Cmd就会被执行。通常Cmd只是简单地重启Erlang系统。 某处出现了严重的问题，导致Erlang进程为僵尸进程 分析转储文件 erl_crash.dump1crashdump_viewer.start(). 获取帮助12erl -man erlerl -man lists 基本并发函数1234567Pid = spawn(Mod, Func, Args)Pid = spawn(Fun)Pid ! Messagereceive ... end 带超时的接收12345receive ...after Time -&gt; Expressionsend Time 为毫秒数 注意， receive 里面的表达式可以忽略。而只保留超时 1234receiveafter T -&gt; Expend. 如果 Time 为0，则会先尝试匹配 receive 里的模式，如果没有匹配，则直接执行 after 的表达式，而不会挂起。 获取最大进程限制数1erlang:system_info(process_limit) 这个数可以通过虚拟机参数 +P 100000 来设置 注册进程 register(AnAtom, Pid) unregister(AnAtom) 移除 AnAtom 的注册信息。某个注册进程崩溃了，就会自动取消注册 whereis(AnAtom) -&gt; Pid | undefined 查看AnAtom是否已经被注册。 registered() -&gt; [AnAtom::atom()] 返回所有注册进程列表 并发Erlang的错误处理它是建立在 远程检测 和 处理错误 的概念之上。即选择让进程崩溃，然后在其他进程里纠正错误。 监控进程可以 实现跨机器 的透明动作，这是编写容错式系统的基础。不能在同一台机器上构建容错式系统。 即如果某个 Erlang 进程出了点小问题，可以尝试用 catch 或 try 语句来修复它。但如果修复失败，就应该直接崩溃，让其他进程来修复这个错误。 进程链接调用函数 link(Pid) 就会在调用进程和Pid之间创建一个链接。 注意，链接是 双向 的。如果 P1 调用了 link(P3) ，则 P1 和 P3 就是相互链接了。 设立防火墙即不想系统里的错误继续扩散 在某个进程上，执行 process_flag(trap_exit, true) 这样子，错误扩散到该进程，就不会继续扩散了。 监视监视是 单向 的。如果A监视B，而B挂了，就会向A发送一个退出消息，反过来而不会如此。 RPC调用1rpc:call(Node, Mod, Func, [Arg1, Arg2, Arg3,...,ArgN]). Magic Cookie设置:1erl -setcookie ABSFSDFSADFSDFSDFSDFSF 这一般只是在测试时使用，因为使用 ps aux 可以查看它的 cookie 。 或保存在 ~/.erlang.cookie 或使用函数来设置： erlang:set_cookie(node(), C) 即将cookie设置为C 使用套接字的分布式模型lib_chan 模块 Erlang中的端口通过它来控制外部进程以及通信。Erlang负责启动和停止外部程序，还可以监视它，在它崩溃后重启。外部进程，称为 端口进程 ，因为它是通过一个 Erlang 端口控制的。 使用端口与外部进程，和使用套接字是不同的。如果使用端口，它会表现得像一个 Erlang 进程，这样就可以链接它，从某个远程分布式 Erlang 节点向它发送消息等等。如果使用套接字，就不会表现出类似进程的行为。 相连进程创建端口的进程被称为该端口的相连进程。所有发往端口的消息，都必须标明相连进程的PID，所有来自外部程序的消息都会发往相连进程。 创建端口open_port(PortName, [Opt]) -&gt; Port 向端口发送消息1Port ! &#123;PidC, &#123;...&#125;&#125; Erlang中调用外部语言代码这是一种不安全的做法。 ETS与DETS它们可以在进程间共享！（但它不会被GC） 它们保存的，都是元组。默认情况下，第一个是该表的 键。 CRUD： ets:new或dets:open_file insert(TableId, X) X为元组，或元组列表 lookup(TableId, Key) dets:close(TableId) 或 ets:delete(TableId) 表的四种类型: set ordered_set bag duplicate_bag DETS的最大文件大小是 2GB Mnesia数据库它是用Erlang编写的数据库。它支持事务，并有自己的查询语言。支持保存在内存，也可以保存在磁盘。在集群里，不同的节点可以是不同的存储类型。 它保存的是 Erlang 中的 记录 （record) 初始化1mnesia:create_schema([node()]). 在非集群里，它会自动创建一个 Mnesia.nodename@hostname 的目录来保存数据库。也可以在启动时，指定保存的目录，而不是默认的 Mnesia.nodename@hostname ，像这样子: 1erl -mnesia dir '"/home/emacsist/Mnesia"' 注意，单引号里面的双引号。 启动1mnesia:start() 其他的就不继续写的，详细直接看文档。 代码性能分析工具 cprof ：统计各个函数被调用的次数。在 online 系统上运行，会增加 5~10%的负载 fprof ：显示调用和被调用函数的时间，结果会输出到一个文件。重量分析，会显著增加系统负载 eprof ：测量erlang程序是如何使用时间的。它是 fprof的前身，适用于小规模的性能分析。 123456789cprof:start().执行你的代码 Mod:xxcprof:pause().cprof:analyse(Mod)cprof:stop(). 代码覆盖测试123456789cover:start().cover:compile(你的模块).你的模块:函数().执行一段时间后。。。。。cover:analyse_to_file(你的模块). 生成交叉引用注意，只有在代码编译时设置了 debug_info 才可以使用 xref 模块 123erlc +debug_info *.erlerl1&gt;xref:d('.'). 跟踪消息与进程执行参考手册下面的这个文档 1erlang:trace/3 配置错误记录器标准错误记录器1erl -boot start_clean 它创建一个适合进行开发的环境，只提供一种简单的错误记录形式。（不带参数的 erl 命令，就等同 erl -boot start_clean） 1erl -boot start_sasl 它会创建一个适合运行生产系统的环境。]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Erlang/OTP 并发编程实战》读书笔记]]></title>
    <url>%2F2017%2F04%2F30%2F%E3%80%8AErlang-OTP-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章：Erlang/OTP 平台 Erlang 中，并发的基本单位是进程。每个进程代表一个持续的活动，它是某段程序代码的执行代理，与其他按各自的节奏执行自身代码的进程一起并发运行。进程有自己的工作内存空间和自己的信箱，其中信箱用于存放外来消息。 4 种进程通信范式 持锁共享内存 软件事务性内存（STM） Future、Promise 以及同类机制 消息传递 Erlang 中的进程Erlang 进程并不是操作系统线程。它们由 Erlang 运行时系统实现，比线程要轻量得多。运行时系统所有进程之间相互隔离；单个进程的内存不与其他进程共享，也不会被其他濒死或跑疯的进程破坏。 Erlang 中的容错架构进程链接 Erlang 进程意外退出时，会产生一个 退出信号 。所有与濒死进程链接的进程都会收到这个信号。默认情况下，接收方会一并退出并将信号传播给与它链接的其他进程，直到所有直接或间接链接在一起的进程统统退出为止。这种联级行为，可以使一组进程像单个应用一样退出，因此系统整体重启时你不必担心是否还有残存下来未能完全关闭的进程。 监督与退出信号捕捉OTP 实现容错的主要途径之一就是改写退出信号默认的传播行为。通过设置 trap_exit 进程标记，你可以令进程不再服从外来的退出信号，而是捕捉。这类会捕捉信号的进程有时被称为 系统进程 （称为监督者） ，其他的进程称为 工作进程 。 Erlang 的进程链接与监督者共同提供了一种细粒度的 重启 机制。OTP 允许监督者按预设的方式和次序来启动进程。我们还可以告知监督者如何在单个进程故障时重启其他进程、一段时间内尝试重启多次后放弃重启等。 而且监督者可以存在多层的 监督树 。 Erlang 运行时系统和虚拟机Erlang 运行时系统（ERTS)，它有一个特别重要的部分就是 Erlang 的虚拟机模拟器：执行 Erlang 程序编译后产出的字节码。这个虚拟机，也就是 Bogdan Erlang 抽象机（BEAM），虽然我们也可以将 Erlang 程序编译为本地机器码，但一般没那个必要，因为 BEAM 模拟器已经够快了。 调度器ERTS 运行的时候通常就是单个操作系统进程（一般名为 beam 或 werl)。这个进程中，就跑着管理所有 Erlang 进程的调度器。 I/O 与调度调度器还替系统优雅地处理了 I/O 问题，在系统的最底层，Erlang 以事件驱动的方式处理所有 I/O，当数据进出系统时，程序可以以非阻塞方式完成数据处理。这降低了连接建立和断开的频次，还避免了 OS 层面上的加锁开销和上下文切换。 进程隔离与垃圾回收器它使用了 分代复制式垃圾回收器 ，它不会像其他开发的系统那样在 GC 时遭受停顿。这主要因为 Erlang 进程之间的隔离：每个进程所使用的内存都是自己的，随进程的创建和结束而分配和释放。 这首先意味着垃圾回收器可以在不影响其他进程运行的前提下单独暂停目标进程。其次，单个进程占用的内存通常较小，遍历可以快速完成。（也有占用内存量大的进程，但这些进程一般不用做出快速响应）。再次，调度器知道每个进程最后一次运行的时间，如果某个进程自上次垃圾回收后什么也没干，调度器会跳过它。 正是这些因素，让 Erlang 既可轻松使用垃圾回收器，又可以保证较短停顿时间。 第二章：Erlang 语言精要安装 Erlang1brew install erlang 启动 Erlang Shell安装完成后，打开终端， 然后输入 erl 即可:12345[15:15:07] emacsist:~ $ erlErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)1&gt; 以非交互式来启动1erl -noshell 要执行批处理任务或要将 Erlang 作为守护进程运行时可以采用这个方法。 表达式在 shell 中输入的，并不是什么命令，而是 表达式 ，它们的区别在于，表达式一定会返回一个求值结果。表达式是以 句号 结束的。比如 42. 。 可以通过 v(N) 来引用第 N 个表达式的结果。 Shell 函数help() 可以列出所有 shell 函数列表。 退出 shell调用 q() 或 init:stop()这是最安全的退出方法。 q() 是 init:stop() 函数的一个简写形式。 BREAK 菜单Unix 系统中按下 Ctrl-C （Windows 下在 werl 终端用 Ctrl-Break)来唤出该菜单: 1234567[15:27:01] emacsist:~ $ erlErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)1&gt;BREAK: (a)bort (c)ontinue (p)roc info (i)nfo (l)oaded (v)ersion (k)ill (D)b-tables (d)istribution a: 退出系统。c: 返回shellp: 显示所有进程信息i: 显示当前 erlang 系统消息v: 显示当前运行的 erlang 版本信息k: 显示所有 Erlang 内部活动进程，以及关闭任何故障进程（前提是你明确知道自己在做什么） Ctrl-G它会唤出用户开关菜单。 1234567891011121314151617[15:37:56] emacsist:~ $ erlErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)1&gt;User switch command --&gt; h c [nn] - connect to job i [nn] - interrupt job k [nn] - kill job j - list all jobs s [shell] - start local shell r [node [shell]] - start remote shell q - quit erlang ? | h - this message --&gt; q[15:38:10] emacsist:~ $ Erlang 的数据类型 数值（整数和浮点数） 二进制串/位串 原子 元组 列表（和字符串） 唯一标识符（pid、端口、引用） Fun 函数 数值你可以使用从 2 进制到 36 进制的整数（0～9 加上字符 A~Z/a~z），如: 12316#FFFFfF2#1010136#ZZ 字符的数值编码$字符 的格式，可以得到它们的数值编码(ASCII/Latin-1/Unicode 皆可)，如: 123454&gt; $a.975&gt; $我.251056&gt; 浮点数它是64位双精度浮点数（IEEE 754-1985 格式）。不能仅以小数点开头，如 .01 ，必须是以数字开头，如 0.01 算术运算Erlang 采用常见的中缀表示法。如果运算符中有一个是浮点数，则运算将被转化为浮点运算。 除法分两种 / ，它总是返回浮点数。如 4 / 2 结果为 2.0 div ，整除运算（即运算结果会被截断），如 7 div 2 结果为 3 取余: rem 。如 15 rem 4 的结果为 3 。 二进制串与位串二进制串: 无符号 8 位字节的序列位串：广义的二进制串，其长度不必是 8 的整数倍 语法如下: 1&lt;&lt;0,1,2,..., 255&gt;&gt; 也就是包含在 &lt;&lt;…&gt;&gt; 内逗号分隔的整数序列，整数取值范围为 0～255 . 还可以用字符串来构造二进制串: 1&lt;&lt;"hello", 32, "dude"&gt;&gt; 原子它是一种仅由字符序列来标识的特殊字符串常量。因此，两个原子只要具有相同的字符表示，就完全等同。 在系统内部，这些字符串放在某张表内，并由表的下标定位，因此在运行时只要比较两个小整数就可以判断两个原子是否相等。每个原子也仅占一个字长的内存。 它的作用类似于 Java 或 C 中的 enum 常量。 你应该把原子当作一类特殊的标签，而不是普通的字符串。它们的长度上限是 255 个字符，在单个系统中原子的总数也有一个上限，目前是一百多万（准确来说是 1048576)。一般来说这个上限已经足够大了，但对于长期运行（数天、数月、数年）的系统，你应该避免动态生成诸如 ‘x_4711’ 、‘x_4712’ 这类全局唯一的原子。 原子一经创建，即便不再使用，也永远不会被清除，除非系统重启。 元组它是 定长序列 ，用大括号来表示，如: 1234&#123;1,2,3&#125;&#123;one, two, three, four&#125;&#123;&#125;&#123;from, "Russa"&#125; 元素可以是同一类型，也可以是不同的数据类型：元素本身也可以是元组或其他数据类型。 Erlang 的一个标准约定是，用原子作为第一个元素来标记元组数据的类别，如: 12&#123;size, 42&#125;&#123;position, 5, 2&#125; 元组的元素项没有名称，只有编号（从 1到 N）。访问元组中的元素是常数时间复杂度的操作，跟 Java 中访问数组元素一样快速和安全。 标准库中实现了一些更为复杂的数据类型：数组、集合、字典等，但在底层，它们大都是采用各种手段基于元组实现的。 列表列表用方括号表示，如: 1234[][1,2,3][[1,2,3], [4,5,6]][&#123;"hello"&#125;, &#123;"world"&#125;] 空表 [] 也被称为 nil 添加列表元素| 管道符，它将右侧的与左侧的合并。如: 1[2 | [1]] 得到列表 [2，1] .注意顺序，新元素是从左侧添加的。 也可以用 ++ 运算符向列表追加任意长度的列表。如: 1[1,2,3,4] ++ [5,6,7,8] 可以得到列表 [1,2,3,4,5,6,7,8] 。其过程还是一样: 先是 [4 | [5,6,7,8]]，再是 [3|[4,5,6,7,8]]，以此类推。 注意，++ 右侧的列表不会被修改——Erlang 不允许这类破坏性修改——它只是借由一个指针成为了一个新列表的一部分。左侧列表就不一样了。左侧列表的长度决定了 ++ 运算符的耗时。 字符串Erlang 中双引号字符串实际上就是列表，其元素就是该字符串中各字符的数值编码所对应的整数。比如: 12"abcd""Hello!" 它们与以下列表等价: 12[97,98,99,100][72,101,108,108,111,33] 还可以写作: 12[$a, $b, $c, $d][$H, $e, $l, $l, $o, $!] 字符串就是列表，也就是说你先前学到的所有处理列表的方法，同样也适用于字符串。 标识符（pid、端口和引用）在 Erlang 中任何代码都需要一个 Erlang 进程作为载体才能执行。每个进程都有一个唯一标识符，通常称为 pid 。它是一种特殊的 Erlang 数据类型，应被视为一种不透明对象。self() 函数能告诉你当前进程（即调用 self() 的那个进程）的 pid 。 1234Eshell V8.3 (abort with ^G)1&gt; self().&lt;0.57.0&gt;2&gt; Fun 函数函数式语言的一个显著特征就是可以像处理数据一样处理函数——也就是说，函数可以成为别的函数的输入，也可以成为别的函数的求值结果，还可以把函数存在数据结构中供后续使用，诸如此类。在 Erlang 中，将这种函数包装成数据的对象称为 fun 函数 （也称为 Lamdba 表达式或闭包） 项式的比较Erlang 的各种数据类型有一个共同点：它们都可以通过内置的 &lt;, &gt; 和 == 运算符进行比较和排序。 原子、字符串（以及其他各种列表）和元组：按字典序排序。 不同类型间的排序规则： 数值小于原子 元组小于列表 原子既小于元组，也小于列表（注意，字符串也是列表） 例如:1233&gt; lists:sort([b,3,a,"z",1,c,"x",2.5,"y"]).[1,2.5,3,a,b,c,"x","y","z"]4&gt; 小于或等于/大于或等于与其他语言不同的是，小于或等于，它不写作 &lt;= ，而是 =&lt; 。大于或等于同同其他语言一样，都是 &gt;= 。即，比较运算符看起来绝不像箭头就行了。 相等比较Erlang 有两种比较运算符。 完全相等，写作 =:= ，仅当运算两侧完全等同（值和类型必须相同）时才返回 true。其否定式为 =/= . 一般来说，判断两个项式是否相等时更倾向于采用完全相等运算符。但这会导致看似相等的整数与浮点数会被判断为不相等，如 2 =:= 2.0 ，它的结果就是 false 算数相等，写作 == ，按数学法则对数值进行比较时，一般使用它。其否定式为 /= 。例如: 2 == 2.0 返回的就是 true。但请记住，针对浮点做相等判断总是有风险的，浮点数的机器表示法伴有微小的舍入误差，这可能会在本应相等的数值间引入些偏差，使 == 返回 false 。涉及浮点数时，最好只用 &lt;, &gt;, =&lt; 或 &gt;= 进行比较。 解读列表列表一般是由空表(nil) 和所谓的列表单元共同构成。这些单元各自携带一个元素挨个儿挂接到现有列表的顶部，从而在内存中形成一个单链表。每个单元仅占两个字长的内存空间：一个用于存放元素值（或指向元素值的指针），称为首部(head)，另一个是指向列表其余部分的指针，称为尾部（tail）（与 Lisp 的非常类似） 非严格列表严格列表：最内层都以一个空表作为尾部。 非严格列表：在非列表数据之上堆叠列表单元而成的列表，如:1[1 | oops] 这就构成了一个尾部不是列表的列表单元（这里 ‘oops’ 作为尾部）。Erlang 并不禁止这样子做，也不会在运行时对这种情况进行检查。但一般来说，要是看到这样的东西，那多半是程序的某些地方写错了。 非严格列表的主要问题在于，很多函数要求输入参数必须是严格列表。 模块和函数Erlang 将模块用作代码的容器。每个模块的名字，都是一个全局唯一的原子。 调用其他模块中的函数(远程调用)如: 1lists:reverse([1,2,3]) 与此相对应的是 本地调用 （调用同一模块中的函数）。 不要将这里的远程调用与远程过程调用（remote procedure call, RPC) 混淆了。 不同元数的函数函数参数的个数被称为 元数 .没有参数时称为 空元函数 ，一个参数的，称为 一元函数 , 以此类推。 两个函数使用同一原子作为函数名，只要它们的元数不同，Erlang 就会将它们视作两个完全不同的函数。因此函数的全名必须包含元数（以斜杠作为分隔符）。比如上面的列表反转函数的全名为 reverse/1 。如果还要强调函数所在的模块，则应该为 lists:reverse/1 ，不过，这种语法仅用于需要函数名的位置。 内置函数和标准库模块内置函数（BIF），它们都是用 C 语言实现的。 erlang 模块中的所有函数，都是 BIF。erlang 模块，会被自动导入。即 self() 的全写为 erlang:self() 创建模块 编写源文件 编译 加载已经编译的模块，或将它放到加载路径中，以便自动加载。 编写源文件my_module.erl 1234567%% This is a simple Erlang module-module(my_module).-export([pie/0]).pie() -&gt; 3.14. pie() -&gt; 3.14. 它为函数定义。注意，这里并不需要 return ：函数的返回值就是函数体中表达式的值。注意末尾必须要有句号. 。 第一行的 % 表示注释。根据规范，与代码同处一行的注释，以一个 % 开头。独占一行的注释，以两个 %% 开头。 除注释外，第一行一定是模块声明，格式为 -module(…) 。 Erlang 中不是函数也不是注释的，都是声明。声明以连字符开头（-）, 必须以句号结尾。模块声明是不可或缺的，且它指定的名字，必须与文件名相符（即除去 .erl 后缀以外的部分） -export([…]) 这个是导出声明，它会告知编译器哪些函数是外部可见的。此处没有列出的函数，都是模块的内部函数。 模块的编译和加载编译模块时，会产生一个和模块对应的扩展名为 .beam 而非 .erl 的文件，其中包含可被 Erlang 系统加载执行的指令。 在 Shell 中编译在 Shell 中，调用函数 c(…) 来进行自动编译和加载（前提是编译通过）。该函数以 Erlang shell 的当前目录(可以用 ls() 函数列出当前目录列表)为相对路径来寻找源码文件，你甚至可以省略模块末尾的 .erl 。例如: 123456789101112[17:44:44] emacsist:erlang $ erlErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)1&gt; ls().my_module.erlok2&gt; c(my_module).&#123;ok,my_module&#125;3&gt; my_module:pie().3.144&gt; 模块加载与代码路径当 Erlang 尝试调用某个尚未加载到系统中的模块时，只要能找到与模块名对应的 .beam 文件，它就会自动尝试加载。查找 .beam 文件的目录由代码路径指定，默认情况下，当前目录也包括在内。可以调用 code:get_path() 函数查看当前代码路径的设置。 独立编译器 erlc123erlc my_module.erl或erlc -o ./ebin my_module.erl 按惯例，存放 .beam 文件的目录应命名为 ebin 。 效率注意，不要在 shell 中评估代码的执行效率，一切应该以编译版本为黄金准则。 变量与模式匹配语法变量名必须以大写字母开头！（小写字母开头的已经被用于原子了），变量中的单词以驼峰体隔开。这种命名的变量在赋值之后一直未被使用的话，会触发编译警告。 变量名也可以以下划线开头，这种情况下，按常规第二个字符通常应该为大写字母。 这种命名的变量，即使不被使用，编译器也不会报警。同时，所有未被使用的变量都会被优化掉。 不过，好像新版的 Erlang，对这两种情况都会报警，如下： 123456789[18:02:21] emacsist:erlang $ erlc my_module.erlmy_module.erl:8: syntax error before: _HelloWroldmy_module.erl:9: syntax error before: 3.14my_module.erl:7: variable 'Helloworld' is unbound[18:02:34] emacsist:erlang $ vim my_module.erlWaiting for Emacs...[18:06:16] emacsist:erlang $ erlc my_module.erlmy_module.erl:9: syntax error before: 3.14my_module.erl:8: variable '_HelloWrold' is unbound 单次赋值Erlang 的变量被严格地限定为只能接受单次赋值。 在大多数其他编程语言中，变量就像是起了名字的盒子，在程序中你随时可以随性盒子里的内容。Erlang 的变量却与对应的数学概念相符：它就是指代某个值的一个名字，且这种指代关系不会背地里悄悄地改变（否则方程就解不出来了）。 匹配运算符 =它的能力可不止是简单的赋值。 如: 1X = 42. 在 shell 中，可以调用函数 f() 来让 shell 遗忘先前绑定的所有变量，或遗忘指定的变量: f(变量名) 匹配 的含义：如果 X 已经被绑定到某个值，匹配运算符会检查右侧的值是否与之相等（比较时使用的是 完全相等运算符） 变量及其更新要想追踪其他值，就给它另起一个名字。例如: 12X = 17.X1 = X + 1. 模式匹配= 就是匹配运算符，因为它的功能就是模式匹配，而不是赋值。 运算符的左侧，是一个模式；右侧，是一个普通表达式。做匹配运算时，首先计算右侧的表达式，得到一个值。接着拿该值去匹配左侧的模式。若模式匹配不上，比如: 17 = 42或 true = false ，则匹配宣告失败并抛出一个原因代码(reason code) 为 badmatch 的异常。若成功，在左侧模式中出现的所有变量都会与右侧值中的相应组成部分绑定，然后程序将继续计算紧随其后的表达式。如: 1&#123;A, B, C&#125; = &#123;1970, "Richard", male&#125;. 另一种常见的模式为: 1&#123;rectangle, Width, Height&#125; = &#123;rectangle, 200, 100&#125;. 再多几个例子： 1[1,2,3 | Rest] = [1,2,3,4,5,6,7] 这样子, Rest 就为 [4，5，7，7] 了。 1[$h, $t, $t, $p, $: | Rest] = "http://www.erlang.org" 这时，Rest 绑定到了字符串 //www.erlang.org 了。 省略模式单下划线：_ 表示省略模式，也就是说，在模式的某处用上 _ 的话就表示你不关心右侧相应位置上的值。它们也被称为 匿名变量 。 匹配模式与子句子句由分号(;)分隔，且最后一个子句由句号结尾。如: 123456either_or_both(true, _) -&gt; true;either_or_both(_, true) -&gt; true;either_or_both(false,false) -&gt; false. case 与 if123456789area(Shape) -&gt; case Shape of &#123;circle, Radius&#125; -&gt; Radius * Radius * math:pi(); &#123;square, Side&#125; -&gt; Side * Side; &#123;rectangle, Height, Width&#125; -&gt; Height * Width end. 注意，最后一个子句后没有分号——分号是分隔符，而不是结束符。 if-then-else根本没这玩意。你可用 case 表达式来替代： 1234case either_or_both(X,Y) of true -&gt; io:format("yes~n"); false -&gt; io:format("no~n")end. if 表达式123456sign(N) when is_number(N) -&gt; if N &gt; 0 -&gt; positive; N &lt; 0 -&gt; negative; true -&gt; zero end. 或 123456sign(N) when is_number(N) -&gt; case dummy of _ when N &gt; 0 -&gt; positive; _ when N &lt; 0 -&gt; negative; _ when true -&gt; zero end. fun 函数作为现有函数别名的 fun 函数： 1fun either_or_both/2 和各种其他类型的值一样，你可以将之与变量绑定: 1F = fun either_or_both/2 或传递给别的函数: 1234567yesno(fun either_or_both/2)yesno(F) -&gt; case F(true, false) of true -&gt; io:format("yes~n"); false -&gt; io:format("no~n") end. 匿名 fun 函数也称为 Lamdba 表达式。它们以 fun 关键字开头，并且以 end 关键字结束。例如: 1fun () -&gt; 0 end 闭包一般特指: fun…end 的内部引用了在 fun 函数外部绑定的变量的情况。fun 函数能将那些变量当前的值封存起来。 异常与 try/catch 异常是什么呢？你可以将之认为是函数的另一种返回形式，区别在于它不仅会返回至调用者，还会返回至调用者的调用者，并一路向上，直至被捕获或抵达进程调用的起点（这时进程便会崩溃）为止。 异常的类别: error ：运行时异常，除零错误、匹配运算失败、找不到匹配的函数子句等情况时触发。一旦它们导致某个进程崩溃，Erlang 错误日志管理器便会将之记录。 exit ：用于通报：“进程即将停止”。它们会在迫使进程崩溃的同时将进程退出的原因告知其他进程，因此一般不捕获这类异常。它不会被汇报至错误日志管理器。 throw ：用于处理用户自定义的情况。如果不捕获 throw 异常，它便会转变为一个原因为 nocatch 的 error 异常，迫使进程终止并记录日志。 抛出异常123throw(SomeTerm)exit(Reason)erlang:error(Reason) 特例：exit(normal) 所抛出的异常不会被捕获。这意味着其他与之链接的进程不会将之视为反常的终止行为。（其余的所有退出原因都会被视作反常） try … of … catch12345678try some_unsafe_function(...)of 0 -&gt; io:format("nothing to do ~n"); N -&gt; do_something_with(N)catch _:_ -&gt; io:format("some problem~n")end after 类似Java中的finally 123456&#123;ok, FileHandle&#125; = file:open("foo.txt", [read]),try do_something_with_file(FileHandle)after file:close(FileHandle)end 获取栈轨迹erlang:get_stackrace() ： 是异常发生那一刻位于栈顶部的那些调用的逆序列表（最后一个位于最前）。如果它返回的是一个空表，表示直至目前为止该进程尚未捕获任何异常。 列表速构记法如: 1[X || X &lt;- ListOfIntegers, X &gt; 0] 此处必须用双竖线 || ,因为单竖线已经被用在普通列表单元上了。 用 &lt;- 来表示生成器， || 右侧除了生成器，便是约束条件，如 X &gt; 0 映射、过滤和模式匹配1[ math:pow(X,2) || X &lt;- ListOfIntegers, X &gt; 0, X rem 2 == 0] 比特位语法与位串速构位串可以写作: &lt;&gt; ，区段指示符可以为以下形式之一: 1234DataData:SizeData/TypeSpecifiersData:Size/TypeSpecifiers 位串速构1233&gt; &lt;&lt; &lt;&lt;X:3&gt;&gt; || X &lt;- [1,2,3,4,5,6,7] &gt;&gt;.&lt;&lt;41,203,23:5&gt;&gt;4&gt; 记录语法记录声明1-record(customer, &#123;name="&lt;anonymous&gt;", address, phone&#125;). 创建记录12#customer&#123;&#125;#customer&#123;phone="12341234"&#125; 记录字段以及模式匹配假设R变量绑定了一个 customer 记录，你可以使用点分记法来访问各个字段： 12R#customer.nameR#customer.address 预处理与文件包含宏的定义和使用宏由 define 指令定义，既可带参数，也可以不带参数。如： 12-define(PI, 3.14).-define(pair(X,Y), &#123;X, Y&#125;). 习惯上常量名为大写，其余大部分宏为小写。在代码中使用宏时，必须加一个问号作为前缀： 1circumference(Radius) -&gt; Radius * 2 * ?PI. 取消宏定义undef 可用于移除宏定义（前提是该宏定义存在）如: 123-define(foo, false).-undef(foo).-define(foo, true). 预定义宏为了方便，预处理器先定义了一些宏。如: MODULE 宏（表示当前正在编译的模块的名称）， FILE 宏（当前正在哪个文件中）和 LINE 宏（当前正身处哪个源文件的哪一行） 文件包含1-include("filename.hrl"). 这类文件通常只有声明，没有函数；一般出现在模块源文件的头部，因此这些文件被称为 头文件 ，以 .hrl 为扩展名。查找这类文件时，Erlang 编译器会同时在当前目录中以及列于 包含路径 内的目录中查找名为 some_file.hrl 的文件。 利用 erlc 的 -I 标志，或shell函数 c(…) 的 {i, Directory} 选项可以向包含路径中添加新目录。如: 11&gt; c("src/my_module", [&#123;i, "../include"&#125;]). include_lib 指令1-include_lib("kernel/inclue/file.hrl"). 该指令会相对于Erlang系统现有应用的安装位置来查找文件。比如 kernel 应用可能被安装在 C:\Program Files\erl5.6.5\lib\kernel-2.12.5 。于是 include_lib 指令会将文件起始处的 kernel/ 匹配至这个路径（除去版本号）并在此目录下寻找含有 file.hrl 的子目录 include 。即便Erlang升级，你的程序也不用做任何修改。 条件编译1234-ifdef(MacroName).-ifndef(MacroName).-else.-endif. 例如: 123-ifdef(DEBUG)-export([foo/1]).-endif. 你可以通过shell函数c的 {d, MacroName, Value} 选项或 erlc 命令的 -Dname=value 选项来进行控制。 进程操纵进程派生和链接它有两个函数。第一个函数仅有一个参数，就是作用新进程入口的（空元）fun函数。另一个则需要模块名、函数名、和参数列表3个参数： 12Pid = spawn(fun() -&gt; do_something() end)Pid = spawn(Module, Function, ListOfArgs) 还有一个名为 spawn_opt(…) 的版本，如: 1Pid = spawn_opt(fun() -&gt; do_something() end, [monitor]) 以及： 1Pid = spawn_link(...) 所有这些派生函数都会返回新进程的进程标识符，通过该标识符，父进程可以与新进程通信。但新进程对父进程却不无所知，只能通过其他方式来获取相关信息。 进程监视1Ref = monitor(process, Pid) 由Pid标识的进程一旦退出，实现监视的进程将会收到一条含有引用Ref的消息。 靠抛异常来终结进程1exit(Reason) 除非被进程捕获，否则该调用将令进程终止，并将Reason作为退出信号的一部分发送给所有与该进程链接的进程。 直接向进程发送退出信号1exit(Pid, Reason) 设置 trap_exit 标志默认情况下，一旦接收来自相互链接的其他进程的退出信号，进程就会退出。为了避免这种行为并捕捉退出信号，进程可设置 trap_exit 标志： 1process_flag(trap_exit, true) 这样除了无法捕捉的信号(kill)，外来的退出信号都会被转换为无害的消息。 消息接收与选择性接收可以用 receive 表达式从信箱中提取消息。尽管接收到的消息严格按照抵达顺序排列，接收方仍然可以自行决定要提取哪条消息。 1234567receive Pattern1 when Guard1 -&gt; Body1; ... PatternN when GuardN -&gt; BodyNafter Time -&gt; TimeoutBodyend after… 为可选，如果省略，表示永不超时。否则 Time 必须是表示 毫秒 的整数或原子 infinity 。如果 Time 为 0，表示永不阻塞。 注册进程每个Erlang系统都有一个本地进程注册表——这是一个用于注册进程的简单命名服务。一个名称一次只能用于一个进程。换言之，该机制仅适用于单例进程：一般都是些系统服务，这些服务在每个运行时系统中，同一时刻最多只能有一个实例。在 Erlang shell中调用内置函数 registered() 可以列出它们。 12345674&gt; registered().[erts_code_purger,init,error_logger,erl_prim_loader, kernel_safe_sup,standard_error_sup,inet_db,rex,user_drv, kernel_sup,global_name_server,global_group,user, file_server_2,code_server,application_controller, standard_error]5&gt; 用内置函数 whereis 可以查找当前与指定注册名对应的 pid: 1234567894&gt; registered().[erts_code_purger,init,error_logger,erl_prim_loader, kernel_safe_sup,standard_error_sup,inet_db,rex,user_drv, kernel_sup,global_name_server,global_group,user, file_server_2,code_server,application_controller, standard_error]5&gt; whereis(user).&lt;0.49.0&gt;6&gt; 你甚至可以直接用注册名向进程发送消息： 1236&gt; init ! &#123;stop, stop&#125;.&#123;stop,stop&#125;7&gt; % [22:59:14] emacsist:erlang $ 你也可以用 register 函数注册自己启动的进程: 12345678910111213[23:02:18] emacsist:erlang $ erlErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)1&gt; Pid = spawn(timer, sleep, [30000]).&lt;0.59.0&gt;2&gt; register(fred, Pid).true3&gt; whereis(fred).&lt;0.59.0&gt;4&gt; whereis(fred).undefined5&gt; 进程退出后，之前注册的名称将自动回归到未定义状态。如果你想跟位于另一个Erlang 节点上的注册进程通信，可以这样子做: 1&#123;some_node_name, some_registered_name&#125; ! Message 消息投递与信号Erlang进程互相用 ! 运算符发送的消息只是Erlang通用信号系统的一种特殊形式。另一大类信号就是濒死进程向与之链接的相邻进程发送的退出信号；还有一小部分对程序员不可见，诸如尝试链接两个进程时发送的链接请求。投递信号时，以下的基本投递保障对所有信号都成立： 如果进程P1向目标进程P2先后发送了两个信号S1和S2，这两个信号将按发送顺序到达P2（如果都能到达的话）。 尽力投递所有信号。同一Erlang运行时系统内，进程之间不存在消息丢失的危险。但，两个依靠网络互联的Erlang系统之间，一旦网络连接断开，消息就有可能丢失。连接恢复后，有可能出现上例的S2最终抵达，但S1却丢失的情况。 进程字典每一个进程都有一个私有的进程字典。通过内置函数 put(Key, Value) 和 get(Key, Value) 可以从中存取项式。无论进程字典看上去多么诱人都不要去碰它。 ETS表ETS(Erlang Term Storage)，用于存储Erlang项式（即任意Erlang数据）且可以在 进程间共享 的表。它作为Erlang运行时系统的一部分，用C实现的。原因在于ETS是Erlang中很多东西的基础。 ETS表的基本用法创建新表: ets:new(Name, Options) .Name必须是原子，Options必须是列表。除非设置 named_table 选项，否则名称不起实际作用。ets:new/2 会返回一个标识符，用于完成针对新创建的表的各种操作，如: 123T = ets:new(mytable, []),ets:insert(T, &#123;17, hello&#125;),ets:insert(T, &#123;42, goodbye&#125;) ETS表和数据库的另一个相似点在于，它同样只存储数据行——也就是元组。存储任何Erlang数据之前，都要先将之放入元组。原因在于, ETS会将元组中的一个字段用作表索引，默认采用第一个字段（可通过建表参数调整） 以递归代替循环比如从0到N的累加和： 12sum(0) -&gt; 0;sum(N) -&gt; sum(N-1) + N. Erlang与其他语言不同，它仅靠递归就可以创建循环，而且没有效率问题。 123456789101112131415[13:05:30] emacsist:erlang $ cat hello.erl-module(hello).-export([start/0]).start() -&gt; io:format("~p~n", [sum(100000000)]).sum(0) -&gt; 0;sum(N) -&gt; sum(N-1) + N.[12:55:27] emacsist:erlang $ time erl -noshell -run hello start -s init stop5000000050000000erl -noshell -run hello start -s init stop 14.58s user 20.07s system 83% cpu 41.598 total 理解尾递归上面那个就是 非尾递归 （因为含有非尾递归调用）。尾递归 ：所有递归调用都是 尾调用 ，编译器总能从代码中准确地定位尾调用，并做出一些相应的特殊处理。 Erlang 是怎么仅靠递归来实现循环的呢？每次调用不是都要往栈上写入新的内容吗？答案是否定的，因为Erlang采用了 尾调用优化 .正是基于这个原因，尾递归函数即使不停地运行也不会将栈空间耗尽，同时还能达到和 while 循环一样高效。 第三章：开发基于TCP的RPC服务行为模式使用 OTP 行为模式。 行为模式接口， 是一组特定函数和相关的调用规范。 行为模式实现， 指的是由程序员提供具体应用相关的代码。是一个导出了接口所需要的全部函数的回调模块。实现模块中，还应包含一项属性 -behaviour(…) 用以说明该模块所实现的行为模式的名称。 行为模式容器， 它执行的是某个库模块中的代码，并且会调用与行为模式实现相对应的回调模块来处理应用相关的逻辑。 测试EUnit （单元测试）和 Common Test （OTP Test Server) 比较重型。 EUnit使用： 1234567-include_lib("eunit/include/eunit.hrl").%写你的测试代码:start_test() -&gt; &#123;ok, _&#125; = tr_server:start_link(1005). 然后在 erlang shell中输入: 123eunit:test(tr_server).或tr_server:test(). test() 函数是由Eunit 自动生成的，同时Eunit会自动导出你编写的所有测试函数。 第四章：OTP应用与监督机制OTP应用的组织形式12345678910[12:51:01] emacsist:erlang $ tree my-otp-app-1.0.0my-otp-app-1.0.0├── doc├── ebin├── include├── priv└── src5 directories, 0 files[12:51:05] emacsist:erlang $ 其中，只有 ebin 是必需的。 为应用添加元数据在 ebin 目录，建立一个名为 .app 的文本文件，它用来描述你的应用。 它的作用在于告诉OTP如何启动应用，以及该应用如何与系统中的其他应用相融合。即组装更大的可启动、停止、监督和升级的功能单元。 application 行为模式该模块通常命名为 _app 监督者 行为模式根监督者行为模式，该模块通常命名为 _sup 生成Edoc文档打开 erlang shell 1edoc:application(your-server-name, "目录 .表示当前目录", []). 它会将生成的文档，放到 doc 目录下. 第五章：主要图形化监测工具的使用Appmon（已经废弃）打开 erlang shell ，输入: 1appmon:start(). 注：如果上面的命令执行不了，请用 observer:start(). ，这个是新版 erlang 的替代者。 WebTool版Appmon1webtool:start(). 我在mac上打不开。这个暂时查资料也没有见什么原因。到时再看看… 12345678[13:35:03] emacsist:lib $[13:35:03] emacsist:lib $ erlErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)1&gt; webtool:start().** exception error: undefined function webtool:start/02&gt; pman1pman:start(). 好像这个也没有用了。我的erlang版本为 12Erlang (BEAM) emulator version 8.3Compiled on Wed Mar 15 18:06:57 2017 调试器1debugger:start(). 要调试时，在编译时要加上调试信息选项: 1erlc +debug_info -o ebin src/*.erl 然后在上面 debugger:start(). 弹出的窗口中，选择 Module-Interpret ，选择要调试的源文件，然后打上断点（在要进行断点的地方，双击即可）。这时，启动应用，然后触发要调试的函数即可。 表查看器1tv:start(). 好像这个也没有用了。 工具栏1toolbar:start(). 好像这个也没有用了。 第八章：分布式Erlang/OTP简介位置透明性在Erlang中，进程间的通信方式与接收方在本地机器还是在远程机器上无关。这点在语法层面上仍然成立。 节点被配置成按分布式模式运行的 Erlang VM 就叫做节点。每一个节点都有一个节点名，其他节点中以通过这个名字来找到该节点并与之通信。当前本地节点的节点名可以通过内置函数 node() 获取，节点名是一个原子，格式为 nodename@hostname （不以分布式模式运行的VM的节点，永远为 nonode@nohost)。在单台主机上可以同时运行多个节点。 调用 nodes() 可以查看互联的节点。 集群一旦两个或两个以上的 Erlang 节点能够相互感知，我们就说它们形成了一个集群。 默认情况下，Erlang集群是一个全联通网络，即集群中的每个节点，都能感知其他所有节点，任意两个节点都可以直接通信。 节点的启动1erl -name your_node_name 这样子就可以以分布式模式启动Erlang节点。（该形式适用于配有 DNS 的普通网络环境，你需要给出节点的完全限定名。 还有一种启动方式: 1erl -sname your_node_name 这种适用于完全限定名不可用的情况（只要所有节点在同一子网，你就可以使用短节点名） 注意，采用短节点和长节点的节点所处的通信模式是不同的，它们之间无法形式集群。只有采用相同模式的节点，才能互联。 在我的Mac上，它们两种启动的提示符如下: 12345678910111213141516[15:18:01] emacsist:~ $ erl -sname hello1Erlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)(hello1@yangzhiyongs-MacBook-Pro)1&gt;[15:16:50] emacsist:~ $ erl -name helloErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)(hello@yangzhiyongs-MacBook-Pro.local)1&gt; 节点的互联同一集群内启动几十个节点没什么问题，但跑上几百个就比较悬了。原因在于维系机器之间的联络是需要一定通信开销的，而Erlang集群又是一个全联通网络，这部分的开销会随节点数的增加按平方规模增长。 比如 a,b 两个节点组成一个集群， c,d两个节点组成一个集群。如果a与c节点互联了的话，则 b与 c,d 也会自动进行互联。 假设，你启动了3个节点: a, b , c 然后在 a 节点上调用: 1net_adm:ping('节点'). 如果成功的话，就会返回 pong ，否则返回 pang 。比如: 节点a:123456789[15:22:29] emacsist:~ $ erl -sname aErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)(a@yangzhiyongs-MacBook-Pro)1&gt; net_adm:ping('b@yangzhiyongs-MacBook-Pro').pong(a@yangzhiyongs-MacBook-Pro)2&gt; nodes().['b@yangzhiyongs-MacBook-Pro'](a@yangzhiyongs-MacBook-Pro)3&gt; 节点b:1234567[15:22:25] emacsist:~ $ erl -sname bErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)(b@yangzhiyongs-MacBook-Pro)1&gt; nodes().['a@yangzhiyongs-MacBook-Pro'](b@yangzhiyongs-MacBook-Pro)2&gt; 节点c:1234Erlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)(c@yangzhiyongs-MacBook-Pro)1&gt; Erlang节点如何定位其他节点并建立通信EPMD 进程（Erlang Port Mapper Daemon）： 12[15:35:18] emacsist:~ $ ps aux | grep epmdemacsist 29193 0.0 0.0 2461456 596 ?? S 3:16下午 0:00.02 /usr/local/Cellar/erlang/19.3/lib/erlang/erts-8.3/bin/epmd -daemon 你每启动一个节点，它都会检查本地机器上是否运行着EPMD，如果没有，节点就会自动启动EPMD。它会跟踪在本地机器上运行的每个节点，并记录分配给它们的端口。 当Erlang节点试图与某远程节点通信时，本地的EPMD就会联络远程机器上的EPMD（默认使用 TCP/IP，端口为 4369），询问在远程机器上有没有叫相应名字的节点。如果有，远程的EPMD就会回复一个端口号，通过该端口便可以直接与远程节点通信 。 不过EPMD不会自动搜寻其他EPMD——只有在某个节点主动搜寻其他节点时通信才能建立。 注意，Erlang默认的分布式模型基于这样一个假设：集群中所有节点都运行在一个受信任的网络内。如果这个假设不成立，或者其中某些机器需要与外界通信，那么你应该直接在TCP（或UDP等）之上配合恰当的应用层协议来实现非受信任网络上的通信。 magic cookie如果成功启动过一次节点的话，可以在 用户主目录 （Windows上一般为 C:/Documents and Settings/ 或 C:/Users/ 目录）下会有一个 .erlang.cookie 文件。 你也可以在shell中，获取当前节点的cookie： 1234567[15:31:54] emacsist:~ $ erl -sname bErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)(b@yangzhiyongs-MacBook-Pro)1&gt; auth:get_cookie().'YVCOJVPHXHCVZYICUVIJ'(b@yangzhiyongs-MacBook-Pro)2&gt; 从shell中获取的字符串与你在 .erlang.cookie 文件看到的应该相同。Erlang节点只有在知晓其他节点的 magic cookie的情况下才能与它们通信。 节点在启动的时候，会读取 .erlang.cookie 文件，如果存在，则以它为自己的 magic cookie，如果找不到，则节点会新建一个 cookie 文件并写入一个随机字符串。 默认情况下，每个节点都会假定所有与自己打交道的节点都拥有和自己一样的 cookie 。 要让运行于两台不同机器上的节点相互通信，最简单的办法就是将其中一台机器随机生成的 cookie 文件复制到另一台机器上即可。 对于更为复杂的配置，你可以用内置函数 set_cookie(Node, Cookie) 来设置 cookie ,这样，节点可以用不同的 cookie 与不同的节点通信。原则上说，集群中每个节点的 cookie 都可以不上，但在实践中，整个系统往往会共用一个 cookie . 远程 shell其实shell进程并不关心与自己连接的终端是否和自己处在同一节点。下面演示了，如何在节点a里，通过 erlang shell连接节点b: 12345678910111213[16:10:04] emacsist:~ $ erl -sname aErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:4:4] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]Eshell V8.3 (abort with ^G)(a@yangzhiyongs-MacBook-Pro)1&gt;User switch command --&gt; r 'b@yangzhiyongs-MacBook-Pro' --&gt; j 1 &#123;shell,start,[init]&#125; 2* &#123;'b@yangzhiyongs-MacBook-Pro',shell,start,[]&#125; --&gt; cEshell V8.3 (abort with ^G)(b@yangzhiyongs-MacBook-Pro)1&gt; 退出远程 shell 千万要小心在使用完远程shell后，你可能会打入: q(). ，这时千万不要回车。这个是 init:stop(). 的简写，用于关闭执行该命令的节点，也就是你的远程节点。 要想安全地退出，请使用 Ctrl-G 和 Ctrl-C ，这两个组合只对本地节点有效。 第九章：用 Mnesia为cache增加分布工支持Mnesia 是一套轻量级的软实时分布式数据存储系统，支持冗余复制和事务，特别适合于存储离散的Erlang数据块，尤其擅长RAM中的数据存储。 使用步骤: 初始化 Mnesia 启动节点 建立数据库模式 启动 Mnesia 建立数据库表 向新建的表中插入数据 对数据做一些基本查询 初始化数据库启动节点1erl -mnesia dir '"/tmp/mnsia_store"' -name mynode 注意，dir 后面的参数格式（单引号用于保留字符串两端的双引号）。 节点启动后，还需要在即将参与冗余复制的所有节点上建立一套空的初始数据模式。 建立数据库模式它是一些描述信息，其中记录着当前数据库中存有哪些表，表的详细情况又如何。一般来说不用关注它，它只是 Mnesia 用于跟踪自身数据的一种手段。 1mnsia:create_schema([node()]). 启动 Mnesia123mnsia:start().mnsia:info(). 建表1mnsia:create_table(Name, Options) Options 是一张 {Name, Value} 选项列表。所在选项中，最重要的是 attributes 。如果没有它，Mnesia 会假定记录仅有两个字段，分别名为 key 和 val 。 表的主键永远都是记录的第一个字段 Mnesia 表的类型 set ：表中的键是唯一的，如果插入的记录与现存某个表项的主键相同，则新的记录会覆盖旧的。 bag ：可以容纳多个具有相同主键的记录，但这些记录至少要有一个字段的值不相等。 ordered_set ：上面两个都是是哈希表实现。ordered_set 则可以按主键的顺序保存记录。 1mnesia:create_table(table_name, [&#123;type, bag&#125;,...]) 表的存储类型1234567891011121314151617181920212223(hello@yangzhiyongs-MacBook-Pro.local)3&gt; mnesia:info().---&gt; Processes holding locks &lt;------&gt; Processes waiting for locks &lt;------&gt; Participant transactions &lt;------&gt; Coordinator transactions &lt;------&gt; Uncertain transactions &lt;------&gt; Active tables &lt;---schema : with 1 records occupying 413 words of mem===&gt; System info in version "4.14.3", debug level = none &lt;===opt_disc. Directory "/tmp/mnesia_store" is used.use fallback at restart = falserunning db nodes = ['hello@yangzhiyongs-MacBook-Pro.local']stopped db nodes = []master node tables = []remote = []ram_copies = []disc_copies = [schema]disc_only_copies = [][&#123;'hello@yangzhiyongs-MacBook-Pro.local',disc_copies&#125;] = [schema]2 transactions committed, 0 aborted, 0 restarted, 0 logged to disc0 held locks, 0 in queue; 0 local transactions, 0 remote0 transactions waits for other nodes: []ok ram_copies ：仅驻留于内存disc_copies ：表示它会被写入磁盘；为了提高读取速度，这些表会被会部加载进内存disc_only_copyies ： 仅存储在磁盘，所以比上面两种要表许多。这种存储类型还不支持 ordered_set 表。 注意：不同节点上的表，可以有不同的存储类型。比如，有一个节点是写磁盘，其他的是RAM的。 向表录入数据12mnesia:write(...)mnsia:dirty_write(...) 事务Mnesia 具有通常所说的ACID性质。要进行事务非常简单： 将逻辑写入到一个（不含参数）的fun表达式，然后将它传递给 mnesia:transaction/1 即可。 脏操作以 dirty_ 为前缀的 Mnesia 函数都是脏操作，它不会考虑事务或数据库锁。 执行基本查询12mnesia:dirty_read(table_name, key)mnesia:read(...)]]></content>
      <categories>
        <category>erlang</category>
      </categories>
      <tags>
        <tag>erlang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]清楚地理解JavaScript中的this并且掌握它]]></title>
    <url>%2F2017%2F04%2F29%2F%E7%BF%BB%E8%AF%91-%E6%B8%85%E6%A5%9A%E5%9C%B0%E7%90%86%E8%A7%A3JavaScript%E4%B8%AD%E7%9A%84this%E5%B9%B6%E4%B8%94%E6%8E%8C%E6%8F%A1%E5%AE%83%2F</url>
    <content type="text"><![CDATA[清楚地理解 JavaScript 中的 this, 并且掌握它 原文：Understand JavaScript’s “this” With Clarity, and Master It （当this让最你棘手时，可以学习以下所有使用this的情景） 前提：一点 JavaScript 基础学习时间：大约 40 分钟 在 JavaScript 中this关键字同样困惑着 JavaScript 新手以及经验丰富的开发者。本文的目标就是完整地解释this。当我们学习完这篇文章后，JavaScript 中的this关键字这部分 我们就不必再担心了。我们将会明白如何在每个脚本里正确地使用this，包括那些难以捉摸和棘手情况的地方。 我们使用this，类似于我们在自然语言比如英语和法语中的代词。我们写 ：“John 正在飞快地跑着，因为他正在试图追上火车“。 注意代词 他 的使用。我们可以写成这样子：“John 正在飞快地跑着，因为 John 正在试图追上火车”。我们不要以这种方式重复地使用John，如果我们这样子做了，我们的家人、朋友和同事会很嫌弃我们。是的，他们肯定会这样子。好吧，也许不是你的家人，而是我们的那些酒肉朋友和同事。以类似的优雅方式，在 JavaScript 中， 我们使用this关键字作为一个快捷方式，一个引用；它引用一个对象；也就是在上下文中的主语，或者是正在执行代码的主体。思考下下面的例子： 12345678910 var person = &#123; firstName: "Penelope", lastName: "Barrymore", fullName: function () &#123; // 注意我们使用`this`就像我们上面例句中使用的`他` ： console.log(this.firstName + " " + this.lastName); ​// 我们也可以写成这样子： console.log(person.firstName + " " + person.lastName); &#125;&#125; 如果我们使用person.firstName和person.lastName，在上面的例子中，我们的代码会变得含糊。考虑下有另一个名为person的全局变量（我们可能或根本就没有意识到）。然后，引用 person.firstName，可能试图访问这个person的全局变量的firstName属性，并且会导致难以调试的错误。所以，我们使用this关键字不仅为了美学（例如，作为一个指示词），更为了准确；它的使用实际上使我们的代码更加明确，正如代词他使我们的句子更加清晰一样。它告诉我们：我们正在引用的是在句子开头特定的John。 就像代词他是用于指示先行词（先行词是代词指示的名词），this关键字类似地用于指示一个函数（this就是被用在这里）所绑定的对象。this关键字不仅是引用一个对象，并且它也包含对象的值。就像代词，this可以被用作一个快捷方式（或者一个相当明确的替代）来引用之前在上下文中的对象（“先行词对象”）。我们迟些将学习更多关于上下文的知识。 JavaScript的this关键字的基础知识首先，我们知道 JavaScript 中的所有函数都有属性，就像对象有属性一样。并且，当一个函数执行的时候，它就获得了this属性 ———— this是用于一个带有调用函数的对象的值的变量。this引用总是指示（并且持有值）一个对象 ———— 一个单一对象 ———— 并且它通常用在一个函数或者方法中，尽管它也可以用于全局作用域的函数外部。注意，当我们使用strict mode模式时，this在全局函数中持有undefined的值，并且在匿名函数里并没有绑定任何对象。 译者注：可以用下面的例子来演示： 1234567891011"use strict";console.info(this);(function() &#123;console.info(this) &#125;())function hello()&#123; console.info(this);&#125;hello() 输出的结果为: 123456[Running] node "/var/folders/lz/mpwxkp6s7rq62r08vt2h_j480000gn/T/temp-sgwrfzpgrf.javascript"&#123;&#125;undefinedundefined[Done] exited with code=0 in 0.137 seconds this用于函数内部（让我们假设是函数 A）并且它包含了调用函数 A 的对象的值。我们需要this来访问调用函数 A 的对象的方法和属性，特别地，由于我们并不总是知道调用对象的名字，而且有时是没有名字来引用调用者对象的。确实，this实际上仅仅是一个快捷引用“先行词对象”————调用者对象。 反复思考一下以下这个在 JavaScript 中使用 this的基本例子： 1234567891011var person = &#123; firstName :"Penelope", lastName :"Barrymore", // `this` 关键字用在 showFullName 方法里，并且 showFullName 方法是定义在 person 对象上, // `this` 关键字就会拥有 person 对象的值，因为 person 对象将会调用 showFullName() showFullName:function () &#123; console.log (this.firstName + " " + this.lastName); &#125;​&#125;​person.showFullName (); // Penelope Barrymore 并且再思考下 jQuery 中 this 的基础用法例子： 1234567 // jQuery 中常见的代码片段​ $ ("button").click (function (event) &#123; // $(this) 将拥有 button ($("button"))对象的值 ​// 因为 button 对象调用 click console.log ($ (this).prop ("name")); &#125;); 我将详解前面的 jQuery的例子：$(this) 的使用，它是 JavaScript 中的 this 关键字在 jQuery 中的语法，用在一个匿名函数里面，并且匿名函数是被 button 的 click() 函数执行。$(this) 被绑定到 button 对象的原因，是由于 jQuery 库绑定了 $(this) 到那些调用 click 方法的对象身上。因此，$(this) 将拥有 jQuery button ($(&quot;button&quot;))对象的值，尽管 $(this) 是被定义在一个匿名函数的内部，在匿名函数的外部，它是不能访问自身的this变量的。 注意：button 是一个在 HTML 页面的 DOM 元素，并且它也是一个对象；在这情况下，它是一个 jQuery 对象，因为我们在 jQuery $() 函数包住了它。 更新：下面(“最大的问题”部分)是在我发布了这篇文章几天后添加的。 JavaScript this 关键字的最大问题如果你理解了这一个 JavaScript中的 this 的原则，你将会清晰地明白this关键字了：this是直到一个对象调用了函数才会在this定义的地方进行赋值。让我们将那些定义this的函数的地方叫作“this 函数”。 尽管this的出现是指示定义它的对象，它是直到一个对象调用this 函数时才会真正地赋值的。并且这值是完全基于那个调用this 函数的对象的。在绝大部分情况下，this 有一个调用对象。然而，有极少情况下，this是没有调用者对象的值的。迟些会接触到这些情况。 在全局作用域范围中使用this在全局作用域范围，当代码正在浏览器中执行时，所有全局变量和函数都被定义在一个window对象上。因此，当我们在全局函数中使用this时，它是引用（并且拥有值）全局的window对象（不是在strict模式，这个在前面提到过了），它是整个 JavaScript 应用程序或者web 页面的主要容器。 这样： 12345678910111213141516171819202122232425 var firstName = "Peter", lastName = "Ally";​ function showFullName () &#123; // `this`在该函数里将拥有 `window` 对象的值 // 因为 showFullName() 函数是定义在全局作用域范围，就像 firstName 和 lastName 一样 console.log (this.firstName + " " + this.lastName); &#125;​ var person = &#123; firstName :"Penelope", lastName :"Barrymore", showFullName:function () &#123; // 在下面的`this`引用的是 person 对象，因为 showFullName 函数将被 person 对象调用 console.log (this.firstName + " " + this.lastName); &#125; &#125;​ showFullName (); // Peter Ally​​ // window 是所有全局变量和函数定义所在的地方，因此 window.showFullName (); // Peter Ally​​ // `this`定义在 person 对象的 showFullName() 方法内部，所以仍然引用的是 person 对象，因此： person.showFullName (); // Penelope Barrymore 当 this 最容易曲解以及变得棘手时当我们通过方法来使用this时、当我们通过this将一个方法赋值到一个变量时、当一个函数使用回调(callback)函数使用 this时、以及当this被用在一个闭包里面———— 一个内部函数时， this关键字是最容易曲解的。我们将在每一个例子中看一下在这些情景中的this代表适当的值的解决办法。 重点注意： 在我们继续之前，了解一下上下文（context）在 JavaScript 中，上下文类似于英语中句子的主体：“John is the winner who returned the money.”。 这个句子中的主体就是John，我们可以说句子的上下文(context)就是John，因为在此时此句中，焦点就是他。并且像我们可以使用分号来切换句子的主体，我们可以通过另一个对象来调用函数从当前上下文的对象来切换到另一个上下文的对象。 类似地，在 JavaScript 代码中： 12345678910111213141516171819202122232425var person = &#123; firstName :"Penelope", lastName :"Barrymore", showFullName:function () &#123;​// 这就是 上下文(context)console.log (this.firstName + " " + this.lastName); &#125;&#125;​​// 当我们正调用 person 对象的 showFullName() 方法时， 上下文就是 person 对象。​// 并且，`this`在 showFullName() 方法中的使用，它拥有 person 对象的值。person.showFullName (); // Penelope Barrymore​​​// 如果我们用另一个不同的对象来调用 showFullName ​var anotherPerson = &#123;firstName :"Rohit",lastName :"Khan"​&#125;;​​// 我们可以显式地使用`apply`方法来设置`this`的值 —— 后面会有更多关于 `apply()` 方法的介绍​// 这时，`this` 获得了无论是哪个对象调用了`this 函数`的值 ，因此：person.showFullName.apply (anotherPerson); // Rohit Khan​​​// 所以，现在的上下文(context)就是 anotherPerson 了，因为 anotherPerson 通过使用`apply()`方法来调用了 person.showFullName() 方法时， 外带的是，在上下文中对象调用this 函数，我们可以通过另一个对象来调用this 函数来改变上下文；然后，这新的对象就在上下文中了。 以下是一些this关键字变得棘手的情景，他们包含了修正this的错误的例子。 1. 当用在回调函数时，this 的困境当我们传递一个方法（使用this的方法）作为一个参数用作一个回调函数来使用时，这会变得比较棘手。例如： 1234567891011121314151617181920212223// 假设我们有一个带有当在页面上的 button 被点击时就调用 clickHandler 方法的简单对象：var user = &#123; data: [ &#123; name: "T. Woods", age: 37 &#125;, &#123; name: "P. Mickelson", age: 43 &#125; ], clickHandler: function (event) &#123; var randomNum = ((Math.random() * 2 | 0) + 1) - 1; // random number between 0 and 1​ ​ // 这一行是随机从 data 数组中打印用户对象的名字和年龄 console.log(this.data[randomNum].name + " " + this.data[randomNum].age); &#125;&#125;​// button 现在包装在 jQuery 的 $ 符号里，所以，它现在是一个 jQuery 对象// 并且输出将会是 `undefined`， 因为在 button 对象中，并没有 data 属性。$("button").click(user.clickHandler); // 并不能读取 `undefined` 的'0' 属性 在以上代码中，由于 button ($(&quot;button&quot;))自己是一个对象，并且我们传递user.clickHandler 方法作为它的click()方法的回调函数，我们知道this是在user.clickHandler 方法内部，它将不再引用user对象了。this 现在引用的对象是user.clickHandler方法被执行的对象了，因为this是定义在user.clickHandler方法的内部。既然正在调用user.clickHandler方法的对象是 button 对象 ———— user.clickHandler 将被执行在 button 对象的 click 方法内部。 注意，尽管我们正在调用的clickHandler()方法是user.clickHandler（这是我们必须这样子做的，因为 clickHandler 是定义在 user 内部），clickHandler方法自身将被现在上下文中的this———— button 对象调用。 在这一点上，很明显的是当上下文改变时 ———— 当我们执行一个不是在对象自身定义而是在其他对象上定义的方法时，this关键字就不再引用定义this的自身对象了，而是引用了调用这些定义this方法的对象。 当一个方法是作为一个回调函数来传递的this解决方案我们真正地想让 this.data 是引用 user 对象的 data 属性时，我们可以使用bind(), apply() 或 call()方法来显式地设置this的值。 我已经写了一篇详细的文章：JavaScript’s Apply, Call, and Bind Methods are Essential for JavaScript Professionals，在这些方法里，包括如何在各种棘手的情景下使用它们来设置this的值的。为了不重复发布这些细节到这里，我建议你先完整阅读那篇文章先，这是一篇我认为对于一名 JavaScript 专业人士必读的文章。 为了修正前面例子的问题，我们可以使用bind方法，因此： 替代这一行： 12$ ("button").click (user.clickHandler); 我们必须bind绑定clickHandler方法到 user 对象，就像这样： 12$("button").click(user.clickHandler.bind(user)); // P. Mickelson 43 —— 在JSBin上看一下一个可行的例子 2. 在闭包中时， this 困境另一个比较棘手的例子是，我们把this用在一个内部函数（闭包）中。有一点是非常重要的是要注意：闭包并不能通过使用this关键字来访问外部函数的this变量，因为this仅仅只能被函数自身访问，而不是内部函数。例如： 123456789101112131415161718192021222324252627282930var user = &#123; tournament: "The Masters", data: [ &#123; name: "T. Woods", age: 37 &#125;, &#123; name: "P. Mickelson", age: 43 &#125; ], ​ clickHandler: function () &#123; // 在这里使用 `this.data`是 OK 的，因为`this`是引用 user 对象，并且 data 是 user 对象的一个属性。 ​ this.data.forEach(function (person) &#123; // 但是，在这个匿名函数的内部（传递到 forEach 参数的方法），`this` 不再引用 user 对象了。 // 这个内部函数并不能访问外部函数的`this` console.log("What is This referring to? " + this); //[object Window]​ console.log(person.name + " is playing at " + this.tournament); // T. Woods is playing at undefined​ // P. Mickelson is playing at undefined​ &#125;) &#125;​&#125;​user.clickHandler(); // 这时`this`引用的对象是哪个？—— `window` 对象 this在匿名函数的内部并不能访问外部函数的this，所以，它（匿名函数的this）绑定到了全局作用域的window对象，当没有使用strict模式时。 this作为内部匿名函数里使用的解决方案为了解决在传递给forEach方法参数的匿名函数中使用this的问题，我们使用一个在 JavaScript 里常用实践：在我们进入 forEach方法之前， 设置this的值到另一个变量里： 123456789101112131415161718192021222324252627var user = &#123; tournament: "The Masters", data: [ &#123; name: "T. Woods", age: 37 &#125;, &#123; name: "P. Mickelson", age: 43 &#125; ], ​ clickHandler: function (event) &#123; // 为了获取`this`是指向 user 对象的值，我们必须将它赋值到另一个变量里 // 我们设置`this`的值到 theUserObj 变量里了，所以我们可以在后面使用它 var theUserObj = this; this.data.forEach(function (person) &#123; // 替代 this.tournament， 我们现在使用 theUserObj.tournament console.log(person.name + " is playing at " + theUserObj.tournament); &#125;) &#125;​&#125;​user.clickHandler();// T. Woods is playing at The Masters​// P. Mickelson is playing at The Masters 值得注意的是，许多 JavaScript 开发者喜欢使用名为that的变量名，正如下面所见的一样，来保存this的值。使用that这个词对我来说是非常尴尬的，所以，我试图命名这个变量为一个描述this真正要引用的对象的名词，所以，在上面的代码里，我这里使用了 var theUserObj = this。 123// 常见于在 JavaScript 开发者里使用下面的代码var that = this; —— JSBin上的例子 3. 当一个方法被赋值到一个变量时， this 的困境如果我们赋值一个使用this的方法时，this的值会逃逸我们的想像并且它被绑定到另一个对象。让我们看以下的代码： 123456789101112131415161718192021222324252627282930313233343536// data 变量是一个全局变量var data = [ &#123; name: "Samantha", age: 12 &#125;, &#123; name: "Alexis", age: 14 &#125;];​var user = &#123; // 这个 data 变量是 user 对象的一个属性 data: [ &#123; name: "T. Woods", age: 37 &#125;, &#123; name: "P. Mickelson", age: 43 &#125; ], showData: function (event) &#123; var randomNum = ((Math.random() * 2 | 0) + 1) - 1; // random number between 0 and 1​ ​ // 这行是从 data 数组中添加一个 person 对象为文本字符串表示 console.log(this.data[randomNum].name + " " + this.data[randomNum].age); &#125;​&#125;​// 将 user.showData 赋值到一个变量 showUserDatavar showUserData = user.showData;​// 当我们执行 showUserData 函数，打印出的值将会是全局变量的 data 中的值，而不是 user 对象中的 data 数组的值//​showUserData(); // Samantha 12 (from the global data array)​ 当一个方法被赋值到一个变量时的解决方案我们可以通过显式地通过bind方法来设置this的值来解决这个问题： 123456// 绑定 showData() 方法到 user 对象var showUserData = user.showData.bind (user);​// 现在，我们获取了 user 对象的值，因为`this`关键字绑定到了 user 对象上showUserData (); // P. Mickelson 43 4. 当借用方法时， this 的困境在 JavaScript 开发中，借用方法是一个常见的用法，并且作为 JavaScript 开发者，我们无疑会一次又一次地遇到这种做法。并且时不时地，我们也将参与这种节省时间的实践中。关于更多的借用方法的细节，请阅读我的深入的文章 JavaScript’s Apply, Call, and Bind Methods are Essential for JavaScript Professionals。 让我们仔细检查一下在借用方法相关的上下文中的 this： 12345678910111213141516171819202122232425262728293031323334// 假设我们有两个对象。一个对象有名为 avg() 方法，而另一个对象则没有该方法。// 所以，我们将借用 (avg()) 方法var gameController = &#123; scores: [20, 34, 55, 46, 77], avgScore: null, players: [ &#123; name: "Tommy", playerID: 987, age: 23 &#125;, &#123; name: "Pau", playerID: 87, age: 33 &#125; ]&#125;​var appController = &#123; scores: [900, 845, 809, 950], avgScore: null, avg: function () &#123;​ var sumOfScores = this.scores.reduce(function (prev, cur, index, array) &#123; return prev + cur; &#125;);​ this.avgScore = sumOfScores / this.scores.length; &#125;&#125;​// 如果我们执行下面的代码// gameController.avgScore 属性将会被设置为 appController 对象的 scores 数组的平均分数 // 所以不要执行这段代码，它仅用于说明；我们希望 appController.avgScore 仍然为 nullgameController.avgScore = appController.avg(); avg 方法的this关键字将不再引用gameController对象了，它将引用appController对象，因为它正在被appController调用。 当借用方法时，this 的解决方案为了解决这个问题并且确定在 appController.avg() 方法内的this是引用gameController，我们可以使用apply()方法，因此： 123456789// 注意，我们正使用 apply() 方法，所以第二个参数必须是一个数组 —— 这个参数是传递到 appController.avg() 方法的。appController.avg.apply (gameController, gameController.scores);​// avgScore 属性现在被正确地设置到了 gameController 对象了，尽管我们是从 appController 对象上借用了 avg() 方法console.log (gameController.avgScore); // 46.4​​// appController.avgScore 仍然是 null，它没有被更新，仅仅是 gameController.avgScore 被更新了console.log (appController.avgScore); // null gameController对象借用了appController的avg()方法。在appController里的this的值将被设置为了gameController对象，因为我们将gameController对象作为第一个参数传递到了apply()方法。在apply()方法的第一个参数总是被显式地设置为this的值。 —— JSBin上的例子 后记我希望你已经学会了足够帮你理解 JavaScript 中的 this 关键字了。现在，你已经有工具（bind, apply和 call 来设置this到一个对象）在必要攻克 JavaScript 中这些 this的棘手情况。 正如你已经学习了，在那些原始上下文（就是那些定义this的地方）改变时，this就变得有点麻烦了，尤其是在那些用在回调函数、当被不同的对象调用或者借用函数时。永远记住：this被赋予的值是那个调用this函数的对象的值。 好的，祝睡得安好和享受 Coding.]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>JavaScript</tag>
        <tag>js</tag>
        <tag>this</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]RabbitMQ 持久化配置]]></title>
    <url>%2F2017%2F04%2F27%2F%E7%BF%BB%E8%AF%91-RabbitMQ-%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[原文 RabbitMQ 持久层旨在在没有配置的情况下在大多数主要场景中给出一个好的结果。然而，一些配置有时比较有用。这篇文章会解释你可以怎样配置它。建议你在开始任何行动之前阅读完它。 持久层是如何工作的首先，一些背景：所有 persistent 和 transient 的消息都可以被刷盘。 Persistent 消息到达消息后会尽可能快地刷盘，而 transient 的消息仅会在内存有压力的情况下被刷盘以便释放内存。当可能时， Persistent 消息也会保持在内存中，并仅会在内存有压力时才会被淘汰。持久层是指将这两种类型的消息( persistent 与 transient )持久化到磁盘的机制。 在这篇文章中，我们说 队列 是指一个非镜像队列( unmirrored queue )或者是一个主队列( a queue master)又或者是一个从队列(a queue slave)。队列镜像(Queue mirroring) 发生在持久化之上(happen “above”)。 持久层有两个组件：队列索引(queue index) 和 消息存储（message store)。队列索引是负责维护在一个队列中给定的消息的位置，以及它是否被投递和确认(ack) 了。因此，每一个队列都有一个队列索引。 消息存储(message store) 是一个对消息进行 键-值对 的存储，在服务器中的所有队列中共享。消息（内容，和其他任何属性，以及/或者消息头）既可以直接保存在队列索引中，也可以写到消息存储(message store) 中。在技术中有两种消息存储（一个是 transient ，另一个是 persistent 消息），但它们通常被一起视作为 消息存储 (the message store)。 内存消耗在内存压力下，持久层会试图将尽可能多地刷盘，并尽可能多地从内存中移除（消息）。但这仍然有一些东西它们必须保留在内存中： 每个队列的中对每一条未确认(unacknowledged)消息的一些元数据(metadata)。消息自身可以从内存中移除，如果它的目的是消息存储。 消息存储需要一个索引。默认的消息存储索引对每一条存储的消息都会使用少量的内存。 在队列索引中的消息将消息写到队列索引的优缺点： 优点 消息可以在一个操作来进行刷盘，而不是要两个操作；对于小型消息来说，这是比较可观的收益。 保存在队列索引的消息，并不需要消息存储索引中的条目，因此当在进行 paged out 时，并不会有内存代价。 缺点 队列索引在内存中保留固定数量的记录块；如果有非小型消息写到队列索引的话，内存使用就会比较明显。 如果消息被一个交换机路由到多个队列，消息就需要被写到多个队列索引中。如果这样一条消息被保存到消息存储中，仅有一个副本需要被写。 这些存储在队列索引的未确认(Unacknowledged)消息，会一直保留在内存中。 继续意图将一个非常小的消息存储在队列索引中作为一个优化，并且将所有其他消息写到消息存储中。这可以通过配置项 queue_index_embed_msgs_below 来控制。默认情况下，消息的序列化大小小于 4096 个字节的（包括属性和头）是被存储在队列索引中的。 当从磁盘读取消息时，每一个队列索引需要保留至少一个段文件(one segment file)在内存中。段文件包含了 16384 条消息记录。如果加大 queue_index_embed_msgs_below 的话，请小心，增加一点可能会导致大量的内存占用。 意外限制持久化性能对于持久化来说由于持久化受限于文件句柄的数量或与它一起工作的异步线程的数量，它可能表现平平。在这两种情况下，当你有大量的队列同时需要访问磁盘时就会发生这种情况。 太少的文件句柄RabbitMQ 服务器典型情况下会受限于它可以打开的文件句柄数量（至少是在 Unix 上面）。每一条正在运行的网络连接都要一个文件句柄，剩下可用的是队列使用的。在考虑完网络连接之后，如果要磁盘访问的队列比文件句柄更多的话，要磁盘访问的队列就会在它们自己之间共享文件句柄；在文件句柄被返回之前每个获取该句柄的队列使用一会，完成之后就会被下一个队列使用。 这是为了防止服务器由于有大量的磁盘访问的队列而崩溃，但代价比较昂贵。management 插件可以为每个集群中的节点显示 I/O 统计信息；也会显示读、写、seek 等等的频率，并也会显示重新打开的频率——即文件句柄被循环利用的频率。一个拥有比较少量文件句柄的繁忙服务器，可能会有数百每秒的重新打开文件句柄的处理——在这种情况下明显地提高它的性能就是允许它打开更加多的文件句柄。 太少的异步线程Erlang 虚拟机会创建一个异步线程池来处理长时间运行的文件I/O 操作。这是在所有的队列中共享的。当每一个激活的文件 I/O 操作发生时，它都需要一条异步纯种。只是少量的异步线程的话就会伤害性能了。 注意，异步线程的情况并不完全类似于文件句柄的情况。如果一个队列顺序地执行许多 I/O 操作，最好的执行情况是它持有一个文件句柄，然后所有的操作都在该句柄上执行；否则我们可能要刷盘，然后进行大量的 seek 并且要使用额外的 CPU 时间来精确它。然而，队列并不能从拥有一个异步线程地通过顺序地执行操作来得益（事实上，它们并不能这样子做）。 因此，理想的情况下所有正在执行 I/O 流操作的队列都应该有足够的文件句柄，并且有足够的异步线程为存储层可以合理地执行同时需要一定数量的 I/O 操作。 然而缺少异步线程而导致性能的问题并不太明显（一般情况下这也不太可能；所以首先检查其他的东西）。拥有太少异步线程的症状包括当服务器也许忙于持久化时，短期内每秒的 I/O 操作数下降为 0（正如 management 插件报告的那样），同时，报告的每次 I/O 操作的时间在增加。 异步线程的数量可以如文档这里描述的一样，通过传递 +A 参数给 Erlang 虚拟机来配置，并且典型的情况下是通过环境变量 RABBITMQ_SERVER_ERL_ARGS 来配置。默认值为 +A 64 。改变这个值之前，尝试几个不同的值来验证下比较好。 替换消息存储索引实现正如上面提到，每一条写到消息存储里的消息会为它的索引条目使用小量的内存。在 RabbitMQ 中，消息存储索引是一种可拔插的，其他的实现可以作为插件来使用，这可以移除这个限制。(我们的服务器不带有任何实现的原因是，它们都是使用本地代码的)。注意，这种插件典型情况下会使消息存储运行得更慢。]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>rabbitmq</tag>
        <tag>rabbit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]理解 RabbitMQ 3.4 中内存的使用]]></title>
    <url>%2F2017%2F04%2F27%2F%E7%BF%BB%E8%AF%91-%E7%90%86%E8%A7%A3-RabbitMQ-3-4-%E4%B8%AD%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[原文 我的队列使用了多少内存？这是一个容易问的问题，并且回答起来比较困难。RabbitMQ 3.4 给你一个清晰的视图来显示你的队列使用了多少内存。这篇博客就是来谈一下这些的，并且也会解释在一般情况下队列内存的使用情况。 一点背景首先，我们需要知道 Erlang 是如何管理内存的。Erlang 与绝大部分的垃圾收集(GC)语言的一个不同点就是，它并没有一个全局的堆(global heap)。相反，每一个 进程 都有一个属于它自己的私有的隔离堆。在 RabbitMQ 中的术语 进程 可以是指 queues 、 channels 、connections 等等。这意味着并不必在每次进行 GC 时来暂停整个系统；相反，每个 进程 都有它们自己的 GC 调度。 这很好，但是当一条消息通过 RabbitMQ 传递时，它会通过几个不同的 进程 。在这种情况下，我们希望避免进行太多的复制。因此, Erlang 给了我们一个不同的内存管理模式—— binaries ，它用于 RabbitMQ 内部的一些部件，其中最感兴趣的是消息的内容(message bodies)。 Binaries 是在 进程 间共享的，并且是引用计数的。 这是如何应用到 RabbitMQ 的这意味着，消息内容占用的内存在 RabbitMQ 里是在 进程 之间共享的。并且这共享也发生在队列之间：如果交换机路由一条消息到许多队列中，这条消息内容仅会在内存中保存一次。 所以，我们看到那个问题：”这个队列使用了多少内存？” 是比较难回答的——我们可以排除所有被队列引用的 binary 内存，这会导致统计偏低；或者包含这种内存，那就可能会导致统计偏高。 早期的 RabbitMQ 版本并没有试图对这个情况做太多的工作；它们报告队列的 memory use 与 进程 内存一样大（即，并没有包含任何引用的 binaries 内存）并且在全局内存分析中显示一块巨大的 binary memory use。就没有办法进一步调查了。 RabbitMQ 3.4 给我们一些更好的指导，从上到下和从下到上，首先，让我们看一下自上而下的内存使用视图: 这里有一些与我们以前的不同。总体内存使用类型现在有了更多的类别，并且有一个新的 binary memory 类。 我们分别显示 binary memory 类别的原因有两个：一是它计算代价比较昂贵（我们必须遍历服务器所有使用的内存；如果有大量的小型 binaries 的话，这需要花费一段时间），另一个原因是我们不保证它在整体内存类别中加起来的大小（原因是 binaries 在前面提到的是共享的） 但我们可以看到，几乎所有的 binary 使用是由于在队列中的消息。这个屏幕快照是从一个通常是静态的 broker 中获得的，所以这正是我们期待的。 但是队列呢？好的，但哪些队列正在使用所有的内存？我们可以通过查看每个队列的详细页来调查它（这个信息当然也可以通过 rabbitmqctl 来获取，但是图形化查看更好） 这里我们可以看到 RabbitMQ 3.4 的一个新特性：队列维护一个它包含的消息内容字节总数。因此，我们看到该队列包含了 1.2GB 的消息内容， 420 MB 在内存里。我们可以假设这 420MB 是该队列中所有 binary 使用的内存。该队列也使用了 421MB 的 进程 内存（这里纯粹是巧合的非常相似的量）——这包括了每一条消息的消息属性(message properties)、头(header)和元数据(metadata)。 所以合理地说 “该队列正使用 841MB 内存” —— 除了消息内容可能也会与其他队列共享。 除此之外，注意到 In memory 和 Persistent 消息在这里并不是反义词：一条 non-persistent 消息可以在内存有压力的情况下被 paged out ，并且一条 persistent 的消息也可以是在内存中的。可以参考 the document 来获取更多关于 paging 的信息。 我们也可以在队列列表视图中查看这些信息： (这里我已经点击了 “+/-“ 的链接为了添加一些列来显示内存使用并且为了更清晰点移除了一些其他的列) 当然，这仍然并没有给出一个队列使用了多少内存的完美统计；这种统计在一个动态系统中几乎是不可能的事。但是，它给出了我们更接近的数据了。]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>rabbitmq</tag>
        <tag>rabbit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 资料收集]]></title>
    <url>%2F2017%2F04%2F27%2FRabbitMQ-%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[关于性能及优化 http://stackoverflow.com/questions/10030227/maximize-throughput-with-rabbitmq https://www.cloudamqp.com/blog/index.html 负载测试: https://www.cloudamqp.com/blog/2016-11-18-load-testing-and-performance-measurements-rabbitmq.html Java 工具: https://www.rabbitmq.com/java-tools.html RabbitMQ 持久化默认情况下，重启 Broker 时，那些非持久化(not durable and persistent)的 Messages 、 Exchanges 和 Queues 会丢失。 如果你不想丢失任何信息，请确保你的 Queues 是声明为 durable 的，并且你的 Messages 的分发模式(delivery mode) 为 persistent 的( transient 为短暂模式，也即内存模式) 注意，声明 Queues 为 durable 并不表示 Messages 也是 persistent 的，你必须显式地声明 Messages 为 persistent 才行。 占用高 CPU/内存 常见原因这一段是看了 英文原文 时做下的简要翻译和笔记的。 排队的消息太多 长时间的高速率消息 频繁地打开和关闭连接 排队的消息太多占用比较高的内存，可能说明队列里的消息增长过快。当这种情况发生时，RabbitMQ 为了释放内存，就会开始刷盘，而当开始刷盘时，队列的速度就会再恶化。对条消息的 CPU 成本将会比当队列为空时的成本更高（因为消息现在必须排队）。然后 CPU I/O Wait 很可能会增高，这个说明了该百分比的 CPU 时间必须等待刷盘。 优化你应该将你的队列消息，一直保持在 0 。即最好不要堆积消息。 太多未确认的消息所有未确认的消息，都必须居住在服务器的内存中。如果你有太多的未确认消息，你将会用尽你的内存。一个有效的方式来限制未确认消息就是限制你的客户端的 prefetch 参数。 太高的消息吞吐量CPU User time 表明你的程序在 CPU 中花费在执行指令的百分比时间，在这情况下，就是花费在运行 RabbitMQ 的时间。如果你的 CPU User time 太高，它可能是由于太高的消息吞吐量了。 频繁地打开和关闭连接如果 CPU System time 比较高，你应该检查一下你是如何处理你的连接了。RabbitMQ 中的连接要比 Channel 更耗资源，即所谓比较重。连接应该长时间存活，并且 Channel 可以更频繁地打开和关闭。 最佳实践是，在线程与 Channel 之间重用连接，换句话说，如果你的连接与 Channel 一样多，那你就可能需要看一下你的架构了。 理想情况下，每个进程里应该仅有一条连接，然后在你的应用程序里，每条线程各自使用自己的 Channel（Channel并不是线程安全的）。 连接或 Channel 泄漏如果大量的 Channel 或 连接失去控制的话，它可能是由于你客户端代码的 Channel 或 Connection 泄漏了。请尝试去发现导致泄漏的原因并确保你不再使用 Channel 时记得及时关闭它们。 RabbitMQ 3.6.0 版本这不是一个好的 RabbitMQ 版本——它有大量的问题，并且在新的版本中被修复了。 RabbitMQ 默认启动参数版本为 3.6.9 ，Erlang版本为 Erlang/OTP 18 erlang erl man 1234567-W w :-A 128 -P 1048576 -t 5000000 -stbt db -zdbbl 32000 -K true RabbitMQ 添加交换机的性能今天测试了下，将不同的队列，绑定到不同的交换机，有没有能提高性能。结果是：No 测试的情况是，使用2个交换机(hello-exchange, hello-exchange2)和两个队列(hello-queue-name, hello-queue-name2)分别一一对应，然后再使用一个队列 hello-queue 绑定到默认的交换机(default)。它们入队的消息数分别为 2000,2000,4000。测试结果是它们的总耗时是差不多的。]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
        <tag>rabbit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https.protocols在Java中的使用]]></title>
    <url>%2F2017%2F03%2F02%2Fhttps-protocols%E5%9C%A8Java%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Caused by: java.io.EOFException: SSL peer shut down incorrectly在服务器上，发现一个微博爬虫系统偶尔会报这种异常。Google 了下，在 Stackoverflow 上看到相关的回答。所以决定详细了解下这原理。 上面说，明确指定HTTPS的协议版本即可。即：System.setProperty(&quot;https.protocols&quot;, &quot;TLSv1.1&quot;) HTTPS 的 protocols查看维基百科，关于 HTTPS 的介绍可知： 严格地讲，HTTPS并不是一个单独的协议，而是对工作在一加密连接（TLS或SSL）上的常规HTTP协议的称呼。 TLS 与 SSLSSL 是 TLS 的前身。SSL 是 Netscape 公司推出的 HTTPS 协议，以 SSL 进行加密。 IETF 将 SSL 进行标准化，公布了第一版的 TLS 标准文件。 发展历史SSL 1.0 没有公开过 2.0 1995年2月发布 3.0 1996年发布。2014年10月，Google 发现 SSL 3.0 设计缺陷，建议禁用此一协议。 TLSIETF 将SSL标准化，并称为 TLS. TLS1.0 与 SSL 3.0 的差异非常小。 1.0 1.1 2006 1.2 2008 1.3 2016 JDK中对 HTTPS 版本的支持情况JDK 6 SSL v3 TLS v1(默认) TLS v1.1(JDK6 update 111 及以上) JDK 7 SSLv3 TLS v1(默认) TLS v1.1 TLS v1.2 JDK 8 SSL v3 TLS v1 TLS v1.1 TLS v1.2(默认) JSSEJSSE（Java Security Socket Extension），它实现了SSL和TSL（传输层安全）协议。 JSSE 参数调节 javax.net.debug ：打印连接的详细信息。例如 -Djavax.net.debug=all 或者 -Djavax.net.debug=ssl:handshake:verbose https.protocols ：控制使用 Java 客户端通过 HttpsURLConnection 或 URL.openStream() 操作的协议版本。例如 -Dhttps.protocols=TLSv1,TLSv1.1,TLSv1.2. 对于非HTTP协议，可以通过 SocketFactory&#39;s SSLContext 来控制 。 jdk.tls.client.protocols ：控制底层平台的TLS实现。例如 -Djdk.tls.client.protocols=TLSv1.1,TLSv1.2 http.agent ：当初始化连接时，Java会使用这个作为 user-agent 的字符串。例如: -Dhttp.agent=&quot;known agent&quot; java.net.useSystemProxies ：使用系统本身的代理： -Djava.net.useSystemProxies=true http.proxyHost 和 http.proxyPort : 使用HTTP协议时的代理。例如: -Dhttp.proxyHost=proxy.example.com -Dhttp.proxyPort=8080 https.proxyHost 和 https.proxyPort : 和上面一样，区别只是 HTTP 和 HTTPS http.proxyUser,http.proxyPassword, https.proxyUser,https.proxyPassword : 认证用户名和密码。 查看服务器支持的 HTTPS 协议版本1nmap --script ssl-enum-ciphers -p 443 api.weibo.com 返回的结果为: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137Starting Nmap 7.40 ( https://nmap.org ) at 2017-03-02 14:18 CSTNmap scan report for api.weibo.com (180.149.135.176)Host is up (0.039s latency).Other addresses for api.weibo.com (not scanned): 180.149.135.230PORT STATE SERVICE443/tcp open https| ssl-enum-ciphers:| SSLv3:| ciphers:| TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_SEED_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_IDEA_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C| TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C| TLS_RSA_WITH_DES_CBC_SHA (rsa 2048) - C| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C| TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA (dh 1024) - D| compressors:| NULL| cipher preference: server| warnings:| 64-bit block cipher 3DES vulnerable to SWEET32 attack| 64-bit block cipher DES vulnerable to SWEET32 attack| 64-bit block cipher IDEA vulnerable to SWEET32 attack| Broken cipher RC4 is deprecated by RFC 7465| CBC-mode cipher in SSLv3 (CVE-2014-3566)| Key exchange (dh 1024) of lower strength than certificate key| TLSv1.0:| ciphers:| TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_SEED_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_IDEA_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C| TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C| TLS_RSA_WITH_DES_CBC_SHA (rsa 2048) - C| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C| TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA (dh 1024) - D| compressors:| NULL| cipher preference: server| warnings:| 64-bit block cipher 3DES vulnerable to SWEET32 attack| 64-bit block cipher DES vulnerable to SWEET32 attack| 64-bit block cipher IDEA vulnerable to SWEET32 attack| Broken cipher RC4 is deprecated by RFC 7465| Key exchange (dh 1024) of lower strength than certificate key| TLSv1.1:| ciphers:| TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_SEED_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_IDEA_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C| TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C| TLS_RSA_WITH_DES_CBC_SHA (rsa 2048) - C| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C| TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA (dh 1024) - D| compressors:| NULL| cipher preference: server| warnings:| 64-bit block cipher 3DES vulnerable to SWEET32 attack| 64-bit block cipher DES vulnerable to SWEET32 attack| 64-bit block cipher IDEA vulnerable to SWEET32 attack| Broken cipher RC4 is deprecated by RFC 7465| Key exchange (dh 1024) of lower strength than certificate key| TLSv1.2:| ciphers:| TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A| TLS_RSA_WITH_AES_256_CBC_SHA256 (rsa 2048) - A| TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A| TLS_RSA_WITH_AES_128_CBC_SHA256 (rsa 2048) - A| TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_SEED_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_IDEA_CBC_SHA (rsa 2048) - A| TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C| TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C| TLS_RSA_WITH_DES_CBC_SHA (rsa 2048) - C| TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (secp256r1) - A| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 (dh 1024) - A| TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 (dh 1024) - A| TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (secp256r1) - A| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A| TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (dh 1024) - A| TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 (dh 1024) - A| TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 1024) - A| TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 1024) - A| TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C| TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA (dh 1024) - D| compressors:| NULL| cipher preference: server| warnings:| 64-bit block cipher 3DES vulnerable to SWEET32 attack| 64-bit block cipher DES vulnerable to SWEET32 attack| 64-bit block cipher IDEA vulnerable to SWEET32 attack| Broken cipher RC4 is deprecated by RFC 7465| Key exchange (dh 1024) of lower strength than certificate key|_ least strength: DNmap done: 1 IP address (1 host up) scanned in 10.99 seconds 可知，它支持的协议有: SSLv3 TLSv1.0 TLSv1.1 TLSv1.2 解决办法服务器为Linux + JDK7 + 64位。添加 12System.setProperty("https.protocols", "TLSv1.2"); 在爬虫爬取数据时，就没有报这类似的异常了。 参考资料 Oracle 上关于 https.protocols 的文档 wiki]]></content>
      <categories>
        <category>java</category>
        <category>https</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log</tag>
        <tag>http</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 出队发送邮件注意事项]]></title>
    <url>%2F2017%2F02%2F22%2FRabbitMQ%20%E5%87%BA%E9%98%9F%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[线上一个发送邮件的系统，通过 RabbitMQ 出队发送系统中的邮件时，发现虽然 consumer 连接在那里，但是日志中却没有任何输出相关的成功或失败或抛出异常的信息。 这种情况下，我的解决思路如下 打印出当前 JVM 线程栈 线程栈如下，然后直接定位到相应的代码所在的线程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 "org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer#6-1" prio=10 tid=0x00007f296c5c6000 nid=0x5362 runnable [0x00007f29963e2000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.read(SocketInputStream.java:150) at java.net.SocketInputStream.read(SocketInputStream.java:121) at sun.security.ssl.InputRecord.readFully(InputRecord.java:312) at sun.security.ssl.InputRecord.read(InputRecord.java:350) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:927) - locked &lt;0x0000000787590178&gt; (a java.lang.Object) at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:884) at sun.security.ssl.AppInputStream.read(AppInputStream.java:102) - locked &lt;0x0000000787590200&gt; (a sun.security.ssl.AppInputStream) at com.sun.mail.util.TraceInputStream.read(TraceInputStream.java:110) at java.io.BufferedInputStream.fill(BufferedInputStream.java:235) at java.io.BufferedInputStream.read(BufferedInputStream.java:254) - locked &lt;0x0000000787591850&gt; (a java.io.BufferedInputStream) at com.sun.mail.util.LineInputStream.readLine(LineInputStream.java:89) at com.sun.mail.smtp.SMTPTransport.readServerResponse(SMTPTransport.java:2131) at com.sun.mail.smtp.SMTPTransport.issueSendCommand(SMTPTransport.java:2036) at com.sun.mail.smtp.SMTPTransport.data(SMTPTransport.java:1849) at com.sun.mail.smtp.SMTPTransport.sendMessage(SMTPTransport.java:1099) - locked &lt;0x0000000787590a78&gt; (a com.sun.mail.smtp.SMTPTransport) at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:448) at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:345) at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:340) at com.company.util.SendMail.sendFileMail(SendMail.java:110) at com.company.listener.MailListener.sendMail(MailListener.java:29) at sun.reflect.GeneratedMethodAccessor433.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.springframework.util.MethodInvoker.invoke(MethodInvoker.java:269) at org.springframework.amqp.rabbit.listener.adapter.MessageListenerAdapter.invokeListenerMethod(MessageListenerAdapter.java:387) at org.springframework.amqp.rabbit.listener.adapter.MessageListenerAdapter.onMessage(MessageListenerAdapter.java:298) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:777) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:700) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$001(SimpleMessageListenerContainer.java:95) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$1.invokeListener(SimpleMessageListenerContainer.java:187) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.invokeListener(SimpleMessageListenerContainer.java:1187) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:681) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:1165) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:1149) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1100(SimpleMessageListenerContainer.java:95) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1312) at java.lang.Thread.run(Thread.java:722) Locked ownable synchronizers: - None 可以看到，问题代码所在的位置是: 123at com.company.util.SendMail.sendFileMail(SendMail.java:110)at com.company.listener.MailListener.sendMail(MailListener.java:29) 之后的栈中，出现了这么多locked 线程。最后停留在了读取数据相关的方法里。这样子就可以表明，它在无限等待读取数据了。 项目里的 sender 的属性配置12345678910111213141516mail.host=smtp.exmail.qq.com## service (finding password, active accout)mail.service.username=companymail.service.password=password## Mail connection propertiesmail.smtp.host=smtp.exmail.qq.commail.mime.charset=UTF-8mail.smtp.starttls.enable=truemail.smtp.socketFactory.fallback=falsemail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactorymail.smtp.port=465mail.smtp.socketFactory.port=465mail.smtp.auth=truemail.transport.protocol=smtp 配置属性的问题这个是因为没有设置相关的 timeout 属性，导致一直在等待，最后线程不可用了。 javaMailProperties 所有属性 imap pop3 smtp 解决12345678## 连接超时mail.smtp.connectiontimeout## 读取数据超时mail.smtp.timeout ## 写入数据超时mail.smtp.writetimeout 加上这三个属性，设置适合的超时时间。超时后，重新进队再继续重试即可。]]></content>
      <categories>
        <category>rabbitmq</category>
        <category>javamail</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>rabbitmq</tag>
        <tag>javamail</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 多模块开发]]></title>
    <url>%2F2017%2F02%2F20%2FSpring%20Boot%20%E5%A4%9A%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[本文假设项目名为 wxsdk，它有如下模块 123456789wxsdk├── bean├── constant├── dao├── listener├── service├── utils├── webapp├── wx-plugin wxsdk 根目录下的 pom 文件如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.8.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;modules&gt; &lt;module&gt;wx-plugin&lt;/module&gt; &lt;module&gt;constant&lt;/module&gt; &lt;module&gt;dao&lt;/module&gt; &lt;module&gt;bean&lt;/module&gt; &lt;module&gt;service&lt;/module&gt; &lt;module&gt;listener&lt;/module&gt; &lt;module&gt;utils&lt;/module&gt; &lt;module&gt;webapp&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/commons-codec/commons-codec --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-api --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.22&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.6.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.6.7&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.mybatis.spring.boot/mybatis-spring-boot-starter --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot&lt;/artifactId&gt; &lt;version&gt;1.3.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context-support --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/javax.servlet/javax.servlet-api --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.thoughtworks.xstream&lt;/groupId&gt; &lt;artifactId&gt;xstream&lt;/artifactId&gt; &lt;version&gt;1.4.7&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/commons-io/commons-io --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-tools&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-redis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;1.3.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.codehaus.jackson/jackson-mapper-asl --&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt; &lt;version&gt;1.8.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-amqp.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.testng&lt;/groupId&gt; &lt;artifactId&gt;testng&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-httpclient&lt;/groupId&gt; &lt;artifactId&gt;commons-httpclient&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.coobird&lt;/groupId&gt; &lt;artifactId&gt;thumbnailator&lt;/artifactId&gt; &lt;version&gt;0.4.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org&lt;/groupId&gt; &lt;artifactId&gt;jaudiotagger&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-aop --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;version&gt;1.3.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.18&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-batch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; --&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.7&lt;/java.version&gt; &lt;spring.version&gt;4.2.8.RELEASE&lt;/spring.version&gt; &lt;spring-amqp.version&gt;1.5.6.RELEASE&lt;/spring-amqp.version&gt; &lt;/properties&gt;&lt;/project&gt; 这个 pom 父 pom，主要用于配置子模块，以及子模块依赖的版本统一的问题。如果这里的&lt;build&gt;元素，是可以应用到所有子模块的&lt;build&gt;操作的。 子模块的 pom这里只是举个 service 模块的 pom.xml 为例子，其他模块的 pom 是一类似的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;dao&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;constant&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;bean&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;utils&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-redis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-httpclient&lt;/groupId&gt; &lt;artifactId&gt;commons-httpclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.coobird&lt;/groupId&gt; &lt;artifactId&gt;thumbnailator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org&lt;/groupId&gt; &lt;artifactId&gt;jaudiotagger&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.codehaus.jackson/jackson-mapper-asl --&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 在子模块下面的 pom 的依赖，是不用写版本号（项目模块自身除外）的。项目模块里，其实也可以用${project.version} 来代替会更好点。 webapp 模块的 pom因为这是一个web 应用，所以该模块相当于主模块。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;webapp&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- module dependency --&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;listener&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;utils&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;wx-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;constant&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.company.wxsdk&lt;/groupId&gt; &lt;artifactId&gt;bean&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;&gt; 主模块的&lt;build&gt;元素要加上spring-boot-maven-plugin插件。 配置文件存放的问题spring boot 应用，并不能从 jar 里读取application.propertis文件（即配置文件的位置，就算是写成classpath*:application，spring boot 也是读取不了的），这个不像普通的 spring 项目一样。（之前也写个一份maven 模块化开发的 blog，然后可以有一个 config 模块，然后将配置文件，都放在这个模块里，然后在主模块里，通过写成classpath*:xxx.properties 来加载，但 spring boot 并不行） mybatis 配置文件存放的问题因为项目里的 xml，是放在 java 文件的同一个目录的，但 maven 默认打包时，资源文件是不包含 xml 文件的。所以在要build配置里，添加上 1234567891011121314151617181920&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 配置多个 redis 实例因为项目里，需要用到多个 redis 实例来通信。配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package com.company.wxsdk.service;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.ImportResource;import org.springframework.context.annotation.Primary;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.GenericToStringSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;import java.nio.charset.StandardCharsets;/** * Created by emacsist on 2017/2/17. */@Configuration@ImportResource("classpath:wxsdk-service-context.xml")public class ServiceConfiguration &#123; @Value("$&#123;redis.host&#125;") private String redisHost; @Value("$&#123;redis.port&#125;") private int redisPort; @Value("$&#123;redis.password&#125;") private String pwd; @Value("$&#123;redis.database&#125;") private int db; @Value("$&#123;redis.v2.host&#125;") private String v2RedisHost; @Value("$&#123;redis.v2.port&#125;") private int v2RedisPort; @Value("$&#123;redis.v2.password&#125;") private String v2Pwd; @Value("$&#123;redis.v2.database&#125;") private int v2DB; @Primary @Bean public JedisConnectionFactory jedisConnectionFactory()&#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(); jedisConnectionFactory.setPassword(pwd); jedisConnectionFactory.setHostName(redisHost); jedisConnectionFactory.setPort(redisPort); jedisConnectionFactory.setDatabase(db); return jedisConnectionFactory; &#125; @Bean public JedisConnectionFactory v2redisConnectionFactory()&#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(); jedisConnectionFactory.setPassword(v2Pwd); jedisConnectionFactory.setHostName(v2RedisHost); jedisConnectionFactory.setPort(v2RedisPort); jedisConnectionFactory.setDatabase(v2DB); return jedisConnectionFactory; &#125; @Bean public RedisTemplate&lt;String, Object&gt; v2RedisTemplate(@Qualifier("v2redisConnectionFactory") RedisConnectionFactory cf) &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(cf); redisTemplate.setKeySerializer(new StringRedisSerializer(StandardCharsets.UTF_8)); redisTemplate.setValueSerializer(new GenericToStringSerializer&lt;&gt;(Object.class)); redisTemplate.setHashKeySerializer(new StringRedisSerializer(StandardCharsets.UTF_8)); redisTemplate.setHashValueSerializer(new GenericToStringSerializer&lt;&gt;(Object.class)); return redisTemplate; &#125; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(@Qualifier("jedisConnectionFactory") RedisConnectionFactory cf) &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(cf); redisTemplate.setKeySerializer(new StringRedisSerializer(StandardCharsets.UTF_8)); redisTemplate.setValueSerializer(new GenericToStringSerializer&lt;&gt;(Object.class)); redisTemplate.setHashKeySerializer(new StringRedisSerializer(StandardCharsets.UTF_8)); redisTemplate.setHashValueSerializer(new GenericToStringSerializer&lt;&gt;(Object.class)); return redisTemplate; &#125;&#125; 使用时： 123456789## 这种就会使用 jedisConnectionFactory 的 redisTemplate 实例@Autowiredprivate RedisTemplate&lt;String, String&gt; redisTemplate;## 这种就会使用 v2redisConnectionFactory 的 v2RedisTemplate 实例@Resource(name = "v2RedisTemplate")private ValueOperations&lt;String, String&gt; valueOperations;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Spring session时 SessionListener 执行 2 次的分析]]></title>
    <url>%2F2017%2F02%2F14%2F%E4%BD%BF%E7%94%A8Spring-session%E6%97%B6%20SessionListener%20%E6%89%A7%E8%A1%8C%202%20%E6%AC%A1%E7%9A%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[项目中使用 Spring-session 这个分布式 session 作为负载均衡的 session 中间件，以便统一 session 的管理。 然后我们自己添加了一个 HttpSessionListener, 但是发现它执行了 2 次，实在是太诡异了。（其实是太菜了） 首先项目里的配置大概如下: 12345678910&lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"/&gt;&lt;bean id="l" class="org.springframework.session.web.http.SessionEventHttpSessionListenerAdapter"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;ref bean="webHttpSessionListener" /&gt; &lt;/list&gt; &lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean class="org.springframework.security.web.session.HttpSessionEventPublisher"/&gt; 定位问题这个之前是看了下 SpringSecurity 项目中大概的配置的，使用 SessionEventHttpSessionListenerAdapter 来添加HttpSessionListener，那就怀疑是这里出了问题。所以打开该类的源码，定位到相应的初始化 listeners 的方法。 发现它初始化了 2 次！ 第一次： 第二次： 原因12&lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"/&gt; 再通过详细查看资料，发现 Spring-session 这个类是进行自动配置的（spring-boot 风格），所以不用再显式添加下面的 listener 这些配置了的。 所以，直接注释掉这段代码即可： 1234567891011 &lt;bean id="l" class="org.springframework.session.web.http.SessionEventHttpSessionListenerAdapter"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;ref bean="webHttpSessionListener" /&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="org.springframework.security.web.session.HttpSessionEventPublisher"/&gt;` 实现监听器 HttpSessionListener自定义的类，实现了该接口，并且注册到 Spring 容器，那么它就会自动添加到 SessionListener 容器里的，就不用再进行其他额外的配置了。看来，以前看的文档还不够详细，只是匆匆忙忙赶着能用的态度。没有注意到该 listener 被注册了多次的问题！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 删除大表中的大部分数据的方式]]></title>
    <url>%2F2017%2F02%2F09%2FMySQL%20%E5%88%A0%E9%99%A4%E5%A4%A7%E8%A1%A8%E4%B8%AD%E7%9A%84%E5%A4%A7%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[昨晚要删除一张原有 2 亿多条日志表的数据，只保留 今年 2017 及之后的数据，删除之前的，以释放磁盘空间，发现 delete from t where id &lt; 2亿; 发现这样子删除实在是太慢了，而且效率性能低下 创建一个中间表12create table t_copy like 原表名; 不删除的数据复制到中间表12insert into t_copy select * from 原表名 where ... 重命名表12rename table 原表名 to t_old, t_copy to 原表名; 删除整张表12drop table t_old]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 一次启动失败分析案例]]></title>
    <url>%2F2017%2F02%2F09%2FJava%20%E4%B8%80%E6%AC%A1%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[今天，在部署外网的测试环境时，发现启动时报如下错误： 1234567Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c6d80000, 42991616, 0) failed; error='Cannot allocate memory' (errno=12)## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (malloc) failed to allocate 42991616 bytes for committing reserved memory.# An error report file with more information is saved as:# /home/username/hs_err_pid19325.log 根据 JVM 的日志 提示，很明显是因为内存不足，导致分配内存给 JVM 时启动失败。 因为平时都一直可以启动成功的，为什么今天却报因为内存问题而导致项目启动失败。 top查看当前系统的进程状态，发现有一个 Java 进程：3679，属于 wxsdk 项目的，占用了 23% 的内存（物理内存为 8GB），这个值得注意，因为平时这些 Java 进程的内存，一般只是占用%几的内存的。 free -m查看当前系统的总内存状态： 123456free -m total used free shared buffers cachedMem: 3953 3254 698 0 28 73-/+ buffers/cache: 3152 800Swap: 0 0 0 dump 出 wxsdk 的 heap 状态12jmap -dump:format=b,file=/tmp/heap.hprof 3670 然后下载回地本，使用 Eclipse 的 MAT 分析： 12/Applications/mat.app/Contents/MacOS/MemoryAnalyzer -vmargs -Xmx8g -XX:-UseGCOverheadLimit heap.hprof MAT 结果MAT 报告的问题有： Problem Suspect 112345The classloader/component "org.apache.catalina.loader.WebappClassLoader @ 0xc2578048" occupies 11,875,448 (31.20%) bytes. The memory is accumulated in classloader/component "org.apache.catalina.loader.WebappClassLoader @ 0xc2578048".Keywordsorg.apache.catalina.loader.WebappClassLoader @ 0xc2578048 Problem Suspect 212345678The classloader/component "org.apache.catalina.loader.StandardClassLoader @ 0xc25e67d8" occupies 3,954,080 (10.39%) bytes. The memory is accumulated in one instance of "org.apache.tomcat.util.bcel.classfile.ConstantUtf8$1" loaded by "org.apache.catalina.loader.StandardClassLoader @ 0xc25e67d8".Keywordsorg.apache.tomcat.util.bcel.classfile.ConstantUtf8$1org.apache.catalina.loader.StandardClassLoader @ 0xc25e67d8Details » Problem Suspect 3123455,236 instances of "java.lang.Class", loaded by "&lt;system class loader&gt;" occupy 4,494,072 (11.81%) bytes. Keywordsjava.lang.Class 分析结果及结论从上面的 MAT 的结果可知，是因为 Tomcat 的 ClassLoader 的问题，导致内存过大。而 ClassLoader 的问题，一般来说有如下两种情况: 要加载的类本身就过多 因为热加载，导致加载的 class 过多 然后查看 Tomcat 的配置文件 Tomcat 目录/conf/server.xml，发现 &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; 中的autoDeploy为true，表示 Tomcat 会自动进行热加载。 解决 关闭 Tomcat 的热加载autoDeploy=false 重新启动 wxsdk 项目，以释放这些内存空间]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次 MySQL 批量插入的优化]]></title>
    <url>%2F2017%2F01%2F11%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%20MySQL%20%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[公司的DSP 项目,有个模块就是插入 RabbitMQ 里的 BID 的对象到 MySQL 然后再统计数据的业务. 但是, 发现这个 BID 批量插入的性能, 低得有点吓人. 平均 1K/s 的速度. 而这些日志, 每天有时可产生好几千 W 条 BID 的数据. 环境MyBatis3.1 + Spring4.3.2 + shardbatis 分表插件 原因本地测试时, 每次批量插入 1K 条数据性能: 123bid insert time = 2506 msbid insert time = 2546 msbid insert time = 2632 ms 代码初始版本代码Java里的代码: 123456public int bidInsertBatch(List&lt;TaskBidLog&gt; logs, int userid) throws SQLException &#123; if (logs.size() &gt; 0) &#123; return taskBidLogMapper.bidInsertBatch(logs, userid); &#125; return 0;&#125; Mapper 的 XML: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;insert id="bidInsertBatch"&gt; insert into task_bid_log ( bid_id, imp_id, task_id, bid_price, win_price, is_won, age, gender, location, con_type, os, osv, brand, geo, ip, idfa, wax_user_id, create_time, update_time ) values &lt;foreach collection="list" item="log" separator="," index="index"&gt; ( #&#123;log.bidId&#125;, #&#123;log.impId&#125;, #&#123;log.taskId&#125;, #&#123;log.bidPrice&#125;, #&#123;log.winPrice&#125;, #&#123;log.isWon&#125;, #&#123;log.age&#125;, #&#123;log.gender&#125;, #&#123;log.location&#125;, #&#123;log.conType&#125;, #&#123;log.os&#125;, #&#123;log.osv&#125;, LEFT(#&#123;log.brand&#125;, 64), #&#123;log.geo&#125;, #&#123;log.ip&#125;, #&#123;log.idfa&#125;, #&#123;log.waxUserid&#125;, #&#123;log.createTime&#125;, #&#123;log.updateTime&#125; ) &lt;/foreach&gt; ON DUPLICATE KEY UPDATE bid_price = values(bid_price), age = values(age), gender = values(gender), location = values(location), con_type = values(con_type), os = values(os), osv = values(osv), brand = values(brand), ip = values(ip), idfa = values(idfa), wax_user_id = values(wax_user_id), create_time = values(create_time)&lt;/insert&gt; 记录实际执行时间JDBC 的连接信息mysql connector configuration properties 看官方文档, 可以看到可以记录 SQL 实际执行的各种时间, 即在 JDBC 的连接 URL 上加上如下代码: profileSQL=true&amp;gatherPerfMetrics=true&amp;reportMetricsIntervalMillis=500&amp; 1jdbc:mysql://10.0.0.40:3308/unidsp?profileSQL=true&amp;gatherPerfMetrics=true&amp;reportMetricsIntervalMillis=500&amp;useUnicode=true&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;characterEncoding=UTF-8 调试结果: 结果数据分析耗时及结论: 123451 ms execute, 45 ms commit,1590 ms : mapper 那条语句 (这里包括上面两个时间了)1664ms 是整个方法 在 MySQL 客户端操作用 root 用户登录 MySQL, 然后使用 show full process list 命令捕获线程执行的完整 SQL, 然后再在客户端直接执行, 发现执行的时间是119 ms: 这个与上面的 51 ms execute, 45 ms commit 这个记录的数据很接近了. 所以, 可以排除是 DB 服务自身的问题, 而是在 Java 代码层出现了问题. 使用原生的 JDBC 来操作Java代码: 123456789101112131415161718192021222324252627282930String sql = "insert into task_bid_log_2 (bid_id,imp_id,task_id,bid_price,win_price,is_won,age, gender,location,con_type,os,osv,brand,geo,ip,idfa,wax_user_id,create_time,update_time) values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?) ON DUPLICATE KEY UPDATE bid_price = values(bid_price),age = values(age),gender = values(gender),location = values(location),con_type = values(con_type),os = values(os),osv = values(osv),brand = values(brand),ip = values(ip),idfa = values(idfa),wax_user_id = values(wax_user_id),create_time = values(create_time)";PreparedStatement pstmt = connection.prepareStatement(sql);for (TaskBidLog log : logs) &#123; pstmt.setString(1, log.getBidId()); pstmt.setString(2, log.getImpId()); pstmt.setString(3, log.getTaskId()); pstmt.setInt(4, log.getBidPrice()); pstmt.setInt(5, log.getWinPrice()); pstmt.setInt(6, log.getIsWon()); pstmt.setInt(7, log.getAge()); pstmt.setString(8, log.getGender()); pstmt.setString(9, log.getLocation()); pstmt.setString(10, log.getConType()); pstmt.setString(11, log.getOs()); pstmt.setString(12, log.getOsv()); pstmt.setString(13, log.getBrand()); pstmt.setString(14, log.getGeo()); pstmt.setString(15, log.getIp()); pstmt.setString(16, log.getIdfa()); pstmt.setString(17, log.getWaxUserid()); pstmt.setTimestamp(18, new Timestamp(log.getCreateTime().getTime())); pstmt.setTimestamp(19, new Timestamp(log.getUpdateTime().getTime())); pstmt.addBatch();&#125;// Execute the batchint [] updateCounts = pstmt.executeBatch();System.out.append("inserted "+updateCounts.length); 执行情况跟踪(按上面的 JDBC 连接上加上那些记录时间的参数) !!!惊呆了, 发现批量执行时, 它是每一条 SQL 发送一次给 MySQL 服务器的. 导致整个耗时为 47058ms, 即 47.058 秒了… 查了下资料, 这种情况下, 还要修改 JDBC 连接的 URL 的参数, 即加上以下参数: useServerPrepStmts=false&amp;rewriteBatchedStatements=true&amp;useCompression=true 这时, 可以看到整个耗时为: 只要191 ms了. 使用 Mybatis + 事件循环插入Java 代码:123456789@Transactionalpublic int bidInsertBatch(List&lt;TaskBidLog&gt; logs, int userid) throws SQLException &#123; int rs = 0; for (TaskBidLog log : logs) &#123; rs += taskBidLogMapper.insert(log, userid); &#125; return rs;&#125; 这种耗时, 也是非常久的. 通过按上面的参数的跟踪发送 SQL 的情况下发现, 虽然整体是一个事务, 但是 SQL 上, 是每一条 SQL 发送一次给 MySQL 服务器的.最后统一提交事务的. 加不加以下参数, 都是一样的: 1useServerPrepStmts=false&amp;rewriteBatchedStatements=true&amp;useCompression=true MyBatis 的问题经过同事在另一边的 debug, 发现 MyBatis 在解析大量SQL 的时候, 耗时非常严重. 看来 Mybatis 并不是我们想像中的那样完美. MyBatis 解析 SQL解析 XML 里的语句得到 originalSql, 以及参数的类型 Class&lt;?&gt; parameterType, 这时得到的是带有#{xxx}类似的 SQL 的语句, 然后 MyBatis 再将#{} 替换为?,最后再将parameterType 的值替换到? 所对应的位置里. 将#{}替换为?, 结果如下: 就是这解析的步骤, 在批量大的时候, 性能是非常低的… 总结批量插入的情况下, 最理想的速度经测试, 应该是JDBC + executeBatch + JDBC url 加上参数 : useServerPrepStmts=false&amp;rewriteBatchedStatements=true&amp;useCompression=true]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>mysql</tag>
        <tag>mybatis</tag>
        <tag>batch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL不重启添加slow log慢查询日志]]></title>
    <url>%2F2016%2F12%2F07%2FMySQL%E4%B8%8D%E9%87%8D%E5%90%AF%E6%B7%BB%E5%8A%A0slow-log%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162## 开启慢查询mysql&gt; set global slow_query_log = 'ON';Query OK, 0 rows affected (0.78 sec)## 检查变量值mysql&gt; show global variables like '%slow%';+---------------------------+------------------------------------------------------+| Variable_name | Value |+---------------------------+------------------------------------------------------+| log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || slow_launch_time | 2 || slow_query_log | ON || slow_query_log_file | /home/username/mysql/data/db/logs/myql-slow.log |+---------------------------+------------------------------------------------------+5 rows in set (0.00 sec)## 记录不使用索引的语句mysql&gt; set global log_queries_not_using_indexes = 'ON';Query OK, 0 rows affected (0.00 sec)mysql&gt; show global variables like '%indexes%';+----------------------------------------+-------+| Variable_name | Value |+----------------------------------------+-------+| log_queries_not_using_indexes | ON || log_throttle_queries_not_using_indexes | 0 |+----------------------------------------+-------+2 rows in set (0.00 sec)## 设置慢查询日志的位置mysql&gt; set global slow_query_log_file ='/home/username/mysql/data/db/logs/myql-slow.log';Query OK, 0 rows affected (0.01 sec)mysql&gt; show variables like '%slow%';+---------------------------+------------------------------------------------------+| Variable_name | Value |+---------------------------+------------------------------------------------------+| log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || slow_launch_time | 2 || slow_query_log | ON || slow_query_log_file | /home/username/mysql/data/db/logs/myql-slow.log |+---------------------------+------------------------------------------------------+5 rows in set (0.00 sec)## 按需要修改记录慢于该时间的语句mysql&gt; show variables like '%query_time%';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.00 sec)## 刷新即可生效mysql&gt; FLUSH LOGS;Query OK, 0 rows affected (0.22 sec)mysql&gt;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一名技术菜鸟分析一次微信红包诱导点击过程]]></title>
    <url>%2F2016%2F12%2F01%2F%E4%B8%80%E5%90%8D%E6%8A%80%E6%9C%AF%E8%8F%9C%E9%B8%9F%E5%88%86%E6%9E%90%E4%B8%80%E6%AC%A1%E5%BE%AE%E4%BF%A1%E7%BA%A2%E5%8C%85%E8%AF%B1%E5%AF%BC%E7%82%B9%E5%87%BB%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[今晚遇到一微信群，发了一个所谓的”拼手气红包”，其中的内幕大家应该都知道了的。但想到自己也是搞 Web 开发的（虽然是后端苦 B 程序员一枚），但也尝试着一步一步分析下其中的“原理”收到的链接是这样子的：（因为要调试，所以这里只是弄到微信的文件助手里） 第一眼首先，打一次打开时，是这样子的： 这里录制了个 gif， 比较模糊，请将就下哈。可以看到，整个过程，其实它是没有发送任何数据给后端程序来获取红包数，以及底下那些人的获取金额及个人信息的。 如果是在非移动浏览器下，它的页面是一个普通的页面。但在移动端的浏览器下，它就是这样子了。通过源码，了解到这个东东： 当在普通浏览器与微信里打开时是不同的，它就是通过上面那段代码来进行内容替换： HTML 内容整个页面，几乎是由大量图片+少量 HTML 文本组成的。如下: 从点击“开”入手 下面是自己添加的一些代码注释说明: 点击“提现”还剩下多少份的代码，也是写死的，也就是不会再变的了。呵呵。 分享次数的重复当你点分享后，它会累加你的分享3次才能“提现” 当你分享超过 3 次的时候，就会提示： 1领取成功，由于活动量较大，红包稍后会逐步到账。。。。 我忍住不笑。这和某宝，某东，某猫，会不会是一样的。^_^ 主题 – 抽奖大转盘好像整个过程，都没有什么有害的事呀？So，那骗子们到底是想要干什么呢。然后我就返回了，这时候，主角才出来。 完整的转盘代码如下（本人没有添加或修改过任何东西。这个就是它的源码内容） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298function Rollbox() &#123; // 规则弹窗 (function() &#123; $(".rule-btn").on("click", function() &#123; showsth(2); &#125;) &#125;)(); var that; function time_out() &#123; var cjjh = ["恭喜您,获得3次抽奖机会", "您还剩余2次抽奖机会", "您还剩余1次抽奖机会", "您的机会已经抽完啦"]; try &#123; $(".container h2.title").text(cjjh[unescape($.getCookie("selectnum"))]); &#125; catch (err) &#123;&#125; &#125;; time_out(); roll(); var allangle = 0; var lastangle = 0; function roll() &#123; $(".four-up").rotate(&#123; bind: &#123; click: function() &#123; that = this; var mo = random(); $(".four").rotate(&#123; angle: lastangle, animateTo: allangle, duration: 5000, callback: function() &#123; time_out(); roll(); if (mo.split("|")[1] == "1") &#123; showsth(1); // $("body").append('&lt;iframe src="RedBag.htm?id=1" style="display:none"&gt;&lt;/iframe&gt;') &#125; else &#123; showsth(0); // $("body").append('&lt;iframe src="RedBag.htm?id=0" style="display:none"&gt;&lt;/iframe&gt;') &#125; &#125; &#125;); &#125; &#125; &#125;); &#125; // 红包弹窗 // function showsth(e) &#123; // $(".showbox,.showbox-two").hide(0); // $(".hbbg").fadeIn(200); // $("#hbbg_1").attr("style", "display:none"); // switch (e) &#123; // // 显示继续抽奖 // case 0: // $(".showbox-two").fadeIn(200, function() &#123; // $(this).on("click", function() &#123; // $(".hbbg").fadeOut(200); // $(".four-up").click(); // &#125;) // &#125;); // break; // // 显示抽到内容 // case 1: // $(".showbox").fadeIn(200); // break; // // 显示规则内容 // case 2: // $(".rule-box").fadeIn(200, function() &#123; // $(this).on("click", function() &#123; // $(this).fadeOut(200); // $(".hbbg").fadeOut(200); // &#125;) // &#125;); // break; // default: // &#125; // &#125; // function showsth(e) &#123; $(".showbox,.showbox-two").hide(0); $(".hbbg").fadeIn(200); $("#hbbg_1").attr("style", "display:none"); if (e == 1) &#123; $(".showbox").fadeIn(200); &#125; else &#123; $(".showbox-two").fadeIn(200); &#125; $(".showbox-two").bind("click", function() &#123; $(".hbbg").fadeOut(200); document.getElementById("four-up").click(); &#125;) $(".showbox").click(function()&#123; $(".hbbg").fadeOut(200); var mydate = new Date(); var sth = "ischoujiang"; var coosth = $.getCookie(sth); if (coosth == "" || coosth == "undefined" || coosth == null) &#123; $.setCookie(sth, 0, 90); &#125; $.setCookie('ischoujiang', 1, 90); localStorage.setItem(sth, 1); tsburl(); &#125;) &#125; function random() &#123; $(that).unbind("click"); // cookie判断 if (!unescape($.getCookie("selectnum"))) &#123; $.setCookie("selectnum", 1); &#125; else &#123; var xx = Number(unescape($.getCookie("selectnum"))) + 1; xx &gt;= 3 ? xx = 3 : xx; $.setCookie("selectnum", xx); &#125; if ($.getCookie("selectnum") &lt; 3) &#123; n = 0 &#125; else &#123; n = 3; &#125; // localStorage判断 var selectnum; if (!localStorage.selectnum) &#123; localStorage.selectnum = 1; &#125; else &#123; localStorage.selectnum++; &#125;; if (localStorage.selectnum &lt; 3) &#123; n = 0 &#125; else &#123; n = 3; &#125; // lastangle = allangle % 360; allangle = 2160 + n * 60; var money = ["", "很抱歉没有抽中，还有抽奖机会哦|0", "待定|0", "恭喜你抽中10元红包，分享到QQ空间后重新打开本页即可领取|1"]; return money[n]; &#125;&#125;Rollbox(); //启动转盘// 基于jq的滑动 parentName//父节点,slidetime//滚动速度,addtime//滚动间隔,len//子元素的数量var Autoslide = function(parentName, slidetime, addtime, len) &#123; this.parentName = parentName; this.len = len; this.init = function() &#123; var parentNode = $(parentName); // 获取节点 var child_height = parentNode.find("li").outerHeight(); // 获取子节点高度 var parent_height = len * child_height; // 获取parent父元素的高 parentNode.height(parent_height); setInterval(function() &#123; parentNode.find("li:first").animate(&#123; marginTop: -child_height &#125;, slidetime); setTimeout(function() &#123; var oldnode = parentNode.find("li:first"); parentNode.append(oldnode.clone().css("margin-top", 0)); oldnode.remove(); &#125;, (slidetime + 5)) &#125;, addtime); &#125;&#125;;// 请求数据// 用户滚动//var page = 10;//var SlideName = function () &#123;// // 滚动1// var data = &#123;&#125;;// $.post('/Home20160701/IndexData.aspx', &#123; page: page &#125;, function (data) &#123;// // if (data != '') &#123;// var interText = doT.template($("#itemperson-box").text());// $(".itemperson-box").html(interText(data));// var buyName = new Autoslide(".itemperson", 1000, 2000, 3); //实例化// buyName.init(); //初始化// &#125;// &#125;);// $.post('/Home20160701/NewIndexData.aspx', &#123; page: page &#125;, function (data) &#123;// // if (data != '') &#123;// var interText = doT.template($("#itemperson-box-two").text());// $(".itemperson-box-two").html(interText(data));// setTimeout(function () &#123;// var buysomebody = new Autoslide(".buy-box", 2000, 3000, 5); //实例化// buysomebody.init();// &#125;, 5000)// &#125;// &#125;);//&#125;//SlideName();//地址信息的判断function dzcleck() &#123; var cpsth = $("#detail .box .name span.current").text(); var name = $("#name").val(); var tel = $("#phone").val(); //获取手机号 var telReg = !!tel.match(/^[1-9][0-9]&#123;10&#125;$/); //如果手机号码不能通过验证 var address = $("#s3").val(); var xxdz = $("#xxdz").val(); if (cpsth == "") &#123; alert("请选择商品类型"); return; &#125; if (name == "") &#123; alert("请正确的填写姓名"); return; &#125; if (telReg == false) &#123; alert("请正确的填写手机号"); return; &#125; if (address == "选择区县" || address == "") &#123; alert("请正确的填写地址"); return; &#125; if (xxdz == "") &#123; alert("请您填写详细地址"); return; &#125; var address = $("#s1").val() + $("#s2").val() + $("#s3").val(); return cpsth + "|" + name + "|" + tel + "|" + address + "|" + xxdz;&#125;$(function() &#123; $("#detail .box .name span").on("click", function() &#123; $(this).siblings().removeClass("current"); $(this).addClass("current"); &#125;) //选择商品信息状态 $("#detail .bottom .btn").on("click", function() &#123; var x = $('input:radio[name="agbtn"]:checked').val(); if (x != undefined) &#123; var sth = dzcleck(); // 请求发送 &#125; else &#123; alert("请勾选同意活动说明") &#125; &#125;) //点击提交 var num = 1; &#125;) //判断微信function isWeiXin() &#123; var ua = window.navigator.userAgent.toLowerCase(); if (ua.match(/MicroMessenger/i) == 'micromessenger') &#123; return true; &#125; else &#123; return false; &#125;&#125;//判断是否为Safarifunction isSafari() &#123; if (+browser.versions.ios) &#123; return true; &#125; else &#123; return false; &#125;&#125;//判断是否为qqfunction qq() &#123; if (+browser.versions.qq) &#123; return true; &#125; else &#123; return false; &#125;&#125;var browser = &#123; versions: function() &#123; var u = window.navigator.userAgent; return &#123; trident: u.indexOf('Trident') &gt; -1, //IE内核 presto: u.indexOf('Presto') &gt; -1, //opera内核 webKit: u.indexOf('AppleWebKit') &gt; -1, //苹果、谷歌内核 gecko: u.indexOf('Gecko') &gt; -1 &amp;&amp; u.indexOf('KHTML') == -1, //火狐内核 mobile: !!u.match(/AppleWebKit.*Mobile.*/) || !!u.match(/AppleWebKit/), //是否为移动终端 ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端 android: u.indexOf('Android') &gt; -1 || u.indexOf('Linux') &gt; -1, //android终端或者uc浏览器 iPhone: u.indexOf('iPhone') &gt; -1 || u.indexOf('Mac') &gt; -1, //是否为iPhone或者安卓QQ浏览器 iPad: u.indexOf('iPad') &gt; -1, //是否为iPad webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部 weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器 qq: u.indexOf('Mac') &gt; -1 &#125;; &#125;()&#125;document.onselectstart = new Function("event.returnValue=false;");document.oncontextmenu = new Function("event.returnValue=false;"); 然后，我们也可以知道，这些东西，都已经是固化写死在 HTML 上面了的，并没有什么真正的奖品，而且那个转盘也是固定根据你的转动次数来决定转到某个“奖品”里的。showsth函数就是干这事的。第一轮是：谢谢参与第二轮是：谢谢参考第三轮是：时常腕表 这个时候,就会弹出这个填入表单，手机这些信息了。（还是原来的配方，还是熟悉的味道） 这时我随便输入一些信息，看看提交表单： 然后，大家都懂了的。 总结首先，骗子利用红包诱导用户来点击红包，用户点击后发现还要分享至少 3 次，才能“提现”，（撒网），当分享够次数了后，然后假装“由于交易量过大，红包金额稍后返回用户的钱包”。这时，用户开始返回，咦，发现可以抽奖，然后。。。。。。]]></content>
      <categories>
        <category>微信红包</category>
        <category>诱导</category>
      </categories>
      <tags>
        <tag>微信红包</tag>
        <tag>诱导</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中报java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()]]></title>
    <url>%2F2016%2F12%2F01%2FJava%E4%B8%AD%E6%8A%A5java.lang.NoSuchMethodError%3A%20java.util.concurrent.ConcurrentHashMap.keySet()%2F</url>
    <content type="text"><![CDATA[原因公司某生产环境在Tomcat启动时，报如下错误: 1java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()Ljava/util/concurrent/ConcurrentHashMap$KeySetView; 然后 Google 了下，发现在Github上也有在讨论: gist.github.com 导致原因： 因为开发人员在本地使用的JDK版本为1.8，但生产环境中使用的JDK版本为1.7，虽然也在项目的Maven里，添加了source和target的级别都为1.7，但是，当放到生产环境启动的时候，还是会报这个错误。 重现所以，在本机测试了下。按gist上面的步骤来重现： 在1.8的环境下编译，也将项目的级别设置为1.7，然后使用JDK1.7的JVM来运行: java代码: 123456789import java.util.Set;import java.util.concurrent.ConcurrentHashMap;public class HelloConvariance &#123; public static void main(String[] args) &#123; ConcurrentHashMap&lt;String, String&gt; properties = new ConcurrentHashMap&lt;&gt;(); Set&lt;String&gt; keySet = properties.keySet(); &#125;&#125; 123└─[1] &lt;&gt; /ihome/java/jdk/jdk1.7.0_79/bin/java com.github.emacsist.AppException in thread "main" java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()Ljava/util/concurrent/ConcurrentHashMap$KeySetView; at com.github.emacsist.App.main(App.java:12) 解决一将开发人员的JDK也设置为1.7 二在编译的时候，指定bootclasspath为1.7的，即按上面的gist的处理: 1$ /usr/lib/jvm/java-8-oracle/bin/javac -source 1.7 -target 1.7 HelloCovariance.java -bootclasspath /usr/lib/jvm/java-1.7.0-openjdk-amd64/jre/lib/rt.jar]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ中的内存与流量控制]]></title>
    <url>%2F2016%2F12%2F01%2FRabbitMQ%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E4%B8%8E%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[相关内存参数vm_memory_high_watermark这个是与流量控制相关的内存参数. RabbitMQ会在启动和执行命令rabbitmqctl set_vm_memory_high_watermark 百分比的时候检测系统所安装的内存总量。默认情况沔，当RabbitMQ服务器使用超过40%的内存时，它会引起一个内存报警并且阻塞所有连接。一旦内存报警清除后（例如，由于RabbitMQ服务器将消息页交换到磁盘或者分发到客户端时）就会恢复正常服务了。 所以，将这个值设置为0,然后它就会立即触发内存报警！如果你希望允许RabbitMQ使用更加多的内存，它可以增大该值. 另一个重要的事项： 默认的内存阀值是 40% 的系统安装的内存。请注意，该值并不是防止RabbitMQ服务器使用超过40%的内存，它仅仅只是指明生产者(publishers)会进行节流（流量控制） 所以，如果你在引起内存报警的时候尝试发送消息，在进行发送期间就会被阻塞了。 如果你想阻塞所有的发送者，你可以将该参数 vm_memory_high_watermark 设置为0. 如果你想禁止基于内存的流量控制，你可以将该参数vm_memory_high_watermark 设置为100。 rabbitmq memory vm_memory_limit这个值，默认就是 vm_memory_high_watermark * installed memory（如果设置的是百分比参数的话） 可使用内存上限。注意，如果 vm_memory_high_watermark 生效的话，那MQ是有可能超过这个值的（上下波动） 如果 vm_memory_high_watermark 设置的是绝对值的话，那vm_memory_limit = vm_memory_high_watermark。 流量控制当达到内存阀值的时候（无论设置的是百分比，还是绝对值），RabbitMQ就会触发流量控制。即publishers会全部阻塞，直到解除报警才会恢复正常的publishers服务。 注意因为RabbitMQ提供两种协议HTTP和AMQP。这个流量控制，只是对AMQP生效的。对HTPP协议发送的消息并不会进行流量控制。所以，rabbitmq使用的总内存会超过vm_memory_limit也就不奇怪了。 例子测试环境: 1234567891011┌─[sky@sky-linux] - [/ihome/rabbitmq/rabbitmq_server-3.6.1] - [2016-12-01 03:21:31]└─[0] &lt;&gt; free -m total used free shared buffers cachedMem: 15920 13144 2775 1038 608 5794-/+ buffers/cache: 6741 9178Swap: 0 0 0┌─[sky@sky-linux] - [/ihome/rabbitmq/rabbitmq_server-3.6.1] - [2016-12-01 03:22:16]└─[0] &lt;&gt; uname -aLinux sky-linux 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux┌─[sky@sky-linux] - [/ihome/rabbitmq/rabbitmq_server-3.6.1] - [2016-12-01 03:22:34]└─[0] &lt;&gt; 默认情况下的内存1234./sbin/rabbitmqctl status &#123;vm_memory_high_watermark,0.4&#125;, &#123;vm_memory_limit,6677449932&#125;, 1215920 * 0.4 = 6368.0 MB6677449932 / 1024 / 1024 = 6368 MB 修改 vm_memory_high_watermark修改为 0.8 看看效果: 123456789─[sky@sky-linux] - [/ihome/rabbitmq/rabbitmq_server-3.6.1] - [2016-12-01 03:22:34]└─[0] &lt;&gt; ./sbin/rabbitmqctl set_vm_memory_high_watermark 0.8Setting memory threshold on 'rabbit@sky-linux' to 0.8 ...┌─[sky@sky-linux] - [/ihome/rabbitmq/rabbitmq_server-3.6.1] - [2016-12-01 03:25:30]└─[0] &lt;&gt; ./sbin/rabbitmqctl status ... &#123;vm_memory_high_watermark,0.8&#125;, &#123;vm_memory_limit,13354899865&#125;,... 1215920 * 0.8 = 12736 MB13354899865 / 1024 / 1024 = 12736 MB 可知，vm_memory_high_watermark 修改后，vm_memory_limit 也会随之改变. 修改 vm_memory_high_watermark 为绝对值12345678910┌─[sky@sky-linux] - [/ihome/rabbitmq/rabbitmq_server-3.6.1] - [2016-12-01 03:38:10]└─[64] &lt;&gt; ./sbin/rabbitmqctl set_vm_memory_high_watermark absolute 10MBSetting memory threshold on 'rabbit@sky-linux' to 10000000 bytes ...┌─[sky@sky-linux] - [/ihome/rabbitmq/rabbitmq_server-3.6.1] - [2016-12-01 03:38:38]└─[0] &lt;&gt; ./sbin/rabbitmqctl status ...&#123;vm_memory_high_watermark,&#123;absolute,10000000&#125;&#125;, &#123;vm_memory_limit,10000000&#125;,... 可以看到，它们的值是相等的.]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ的crash dump文件分析]]></title>
    <url>%2F2016%2F12%2F01%2FRabbitMQ%E7%9A%84crash%20dump%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[原因今天一早来到公司，同事说客户反馈生产上的系统数据没有进来了。所以，就排查了下问题才行。 最直接的，先看Tomcat的日志，可以发现到: 123456789Dec 01, 2016 11:01:31 AM org.apache.catalina.core.StandardWrapperValve invokeSEVERE: Servlet.service() for servlet [ROOT] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.amqp.AmqpConnectException: java.net.ConnectException: Connection refused] with root causejava.net.ConnectException: Connection refused at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:579) 无语，又是RabbitMQ连接不上。 分析crash文件进入到RabbitMQ，看到有个文件在安装目录下: 12345678910111213141516-rw-r----- 1 xxx xxx 30908860 Dec 1 09:29 erl_crash.dump``` 然后接下来就是分析这个crash日志文件了。### 分析工具:[github recon erl_crashdump_analyzer](https://github.com/ferd/recon/blob/master/script/erl_crashdump_analyzer.sh)### 分析直接执行如何命令即可:```bash./erl_crashdump_analyzer.sh erl_crash.dump` 输出样本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859analyzing erl_crash.dump-2016-12-1, generated on: Thu Dec 1 09:28:44 2016 Slogan: eheap_alloc: Cannot allocate 169124672 bytes of memory (of type "heap").Memory:=== processes: 362 Mb processes_used: 362 Mb system: 181 Mb atom: 0 Mb atom_used: 0 Mb binary: 70 Mb code: 18 Mb ets: 83 Mb --- total: 544 MbDifferent message queue lengths (5 largest different):=== 1 1 367 0Error logger queue length:===0File descriptors open:=== UDP: 0 TCP: 10 Files: 77 --- Total: 87Number of processes:===368Processes Heap+Stack memory sizes (words) used in the VM (5 largest different):=== 1 24722235 1 7582861 2 2072833 1 1727361 2 833026Processes OldHeap memory sizes (words) used in the VM (5 largest different):=== 1 28690 1 10958 1 6772 3 4185 3 2586Process States when crashing (sum): === 1 Garbing 1 Scheduled 366 Waiting 导致RabbitMQ crash的原因就在 Slogan 这一行里：比如这里，就是因为 Cannot allocate 169124672 bytes of memory (of type &quot;heap&quot;). （在堆上分配不到 169124672 bytes 的内存导致崩溃） 内存列说明123456789total：当前分配给进程 processes 和系统 system 的内存总量processes：当前分配给 Erlang 进程的内存总量processes_used：当前已被 Erlang 进程使用的内存总量（进程内存的一部分）system：当前分配给 Erlang 虚拟机，不过没有被 Erlang 进程占用的内存总量。atom：当前分配给原子的内存总量（系统进程的一部分）atom_used：当前已被 原子使用的内存总量（系统进程的一部分）binary：当前分配给二进制数据的内存总量（系统进程的一部分）code：当前代码数据所占用的内存总量（系统进程的一部分）ets：当前分配给 ETS 表的内存总量（系统进程的一部分） 参考资料atombinarybinary 所有列详解 解决添加swap分区发现生产上的系统，根本没有swap分区。如果允许的话，可以添加一个swap分区来进行内存交换到磁盘的缓冲（这个会导致性能下降） 增大内存因为是使用阿里云，所以，可以动态扩展机器性能 优化程序尽可能不让MQ堆积太多数据，应该及时处理好出入队的速率]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 中的接口类型与指针]]></title>
    <url>%2F2016%2F11%2F24%2FGolang%20%E4%B8%AD%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[这是在Google Golang的Nuts上看到的golang-nuts 当作为interface类型调用时，指针值没有更新？12345678910func f(resp interface&#123;&#125;) &#123; resp = "abcd"&#125;func main() &#123; var s string f(&amp;s) fmt.Println(s) //prints blank?&#125; interface只是一个值，想要间接成指针，可以如下处理: 123456789101112131415package mainimport ( "fmt")func f(resp interface&#123;&#125;) &#123; *resp.(*string) = "abcd"&#125;func main() &#123; var s string f(&amp;s) fmt.Println(s)&#125; resp.(*string)：转换为string指针*resp.(*string)：这个表示指针的内容*resp.(*string) = &quot;abcd&quot;：将abcd的值赋给指针的内容.]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 归并排序MergeSort]]></title>
    <url>%2F2016%2F11%2F22%2FGolang%20%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8FMergeSort%2F</url>
    <content type="text"><![CDATA[思路将一排数据，进行左右不断地进行划分（递[归]），然后再对比左右两边的数据后再(合[并])，这就是”归并排序“。 注意：[左右]对比，是指左的第一个元素，与右边的第一个元素进行对比，哪个小，就先放到结果的第一位，然后左或右取出了元素的那边的索引进行++，没有取出的元素的，则不用进行++。比较完后，还要分别将左，右的剩余的元素，追加到结果列的后面。 归并排序(MergeSort)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mainimport "fmt"import "time"import number "github.com/emacsist/go-common/helper/number"func main() &#123; data := number.GenerateInt(100000, 100000) start := makeTimestamp() // fmt.Printf("%v\n", data) data = mergeSort(data) fmt.Printf("cost %v ms \n", makeTimestamp()-start) // fmt.Printf("%v\n", data)&#125;//------------------------------------------------------------------------------func makeTimestamp() int64 &#123; return time.Now().UnixNano() / int64(time.Millisecond)&#125;func mergeSort(data []int) []int &#123; if len(data) &lt;= 1 &#123; return data &#125; //递[归] middle := len(data) / 2 //不断地进行左右对半划分 left := mergeSort(data[:middle]) right := mergeSort(data[middle:]) //合[并] return merge(left, right)&#125;func merge(left, right []int) (result []int) &#123; l, r := 0, 0 // 注意：[左右]对比，是指左的第一个元素，与右边的第一个元素进行对比，哪个小，就先放到结果的第一位，然后左或右取出了元素的那边的索引进行++ for l &lt; len(left) &amp;&amp; r &lt; len(right) &#123; //从小到大排序. if left[l] &gt; right[r] &#123; result = append(result, right[r]) //因为处理了右边的第r个元素，所以r的指针要向前移动一个单位 r++ &#125; else &#123; result = append(result, left[l]) //因为处理了左边的第r个元素，所以r的指针要向前移动一个单位 l++ &#125; &#125; // 比较完后，还要分别将左，右的剩余的元素，追加到结果列的后面(不然就漏咯）。 result = append(result, left[l:]...) result = append(result, right[r:]...) return&#125;]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 快速排序]]></title>
    <url>%2F2016%2F11%2F21%2FGolang%20%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[思路12345678910111213141516171819202122232425262728293031323334data = [3 2 6 1 2 7]middle = 3? 2 6 1 2 7//第一轮:// data[i] = 2// middle = 3if data[i] &lt; middle &#123; //则与头指针进行交换 //然后 i++ //头指针也 ++ //即头指针一直指向那个 ？的值.&#125; 第二轮时data[i] = 6head = 1此时就会进入 else 那个分支了：将它从尾开始交换后变成：2 ? 7 1 2 6变化：head 不变：因为头是在?那里，位置 没有交换过，则不用改变i 不变： 因为它与尾的值交换了，但原来的那个尾的值还没有比较，所以，还是从 i 的位置开始比较tail -- ： 因为尾那里已经将元素交换过去了，那个元素就不用再进行比较了第一次完成后，进行递归，递归前，要将原来的 miidle 的值保存到 ? 的位置(data[head])然后开始递归 快速排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package mainimport "helper/number"import "helper/time"import "fmt"func main() &#123; //待排序的数据 data := number.GenerateInt(29, 1000) fmt.Printf("before %v\n", data) start := time.CurrentMillis() quitSort(data) fmt.Printf("after %v\n", data) fmt.Printf("quitSort %v ms", time.CurrentMillis()-start)&#125;func quitSort(data []int) &#123; if len(data) &lt;= 1 &#123; return &#125; //假设第一个元素为 0，并且假设为"中值" middleValue := data[0] //这个是索引值了，不是表示大小了, 头尾指针 head, tail := 0, len(data)-1 // i := 1 for head &lt; tail &#123; //如果下一个元素，比中值小，那从头开始交换位置 if data[i] &lt; middleValue &#123; data[head], data[i] = data[i], data[head] //因为已经交换了，头指针向前移动一个 head++ //则进行下一个元素比较 i++ &#125; else &#123; //这个表示下一个元素比中值大，则从 尾开始交换 data[tail], data[i] = data[i], data[tail] tail-- &#125; &#125; data[head] = middleValue quitSort(data[:head]) quitSort(data[head+1:])&#125;]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java报 Exception in thread main java.lang.IllegalArgumentException: Comparison method violates its general contract]]></title>
    <url>%2F2016%2F11%2F21%2FJava%E6%8A%A5%20Exception%20in%20thread%20main%20java.lang.IllegalArgumentException%3A%20Comparison%20method%20violates%20its%20general%20contract%2F</url>
    <content type="text"><![CDATA[问题12345678910111213141516171819202122232425262728293031323334353637Nov 21, 2016 11:46:25 AM org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer invokeErrorHandlerWARNING: Execution of Rabbit message listener failed, and no ErrorHandler has been set.org.springframework.amqp.rabbit.listener.ListenerExecutionFailedException: Listener method 'dequeue' threw exception at org.springframework.amqp.rabbit.listener.adapter.MessageListenerAdapter.invokeListenerMethod(MessageListenerAdapter.java:443) at org.springframework.amqp.rabbit.listener.adapter.MessageListenerAdapter.onMessage(MessageListenerAdapter.java:344) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:546) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:472) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$001(SimpleMessageListenerContainer.java:58) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$1.invokeListener(SimpleMessageListenerContainer.java:107) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.invokeListener(SimpleMessageListenerContainer.java:608) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:454) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:471) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:455) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$300(SimpleMessageListenerContainer.java:58) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:548) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: Comparison method violates its general contract! at java.util.TimSort.mergeLo(TimSort.java:747) at java.util.TimSort.mergeAt(TimSort.java:483) at java.util.TimSort.mergeCollapse(TimSort.java:410) at java.util.TimSort.sort(TimSort.java:214) at java.util.TimSort.sort(TimSort.java:173) at java.util.Arrays.sort(Arrays.java:659) at java.util.Collections.sort(Collections.java:217) at com.uniweibov2.callcenter.assign.engine.impl.CcLastAssignTimePriorityAssignEngine.priorityAssign(CcLastAssignTimePriorityAssignEngine.java:44) at com.uniweibov2.callcenter.CcAssignEngine.assignCommon(CcAssignEngine.java:119) at com.uniweibov2.callcenter.CcAssignEngine.assign(CcAssignEngine.java:83) at com.uniweibov2.callcenter.service.CcRouterService.newSessionRedisWithDequeue(CcRouterService.java:163) at com.uniweibov2.callcenter.CcRouter.dequeueSessionMsg(CcRouter.java:238) at com.uniweibov2.callcenter.mq.listener.CCSessionMsgListener.manualDequeue(CCSessionMsgListener.java:107) at com.uniweibov2.callcenter.mq.listener.CCSessionMsgListener.dequeue(CCSessionMsgListener.java:135) at sun.reflect.GeneratedMethodAccessor123.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.util.MethodInvoker.invoke(MethodInvoker.java:273) at org.springframework.amqp.rabbit.listener.adapter.MessageListenerAdapter.invokeListenerMethod(MessageListenerAdapter.java:437) ... 12 more 有问题的Java代码12345678private static class CcLastAssignTimeComparator implements Comparator&lt;CCUserConfig&gt;, Serializable &#123; @Override public int compare(CCUserConfig o1, CCUserConfig o2) &#123; long redisSizeA = o1.getLastAssignTime(); long redisSizeB = o2.getLastAssignTime(); return (int) (redisSizeA - redisSizeB); &#125;&#125; 原因这自己写的代码，也太挫了。在公司有同事指出：强制将long转换为int，导致溢出。从而不满足比较器的传递性。这个异常，是在JDK1.7及之后的版本才会抛出的. 同事的原话: 举个例子，无溢出情况下，a &gt; b return positive, b &gt; c return positive, 但当a - c 溢出了，a &gt; c return negative 重现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.github.emacsist;import java.util.*;/** * Hello world! */public class App &#123; public static void main(String[] args) &#123; Random r = new Random(System.currentTimeMillis()); int n = 800; List&lt;Person&gt; l = new ArrayList&lt;&gt;(n); for (int i = 0; i &lt; n; i++) &#123; Person p = new Person(); if (i % 11 == 0) &#123; p.setAge(System.currentTimeMillis()+Integer.MAX_VALUE); &#125; else &#123; p.setAge(System.currentTimeMillis()-10 * r.nextInt(10)); &#125; l.add(p); &#125; System.out.println("befor " + l); Collections.sort(l, new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; return (int)(o1.getAge()-o2.getAge()); &#125; &#125;); System.out.println("after " + l); &#125; public static class Person &#123; private long age; public long getAge() &#123; return age; &#125; public void setAge(long age) &#123; this.age = age; &#125; @Override public String toString() &#123; return String.valueOf(getAge()); &#125; &#125;&#125; 输出结果：（如果没有出现，那就执行多几次即可） 12345678910111213141516Exception in thread "main" java.lang.IllegalArgumentException: Comparison method violates its general contract! at java.util.TimSort.mergeHi(TimSort.java:899) at java.util.TimSort.mergeAt(TimSort.java:516) at java.util.TimSort.mergeCollapse(TimSort.java:441) at java.util.TimSort.sort(TimSort.java:245) at java.util.Arrays.sort(Arrays.java:1512) at java.util.ArrayList.sort(ArrayList.java:1454) at java.util.Collections.sort(Collections.java:175) at com.github.emacsist.App.main(App.java:23) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)Process finished with exit code 1 解决123456789101112131415161718192021222324// ASC Collections.sort(l, new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; if(o1 == null &amp;&amp; o2 == null) &#123; return 0; &#125; //这个根据自己的情况，null到底是在最前，还是最后 if(o1 == null) &#123; return -1; &#125; if(o2 == null) &#123; return 1; &#125; if(o1.getAge() &gt; o2.getAge()) &#123; return 1; &#125; if(o2.getAge() &gt; o1.getAge()) &#123; return -1; &#125; return 0; &#125; &#125;); 注意 最好习惯返回1,0,-1 如果不这样子，两个数在进行比较时，须保证是无损失精度的比较。（如果是浮点数，最好使用 Double.compare() 之类的方法来比较） 在JDK1.7及之后版本里，必须要保证如果它们是两等的话，那应该要返回0.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>compare</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 希尔排序 VS 插入排序]]></title>
    <url>%2F2016%2F11%2F20%2FGolang%20%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%20VS%20%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[希尔排序 VS 插入排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport ( "fmt" "helper/number" "helper/time")func main() &#123; data := number.GenerateInt(100000, 1000) dataCopy := make([]int, len(data)) copy(dataCopy, data) start := time.CurrentMillis() // fmt.Printf("insert sort: before data = %v\n", data) insertSort(data) // fmt.Printf("insert sort: after data = %v\n", data) fmt.Printf("insert cost %v ms\n", time.CurrentMillis()-start) start = time.CurrentMillis() // fmt.Printf("shell sort: before data = %v\n", dataCopy) shellSort(dataCopy) // fmt.Printf("shell sort: after data = %v\n", dataCopy) fmt.Printf("shell sort cost %v ms\n", time.CurrentMillis()-start)&#125;func shellSort(data []int) &#123; //一共有多少列: 4 -&gt; 2 -&gt; 1 for col := len(data) / 2; col &gt;= 1; col = col / 2 &#123; //对每一列处理 0 -&gt; col（即每一次循环，就是处理该列的排序） for i := 0; i &lt; col; i++ &#123; //从每一列的第二个数开始进行插入排序（因为只有 &gt;= 2 个元素时，才有可比性） n := 1 //i + col * n 表示该列的下一个元素的位置 , 它要 &lt; len(data) for i+col*n &lt; len(data) &#123; //保存当前元素的位置（因为它要不断地与位置比它小的进行交换（即插入排序） k := i + col*n for k &gt;= 0 &amp;&amp; (k-col) &gt;= 0 &#123; //不断地与前一个元素进行比较（直到 前一个元素 &gt;= 即可停止）这里是开始排序 if data[k] &lt; data[k-col] &#123; data[k], data[k-col] = data[k-col], data[k] k = k - col &#125; else &#123; break &#125; &#125; //该列的下一个元素 n++ &#125; &#125; &#125;&#125;func insertSort(data []int) &#123; //从第二个元素开始排序，第一个为 i = 0 for i := 1; i &lt; len(data); i++ &#123; //保存当前位置的一个副本，因为它要不断地减小，（因为要不断地缩小并比较之前的数据，以便进行交换） currentIndex := i //不断与前一个相比较 for currentIndex-1 &gt;= 0 &#123; //符合条件则交换 if data[currentIndex] &lt; data[currentIndex-1] &#123; data[currentIndex], data[currentIndex-1] = data[currentIndex-1], data[currentIndex] currentIndex-- &#125; else &#123; break &#125; &#125; &#125;&#125; 性能比较: 1234567[23:04:37] emacsist:test4 $ go build insert_sort_vs.go &amp;&amp; ./insert_sort_vsinsert cost 5295 msshell sort cost 22 ms[23:09:15] emacsist:test4 $ go build insert_sort_vs.go &amp;&amp; ./insert_sort_vsinsert cost 5220 msshell sort cost 17 ms[23:09:23] emacsist:test4 $]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 希尔排序]]></title>
    <url>%2F2016%2F11%2F20%2FGolang%20%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[希尔排序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( "fmt" "helper/number" "helper/time")func main() &#123; data := number.GenerateInt(100000, 100) start := time.CurrentMillis() shellSort(data) fmt.Printf("cost %v ms\n", time.CurrentMillis()-start)&#125;func shellSort(data []int) &#123; //一共有多少列: 4 -&gt; 2 -&gt; 1 for col := len(data) / 2; col &gt;= 1; col = col / 2 &#123; //对每一列处理 0 -&gt; col（即每一次循环，就是处理该列的排序） for i := 0; i &lt; col; i++ &#123; //从每一列的第二个数开始进行插入排序（因为只有 &gt;= 2 个元素时，才有可比性） n := 1 //i + col * n 表示该列的下一个元素的位置 , 它要 &lt; len(data) for i+col*n &lt; len(data) &#123; //保存当前元素的位置（因为它要不断地与位置比它小的进行交换（即插入排序） k := i + col*n for k &gt;= 0 &amp;&amp; (k-col) &gt;= 0 &#123; //不断地与前一个元素进行比较（直到 前一个元素 &gt;= 即可停止）这里是开始排序 if data[k] &lt; data[k-col] &#123; data[k], data[k-col] = data[k-col], data[k] k = k - col &#125; else &#123; break &#125; &#125; //该列的下一个元素 n++ &#125; &#125; &#125;&#125; 性能1234567[22:34:42] emacsist:test3 $ go build main.go &amp;&amp; time ./maincost 11 ms./main 0.02s user 0.01s system 83% cpu 0.029 total[22:39:18] emacsist:test3 $ go build main.go &amp;&amp; time ./maincost 12 ms./main 0.02s user 0.01s system 95% cpu 0.024 total[22:39:56] emacsist:test3 $]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 插入排序]]></title>
    <url>%2F2016%2F11%2F18%2FGolang%20%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[插入排序 – 初版 这个版本的思想是：先找出要交换的两个位置的 index ， 然后再统一移动位置. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( "fmt" "math/rand" "time")func main() &#123; var data []int rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 50; i++ &#123; data = append(data, rand.Intn(100)) &#125; fmt.Printf("%v\n", data) insertSort(data)&#125;func insertSort(data []int) &#123; if len(data) &lt;= 1 &#123; return &#125; //sortIndex := 1 for i := 1; i &lt; len(data); i++ &#123; startIndex := findPosition(data, i) if startIndex &gt;= 0 &#123; moveRights(data, i, startIndex) fmt.Printf("after %v times. data = %v, startIndex = %v\n", i, data, startIndex) &#125; &#125; fmt.Printf("%v\n", data)&#125;func findPosition(data []int, sortIndex int) (startIndex int) &#123; startIndex = -1 sortEle := data[sortIndex] if sortIndex &gt;= 1 &#123; startIndex = sortIndex - 1 for startIndex &gt;= 0 &#123; preEle := data[startIndex] if startIndex &gt;= 1 &#123; prePreEle := data[startIndex-1] if sortEle &lt;= preEle &amp;&amp; sortEle &gt;= prePreEle &#123; return &#125; &#125; else &#123; if sortEle &lt;= preEle &#123; return &#125; &#125; startIndex-- &#125; &#125; return&#125;// 从小到大，那就是向右移动func moveRights(data []int, sortIndex int, startIndex int) &#123; if sortIndex &gt; startIndex &#123; tmp := data[sortIndex] n := sortIndex - startIndex for n &gt; 0 &amp;&amp; sortIndex &gt; 0 &#123; data[sortIndex] = data[sortIndex-1] sortIndex-- n-- &#125; data[startIndex] = tmp &#125;&#125; 插入排序 – 改进版 这个版本的思想是：不断的对比，然后不断地立马交换位置。而不是像初版那样，先不断地对比，然后找出两个位置 ，最后再统一移动。 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( "fmt" "helper/number" "helper/time")func main() &#123; data := number.GenerateInt(15, 1000) //fmt.Printf("before data = %v\n", data) start := time.CurrentMillis() insertSort(data) fmt.Printf("cost %v ms\n", time.CurrentMillis()-start) //fmt.Printf("after data = %v\n", data)&#125;func insertSort(data []int) &#123; //从第二个元素开始排序，第一个为 i = 0 for i := 1; i &lt; len(data); i++ &#123; //保存当前位置的一个副本，因为它要不断地减小，（因为要不断地缩小并比较之前的数据，以便进行交换） currentIndex := i //不断与前一个相比较 for currentIndex-1 &gt;= 0 &#123; //符合条件则交换 if data[currentIndex] &lt; data[currentIndex-1] &#123; data[currentIndex], data[currentIndex-1] = data[currentIndex-1], data[currentIndex] currentIndex-- &#125; else &#123; break &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 堆排序与选择排序]]></title>
    <url>%2F2016%2F11%2F17%2FGolang%20%E5%A0%86%E6%8E%92%E5%BA%8F%E4%B8%8E%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[选择排序select.go，这里以选择最小的为例子 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport "fmt"import "math/rand"func main() &#123; var data []int for i := 0; i &lt; 10000000; i++ &#123; data = append(data, rand.Int()) &#125; //fmt.Printf("%v\n", data) selectSort(data) fmt.Printf("%v\n", len(data))&#125;func selectSort(data []int) &#123; swapIndex := 0 for i := 0; i &lt; len(data); i++ &#123; index, _ := min(data, swapIndex) //fmt.Printf("min index = %v, i = %v\n", index, i) swap(data, swapIndex, index) swapIndex++ &#125;&#125;func swap(data []int, src int, dest int) &#123; data[src], data[dest] = data[dest], data[src] //fmt.Printf("after swap =&gt; %v\n", data)&#125;func min(data []int, startIndex int) (index int, d int) &#123; d = data[startIndex] index = startIndex for i := startIndex + 1; i &lt; len(data); i++ &#123; next := data[i] if next &lt; d &#123; d = next index = i &#125; &#125; return&#125; 堆排序heapSort.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport "math/rand"import "fmt"func main() &#123; var data []int for i := 0; i &lt; 25; i++ &#123; data = append(data, rand.Intn(100)) &#125; HeapSort(data) fmt.Printf("final value = %v\n", data)&#125;// HeapSort : 堆排序func HeapSort(data []int) &#123; if len(data) &lt;= 1 &#123; return &#125; maxIndex := len(data) - 1 buildAllMaxHeap(data) for i := len(data) - 1; i &gt;= 0; i-- &#123; data[0], data[maxIndex] = data[maxIndex], data[0] localMaxHeap(data[:maxIndex], 0) maxIndex-- &#125;&#125;//全局创建最大堆func buildAllMaxHeap(data []int) &#123; //从最后一颗树的根节点开始处理 for i := (len(data) - 1) / 2; i &gt;= 0; i-- &#123; localMaxHeap(data, i) &#125;&#125;//每一颗小树中，要保持最大堆func localMaxHeap(data []int, root int) &#123; left := getLeft(root) right := getRight(root) biggest := root if left &lt; len(data) &amp;&amp; data[left] &gt; data[biggest] &#123; biggest = left &#125; if right &lt; len(data) &amp;&amp; data[right] &gt; data[biggest] &#123; biggest = right &#125; if biggest != root &#123; data[root], data[biggest] = data[biggest], data[root] localMaxHeap(data, biggest) &#125;&#125;// 获取元素的左节点func getLeft(index int) int &#123; left := 2*index + 1 return left&#125;// 获取元素的右节点func getRight(index int) int &#123; right := 2 * (index + 1) return right&#125;// 获取元素的父节点func getParentIndex(index int) int &#123; if index == 0 &#123; return index &#125; if index%2 == 0 &#123; return index/2 - 1 &#125; return index / 2&#125; 参考资料liuyu314.github.io]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 中等待Goroutines 执行完毕]]></title>
    <url>%2F2016%2F11%2F13%2FGolang%20%E4%B8%AD%E7%AD%89%E5%BE%85Goroutines%20%E6%89%A7%E8%A1%8C%E5%AE%8C%E6%AF%95%2F</url>
    <content type="text"><![CDATA[方式一使用 sync.WaitGroup 12345678910111213141516171819202122232425package mainimport ( "fmt" "math/rand" "strconv" "sync" "time")func main() &#123; workerNum := 10 var wg sync.WaitGroup wg.Add(workerNum) for i := 0; i &lt; workerNum; i++ &#123; go worker(i, "Name"+strconv.FormatInt(int64(i), 10), &amp;wg) &#125; wg.Wait()&#125;func worker(id int, hello string, wg *sync.WaitGroup) &#123; time.Sleep(time.Second * time.Duration(rand.Int31n(10))) fmt.Printf("workerID = %v, Hello %v\n", id, hello) wg.Done()&#125; 输出的结果: 12345678910111213[Running] go run "/Users/emacsist/go-project/src/main.go"workerID = 5, Hello Name5workerID = 8, Hello Name8workerID = 1, Hello Name1workerID = 2, Hello Name2workerID = 4, Hello Name4workerID = 7, Hello Name7workerID = 0, Hello Name0workerID = 3, Hello Name3workerID = 6, Hello Name6workerID = 9, Hello Name9[Done] exited with code=0 in 9.214 seconds 方法二12345678910111213141516171819202122232425package mainimport ( "fmt" "math/rand" "strconv" "time")func main() &#123; workerNum := 10 result := make(chan int, workerNum) for i := 0; i &lt; workerNum; i++ &#123; go worker(i, "Name"+strconv.FormatInt(int64(i), 10), result) &#125; for i := 0; i &lt; workerNum; i++ &#123; fmt.Printf("workerID = %v is finished.\n", &lt;-result) &#125;&#125;func worker(id int, hello string, result chan int) &#123; time.Sleep(time.Second * time.Duration(rand.Int31n(10))) fmt.Printf("workerID = %v, Hello %v\n", id, hello) result &lt;- id&#125; 输出的结果类似如下: 1234567891011121314151617181920212223[Running] go run "/Users/emacsist/go-project/src/main.go"workerID = 4, Hello Name4workerID = 4 is finished.workerID = 5, Hello Name5workerID = 5 is finished.workerID = 1, Hello Name1workerID = 0, Hello Name0workerID = 1 is finished.workerID = 0 is finished.workerID = 7, Hello Name7workerID = 7 is finished.workerID = 8, Hello Name8workerID = 8 is finished.workerID = 3, Hello Name3workerID = 9, Hello Name9workerID = 3 is finished.workerID = 9 is finished.workerID = 6, Hello Name6workerID = 6 is finished.workerID = 2, Hello Name2workerID = 2 is finished.[Done] exited with code=0 in 9.251 seconds]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hugo 自动化部署到 Github Pages]]></title>
    <url>%2F2016%2F11%2F13%2FHugo%20%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E5%88%B0%20Github%20Pages%2F</url>
    <content type="text"><![CDATA[脚本由于将博客从 Hexo 迁移到了 Hugo ， 没有发现好的自动化部署方法，查资料用的什么 Hook 等机制这些又觉得太麻烦。所以，自己动手写了个自动化部署的脚本，从博客内容自动化部署到 Github Pages 和 Coding Pages 上： 前提：创建一个静态博客的目录，这里假设为/Users/emacsist/public-blog, 用 Hugo 生成的站点目录，这里假设为:/Users/emacsist/git/hugo-blog 然后在你的public-blog上，添加两个远程分支：（自行修改为自己对应的分支路径） 12345#Githubgit remote add origin http://github.com/emacsist/emacsist.github.io#Codinggit remote add coding http://xxxxx 脚本内容： 1234567891011121314151617181920#!/bin/bashSITE_SOURCE="/Users/emacsist/git/hugo-blog"PUBLIC_DIR="/Users/emacsist/public-blog"cd "$&#123;SITE_SOURCE&#125;"rm -rf "$&#123;SITE_SOURCE&#125;/"public/*# 将 vec 修改为你的主题名hugo -t vec || exit 1rm -rf "$&#123;PUBLIC_DIR&#125;/"* &amp;&amp; cp -R "$&#123;SITE_SOURCE&#125;/public/"* "$&#123;PUBLIC_DIR&#125;/"cd "$&#123;PUBLIC_DIR&#125;"git add .git commit -m 'update blog files'git push origin master --forcegit push coding master --force 效果123456789101112131415161718192021222324252627282930313233343536[18:24:23] emacsist:hugo-blog git:(master) $ ./deploy.sh Started building sites ...Built site for language en:0 draft content0 future content0 expired content271 pages created0 non-page files copied220 paginator pages created132 tags created49 categories createdtotal in 562 ms[master 72b4092] update blog files 32 files changed, 923 insertions(+), 580 deletions(-) create mode 100644 2016/11/13/Github-上发起-Pull-request/index.html create mode 100644 img/first-git-pull-request.png create mode 100644 tags/pull-request/index.html create mode 100644 tags/pull-request/index.xml create mode 100644 tags/pull-request/page/1/index.htmlUsername for 'https://github.com': xxxPassword for 'xxx': Counting objects: 65, done.Delta compression using up to 4 threads.Compressing objects: 100% (47/47), done.Writing objects: 100% (65/65), 277.14 KiB | 0 bytes/s, done.Total 65 (delta 34), reused 0 (delta 0)remote: Resolving deltas: 100% (34/34), completed with 28 local objects.To xxxx a298898..72b4092 master -&gt; masterCounting objects: 65, done.Delta compression using up to 4 threads.Compressing objects: 100% (47/47), done.Writing objects: 100% (65/65), 277.14 KiB | 0 bytes/s, done.Total 65 (delta 34), reused 0 (delta 0)To xxxx a298898..72b4092 master -&gt; master 之前用 Hexo，每次部署一下，都要成分钟。现在 1 秒钟都不用了，飞一般的感觉。Enjoy it ！]]></content>
      <categories>
        <category>hugo</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hugo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github 上发起 Pull request]]></title>
    <url>%2F2016%2F11%2F13%2FGithub%20%E4%B8%8A%E5%8F%91%E8%B5%B7%20Pull%20request%2F</url>
    <content type="text"><![CDATA[第一次在 Github 上发起 Pull request 是因为在将博客从 Hexo 迁移到 Hugo 的时候，遇到一个问题： 用 Hugo 命令将原先的 Hexo 的博客的源文件，用 Hugo 命令来生成的时候，报个如下的错误: page.go:750: Failed to parse date &#39;2016-03-06 15:28:01&#39; in page xxxxxx.md. 为了方便迁移，所以看了下 Hugo 的相关源码，发现它调用了cast库的转换代码，如下： 1234567891011121314151617181920// StringToDate casts an empty interface to a time.Time.func StringToDate(s string) (time.Time, error) &#123; return parseDateWith(s, []string&#123; time.RFC3339, "2006-01-02T15:04:05", // iso8601 without timezone time.RFC1123Z, time.RFC1123, time.RFC822Z, time.RFC822, time.ANSIC, time.UnixDate, time.RubyDate, "2006-01-02 15:04:05Z07:00", "02 Jan 06 15:04 MST", "2006-01-02", "02 Jan 2006", "2006-01-02 15:04:05 -07:00", "2006-01-02 15:04:05 -0700", &#125;)&#125; 可以看到，这些格式，都与 Hexo 默认的日期的格式不一样，Hexo 的是yyyy-MM-dd HH:mm:ss，所以，为了将种格式的字符串转换为 Hugo 所能理解的日期的格式，就必须要添加这种格式的字符串让 Golang 解析。 当时想着，可以发起一个 Pull request, 看看能不能加入自己添加这个格式日期的 layout，这样子，就不用自己维护了，也方便其他将 Hexo 迁移到 Hugo 又不想自己修改源码来迁移的朋友了。这就开始了我的 Github 上第一次 Pull requst。（虽然改动的非常小，就添加一行代码，其实我也不太清楚为什么当时没有添加这种日期的格式上去，但是测式代码还是要提供的） Pull request 使用Fork要发起 Pull request，首先第一步去 Fork 你想修改的开源项目。 修改源码fork 完之后，你就可以在自己的代码仓库上, checkout 这个项目代码下来本地进行修改了。 创建一个新的分支，比如叫feature-xxxx（添加功能)，或者fix-xxx（修bug)等。 进行修改代码 查看本地的 git 配置的用户名和邮箱是否与 github 上的一致 这一步非常重要，我在发起 Pull request 后，发现要进行CLA签名（就是 Contributors License Agreement，贡献者许可同意证书），如果你的本地的用户名和邮箱，与 github 上的不一致，就会导致这个 CLA 这步通不过。 提交你的内容（代码，注释，文档和测试代码，尽可能详细） 这步也非常重要，最好要说明一下，你修改这段代码的前因后果，都交待以及说明清楚，必要时提供文档和截图。总之尽可能详尽。 push 你的修改后的分支到你的 githhub 远程仓库 发起 pull request登录 github 进入对应的项目上，github 会提醒你，是否要发起一个新的 Pull request。这时确认，然后就可以提交你的 Pull request 了，然后剩下的就等开源项目成员是否Merge 你的代码了。 后记第一次发起 Pull request ，当时是非常激动的，哈哈。我想一个程序员最大的成就感，想必就是得到同行的认可，以及有大量的开发者使用你的项目或调用你的代码了。^_^ Github 上 pull request 的一小步，人生的一大步. 更新 2016-11-16因为第一次提交的时候，本地提交的代码的邮箱及用户名与Github上的账号不一致，所以导致Github上的CLA检查一直不通过。最后，自己在Github上关闭了原来的Pull request, 然后修正了本地的邮箱和用户名再次提交一次Pull request，这时CLA就变成绿色的勾并通过了。 最后，自己第一次的Pull request也被Merge到master分支了。哈哈.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
        <tag>pull request</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang中的select使用]]></title>
    <url>%2F2016%2F11%2F10%2FGolang%E4%B8%AD%E7%9A%84select%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package mainimport ( "fmt" "time" "sync")type resultData struct &#123; Job int Result bool&#125;func main() &#123; n := 10 jobs := make(chan int, n) result := make(chan resultData, n) var wg sync.WaitGroup wg.Add(n) go publishJob(jobs, n) go daemon(jobs, result, &amp;wg) wg.Wait() fmt.Printf("finish %v jobs", n)&#125;func publishJob(jobs chan int, n int) &#123; for i:=0;i&lt;n ;i++&#123; jobs &lt;- i //time.Sleep(time.Duration(i) * time.Millisecond) &#125;&#125;func daemon(jobs chan int, result chan resultData, wg *sync.WaitGroup) &#123; for &#123; select &#123; case j := &lt;- jobs : fmt.Printf("have jobs %v\n", j) r := resultData&#123;Job:j, Result:true&#125; result &lt;- r time.Sleep(time.Millisecond * 3) case r := &lt;- result : fmt.Printf("job = %v, result = %v\n", r.Job, r.Result) wg.Done() default : //fmt.Printf("in default \n") &#125; &#125;&#125; 输出结果如下： 1234567891011121314151617181920212223[Running] go run "/home/sky/go-dsp/src/test2/main.go"have jobs 0job = 0, result = truehave jobs 1have jobs 2have jobs 3job = 1, result = truejob = 2, result = truehave jobs 4have jobs 5have jobs 6job = 3, result = truejob = 4, result = truehave jobs 7job = 5, result = truejob = 6, result = truejob = 7, result = truehave jobs 8have jobs 9job = 8, result = truejob = 9, result = truefinish 10 jobs[Done] exited with code=0 in 0.142 seconds]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang中的copy使用]]></title>
    <url>%2F2016%2F11%2F10%2FGolang%E4%B8%AD%E7%9A%84copy%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[注意copy函数复制的元素个数=min(len(dest), len(src)) 来决定 删除保持有序即后面的元素经，都向前移动一个元素，然后删除最后一个元素即可. 123456789101112131415161718192021package mainimport ( "fmt")func remove(slice []int, i int) []int &#123; // copy(dst, src) // det = slice[i:] 即为 2,3,4,5,6,7,8,9 // src = slice[i+1:] 即为 3,4,5,6,7,8,9 // copy完成为，slice 即为 0,1,3,4,5,6,7,8,9,9, slice[i:]即为 3,4,5,6,7,8,9,9 // 所以 slice[:len(slice)-1] 即为 0,1,3,4,5,6,7,8,9 copy(slice[i:], slice[i+1:]) return slice[:len(slice)-1]&#125;func main() &#123; s := []int&#123;0,1,2,3,4,5,6,7,8,9&#125; s = remove(s, 2) fmt.Println(s)&#125; 输出的结果: 1234[Running] go run "/home/sky/go-dsp/src/test2/main.go"[0 1 3 4 5 6 7 8 9][Done] exited with code=0 in 0.113 seconds 不需要保持有序直接将最后一个元素，赋值给要被删除元素的位置，然后删除最后一个元素即可 12345678910111213141516package mainimport ( "fmt")func remove(slice []int, i int) []int &#123; slice[i] = slice[len(slice)-1] return slice[:len(slice)-1]&#125;func main() &#123; s := []int&#123;0,1,2,3,4,5,6,7,8,9&#125; s = remove(s, 2) fmt.Println(s)&#125; 输出的结果: 1234[Running] go run "/home/sky/go-dsp/src/test2/main.go"[0 1 9 3 4 5 6 7 8][Done] exited with code=0 in 0.096 seconds 参考资料gogl-zh]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下Cannot assign requested address]]></title>
    <url>%2F2016%2F11%2F09%2FUbuntu%E4%B8%8BCannot-assign-requested-address%2F</url>
    <content type="text"><![CDATA[Cannot assign requested address这个表示可以分配的端口范围 1echo "10000 65535" &gt; /proc/sys/net/ipv4/ip_local_port_range 永久生效 123# vim /etc/sysctl.conf net.ipv4.ip_local_ports_range= 10000 65535 sysctl -p aliyun]]></content>
      <categories>
        <category>liinux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang中接口常见用法]]></title>
    <url>%2F2016%2F11%2F06%2FGolang%E4%B8%AD%E6%8E%A5%E5%8F%A3%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Talk is cheap, show me the code ^_^ 123456789101112131415161718192021222324252627282930313233343536373839404142434445package mainimport ( "fmt")// PrintString : test for interfacetype PrintString interface &#123; String() string&#125;// Person : typetype Person struct &#123; Name string&#125;// Animal : typetype Animal struct &#123; Name string&#125;func (p *Person) String() string &#123; toString := "[Person&lt;name:" + p.Name + "&gt;]" return toString&#125;func (a *Animal) String() string &#123; toString := "[Animal&lt;name:" + a.Name + "&gt;]" return toString&#125;// Print : invoke String() from PrintString interfacefunc Print(p interface&#123;&#125;) &#123; if v, ok := p.(PrintString); ok &#123; fmt.Printf("%v\n", v.String()) &#125;&#125;func main() &#123; p := Person&#123;"emacsist"&#125; a := Animal&#123;"cat"&#125; Print(&amp;p) Print(&amp;a)&#125; 输出的结果如下: 12345[Running] go run "/Users/emacsist/go-project/src/main.go"[Person&lt;name:emacsist&gt;][Animal&lt;name:cat&gt;][Done] exited with code=0 in 0.724 seconds]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang VS Java 在DSP系统对比]]></title>
    <url>%2F2016%2F11%2F02%2FGolang-VS-Java-%E5%9C%A8DSP%E7%B3%BB%E7%BB%9F%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[起因最近一段时间在学Golang，突然间想着，将公司现在的DSP的产品（竞价部分的逻辑），翻译为Golang来试一试它们的性能。 测试的环境: 12345678Golang 1.7JDK 1.8Tomcat 7.0以上都是使用默认配置i5 CPU 4核心16 GB内存 下面是AB后的结果Go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758┌─[sky@sky-linux] - [~] - [2016-11-02 12:36:44]└─[0] &lt;&gt; ab -n 10000 -c 100 -p /tmp/post.data -T 'application/x-www-form-urlencoded' http://localhost:9090/dsp/recbidThis is ApacheBench, Version 2.3 &lt;$Revision: 1528965 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking localhost (be patient)Completed 1000 requestsCompleted 2000 requestsCompleted 3000 requestsCompleted 4000 requestsCompleted 5000 requestsCompleted 6000 requestsCompleted 7000 requestsCompleted 8000 requestsCompleted 9000 requestsCompleted 10000 requestsFinished 10000 requestsServer Software: Server Hostname: localhostServer Port: 9090Document Path: /dsp/recbidDocument Length: 786 bytesConcurrency Level: 100Time taken for tests: 3.713 secondsComplete requests: 10000Failed requests: 0Total transferred: 9040000 bytesTotal body sent: 8060000HTML transferred: 7860000 bytesRequests per second: 2693.39 [#/sec] (mean)Time per request: 37.128 [ms] (mean)Time per request: 0.371 [ms] (mean, across all concurrent requests)Transfer rate: 2377.75 [Kbytes/sec] received 2119.99 kb/s sent 4497.74 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.1 0 1Processing: 1 37 27.4 31 425Waiting: 1 37 27.4 31 425Total: 1 37 27.4 31 425Percentage of the requests served within a certain time (ms) 50% 31 66% 39 75% 46 80% 50 90% 61 95% 69 98% 79 99% 92 100% 425 (longest request) Java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758┌─[sky@sky-linux] - [~] - [2016-11-02 11:04:09]└─[0] &lt;&gt; ab -n 10000 -c 100 -p /tmp/post.data -T 'application/x-www-form-urlencoded' http://localhost:8080/dsp/recbidThis is ApacheBench, Version 2.3 &lt;$Revision: 1528965 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking localhost (be patient)Completed 1000 requestsCompleted 2000 requestsCompleted 3000 requestsCompleted 4000 requestsCompleted 5000 requestsCompleted 6000 requestsCompleted 7000 requestsCompleted 8000 requestsCompleted 9000 requestsCompleted 10000 requestsFinished 10000 requestsServer Software: Apache-Coyote/1.1Server Hostname: localhostServer Port: 8080Document Path: /dsp/recbidDocument Length: 810 bytesConcurrency Level: 100Time taken for tests: 1.558 secondsComplete requests: 10000Failed requests: 0Total transferred: 9580000 bytesTotal body sent: 8060000HTML transferred: 8100000 bytesRequests per second: 6419.10 [#/sec] (mean)Time per request: 15.579 [ms] (mean)Time per request: 0.156 [ms] (mean, across all concurrent requests)Transfer rate: 6005.37 [Kbytes/sec] received 5052.53 kb/s sent 11057.90 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.1 0 1Processing: 1 15 21.7 8 319Waiting: 1 15 21.7 8 319Total: 1 15 21.7 8 319Percentage of the requests served within a certain time (ms) 50% 8 66% 11 75% 16 80% 21 90% 37 95% 56 98% 86 99% 105 100% 319 (longest request) 说明这个是平均多次执行后对比的最后结果，按照这些数据来看，Golang还是远远比不上Java的性能。 后记刚开始学Golang时，越发觉得是个好东西，就是感觉很容易上手，语法这些也很容易熟悉。学了半个星期，然后用半个星期将公司的DSP产品翻译为Golang版本。在这过程中，对Golang也渐渐更加了解点。不过，按照目前这情况，Golang的性能，还是比不上Java的。毕竟JVM和JIT的时间都有20多个年头的，这真的不是开玩笑的。Golang未来还是要有很长一段时间要走。 给我最大的感觉，大概就是Golang的非常简洁的语法及丰富的库。写个Web服务，本身并不需要依赖其他第三方库就已经很方便实现了。内置的对JSON的天生支持（encode和decode），非常简单的并发 go function(...)，以及管道的同步。结构体之间的继承以及接口类型+反射，这些都是个很好的东西，相对于纯OO语言来说，这种实现显得更加优雅点。不过，到目前为至，还没有支持泛型，虽然可以通过反射interface{}类型来实现，不过，总觉得这种太挫了。]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang的检查性能工具]]></title>
    <url>%2F2016%2F11%2F02%2FGolang%E7%9A%84%E6%A3%80%E6%9F%A5%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[Go 自带的 pprofWeb程序只要添加如下代码即可： 12345678910package mainimport ( _ "net/http/pprof")func main() &#123; &#125; 这样子添加后，就可以在 http://127.0.0.1:8080/debug/pprof (假设是监听在8080端口)查看性能数据了. 生成数据这个是启动30秒内收集数据的：输入命令后，要停留在收集状态，（这时，可以启动你的压测工具压它），30秒后，就会自动进入交互状态. 1go tool pprof 你的二进制文件名 http://127.0.0.1:8080/debug/pprof/profile 注意，那个参数 你的二进制文件名 是用来查看相应的源码的。否则的话，它会以下这些类似的错误。 1No source information for .... 查看各方法耗时进入交互状态后，TOP的输出格式:（查看耗时） 12flat flat% sum% cum cum%2720ms 18.01% 18.01% 2880ms 19.07% syscall.Syscall 查看具体某方法耗时list 方法名的输出格式: 123456789101112131415161718192021222324252627282930313233(pprof) list GetAdinfoRedisTotal: 15.10sROUTINE ======================== service.GetAdinfoRedis in /home/sky/go-dsp/src/service/AdInfoCache.go 30ms 1.14s (flat, cum) 7.55% of Total . . 29: if con.Err() != nil &#123; . . 30: logrus.Errorf("get redis con error :%v", con.Err()) . . 31: return . . 32: &#125; . . 33: key := constant.AdInfo + crtid 10ms 320ms 34: v, err := con.Do("GET", key) . . 35: 10ms 20ms 36: value, err := redis.String(v, err) . . 37: . . 38: if err != nil &#123; . . 39: logrus.Warnf("GetAdinfoRedis invald data : %v, error=%v", v, err.Error()) . . 40: return . . 41: &#125; . . 42: . . 43: if len(value) == 0 &#123; . . 44: return . . 45: &#125; . 30ms 46: adinfo = new(bean.AdInfo) . 690ms 47: err = json.Unmarshal([]byte(value), adinfo) . . 48: if err != nil &#123; . . 49: logrus.Errorf("unmarshal data [%v] to type adinfo error ", err.Error()) . . 50: &#125; 10ms 80ms 51: return . . 52:&#125; . . 53: . . 54:// SetAdInfoLocal : . . 55:func SetAdInfoLocal(adInfo *bean.AdInfo) &#123; . . 56: MemoryCache.Set(constant.AdInfo+adInfo.CreativeID, *adInfo, goCache.NoExpiration)(pprof) flat: 表示该方法自身（不包括调用其他方法）在取样总时间内的总耗时cum：表示该方法（包括调用其他方法）的总耗时）在取样总时间内的总耗时 查看调用关系耗时1234567891011121314(pprof) peek GetAdinfoRedis12s of 15.10s total (79.47%)Dropped 392 nodes (cum &lt;= 0.08s)----------------------------------------------------------|------------- flat flat% sum% cum cum% calls calls% + context ----------------------------------------------------------|------------- 1.14s 100% | service.isAdInfoMatch 0.03s 0.2% 0.2% 1.14s 7.55% | service.GetAdinfoRedis 0.68s 62.96% | encoding/json.Unmarshal 0.31s 28.70% | github.com/garyburd/redigo/redis.(*pooledConnection).Do 0.06s 5.56% | github.com/garyburd/redigo/redis.(*pooledConnection).Close 0.03s 2.78% | runtime.newobject----------------------------------------------------------|-------------(pprof) 在浏览器中查看list输入weblist确定即可 普通应用程序1234567891011import ( "runtime/pprof")func main()&#123; pprof.StartCPUProfile(要写到CPU分析的文件) pprof.WriteHeapProfile(要写到的内存分析的文件) defer pprof.StopCPUProfile()&#125; 查看：goo tool pprof AppName /path/to/pro文件。更多命令： go tool pprof -h 图形化查看1sudo apt-get install kcachegrind 进入以上的交互式命令，可以看到有一个callgrind命令。使用方式: 123456789在go tool pprof的交互式命令行里输入：callgrind &gt; /tmp/prof.grind然后在另一个普通bash(zsh)里输入:kcachegrind /tmp/prof.grind即可看到图形了 可以pprof的urltrace1234530秒收集 trace 的数据:curl http://127.0.0.1:9090/debug/pprof/trace\?seconds\=30 &gt; /tmp/trace.data然后查看:go tool trace -http=":9999" main /tmp/trace.data heap1go tool pprof http://127.0.0.1:9090/debug/pprof/heap profile1go tool pprof http://127.0.0.1:8080/debug/pprof/profile 其他1234http://127.0.0.1:9090/debug/pprof/threadcreatehttp://127.0.0.1:9090/debug/pprof/block` GC 日志收集日志1GODEBUG="gctrace=1" ./main 2&gt;/tmp/go-gc.log 日志格式更多信息，参考官方文档 golang runtime 1gc 99 @5065.785s 0%: 0.006+1.1+0.23 ms clock, 0.026+0/1.0/3.2+0.93 ms cpu, 6-&gt;6-&gt;6 MB, 13 MB goal, 4 P gc 99：表示第99次GC @5065.785s ： 从程序开始启动到现在的时间，单位为秒 0% : 从程序启动以来，GC时间占用的百分比 0.006+1.1+0.23 ms clock ： GC阶段的时钟数 0.026+0/1.0/3.2+0.93 ms cpu : GC阶段CPU时间 6-&gt;6-&gt;6 MB : GC开始时堆的大小/GC结束时堆的大小/存活的堆大小 13 MB goal : 目标堆大小（总大小，包括垃圾对象） 4 P：该次GC使用的CPU核心数 GODEBUG查看调度器1GOMAXPROCS=设置你的核数 GODEBUG=schedtrace=N(单位是毫秒，即每N毫秒输出一次) ./main 查看更详细1GOMAXPROCS=设置你的核数 GODEBUG=schedtrace=1000,scheddetail=1 ./main 参考来源]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 中自定义 JSON 转换]]></title>
    <url>%2F2016%2F10%2F30%2FGolang-%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89-JSON-%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[起因Java 中的 Timestamp 转换为 JSON 是长整型，但在 Golang 中，却是完全不同。因为需要将 Java 的代码转换为 Golang，所以遇到这种相互转换的问题。在 Golang中，默认的转换如下: 123456789101112131415161718package mainimport ( "encoding/json" "fmt" "time")// Person : for test structtype Person struct &#123; Birthday time.Time `json:"birthday"`&#125;func main() &#123; p := Person&#123;Birthday: time.Date(1991, time.August, 01, 0, 0, 0, 0, time.UTC)&#125; j, _ := json.Marshal(p) fmt.Printf("json := %v\n", string(j))&#125; 输出如下： 1234[Running] go run "/private/tmp/goooo/src/main.go"json := &#123;"birthday":"1991-08-01T00:00:00Z"&#125;[Done] exited with code=0 in 0.271 seconds 解决因为在 Java 中，它输出的是 long 类型（毫秒）。所以， 要自定义格式化输入输出 JSON 转换了。不过还好， Golang 中可以自定义这种格式。它提供两个接口： 1234567891011121314151617181920// JavaTime : time.Timetype JavaTime time.Time// UnmarshalJSON : UnmarshalJSON 自定义从json-&gt;自定义类型func (j *JavaTime) UnmarshalJSON(data []byte) error &#123; millis, err := strconv.ParseInt(string(data), 10, 64) if err != nil &#123; return err &#125; *j = JavaTime(time.Unix(0, millis*int64(time.Millisecond))) return nil&#125;// MarshalJSON : 自定义类型转换到 jsonfunc (j *JavaTime) MarshalJSON() (data []byte, err error) &#123; var buf bytes.Buffer origin := time.Time(*j) buf.WriteString(strconv.FormatInt(origin.UnixNano()/int64(time.Millisecond), 10)) return buf.Bytes(), nil&#125; MarshalJSON ： 从类型转换为 json 字符串UnmarshalJSON : 从json 字符串转换为类型 这样子， 就可以将 Java中的 Timestamp 类型转换为 Golang 中的 time.Time 类型了。 完整例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( "bytes" "encoding/json" "fmt" "strconv" "time")// Person : for test structtype Person struct &#123; Birthday *JavaTime `json:"birthday"`&#125;func main() &#123; bir := JavaTime(time.Date(1991, time.August, 01, 0, 0, 0, 0, time.UTC)) p := Person&#123;Birthday: &amp;bir&#125; // 从类型转换为 json 字符串: j, _ := json.Marshal(p) fmt.Printf("json := %v\n", string(j)) // 从 json 字符串，转换为 类型: json.Unmarshal(j, &amp;p) bir = *p.Birthday golangTime := time.Time(bir) fmt.Printf("bir year = %v\n", golangTime.Year())&#125;// JavaTime : time.Timetype JavaTime time.Time// UnmarshalJSON : UnmarshalJSON 自定义从json-&gt;转换器func (j *JavaTime) UnmarshalJSON(data []byte) error &#123; millis, err := strconv.ParseInt(string(data), 10, 64) if err != nil &#123; return err &#125; *j = JavaTime(time.Unix(0, millis*int64(time.Millisecond))) return nil&#125;// MarshalJSON : 自定义对象转换到 jsonfunc (j *JavaTime) MarshalJSON() (data []byte, err error) &#123; var buf bytes.Buffer origin := time.Time(*j) buf.WriteString(strconv.FormatInt(origin.UnixNano()/int64(time.Millisecond), 10)) return buf.Bytes(), nil&#125; 输出如下: 12345[Running] go run "/private/tmp/goooo/src/main.go"json := &#123;"birthday":681004800000&#125;bir year = 1991[Done] exited with code=0 in 0.325 seconds 注意事项类型别名 与 原类型的转换如上面的 type JavaTime time.Time JavaType 转换为 time.Time : time.Time(JavaTime)time.Time 转换为 JavaTime : JavaTime(time.Time) 使用可以看到，Birthday *JavaTime, 它使用的是指针的形式。不然，无法正常转换。 因为我们的那两个接口的接收者为(j *JavaTime) 可以自行将这两个方法， 将接收者去掉指针的形式的话， 转换的结果如何。我这时测试的是Go 1.7，发现只能指针的形式及指针的使用才能正常转换。看网上的资料的， 好像将MarshalJSON的接收者不为指针的形式也可以。这个我也没有测试过，因为只想使用最新版的 Go， ^_^.]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go学习]]></title>
    <url>%2F2016%2F10%2F18%2FGo%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[安装多个版本的 goGVM Go依赖管理与 GOPATH 的关系.GOPATH环境变量中可以包含多个目录。 1go get 这种方式，它会将依赖下载在$GOPATH环境变量中的第一个目录中. 自己对Go中包的理解1234编写代码时，使用的`package`，表示代码所在的包名。引用时，`import package`，这个`package`表示相对于`GOPATH`中的`src`目录下的目录名，多层目录，使用`/`分隔。一般来说，引用的`package`的名字，和你的最后一个目录的名字相同，但也可以不同。`import package`的名字，以所在包名的名字为准，而不是以目录名为准. Golang中的字符串拼接12345678910111213141516package mainimport ( "bytes" "fmt")func main() &#123; var buffer bytes.Buffer for i := 0; i &lt; 1000; i++ &#123; buffer.WriteString("a") &#125; fmt.Println(buffer.String())&#125; vscode中调试Go12can't load package: package .: no buildable Go source files in /ihome/go/golang-weibo-sdkexit status 1 这个问题是由于你没有将设置指向main.go的所在目录里.即，在Go的debug设置里，要类似如下： 12345678910111213141516&#123; "version": "0.2.0", "configurations": [&#123; "name": "Launch", "type": "go", "request": "launch", "mode": "debug", "remotePath": "", "port": 2345, "host": "127.0.0.1", "program": "$&#123;workspaceRoot&#125;/src/main", "env": &#123;&#125;, "args": [], "showLog": true &#125;]&#125; 即，program要设置为指向Go的main函数文件所在的目录即可. Go单元测试必须要将命令行，先切换到要进行单元测试文件的目录的根目录。比如： 12$GOPATH/src/utils/myutil.go$GOPATH/src/utils/myutil_test.go 要想进行 myutil_test.go 的单元测试，则先切换到目录$GOPATH/src/utils，然后在该目录下执行命令:go test即可。 单元测试某个指定的方法1go test -run mehtodName 单元测试递归执行12进入到$GOPATH的根目录，然后按以下方式执行即可:go test com.github.emacsist.weibosdk/api... 关于单元测试中的 Log()， Logf()默认的情况下，go test并不会输出这些， 如果需要的话，可以添加go test -v来输出详细信息. Golang中类似Java中的toString()功能12345678910111213141516package respimport ( "fmt")// ErrorResp ： 错误码返回对象type ErrorResp struct &#123; Request string `json:"request"` ErrorCode int32 `json:"error_code"` Error string `json:"error"`&#125;func (errorResp *ErrorResp) String() string &#123; return fmt.Sprintf("request=%v\nErrorCode=%v\nError=%v\n", errorResp.Request, errorResp.ErrorCode, errorResp.Error)&#125; 即为它添加一个方法 String() string即可，这样子，在调用fmt.Printf()这些格式化打印时，就会自动调用对象的String()方法来打印了. int64 to String1234import "strconv"strconv.FormatInt(int64Value, 10) 通过反射遍历结构体12345678910111213141516171819202122232425package mainimport ( "fmt" "reflect")type Person struct &#123; Age int Name string&#125;func main() &#123; p := Person&#123;Age: 10, Name: "HelloWorld"&#125; refValue := reflect.ValueOf(&amp;p) fields := refValue.Elem() for i := 0; i &lt; fields.NumField(); i++ &#123; field := fields.Field(i) fieldName := fields.Type().Field(i).Name fieldValue := field.Interface() fmt.Printf("fieldName = %v, fieldValue = %v\n", fieldName, fieldValue) &#125;&#125; 要注意的是，fieldName是通过fields这个来获取的. 如果想要将字段的值转换为确定类型的值，则就可以这样子做: 1234567891011121314151617181920212223242526272829303132package mainimport ( "fmt" "reflect")type Person struct &#123; Age int Name string&#125;func main() &#123; p := Person&#123;Age: 10, Name: "HelloWorld"&#125; refValue := reflect.ValueOf(&amp;p) fields := refValue.Elem() for i := 0; i &lt; fields.NumField(); i++ &#123; field := fields.Field(i) fieldName := fields.Type().Field(i).Name if field.Type().Name() == "string" &#123; fieldValue := field.Interface().(string) fmt.Printf("string --&gt; fieldName = %v, fieldValue = %v\n", fieldName, fieldValue) &#125; else if field.Type().Name() == "int" &#123; fieldValue := field.Interface().(int) fmt.Printf("int --&gt; fieldName = %v, fieldValue = %v\n", fieldName, fieldValue) &#125; &#125;&#125; 将json字段串自动转化生成struct结构mervine.netmholt.github.io json 字符串 转换为 struct123import "encoding/json"json.Unmarshal([]byte(body), &amp;status) struct 对象 转换为json字符串12p为结构体变量body, error := json.Marshal(p) 示例123456789101112131415161718192021222324252627282930313233343536package mainimport ( "encoding/json" "fmt")// Person : test objecttype Person struct &#123; Name string Age int&#125;func changeValue(p Person) &#123; p.Age = 10&#125;func changeValue2(p *Person) &#123; p.Age = 10&#125;func main() &#123; p := Person&#123;Age: 1, Name: "HelloWorld"&#125; changeValue(p) fmt.Printf("changeValue, name -&gt;%v, age -&gt; %v\n", p.Name, p.Age) changeValue2(&amp;p) fmt.Printf("changeValue2, name -&gt;%v, age -&gt; %v\n", p.Name, p.Age) body, _ := json.Marshal(p) fmt.Printf("struct to json -&gt; %v\n", string(body)) newP := Person&#123;&#125; fmt.Printf("newP age -&gt; %v\n", newP.Age) json.Unmarshal(body, &amp;newP) fmt.Printf("after json to struct -&gt; %v\n", newP.Age)&#125; 输出的结果为 12345678[Running] go run "/ihome/go/golang-weibo-sdk/src/main/main.go"changeValue, name -&gt;HelloWorld, age -&gt; 1changeValue2, name -&gt;HelloWorld, age -&gt; 10struct to json -&gt; &#123;"Name":"HelloWorld","Age":10&#125;newP age -&gt; 0after json to struct -&gt; 10[Done] exited with code=0 in 0.13 seconds 参数中是否是指针的区别:12345678910111213141516171819202122232425package mainimport "fmt"// Person : test objecttype Person struct &#123; Name string Age int&#125;func changeValue(p Person) &#123; p.Age = 10&#125;func changeValue2(p *Person) &#123; p.Age = 10&#125;func main() &#123; p := Person&#123;Age: 1, Name: "HelloWorld"&#125; changeValue(p) fmt.Printf("changeValue, name -&gt;%v, age -&gt; %v\n", p.Name, p.Age) changeValue2(&amp;p) fmt.Printf("changeValue2, name -&gt;%v, age -&gt; %v\n", p.Name, p.Age)&#125; 输出的结果为 12345[Running] go run "/ihome/go/golang-weibo-sdk/src/main/main.go"changeValue, name -&gt;HelloWorld, age -&gt; 1changeValue2, name -&gt;HelloWorld, age -&gt; 10[Done] exited with code=0 in 0.103 seconds 常用Go包12将struct转换为查询参数:https://godoc.org/github.com/google/go-querystring/query 常见错误http: ContentLength=xxx with Body length yyyContentLength=299 with Body length 367 1这一般是request对象前后的长度不一致（中间关闭了或处理了，导致后面的再次读取时不一致） 参考: stackoverflow 具体例子：我是在构造request时这样子写: 12345678910bodyBuf := &amp;bytes.Buffer&#123;&#125;bodyWriter := multipart.NewWriter(bodyBuf)v := reflect.ValueOf(param)fileds := v.Elem()paramsMap := netURL.Values&#123;&#125;//defer bodyWriter.Close()return http.NewRequest("POST", URL, bodyBuf) 关键是那行：defer bodyWriter.Close()，注释掉这行就可以了. cannot define new methods on non-local type123456789101112131415type MyRouter mux.Routerfunc (m *MyRouter) F() &#123; ... &#125;或者type MyRouter struct &#123; *mux.Router&#125;func (m *MyRouter) F() &#123; ... &#125;...r := &amp;MyRouter&#123;router&#125;r.F() can’t load package: import cycle not allowed1234package project/controllers/account imports project/controllers/base imports project/components/mux imports project/controllers/account 这表明有循环引用，循环引用的结果为: 123456 project/controllers/account ^ \ / \ / \ / \/project/components/mux &lt;--- project/controllers/base 只要处理掉这个循环引用的一条链即可解决. too many arguments to return一般来说，是你的方法签名中没有返回值，但你却进行了return value或者，你的方法签名中的返回值个数与return 语句不匹配 *interface {} is pointer to interface, not interface这个应该是你想在方法里进行泛型例如写成这样子: 123456789101112131415161718192021222324package helperimport "reflect"// SetDefaultValues : 设置参数默认值func SetDefaultValues(param *interface&#123;&#125;) &#123; v := reflect.ValueOf(param) fileds := v.Elem() for i := 0; i &lt; fileds.NumField(); i++ &#123; field := fileds.Field(i) // Ignore fields that don't have the same type as a string if field.Type().Name() == "string" &#123; //如果是一个字符串对象 if field.CanSet() &#123; field.SetString("") &#125; &#125; else if field.Type().Name() == "int" || field.Type().Name() == "int64" &#123; //如果是整型 if field.CanSet() &#123; field.SetInt(-1) &#125; &#125; &#125;&#125; 但其实interface{}它表示的是接收任意的类型（包括指针），所以，这里不能这样子，应该修改参数为:param interface{}即可。 这样子，在调用方法时，传递的是指针，那么它就代表指针，传递的是普通类型，那就是普通类型。 cannot use nil as type xxx这表你的xxx并不能接受nil值。（一般来说，只有指针类型才能接受nil值) found packages xxxx () and xxxx (xxxx) in xxxx1234┌─[sky@sky-linux] - [/ihome/go/golang-weibo-sdk/src/com.github.emacsist.weibosdk/api/business/status] - [2016-10-21 05:40:43] └─[2] &lt;git:(master 3c154e3✱✈) &gt; go test -run StatusesRepostTimelineBizString ../../../helper/HttpHelper.go:8:2: found packages resp (CommentsAndTotalNumberResp.go) and api (TagsTagsBatchOther.go) in /ihome/go/golang-weibo-sdk/src/com.github.emacsist.weibosdk/resp Go语言规则，所有在同一个目录的源文件，都必须是同属一个包的.解决了这个问题就可以编译通过了. struct 结构体的继承1234567891011// Person : test objecttype Person struct &#123; Name string Age int Animal&#125;type Animal struct &#123; Colour string Name string&#125; Go中的字符串转换为字符数组123456789package mainimport "fmt"func main() &#123; fmt.Println(string("Hello"[1])) // ASCII only fmt.Println(string([]rune("Hello, 世界")[1])) // UTF-8 fmt.Println(string([]rune("Hello, 世界")[8])) // UTF-8&#125; 千万要注意：string[0:1]这种形式是按字节来分隔的.len(string)返回的是字节数.要操作字符的话，则要使用rune类型。 Golang中顶级的JSON数组字符串转换为json对象12345678910111213141516package mainimport "fmt"import "encoding/json"type PublicKey struct &#123; Id int Key string&#125;func main() &#123; keysBody := []byte(`[&#123;"id": 1,"key": "-"&#125;,&#123;"id": 2,"key": "-"&#125;,&#123;"id": 3,"key": "-"&#125;]`) keys := make([]PublicKey, 0) json.Unmarshal(keysBody, &amp;keys) fmt.Printf("%#v", keys[2].Id)&#125; 创建一个自定义的error123import "errors"errors.New("xx") json数组转换为map12345678910111213141516171819202122232425package mainimport ( "encoding/json" "fmt")func main() &#123; h := `[ &#123; "221012100001985342": "80后", "weight": 50 &#125;, &#123; "221012100001985342": "80后1", "weight": 51 &#125;]` var hell []map[string]interface&#123;&#125; err := json.Unmarshal([]byte(h), &amp;hell) fmt.Printf("%v\n", err) fmt.Printf("%v\n", h) fmt.Printf("%v\n", hell)&#125; Go交叉编译进入Go的安装目录cd $GOROOT/src，然后 选择要生成的目标构架的工具链: 12345678# windows64位CGO_ENABLED=0 GOOS=windows GOARCH=amd64 ./make.bash# macCGO_ENABLED=0 GOOS=darwin GOARCH=amd64 ./make.bash# linux 64CGO_ENABLED=0 GOOS=linux GOARCH=amd64 ./make.bash 常见错误:123456┌─[sky@sky-linux] - [/ihome/go/go-current/src] - [2016-10-26 02:14:42]└─[0] &lt;&gt; CGO_ENABLED=0 GOOS=windows GOARCH=amd64 ./make.bash##### Building Go bootstrap tool.cmd/distERROR: Cannot find /home/sky/go1.4/bin/go.Set $GOROOT_BOOTSTRAP to a working Go tree &gt;= Go 1.4. 这表需要有一个&gt;=1.4的另一个go安装目录，并将GOROOT_BOOTSTRAP指向该目录即可. Linux下交叉编译Macstackoverflow OS常量以及ARCH常量syslist 12345package buildconst goosList = "android darwin dragonfly freebsd linux nacl netbsd openbsd plan9 solaris windows zos "const goarchList = "386 amd64 amd64p32 arm armbe arm64 arm64be ppc64 ppc64le mips mipsle mips64 mips64le mips64p32 mips64p32le ppc s390 s390x sparc sparc64 " Go打包静态资源安装: go get -u github.com/jteeuwen/go-bindata/... go-bindata 假设/tmp/go是一个$GOPATH: 12345678910111213141516┌─[sky@sky-linux] - [/tmp/go] - [2016-10-26 03:25:55]└─[0] &lt;&gt; ll /tmp/go/src/nlp/dicttotal 820K-rw-r--r-- 1 sky sky 3.1K 10月 25 18:36 adv_full.txt-rw-r--r-- 1 sky sky 3.2K 10月 25 18:36 adv.txt-rw-r--r-- 1 sky sky 212K 10月 25 18:36 neg_full.txt-rw-r--r-- 1 sky sky 305K 10月 25 18:36 neg.txt-rw-r--r-- 1 sky sky 273 10月 25 18:36 not_full.txt-rw-r--r-- 1 sky sky 287 10月 25 18:36 not.txt-rw-r--r-- 1 sky sky 116K 10月 25 18:36 pos_full.txt-rw-r--r-- 1 sky sky 149K 10月 25 18:36 pos.txt-rw-r--r-- 1 sky sky 8.0K 10月 25 21:21 stp_full.txt-rw-r--r-- 1 sky sky 8.0K 10月 25 18:36 stp.txt┌─[sky@sky-linux] - [/tmp/go] - [2016-10-26 12:35:32] └─[0] &lt;&gt; ./bin/go-bindata -o=src/nlp/asset/asset.go -pkg=asset -prefix "/tmp/go/src/nlp/" /tmp/go/src/nlp/dict 说明： -o : 表示生成静态资源的访问包的文件.-pkg ： 表示包名-prefix ： 表示自动添加的前缀。 /tmp/go/src/nlp/dict表示静态资源的目录.如果要递归的话，可以这样子写: /tmp/go/src/nlp/dict/... 成功后，可以看到生成了一个新的文件:/tmp/go/src/nlp/asset/asset.go 使用例子: 1234567891011121314151617181920212223import ( "nlp/asset")func init() &#123; fmt.Printf("init --&gt; %v\n", asset.AssetNames()) loadDict("dict/adv_full.txt", &amp;advMap) loadDict("dict/neg_full.txt", &amp;negMap) loadDict("dict/not_full.txt", &amp;notMap) loadDict("dict/pos_full.txt", &amp;posMap) loadDict("dict/stp_full.txt", &amp;stpMap)&#125;func loadDict(path string, dic *map[string]bool) &#123; //"dict/adv_full.txt" data, _ := asset.Asset(path) bufferReader := bytes.NewReader(data) scan := bufio.NewScanner(bufferReader) for scan.Scan() &#123; t := scan.Text() (*dic)[t] = true &#125;&#125; 因为我们添加了-prefix &quot;/tmp/go/src/nlp/&quot;, 所以，我们可以直接这样子： dict/adv_full.txt的路径，就可以通过asset.Asset(&quot;dict/adv_full.txt&quot;)来访问我们的静态资源了. 常用编译选项输出所有可用编译选项: 1go tool compile -help 去掉调试信息1go build -ldflags '-w' 查看优化的信息(内联 inline 信息、逃逸分析等)1go build -gcflags=-m 数组与slice 区别123456789101112131415161718192021222324252627282930313233343536package mainimport "fmt"func main() &#123; arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; sliceArray := arr[3:5] // 由此可知，slice是一种引用类型，因为它的第一个元素地址，与arr[3]的地址是一样的 fmt.Printf("arr[3] address = %v\n", &amp;arr[3]) fmt.Printf("sliceArray[0] address = %v\n", &amp;sliceArray[0]) // len = 2 fmt.Printf("len slice = %v\n", len(sliceArray)) // cap = 7，cap的计算，是从第一个slice元素的位置，到原数组的结尾的长度. fmt.Printf("cap slice = %v\n", cap(sliceArray)) // 因为sliceArray的cap为7,已经存在2个，那还可以容纳5个元素，这时引用的，还是arr数组，这样子append后，会修改arr的内容 // arr 为 : [0 1 2 3 4 1 2 3 4 5] // sliceArray 为 : [3 4 1 2 3 4 5 sliceArray = append(sliceArray, 1, 2, 3, 4, 5) // 当cap还在arr容纳范围之内时，slice指向的就是arr,通过打印他们的地址可知: fmt.Printf("arr[5] address = %v， value=%v\n", &amp;arr[6], arr[6]) fmt.Printf("sliceArray[2] address = %v, value=%v\n", &amp;sliceArray[3], sliceArray[3]) //但当sliceArray超过了cap时: [3 4 1 2 3 4 5 1 2 3 4 5] sliceArray = append(sliceArray, 1, 2, 3, 4, 5) // 可以发现，它指向了一个新的数组:因为他们的地址不同了. fmt.Printf("arr[5] address = %v， value=%v\n", &amp;arr[6], arr[6]) fmt.Printf("sliceArray[2] address = %v, value=%v\n", &amp;sliceArray[3], sliceArray[3]) fmt.Printf("cap slice = %v\n", cap(sliceArray)) fmt.Printf("%v, %v\n", arr, sliceArray)&#125; append超出cap之前与之后： 1234567891011121314151617package mainimport "fmt"func main() &#123; arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; sliceArray := arr[3:5] sliceArray2 := arr[3:5] fmt.Printf("%v, %v, %v\n", arr, sliceArray, sliceArray2) fmt.Printf("%v, %v, %v\n", &amp;arr[3], &amp;sliceArray[0], &amp;sliceArray2[0]) sliceArray = append(sliceArray, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23) fmt.Printf("%v, %v, %v\n", arr, sliceArray, sliceArray2) fmt.Printf("%v, %v, %v\n", &amp;arr[3], &amp;sliceArray[0], &amp;sliceArray2[0])&#125; Go中使用 redis123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107package mainimport ( "flag" "time" "fmt" "github.com/garyburd/redigo/redis")func newPool(server, password string) *redis.Pool &#123; return &amp;redis.Pool&#123; MaxIdle: 3, IdleTimeout: 240 * time.Second, Dial: func() (redis.Conn, error) &#123; c, err := redis.Dial("tcp", server) if err != nil &#123; return nil, err &#125; if len(password) &gt; 0 &#123; if _, err := c.Do("AUTH", password); err != nil &#123; c.Close() return nil, err &#125; &#125; return c, err &#125;, TestOnBorrow: func(c redis.Conn, t time.Time) error &#123; if time.Since(t) &lt; time.Minute &#123; return nil &#125; _, err := c.Do("PING") return err &#125;, &#125;&#125;var ( pool *redis.Pool redisServer = flag.String("redisServer", ":6379", "") redisPassword = flag.String("redisPassword", "", ""))func main() &#123; redisGet() redisPipline()&#125;func redisGet() &#123; redisConnection := pool.Get() defer redisConnection.Close() //如果这个不为空，表明获取链接时出错 if redisConnection.Err() != nil &#123; fmt.Printf("Hello World %v\n", redisConnection.Err().Error()) return &#125; val, err := redisConnection.Do("get", "hello2") if err == nil &#123; fmt.Printf("Hello %v\n", string(val.([]uint8))) &#125; else &#123; fmt.Printf("happen error : %v\n", err.Error()) &#125;&#125;func redisPipline() &#123; redisConnection := pool.Get() defer redisConnection.Close() //如果这个不为空，表明获取链接时出错 if redisConnection.Err() != nil &#123; fmt.Printf("Hello World %v\n", redisConnection.Err().Error()) return &#125; redisConnection.Send("get", "hello") redisConnection.Send("get", "hello1") redisConnection.Send("get", "hello2") redisConnection.Flush() for i := 0; i &lt; 3; i++ &#123; data, err := redisConnection.Receive() if err == nil &amp;&amp; redisConnection.Err() == nil &#123; if data == nil &#123; continue &#125; fmt.Printf("Hello from pipline %v\n", string(data.([]uint8))) continue &#125; else &#123; fmt.Printf("Hello from pipline error %v\n", err.Error()) break &#125; &#125; fmt.Printf("done\n")&#125;func init() &#123; flag.Parse() fmt.Printf("redis: server = %v, passwd = %v\n", *redisServer, *redisPassword) pool = newPool(*redisServer, *redisPassword) fmt.Printf("init redis connection pool ok\n")&#125; 注意，这个默认是db 0，如果想实现选择（虽然不推荐使用多个DB），可以按如下链接做: stackoverflow Go 中使用 gorm 与 mysql 交互1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( "fmt" "time" "github.com/jinzhu/gorm" _ "github.com/jinzhu/gorm/dialects/mysql")type WbStatus struct &#123; ID int64 `gorm:"primary_key"` Text string CreateAt time.Time&#125;func (WbStatus) TableName() string &#123; return "wb_status"&#125;var db *gorm.DBfunc main() &#123; if db == nil &#123; panic("db is nil") &#125; var wbstatus WbStatus fmt.Printf("tableName = %v\n", wbstatus.TableName()) db.First(&amp;wbstatus) fmt.Printf("rowId = %v\n", wbstatus.ID) fmt.Printf("createAt = %v\n", wbstatus.CreateAt) defer db.Close()&#125;func init() &#123; var err error db, err = gorm.Open("mysql", "root:yang@(127.0.0.1:3306)/test?charset=utf8&amp;parseTime=True&amp;loc=Local") if err != nil &#123; fmt.Printf("init mysql error : %v\n", err.Error()) panic("exit") &#125; if db == nil &#123; fmt.Printf("init mysql error : db is null\n") panic("exit") &#125; else &#123; fmt.Printf("init mysql : db isnot null\n") &#125; db.DB().SetMaxOpenConns(100) db.DB().SetMaxIdleConns(10) fmt.Printf("init mysql OK\n")&#125; gorm go 中使用 rabbitmqgithub amqp whether-to-create-connection-every-time-when-amqp-dial-is-threadsafe-or-not-in-golang ensuring-rabbitmq-connection-in-golang 注意事项12345678910ch, _ := mqCon.Channel() msgs, err := ch.Consume( config.Configuration.Rabbit.Listen, // queue config.Configuration.Rabbit.ConsumerID, // consumer true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) 如果你将auto-ack设置为true，则不用手工确认消息。如果设置为false，则必须手工调用: 1Delivery.Ack, Delivery.Reject or Delivery.Nack rabbitmq-best-practices-in-go autoAck: When autoAck (also known as noAck) is true, the server will acknowledgedeliveries to this consumer prior to writing the delivery to the network. WhenautoAck is true, the consumer should not call Delivery.Ack. Automaticallyacknowledging deliveries means that some deliveries may get lost if theconsumer is unable to process them after the server delivers them. go中long与timestamp json的转换convert-to-time-in-golang-from-milliseconds type A B只是让A获得B的内存模型而已。A不会继承B的方法，但A和B可以使用A()或B()来互相转换。 golangtc Go 中找出实现了某接口的代码1egrep -nr '^func (.*) ReadByte\(' * Golang中实现优雅关闭程序12345678910111213141516171819func main() &#123; sigs := make(chan os.Signal, 1) done := make(chan bool, 1) // sigs 表示将收到的信号放到这个管道中。后面的参数表示你想处理的系统信号 signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM) //开启一个Go routine来监听信号 go func() &#123; sig := &lt;-sigs done &lt;- true &#125;() //这里添加你的程序的功能（监听器，处理器等） fmt.Println("awaiting signal") &lt;-done fmt.Println("exiting")&#125; 常见信号: 12345678910111213141516171819202122232425262728293031Signal Name Number DescriptionSIGHUP 1 Hangup (POSIX)SIGINT 2 Terminal interrupt (ANSI)SIGQUIT 3 Terminal quit (POSIX)SIGILL 4 Illegal instruction (ANSI)SIGTRAP 5 Trace trap (POSIX)SIGIOT 6 IOT Trap (4.2 BSD)SIGBUS 7 BUS error (4.2 BSD)SIGFPE 8 Floating point exception (ANSI)SIGKILL 9 Kill(can't be caught or ignored) (POSIX)SIGUSR1 10 User defined signal 1 (POSIX)SIGSEGV 11 Invalid memory segment access (ANSI)SIGUSR2 12 User defined signal 2 (POSIX)SIGPIPE 13 Write on a pipe with no reader, Broken pipe (POSIX)SIGALRM 14 Alarm clock (POSIX)SIGTERM 15 Termination (ANSI)SIGSTKFLT 16 Stack faultSIGCHLD 17 Child process has stopped or exited, changed (POSIX)SIGCONT 18 Continue executing, if stopped (POSIX)SIGSTOP 19 Stop executing(can't be caught or ignored) (POSIX)SIGTSTP 20 Terminal stop signal (POSIX)SIGTTIN 21 Background process trying to read, from TTY (POSIX)SIGTTOU 22 Background process trying to write, to TTY (POSIX)SIGURG 23 Urgent condition on socket (4.2 BSD)SIGXCPU 24 CPU limit exceeded (4.2 BSD)SIGXFSZ 25 File size limit exceeded (4.2 BSD)SIGVTALRM 26 Virtual alarm clock (4.2 BSD)SIGPROF 27 Profiling alarm clock (4.2 BSD)SIGWINCH 28 Window size change (4.3 BSD, Sun)SIGIO 29 I/O now possible (4.2 BSD)SIGPWR 30 Power failure restart (System V) 检查程序监控了哪些信号signals Golang中的struct tag使用12345678910111213141516171819202122232425package mainimport ( "fmt" "reflect")// Person :type Person struct &#123; Name string `mytag:"HelloName"`&#125;func main() &#123; p := Person&#123;Name: "emacsist"&#125; refValue := reflect.ValueOf(&amp;p) fields := refValue.Elem() for i := 0; i &lt; fields.NumField(); i++ &#123; field := fields.Field(i) fieldName := fields.Type().Field(i).Name fieldValue := field.Interface() fieldTag := fields.Type().Field(i).Tag.Get("mytag") fmt.Printf("fieldName = %v, fieldValue = %v, tagName = %v\n", fieldName, fieldValue, fieldTag) &#125;&#125; 限制Goalng的HTTP 工作线程(goroutine)1234567891011connectionCount := 5000l, err := net.Listen("tcp", ":9090")if err != nil &#123; log.Fatalf("Listen: %v", err)&#125;l = netutil.LimitListener(l, connectionCount)log.Fatal(http.Serve(l, nil))logrus.Infof("start server success. %v", ListenAddress) 为什么我的内存没有被操作系统回收？stackoverflow golang Golang1.8 中的优雅关闭 http12345678910111213141516s := &amp;http.Server&#123; Addr: ":9090",&#125;go func() &#123; log.Infof("%s", s.ListenAndServe())&#125;()// Handle SIGINT and SIGTERM.ch := make(chan os.Signal)signal.Notify(ch, syscall.SIGINT, syscall.SIGTERM)log.Println(&lt;-ch)log.Println("http server gracefully stopping...")// Stop the service gracefully.s.Shutdown(context.Background())log.Println("http server gracefully shutdown done...") 按 github 风格的项目组织结构github code layout 压缩编译后的文件大小去掉符号信息1go build -ldflags "-s -w" 使用 upx 压缩1upx -9 GoBinaryFile Golang 中的 web在 web 中使用 panic 只会退出当前的 goroutine ，而不会整个应用程序退出。 在一般应用中，如果没有捕捉 panic() 的话，就会导致整个应用退出: 1234567891011121314151617181920212223package mainimport ( "sync" "time")func main() &#123; wg := sync.WaitGroup&#123;&#125; wg.Add(1) go func() &#123; time.Sleep(5 * time.Second) println("Hello World") panic("==================&gt;") &#125;() go func() &#123; time.Sleep(2 * time.Second) println("Hello World2") panic("==================&gt;2") &#125;() wg.Wait()&#125; 短声明注意短声明只能声明局部变量，而且它会覆盖外部的同名变量。 所以，如果目的是想进行外部变量的初始化的话，这点可能没达到我们想要的目的，这点要特别注意。 类型转换不论显式还是隐式的 常量 的类型转换，常量从一种类型转换为另一种类型，都要求目标类型能够表示 原值 Golang 中格式化日期123YYYY-MM-DD HH:mm:ss 对应2006-01-02 15:04:05 Go 中发送登录请求（保持 cookie)stackoverflow.com 123456789101112131415161718192021222324252627282930package mainimport ( "golang.org/x/net/publicsuffix" "io/ioutil" "log" "net/http" "net/http/cookiejar")func main() &#123; options := cookiejar.Options&#123; PublicSuffixList: publicsuffix.List, &#125; jar, err := cookiejar.New(&amp;options) if err != nil &#123; log.Fatal(err) &#125; client := http.Client&#123;Jar: jar&#125; resp, err := client.Get("http://dubbelboer.com/302cookie.php") if err != nil &#123; log.Fatal(err) &#125; data, err := ioutil.ReadAll(resp.Body) resp.Body.Close() if err != nil &#123; log.Fatal(err) &#125; log.Println(string(data))&#125; Go 中提交表单1234567891011form := url.Values&#123;&#125;form.Add("qps", strconv.FormatInt(qps, 10))setQPSRequest, err := http.NewRequest("POST", loginURL, strings.NewReader(form.Encode()))if err != nil &#123; return&#125;setQPSRequest.Header.Set("Content-Type", "application/x-www-form-urlencoded; charset=utf-8")]]></content>
      <categories>
        <category>golang</category>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中按条件count]]></title>
    <url>%2F2016%2F10%2F17%2FMySQL%E4%B8%AD%E6%8C%89%E6%9D%A1%E4%BB%B6count%2F</url>
    <content type="text"><![CDATA[问题产品中有个业务是定时发通知的，现有的逻辑是，只有通知数&gt;0时，才会发通知，现在PM说要修改为无论有没有消息数，都要在定时的时间发送通知。 原SQL123SELECT count(1) as total, max(mws.id) as maxRuleStatusId, mwr.user_id as userId, mwr.id as ruleId, mwr.wx_openids as wxOpenIds from micro_warning_status mws INNER JOIN micro_warning_rule as mwr ON mws.micro_warning_rule_id = mwr.idWHERE mwr.notice_interval = #&#123;noticeInterval&#125; AND mws.id &gt; mwr.last_notice_idgroup by mwr.user_id, mwr.id; last_notice_id：表示上一次已经通知的id，mws.id &gt; mwr.last_notice_id 表示距离上一次通知后，有多少条新的消息. 因为这个条件在where里，所以只有在定时的时间内，有新的消息时，此SQL才不会为空。 新SQL因为PM要求无论有没有新消息数，都要进行通知。所以要修改一下SQL，新SQL如下: 123SELECT sum(if(mws.id &gt; mwr.last_notice_id, 1, 0)) as total, max(mws.id) as maxRuleStatusId, mwr.user_id as userId, mwr.id as ruleId, mwr.wx_openids as wxOpenIds from micro_warning_status mws INNER JOIN micro_warning_rule as mwr ON mws.micro_warning_rule_id = mwr.idWHERE mwr.notice_interval = #&#123;noticeInterval&#125;group by mwr.user_id, mwr.id; 通过sum+if来有条件地进行count操作即可达到目的。]]></content>
      <categories>
        <category>mysql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinuxMint下使用VS code]]></title>
    <url>%2F2016%2F10%2F14%2FLinuxMint%E4%B8%8B%E4%BD%BF%E7%94%A8VS-code%2F</url>
    <content type="text"><![CDATA[LinuxMint下禁用按键Menu-&gt;Control Center-&gt;Windows-&gt;Behaviour中选择Movement Key中的Super. 安装VS codeVSCode 开启列编辑打开vscode. File-&gt;Preferences-&gt;Keyboard Shortcuts，在Keybindings.json中添加: 123456789101112131415161718192021222324252627282930313233// Place your key bindings in this file to overwrite the defaults[ &#123; "key": "shift+alt+down", "command": "cursorColumnSelectDown", "when": "editorTextFocus" &#125;, &#123; "key": "shift+alt+left", "command": "cursorColumnSelectLeft", "when": "editorTextFocus" &#125;, &#123; "key": "shift+alt+pagedown", "command": "cursorColumnSelectPageDown", "when": "editorTextFocus" &#125;, &#123; "key": "shift+alt+pageup", "command": "cursorColumnSelectPageUp", "when": "editorTextFocus" &#125;, &#123; "key": "shift+alt+right", "command": "cursorColumnSelectRight", "when": "editorTextFocus" &#125;, &#123; "key": "shift+alt+up", "command": "cursorColumnSelectUp", "when": "editorTextFocus" &#125;] 使用的插件12345678910111213141516171819## 发现自带的 Seti 就已经非常 nice 了.也可以不安装下面这个图标主题了.ext install vscode-icons-- angular 支持ext install language-vscode-javascript-angular2-- 目录和文件名补全ext install christian-kohler.path-intellisense-- 自动关闭标签ext install formulahendry.auto-close-tag-- 格式化js/cssext install vscode-JS-CSS-HTML-formatterext install ecmel.vscode-html-css ext install html-css-class-completionext install code-runner-- 大小写切换ext install change-case 常用的配置user settings: bas 1234-- 自动换行&#123; "editor.wrappingColumn": 0&#125; 光标的移动对称匹配符之间的移动（括号，大括号，中括号等）1⇧⌘\ 将当前光标所在的字符串进行多光标编辑将光标移动到你所想进行文件中的所有与当前光标所在字符串相同的进行多光标编辑 1⇧⌘L]]></content>
      <categories>
        <category>linux</category>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL获取分组后的TopN条数据]]></title>
    <url>%2F2016%2F10%2F13%2FMySQL%E8%8E%B7%E5%8F%96%E5%88%86%E7%BB%84%E5%90%8E%E7%9A%84TopN%E6%9D%A1%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[表结构123456789101112131415161718192021222324252627282930313233mysql&gt; desc dce_his_cs_m_jyhqsj;+---------+---------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------+---------------+------+-----+---------+----------------+| QSJDATE | varchar(20) | YES | | NULL | || QSJDDDD | varchar(8) | NO | PRI | NULL | || QSJMMMM | varchar(4) | NO | PRI | NULL | || QSJHYBH | varchar(10) | NO | PRI | NULL | || QSJKHBH | varchar(10) | NO | PRI | NULL | || QSJKPJG | decimal(10,2) | YES | | NULL | || QSJKPTM | decimal(20,0) | YES | | NULL | || QSJZGJG | decimal(10,2) | YES | | NULL | || QSJZDJG | decimal(10,2) | YES | | NULL | || QSJSPJG | decimal(10,2) | YES | | NULL | || QSJSPTM | varchar(20) | YES | | NULL | || QSJCJSL | decimal(10,0) | YES | | NULL | || QSJSKCL | decimal(10,0) | YES | | NULL | || QSJSPCL | decimal(10,0) | YES | | NULL | || QSJBKCL | decimal(10,0) | YES | | NULL | || QSJBPCL | decimal(10,0) | YES | | NULL | || QSJSCCL | decimal(10,0) | YES | | NULL | || QSJBCCL | decimal(10,0) | YES | | NULL | || QSJZCCL | decimal(10,0) | YES | | NULL | || QSJSWTL | decimal(10,0) | YES | | NULL | || QSJBWTL | decimal(10,0) | YES | | NULL | || QSJZWTL | decimal(10,0) | YES | | NULL | || QSJAMPL | decimal(10,2) | YES | | NULL | || QSJZDFD | decimal(10,2) | YES | | NULL | || id | int(11) | NO | UNI | NULL | auto_increment |+---------+---------------+------+-----+---------+----------------+25 rows in set (0.00 sec)mysql&gt; SQL12345678910111213141516171819202122232425262728293031SET SESSION group_concat_max_len = 1000000;mysql&gt; select id, QSJDDDD, QSJMMMM, QSJCJSL from dce_his_cs_m_jyhqsj where FIND_IN_SET(id, (SELECT group_concat(id) as id from (select substring_index(group_concat(id order by id desc SEPARATOR ','),",",5) as id from dce_his_cs_m_jyhqsj GROUP BY QSJDDDD, qsjmmmm) as b)) order by QSJDDDD, QSJMMMM, QSJCJSL;mysql&gt; select id, QSJDDDD, QSJMMMM, QSJCJSL from dce_his_cs_m_jyhqsj where FIND_IN_SET(id, (SELECT group_concat(id) as id from (select substring_index(group_concat(id order by id desc SEPARATOR ','),",",5) as id from dce_his_cs_m_jyhqsj GROUP BY QSJDDDD, qsjmmmm) as b)) order by QSJDDDD, QSJMMMM, QSJCJSL;+-------+----------+---------+---------+| id | QSJDDDD | QSJMMMM | QSJCJSL |+-------+----------+---------+---------+| 2577 | 20160909 | 1401 | 14 || 10862 | 20160909 | 1401 | 28 || 10702 | 20160909 | 1402 | 21 || 11142 | 20160909 | 1402 | 35 || 11802 | 20160909 | 1402 | 57 || 10070 | 20160909 | 1402 | 98 || 9238 | 20160909 | 1402 | 120 || 11394 | 20160909 | 1403 | 5 || 10863 | 20160909 | 1403 | 11 || 11803 | 20160909 | 1403 | 14 || 11618 | 20160909 | 1403 | 56 || 12651 | 20160909 | 1403 | 95 || 11395 | 20160909 | 1404 | 53 || 12210 | 20160909 | 1404 | 64 || 12010 | 20160909 | 1404 | 67 || 12652 | 20160909 | 1404 | 89 || 12422 | 20160909 | 1404 | 114 || 9672 | 20160909 | 1405 | 9 || 12653 | 20160909 | 1405 | 22 || 11619 | 20160909 | 1405 | 26 || 10071 | 20160909 | 1405 | 64 || 12423 | 20160909 | 1405 | 118 | 思路： 使用group_concat，然后将group_concat的数据取出前N位（TopN），然后再通过FIND_IN_SET 来获取每个TopN的完整数据即可.]]></content>
      <categories>
        <category>mysql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL中的json与jsonb]]></title>
    <url>%2F2016%2F10%2F09%2FPostgreSQL%E4%B8%AD%E7%9A%84json%E4%B8%8Ejsonb%2F</url>
    <content type="text"><![CDATA[hstore vs json vs jsonbstackoverflow 首先，hstore是一个扩展模块，它允许你保存key=&gt;values键值对，且键值都只能是texts类型（但是，值也允许sql的NULL） json与jsonb 允许你保存一个有效的json值(定义). 例如，以下都是有效的json表示方式: null, true, [1, false, &quot;string&quot;, {&quot;foo&quot;:&quot;bar&quot;}], {&quot;foo&quot;:&quot;bar&quot;, &quot;baz&quot;:[null]}. 相比json, hstore只是它的一个很小的子集(但是，如果你只需要这个子集，也OK的.) json与jsonb的区别主要是它们的存储方式： json是保存为文本格式的 jsonb是保存为二进制格式的 这主要有三方面的影响： jsonb通常比json占用更多的磁盘空间（有些情况不是） jsonb比json的写入更耗时间 json的操作比jsonb的操作明显更耗时间（在操作一个json类型值时需要每次都去解析） 当jsonb将在未来稳定版发行可用时，这有两个主要使用情况，你很容易在他们之间选择的： 如果你的应用只用json表示，PostgreSQL只用于保存与获取时，你应该使用json. 如果你需要在PostgreSQL中做比较多的json值的操作，或者在一些json字段上使用索引时，你应该使用jsonb 官方文档上说: 有两个JSON数据类型：json和jsonb。它们接受几乎 相同的值组作为输入。它们实际的主要差别是效率。json 数据类型存储输入文本的精确拷贝，处理函数必须在每个执行上重新解析；而jsonb数据以分解的二进制格式存储，这使得它由于添加了转换机制而在输入上稍微慢些，但是在处理上明显更快，因为不需要重新解析。jsonb也支持索引，这也是一个明显的优势。 因为json类型存储输入文本的精确拷贝，它将保存令牌间语义上无关紧要的空格，和JSON对象中键的顺序。另外，如果值中的一个JSON对象多次包含相同的键，那么保存所有的键/值对。（处理函数将最后一个值当做操作值。）相比之下， jsonb不保存空格，也不保存对象键的顺序，并且不保存重复对象键。如果在输入中指定了重复的键，那么只保存最后一个值。 json（jsonb) 的常用函数及操作符functions-json -&gt;右操作符为int： 获取JSON数组元素（索引从0开始） 1234567select '[&#123;"a":"foo"&#125;,&#123;"b":"bar"&#125;,&#123;"c":"baz"&#125;]'::json-&gt;2; ?column? ------------- &#123;"c":"baz"&#125;(1 row)Time: 1.240 ms 右操作符为text： 通过键获取json值. 1234567SELECT '&#123;"a": &#123;"b":"foo"&#125;&#125;'::json-&gt;'a'; ?column? ------------- &#123;"b":"foo"&#125;(1 row)Time: 0.685 ms -&gt;&gt;右操作符为int： 获取JSON数组元素为text 1234567SELECT '[1,2,3]'::json-&gt;&gt;2; ?column? ---------- 3(1 row)Time: 0.530 ms 右操作符为text： 通过键获取json值为text 1234567 SELECT '&#123;"a":1,"b":2&#125;'::json-&gt;&gt;'b'; ?column? ---------- 2(1 row)Time: 0.585 ms #&gt;右操作符为: text[], 在指定的路径获取JSON对象。 1234567SELECT '&#123;"a": &#123;"b":&#123;"c": "foo"&#125;&#125;&#125;'::json#&gt;'&#123;a,b&#125;'; ?column? -------------- &#123;"c": "foo"&#125;(1 row)Time: 0.665 ms 即在获取a.b的值 #&gt;&gt;右操作符为: text[], 在指定的路径获取JSON对象为text 1234567SELECT '&#123;"a":[1,2,3],"b":[4,5,6]&#125;'::json#&gt;&gt;'&#123;a,2&#125;'; ?column? ---------- 3(1 row)Time: 0.556 ms 即获取a[2]的值并转为text. jsonb 操作符@&gt;右操作数的类型： jsonb, 左侧的JSONB的是否包含右侧的. 1234567SELECT '&#123;"a":1, "b":2&#125;'::jsonb @&gt; '&#123;"b":2&#125;'::jsonb; ?column? ---------- t(1 row)Time: 0.599 ms &lt;@右操作数的类型： jsonb, 右侧的JSONB的是否包含左侧的. 1234567SELECT '&#123;"a":1, "b":2&#125;'::jsonb &lt;@ '&#123;"b":2&#125;'::jsonb; ?column? ---------- f(1 row)Time: 0.435 ms ?右操作符: text, 该字符串是否存在于json的顶级key中. 1234567SELECT '&#123;"a":1, "b":2&#125;'::jsonb ? 'b'; ?column? ---------- t(1 row)Time: 0.551 ms ?|右操作符：text[]，这些元素之一是否存在于json的顶级key中. 1234567SELECT &apos;&#123;&quot;a&quot;:1, &quot;b&quot;:2, &quot;c&quot;:3&#125;&apos;::jsonb ?| array[&apos;b&apos;, &apos;ceeee&apos;, &apos;e&apos;]; ?column? ---------- t(1 row)Time: 0.315 ms ？&amp;右操作符：text[]，所有这些元素是否存都在于json的顶级key中. 1234567891011121314[local]:5432 sky@sky=# SELECT '["a", "b"]'::jsonb ?&amp; array['a', 'b']; ?column? ---------- t(1 row)Time: 36.143 ms[local]:5432 sky@sky=# SELECT '["a", "b"]'::jsonb ?&amp; array['a', 'b', 'c']; ?column? ---------- f(1 row)Time: 0.370 ms ||右操作符: jsonb, 拼接两个jsonb生成一个新的jsonb 12345678[local]:5432 sky@sky=# SELECT '["a", "b", &#123;"hello":"world"&#125;]'::jsonb || '["c", "d", &#123;"hello":"world"&#125;]'::jsonb; ?column? -------------------------------------------------------------- ["a", "b", &#123;"hello": "world"&#125;, "c", "d", &#123;"hello": "world"&#125;](1 row)Time: 0.359 ms[local]:5432 sky@sky=# -右操作符：text，从左操作数中删除K/V或者字符串元素。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[local]:5432 sky@sky=# SELECT '&#123;"a": "b"&#125;'::jsonb - 'a'; ?column? ---------- &#123;&#125;(1 row)Time: 0.357 ms[local]:5432 sky@sky=# SELECT '["a", "b"]'::jsonb - 'a'; ?column? ---------- ["b"](1 row)Time: 0.359 ms``` 右操作符：`int`， 删除指定索引的元素（负数表示从结尾开始）```bash[local]:5432 sky@sky=# SELECT '["a", "b"]'::jsonb - (-1); ?column? ---------- ["a"](1 row)Time: 0.319 ms[local]:5432 sky@sky=# SELECT '["a", "b"]'::jsonb - 0; ?column? ---------- ["b"](1 row)Time: 0.319 ms[local]:5432 sky@sky=# SELECT '["a", "b"]'::jsonb - 1; ?column? ---------- ["a"](1 row)Time: 0.305 ms[local]:5432 sky@sky=# SELECT '["a", "b"]'::jsonb - 2; ?column? ------------ ["a", "b"](1 row)Time: 0.312 ms[local]:5432 sky@sky=# #-右操作符： text[]， 删除字段或指定路径的元素. 1234567891011121314[local]:5432 sky@sky=# SELECT '["a", &#123;"b":1&#125;]'::jsonb #- '&#123;1,b&#125;'; ?column? ----------- ["a", &#123;&#125;](1 row)Time: 0.460 ms[local]:5432 sky@sky=# SELECT '["a", &#123;"b":1&#125;]'::jsonb #- '&#123;0&#125;'; ?column? ------------ [&#123;"b": 1&#125;](1 row)Time: 0.329 ms 常用json函数row_to_json()1234567891011121314151617181920localhost:5433 sky@sky=# SELECT * from test_json ; id | hello ----+--------- 1 | hello 1 | hello2 2 | hello-2 2 | hello-3(4 rows)Time: 0.203 mslocalhost:5433 sky@sky=# SELECT row_to_json(test_json) from test_json ; row_to_json ---------------------------- &#123;"id":1,"hello":"hello"&#125; &#123;"id":1,"hello":"hello2"&#125; &#123;"id":2,"hello":"hello-2"&#125; &#123;"id":2,"hello":"hello-3"&#125;(4 rows)Time: 0.229 ms 123456789101112131415161718192021222324252627282930313233343536localhost:5433 sky@sky=# SELECT * from article ; id | content ----+----------------------- 1 | hello article content(1 row)Time: 0.199 mslocalhost:5433 sky@sky=# SELECT * from tags ; aid | name -----+------ 1 | tag1 1 | tag2(2 rows)Time: 0.210 mslocalhost:5433 sky@sky=# select row_to_json(t)from ( select id, ( select array_to_json(array_agg(row_to_json(d))) from ( select name from tags where tags.aid = article.id ) d ) as tags from article where id = 1) t; row_to_json --------------------------------------------------- &#123;"id":1,"tags":[&#123;"name":"tag1"&#125;,&#123;"name":"tag2"&#125;]&#125;(1 row)Time: 0.349 mslocalhost:5433 sky@sky=# 12345678localhost:5433 sky@sky=# select row_to_json(t) from ( select *, ( SELECT array_to_json(array_agg(name)) as name from tags where aid = article.id) as tags from article ) as t ; row_to_json ------------------------------------------------------------------- &#123;"id":1,"content":"hello article content","tags":["tag1","tag2"]&#125;(1 row)Time: 0.304 mslocalhost:5433 sky@sky=# json(jsonb)中的CRUD添加jsonb的字段 12345678910111213141516171819202122232425localhost:5433 sky@sky=# create TABLE test_json(hello jsonb);CREATE TABLETime: 5.642 mslocalhost:5433 sky@sky=# INSERT INTO test_json VALUES ('&#123;"hello":"hello-value", "wolrd":"world-value"&#125;');INSERT 0 1Time: 1.722 mslocalhost:5433 sky@sky=# SELECT * from test_json ; hello -------------------------------------------------- &#123;"hello": "hello-value", "wolrd": "world-value"&#125;(1 row)Time: 0.179 mslocalhost:5433 sky@sky=# UPDATE test_json set hello = jsonb_set(hello, '&#123;hello&#125;', '"hello-new-value"'::text::jsonb, true);UPDATE 1Time: 0.994 mslocalhost:5433 sky@sky=# SELECT * from test_json ; hello ------------------------------------------------------ &#123;"hello": "hello-new-value", "wolrd": "world-value"&#125;(1 row)Time: 0.174 mslocalhost:5433 sky@sky=# 删除jsonb的某字段 1234567891011localhost:5433 sky@sky=# UPDATE test_json set hello = (hello - 'hello');UPDATE 1Time: 0.883 mslocalhost:5433 sky@sky=# SELECT * from test_json ; hello -------------------------- &#123;"wolrd": "world-value"&#125;(1 row)Time: 0.185 mslocalhost:5433 sky@sky=#]]></content>
      <categories>
        <category>postgresql</category>
        <category>jsonb</category>
        <category>json</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>json</tag>
        <tag>jsonb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables简单使用例子]]></title>
    <url>%2F2016%2F10%2F09%2Fiptables%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[保存1sudo iptables-save &gt; iptables.rule 还原1sudo iptables-restore &lt; iptables.rule 持久化1sudo apt-get install iptables-persistent 删除某条规则1234sudo iptables -L --line-numbers然后删除sudo iptables -D INPUT（即所在类型） 行号 禁用某端口，但只允许指定的ip访问123iptables -A INPUT -p tcp --dport 8000 -s 1.2.3.4 -j ACCEPTiptables -A INPUT -p tcp --dport 8000 -j DROP]]></content>
      <categories>
        <category>linux</category>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL9.6中使用mysql_fdw]]></title>
    <url>%2F2016%2F10%2F09%2FPostgreSQL9-6%E4%B8%AD%E4%BD%BF%E7%94%A8mysql-fdw%2F</url>
    <content type="text"><![CDATA[安装mysql_fdw 123456789SELECT * from pg_available_extensions where name like '%fdw%'; name | default_version | installed_version | comment --------------+-----------------+-------------------+---------------------------------------------------- file_fdw | 1.0 | [null] | foreign-data wrapper for flat file access mysql_fdw | 1.0 | [null] | Foreign data wrapper for querying a MySQL server postgres_fdw | 1.0 | [null] | foreign-data wrapper for remote PostgreSQL servers(3 rows)Time: 1.742 ms 使用1CREATE EXTENSION mysql_fdw; 如果是源码编译安装的MySQL，如果没有设置LD_LIBRARY_PATH，会报如下的错误: 123456CREATE EXTENSION mysql_fdw;ERROR: HV00L: failed to load the mysql query: libmysqlclient.so: cannot open shared object file: No such file or directoryHINT: export LD_LIBRARY_PATH to locate the libraryLOCATION: _PG_init, mysql_fdw.c:267Time: 74.768 ms 这时，需要停止PG服务器，然后在启动PG服务器之前，要配置好LD_LIBRARY_PATH环境变量，将它指向MySQL_HOME/lib目录下.即： 12export LD_LIBRARY_PATH=MySQL_HOME/lib:$LD_LIBRARY_PATHpg_ctl -D pg_data_dir start 然后再创建mysql_fdw即可。 123CREATE EXTENSION mysql_fdw ;CREATE EXTENSIONTime: 155.894 ms 连接外部表 12345678910111213141516171819202122232425262728CREATE SERVER mysql_server_beta FOREIGN DATA WRAPPER mysql_fdw OPTIONS (host 'your_ip_address', port 'your_mysql_port');CREATE USER MAPPING FOR 你的pg的用户名 SERVER mysql_server_beta OPTIONS (username 'your_mysql_user_name', password 'your_mysql_passwd');CREATE FOREIGN TABLE wb_status_ft ( id int, sid bigint, idstr varchar(64), mid bigint, user_id bigint, user_screen_name varchar(40), user_profile_image_url varchar(128), text varchar(1024), source varchar(256), thumbnail_pic varchar(256), bmiddle_pic varchar(256), original_pic varchar(256), retweeted_status_id varchar(64), geo varchar(256), reposts_count int, comments_count int, attitudes_count int, visible varchar(64), pic_urls varchar(1024), create_at timestamp, update_at timestamp, ad varchar(256), is_deleted smallint) SERVER mysql_server_beta OPTIONS (dbname '原mysql的数据库名', table_name '原mysql的表名'); done.]]></content>
      <categories>
        <category>postgresql</category>
        <category>mysql</category>
        <category>fdw</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>mysql</tag>
        <tag>fdw</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL导入微博数据]]></title>
    <url>%2F2016%2F09%2F30%2FPostgreSQL%E5%AF%BC%E5%85%A5%E5%BE%AE%E5%8D%9A%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[微博日志的数据 使用的PG版本为9.6.0 文件的每一行的内容格式如下: 1234&#123;"q":"keyword", "result":"statuses:[&#123;"id":xxxx,"created_at":"Thu Jul 16 12:55:27 +0800 2015"&#125;]"&#125; 关于导入JSON数据，可以参考上一徬 PostgresSQL导入json数据. 详细步骤123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176-- 创建父表CREATE TABLE status(data jsonb);-- 按年分区CREATE TABLE status2016( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2016-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2017-01-01' )) inherits (status);CREATE TABLE status2015( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2015-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2016-01-01' )) inherits (status);CREATE TABLE status2014( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2014-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2015-01-01' )) inherits (status);CREATE TABLE status2013( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2013-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2014-01-01' )) inherits (status);CREATE TABLE status2012( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2012-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2013-01-01' )) inherits (status);CREATE TABLE status2011( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2011-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2012-01-01' )) inherits (status);CREATE TABLE status2010( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2010-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2011-01-01' )) inherits (status);CREATE TABLE status2009( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2009-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2010-01-01' )) inherits (status);CREATE TABLE status2008( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2008-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2009-01-01' )) inherits (status);CREATE TABLE status2007( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2007-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2008-01-01' )) inherits (status);CREATE TABLE status2006( CHECK ( date((data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2006-01-01' AND date((data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2007-01-01' ) ) inherits (status);-- 创建id的唯一索引CREATE UNIQUE INDEX status_id_uniq ON status ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2016_id_uniq ON status2016 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2015_id_uniq ON status2015 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2014_id_uniq ON status2014 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2013_id_uniq ON status2013 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2012_id_uniq ON status2012 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2011_id_uniq ON status2011 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2010_id_uniq ON status2010 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2009_id_uniq ON status2009 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2008_id_uniq ON status2008 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2007_id_uniq ON status2007 ( (data-&gt;&gt;'id') );CREATE UNIQUE INDEX status2006_id_uniq ON status2006 ( (data-&gt;&gt;'id') );-- 创建分区的触发器CREATE OR REPLACE FUNCTION status_insert_trigger()RETURNS TRIGGER AS $$BEGIN IF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2016-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2017-01-01' ) THEN INSERT INTO status2016 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2015-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2016-01-01') THEN INSERT INTO status2015 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2014-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2015-01-01') THEN INSERT INTO status2014 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2013-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2014-01-01') THEN INSERT INTO status2013 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2012-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2013-03-01') THEN INSERT INTO status2012 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2011-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2012-01-01') THEN INSERT INTO status2011 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2010-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2011-01-01') THEN INSERT INTO status2010 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2009-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2010-01-01') THEN INSERT INTO status2009 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2008-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2009-01-01') THEN INSERT INTO status2008 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2007-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2008-01-01') THEN INSERT INTO status2007 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSIF ( date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &gt;= DATE '2006-01-01' AND date((NEW.data-&gt;&gt;'created_at')::timestamp with time zone) &lt; DATE '2007-01-01') THEN INSERT INTO status2006 VALUES (NEW.*) ON CONFLICT DO NOTHING; ELSE RAISE EXCEPTION 'Date out of range. Fix the measurement_insert_trigger() function! %\n', NEW.data; END IF; RETURN NULL;END;$$LANGUAGE plpgsql;-- 设置触发器CREATE TRIGGER status_insert_trigger BEFORE INSERT ON status FOR EACH ROW EXECUTE PROCEDURE status_insert_trigger();-- 将数组的微博数据，拆分成每一条微博的数据并插入到status表insert into status select jsonb_array_elements(data-&gt;'result'-&gt;'statuses') from import_status where jsonb_array_length(data-&gt;'result'-&gt;'statuses') &gt; 0 ON CONFLICT DO NOTHING;-- 创建时间字段的索引CREATE OR REPLACE FUNCTION f_to_imts(text) RETURNS timestamptz AS$$SELECT $1::timestamp with time zone $$ LANGUAGE sql IMMUTABLE;-- CREATE INDEX status_created_at ON status USING btree ( f_to_imts(data-&gt;&gt;'created_at') );-- SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status_created_at on status ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2016_created_at on status2016 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2015_created_at on status2015 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2014_created_at on status2014 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2013_created_at on status2013 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2012_created_at on status2012 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2011_created_at on status2011 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2010_created_at on status2010 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2009_created_at on status2009 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2008_created_at on status2008 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2007_created_at on status2007 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2006_created_at on status2006 ( f_to_imts((data-&gt;&gt;'created_at')) );-- SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status_text on status using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2016_text on status2016 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2015_text on status2015 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2014_text on status2014 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2013_text on status2013 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2012_text on status2012 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2011_text on status2011 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2010_text on status2010 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2009_text on status2009 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2008_text on status2008 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2007_text on status2007 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2006_text on status2006 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));-- text字段的全文索引SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2016_created_at on status2016 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2015_created_at on status2015 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2014_created_at on status2014 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2013_created_at on status2013 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2012_created_at on status2012 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2011_created_at on status2011 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2010_created_at on status2010 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2009_created_at on status2009 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2008_created_at on status2008 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2007_created_at on status2007 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2006_created_at on status2006 ( f_to_imts((data-&gt;&gt;'created_at')) );SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2016_text on status2016 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2015_text on status2015 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2014_text on status2014 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2013_text on status2013 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2012_text on status2012 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2011_text on status2011 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2010_text on status2010 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2009_text on status2009 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2008_text on status2008 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2007_text on status2007 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text'));SET maintenance_work_mem = '1GB'; CREATE INDEX CONCURRENTLY status2006_text on status2006 using gin(to_tsvector('testzhcfg', data-&gt;&gt;'text')); – user id 索引 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162CREATE INDEX CONCURRENTLY index_status_2016_user_id ON status2016 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2015_user_id ON status2015 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2014_user_id ON status2014 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2013_user_id ON status2013 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2012_user_id ON status2012 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2011_user_id ON status2011 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2010_user_id ON status2010 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2009_user_id ON status2009 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2008_user_id ON status2008 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2007_user_id ON status2007 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );CREATE INDEX CONCURRENTLY index_status_2006_user_id ON status2006 ( ((data-&gt;'user'-&gt;&gt;'id')::bigint) );使用`user_id`索引 explain SELECT (data-&gt;'user'-&gt;&gt;'id')::bigint from status order by (data-&gt;'user'-&gt;&gt;'id')::bigint asc limit 100; QUERY PLAN --------------------------------------------------------------------------------------------------------------------------- Limit (cost=3.40..24.43 rows=100 width=8) -&gt; Result (cost=3.40..6920441.97 rows=32905725 width=8) -&gt; Merge Append (cost=3.40..6262327.47 rows=32905725 width=199) Sort Key: ((((status.data -&gt; 'user'::text) -&gt;&gt; 'id'::text))::bigint) -&gt; Sort (cost=0.01..0.02 rows=1 width=32) Sort Key: ((((status.data -&gt; 'user'::text) -&gt;&gt; 'id'::text))::bigint) -&gt; Seq Scan on status (cost=0.00..0.00 rows=1 width=32) -&gt; Index Scan using user_id on status2016 (cost=0.44..4321159.24 rows=29321520 width=190) -&gt; Index Scan using index_status_2015_user_id on status2015 (cost=0.43..269118.91 rows=1850299 width=207) -&gt; Index Scan using index_status_2014_user_id on status2014 (cost=0.43..256224.11 rows=1072512 width=317) -&gt; Index Scan using index_status_2013_user_id on status2013 (cost=0.42..119684.35 rows=546128 width=356) -&gt; Index Scan using index_status_2012_user_id on status2012 (cost=0.29..28551.76 rows=93031 width=530) -&gt; Index Scan using index_status_2011_user_id on status2011 (cost=0.29..4556.18 rows=15193 width=513) -&gt; Index Scan using index_status_2010_user_id on status2010 (cost=0.28..896.41 rows=2942 width=512) -&gt; Index Scan using index_status_2009_user_id on status2009 (cost=0.14..20.42 rows=19 width=32) -&gt; Index Scan using index_status_2008_user_id on status2008 (cost=0.15..64.55 rows=1360 width=32) -&gt; Index Scan using index_status_2007_user_id on status2007 (cost=0.15..64.55 rows=1360 width=32) -&gt; Index Scan using index_status_2006_user_id on status2006 (cost=0.15..64.55 rows=1360 width=32)(18 rows)Time: 36.967 msexplain SELECT (data-&gt;'user'-&gt;&gt;'id')::bigint from status order by (data-&gt;'user'-&gt;&gt;'id') asc limit 100; QUERY PLAN ------------------------------------------------------------------------------------------------- Limit (cost=3445800.51..3445800.76 rows=100 width=40) -&gt; Sort (cost=3445800.51..3528064.83 rows=32905725 width=40) Sort Key: (((status.data -&gt; 'user'::text) -&gt;&gt; 'id'::text)) -&gt; Result (cost=0.00..2188167.37 rows=32905725 width=40) -&gt; Append (cost=0.00..1365524.24 rows=32905725 width=199) -&gt; Seq Scan on status (cost=0.00..0.00 rows=1 width=32) -&gt; Seq Scan on status2016 (cost=0.00..1183150.20 rows=29321520 width=190) -&gt; Seq Scan on status2015 (cost=0.00..73767.99 rows=1850299 width=207) -&gt; Seq Scan on status2014 (cost=0.00..67815.12 rows=1072512 width=317) -&gt; Seq Scan on status2013 (cost=0.00..31833.28 rows=546128 width=356) -&gt; Seq Scan on status2012 (cost=0.00..7462.31 rows=93031 width=530) -&gt; Seq Scan on status2011 (cost=0.00..1189.93 rows=15193 width=513) -&gt; Seq Scan on status2010 (cost=0.00..231.42 rows=2942 width=512) -&gt; Seq Scan on status2009 (cost=0.00..3.19 rows=19 width=32) -&gt; Seq Scan on status2008 (cost=0.00..23.60 rows=1360 width=32) -&gt; Seq Scan on status2007 (cost=0.00..23.60 rows=1360 width=32) -&gt; Seq Scan on status2006 (cost=0.00..23.60 rows=1360 width=32)(17 rows)Time: 1.610 ms]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL导入JSON]]></title>
    <url>%2F2016%2F09%2F29%2FPostgreSQL%E5%AF%BC%E5%85%A5JSON%2F</url>
    <content type="text"><![CDATA[过滤Unicode字符1sed -i 's/\u0000//g' json.txt 使用pgfutterGithub pgfutter 1pgfutter --jsonb json 你的json文件 创建唯一索引1CREATE UNIQUE INDEX status_id_uniq ON status ( (data-&gt;&gt;'id') ); 注意，-&gt;返回的是jsonb，-&gt;&gt;返回的是text. 插入数据导入的json对象是 123456789101112&#123;"result":&#123; "statuees":[ &#123; "id":111, "text":"data" &#125; ]&#125;&#125;然后只抽取 statuses 的来插入到另一张表里.即将数组元素拆分成每个元素（即每一条微博），然后导入到另一个表里，每一行代表一条微博. 1insert into status select jsonb_array_elements(data-&gt;'result'-&gt;'statuses') from import_status where jsonb_array_length(data-&gt;'result'-&gt;'statuses') &gt; 0 ON CONFLICT DO NOTHING; 创建时间索引12345create index status_created_at on status (((data-&gt;&gt;'created_at')::timestamp with time zone));ERROR: 42P17: functions in index expression must be marked IMMUTABLELOCATION: ComputeIndexAttrs, indexcmds.c:1108Time: 0.354 ms use-timestamptz 解决办法: 1234567CREATE OR REPLACE FUNCTION f_to_imts(text) RETURNS timestamptz AS$$SELECT $1::timestamp with time zone $$ LANGUAGE sql IMMUTABLE; create index status_created_at on status ( f_to_imts(data-&gt;&gt;'created_at') );]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 中使用MyBatis]]></title>
    <url>%2F2016%2F09%2F28%2FSpring-Boot-%E4%B8%AD%E4%BD%BF%E7%94%A8MyBatis%2F</url>
    <content type="text"><![CDATA[pom.xml123456789101112131415161718192021222324252627282930313233343536373839 &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 注意上面的，如果你的mapper接口与xml文件是放在同一个目录下的，那需要注意配置上面的resource/main/java里要include你的xml文件。不然，编译后你会看到，并没有将xml文件拷贝过去. application.properties123456789101112131415161718##mysqlspring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.username=your-user-namespring.datasource.password=your-user-passwdspring.datasource.url=jdbc:mysql://mysql-host-ip:mysql-port/yoourDBName?useUnicode=true&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=truespring.datasource.dbcp.max-active=64spring.datasource.dbcp.max-idle=64spring.datasource.dbcp.max-wait=0spring.datasource.dbcp.validation-query=select 1spring.datasource.dbcp.test-while-idle=truespring.datasource.dbcp.min-evictable-idle-time-millis=20000000spring.datasource.dbcp.time-between-eviction-runs-millis=3600000spring.datasource.type=org.apache.commons.dbcp.BasicDataSourcemybatis.config-location=classpath:mybatis-config.xmlmybatis.mapperLocations[0]=classpath:com/yourcompany/mapper/*.xml 使用1234567@Servicepublic class OperationLogService &#123; @Autowired private OperationLogMapper operationLogMapper; ....&#125;]]></content>
      <categories>
        <category>mybatis</category>
        <category>spring-boot</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>mybatis</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中的analyze与optimize]]></title>
    <url>%2F2016%2F09%2F26%2FMySQL%E4%B8%AD%E7%9A%84analyze%E4%B8%8Eoptimize%2F</url>
    <content type="text"><![CDATA[analyze作用： 分析表主要作用是分析并保存索引的分布. analyze-table MySQL document 语法: 12ANALYZE [NO_WRITE_TO_BINLOG | LOCAL] TABLE tbl_name [, tbl_name] ... 使用ANALYZE TABLE分析表的过程中，数据库系统会对表加一个只读锁。在分析期间，只能读取表中的记录，不能更新和插入记录。ANALYZE TABLE语句能够分析InnoDB和MyISAM类型的表。 例如： 1234567891011121314151617181920212223242526272829mysql&gt; show index from wb_status;+-----------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+-----------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| wb_status | 0 | PRIMARY | 1 | id | A | 1195935 | NULL | NULL | | BTREE | | || wb_status | 0 | idx_sid | 1 | sid | A | 1196049 | NULL | NULL | | BTREE | | || wb_status | 1 | idx_user_id | 1 | user_id | A | 678760 | NULL | NULL | YES | BTREE | | || wb_status | 1 | ngram_idx | 1 | text | NULL | 1196049 | NULL | NULL | | FULLTEXT | | |+-----------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+4 rows in set (0.00 sec)mysql&gt; analyze table wb_status;+----------------+---------+----------+----------+| Table | Op | Msg_type | Msg_text |+----------------+---------+----------+----------+| test.wb_status | analyze | status | OK |+----------------+---------+----------+----------+1 row in set (0.03 sec)mysql&gt; show index from wb_status;+-----------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+-----------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| wb_status | 0 | PRIMARY | 1 | id | A | 1279457 | NULL | NULL | | BTREE | | || wb_status | 0 | idx_sid | 1 | sid | A | 1279457 | NULL | NULL | | BTREE | | || wb_status | 1 | idx_user_id | 1 | user_id | A | 887945 | NULL | NULL | YES | BTREE | | || wb_status | 1 | ngram_idx | 1 | text | NULL | 1279457 | NULL | NULL | | FULLTEXT | | |+-----------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+4 rows in set (0.00 sec) optimize作用: 语法: 12OPTIMIZE [NO_WRITE_TO_BINLOG | LOCAL] TABLE tbl_name [, tbl_name] ... 该语句对InnoDB和MyISAM类型的表都有效.重新组织表数据和索引数据的物理存储，以减少存储空间以及提高I/O的效率.具体的操作，还要依赖于表的存储引擎的类型. 无法用于视图，但可用于分区表. 如果用于视图的话，会报如下类似错误: 12345678910mysql&gt; optimize table wsv;+----------+----------+----------+------------------------------+| Table | Op | Msg_type | Msg_text |+----------+----------+----------+------------------------------+| test.wsv | optimize | Error | 'test.wsv' is not BASE TABLE || test.wsv | optimize | status | Operation failed |+----------+----------+----------+------------------------------+2 rows in set (0.00 sec)mysql&gt; 参考资料stackexchange analyze-table optimize-table serverfault 注： OPTIMIZE TABLE simply copies the table to remove unused space. If the table is MyISAM, ANALYZE TABLE is also performed to update index statistics for the sake of the Query Optimizer. If the table is InnoDB, ANALYZE TABLE is bypassed. 这里这个answer说，如果是InnoDB，则analyze table会忽略不处理？ 但官方文档里说: For InnoDB tables, OPTIMIZE TABLE is mapped to ALTER TABLE … FORCE, which rebuilds the table to update index statistics and free unused space in the clustered index 这表明，它其实也已经自动更新了索引的统计信息了的。然后就不需要再执行analyze table的意思？ 我开始时，还以为对于InnoDB，它并不会更新索引的统计信息，而analyze table又被忽略… 51cto [moremysql.weebly.com])(http://moremysql.weebly.com/blog/optimize-vs-analyze-table-in-mysql)]]></content>
      <categories>
        <category>mysql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL PITR实践]]></title>
    <url>%2F2016%2F09%2F19%2FPostgreSQL-PITR%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[初始化示例数据库12345678910111213141516171819202122232425262728293031┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:22:35]└─[0] &lt;&gt; mkdir pitr-data┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:22:47]└─[0] &lt;&gt; initdb -D pitr-data The files belonging to this database system will be owned by user "sky".This user must also own the server process.The database cluster will be initialized with locale "zh_CN.UTF-8".The default database encoding has accordingly been set to "UTF8".initdb: could not find suitable text search configuration for locale "zh_CN.UTF-8"The default text search configuration will be set to "simple".Data page checksums are disabled.fixing permissions on existing directory pitr-data ... okcreating subdirectories ... okselecting default max_connections ... 100selecting default shared_buffers ... 128MBselecting dynamic shared memory implementation ... posixcreating configuration files ... okrunning bootstrap script ... okperforming post-bootstrap initialization ... oksyncing data to disk ... okWARNING: enabling "trust" authentication for local connectionsYou can change this by editing pg_hba.conf or using the option -A, or--auth-local and --auth-host, the next time you run initdb.Success. You can now start the database server using: pg_ctl -D pitr-data -l logfile start 修改配置文件创建一个保存归档文件的目录： 12345┌─[sky@sky-linux] - [/ihome/db/postgresql/pitr-data] - [2016-09-19 03:31:47]└─[0] &lt;&gt; mkdir archive_logs┌─[sky@sky-linux] - [/ihome/db/postgresql/pitr-data] - [2016-09-19 03:31:59]└─[0] &lt;&gt; pwd/ihome/db/postgresql/pitr-data 修改配置文件postgresql.conf 12345678910111213┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:24:51]└─[0] &lt;&gt; vim pitr-data/postgresql.conf 将下面三个参数修改如下:wal_level = hot_standby # minimal, archive, hot_standby, or logical # (change requires restart)archive_mode = on # enables archiving; off, on, or always # (change requires restart)archive_command = 'cp %p /ihome/db/postgresql/pitr-data/archive_logs/%f' # command to use to archive a logfile segment # placeholders: %p = path of file to archive # %f = file name only # e.g. 'test ! -f /mnt/server/archivedir/%f &amp;&amp; cp %p /mnt/server/archivedir/%f' 然后启动PG: 123┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:36:08]└─[1] &lt;&gt; pg_ctl -D pitr-data startserver starting 插入测试数据12345678910111213141516171819202122232425[local]:5432 sky@postgres=# CREATE TABLE test_pitr (id int);CREATE TABLETime: 2.653 ms[local]:5432 sky@postgres=# INSERT INTO test_pitr VALUES (1), (2[local]:5432 sky@postgres=# INSERT INTO test_pitr VALUES (1), (2), (3);INSERT 0 3Time: 1.695 ms[local]:5432 sky@postgres=# SELECT * from test_pitr ; id ---- 1 2 3(3 rows)Time: 0.144 ms[local]:5432 sky@postgres=# SELECT now(); now ------------------------------- 2016-09-19 15:38:48.364466+08(1 row)Time: 0.196 ms[local]:5432 sky@postgres=# 然后进行基础备份12345678[local]:5432 sky@postgres=# select pg_start_backup('basebackup20160915'); pg_start_backup ----------------- 0/3000028(1 row)Time: 1913.146 ms[local]:5432 sky@postgres=# 执行完上面的命令后，不要关闭该终端，然后从另一个终端执行备份: 12┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:41:36]└─[0] &lt;&gt; tar -cvf pitr-data.tar.gz pitr-data 基础备份完后，回到psql终端，停止基础备份状态: 12345678910[local]:5432 sky@postgres=# select pg_stop_backup();NOTICE: 00000: pg_stop_backup complete, all required WAL segments have been archivedLOCATION: do_pg_stop_backup, xlog.c:10543 pg_stop_backup ---------------- 0/3000168(1 row)Time: 1102.195 ms[local]:5432 sky@postgres=# 再插入不同时间点的数据12345678910[local]:5432 sky@postgres=# INSERT INTO test_pitr VALUES (111),(222),(333);INSERT 0 3Time: 1.695 ms[local]:5432 sky@postgres=# SELECT now(); now ------------------------------- 2016-09-19 15:44:32.996545+08(1 row)Time: 0.149 ms 1234567891011[local]:5432 sky@postgres=# INSERT INTO test_pitr VALUES (1111),(2222),(3333);INSERT 0 3Time: 0.807 ms[local]:5432 sky@postgres=# SELECT now(); now ------------------------------- 2016-09-19 15:44:58.188828+08(1 row)Time: 0.147 ms[local]:5432 sky@postgres=# 恢复切换事务日志文件: 1234567[local]:5432 sky@postgres=# select pg_switch_xlog(); pg_switch_xlog ---------------- 0/4000510(1 row)Time: 41.775 ms 停止PostgreSQL1234┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:41:36]└─[0] &lt;&gt; pg_ctl -D pitr-data stop waiting for server to shut down.... doneserver stopped 恢复到时间点 2016-09-19 15:44:32.996545+08即上面的: 12345678910[local]:5432 sky@postgres=# INSERT INTO test_pitr VALUES (111),(222),(333);INSERT 0 3Time: 1.695 ms[local]:5432 sky@postgres=# SELECT now(); now ------------------------------- 2016-09-19 15:44:32.996545+08(1 row)Time: 0.149 ms 执行以下命令： 123456789101112131415161718192021222324252627282930313233343536373839404142┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:50:07]└─[0] &lt;&gt; mv pitr-data pitr-data.bak┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:50:19]└─[0] &lt;&gt; ll total 138Mdrwxr-xr-x 3 sky sky 4.0K 1月 12 2016 buildlrwxrwxrwx 1 sky sky 16 9月 19 15:29 current -&gt; postgresql-9.5.0drwx------ 20 sky sky 4.0K 9月 19 15:46 pitr-data.bak-rw-r--r-- 1 sky sky 102M 9月 19 15:41 pitr-data.tar.gzdrwxr-xr-x 7 sky sky 4.0K 1月 15 2016 postgresql-9.5.0-rw-r--r-- 1 sky sky 18M 1月 12 2016 postgresql-9.5.0.tar.bz2drwxr-xr-x 7 sky sky 4.0K 8月 18 14:32 postgresql-9.6.0drwxr-xr-x 6 sky sky 4.0K 8月 18 14:26 postgresql-9.6beta4-rw-r--r-- 1 sky sky 19M 8月 11 23:54 postgresql-9.6beta4.tar.bz2┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:50:37]└─[0] &lt;&gt; tar -xvf pitr-data.tar.gz pitr-data ┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:51:13]└─[0] &lt;&gt; lltotal 138Mdrwxr-xr-x 3 sky sky 4.0K 1月 12 2016 buildlrwxrwxrwx 1 sky sky 16 9月 19 15:29 current -&gt; postgresql-9.5.0drwx------ 20 sky sky 4.0K 9月 19 15:39 pitr-datadrwx------ 20 sky sky 4.0K 9月 19 15:46 pitr-data.bak-rw-r--r-- 1 sky sky 102M 9月 19 15:41 pitr-data.tar.gzdrwxr-xr-x 7 sky sky 4.0K 1月 15 2016 postgresql-9.5.0-rw-r--r-- 1 sky sky 18M 1月 12 2016 postgresql-9.5.0.tar.bz2drwxr-xr-x 7 sky sky 4.0K 8月 18 14:32 postgresql-9.6.0drwxr-xr-x 6 sky sky 4.0K 8月 18 14:26 postgresql-9.6beta4-rw-r--r-- 1 sky sky 19M 8月 11 23:54 postgresql-9.6beta4.tar.bz2┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:51:40]└─[0] &lt;&gt; ┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:51:40]└─[0] &lt;&gt; rm -rf pitr-data/pg_xlog┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:52:28]└─[0] &lt;&gt; cp -r pitr-data.bak/pg_xlog pitr-data/┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:52:58]└─[0] &lt;&gt; cp -r pitr-data.bak/archive_logs pitr-data/┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:54:23]└─[0] &lt;&gt; rm -rf pitr-data/pg_xlog/archive_status/*zsh: sure you want to delete all the files in /ihome/db/postgresql/pitr-data/pg_xlog/archive_status [yn]? y 创建恢复文件：这个文件名字为recovery.conf，放在$DATA目录的根目录下即可。 12345678910111213┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:55:51]└─[0] &lt;&gt; cp current/share/recovery.conf.sample pitr-data/┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:56:09]└─[0] &lt;&gt; vim pitr-data/recovery.conf.sample ┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:56:39]└─[0] &lt;&gt; mv pitr-data/recovery.conf.sample pitr-data/recovery.conf ┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 03:56:51]└─[0] &lt;&gt; vim pitr-data/recovery.conf 添加以下内容：recovery_target_time = '2016-09-19 15:44:32.996545+08' # e.g. '2004-07-14 22:39:00 EST' restore_command = 'cp /ihome/db/postgresql/pitr-data/archive_logs/%f %p' # e.g. 'cp /mnt/server/archivedir/%f %p' recovery_target_time：即是我们想要恢复到的某个时间点.restore_command：即是原来在postgresql.conf里配置的archive_command，只是将%p与%f互换下位置即可. 配置好之后，即可重启PG了. 由于在操作时有点问题，我又重做了一次以上操作并修正了忽略的步骤就成功了，时间点恢复为:2016-09-19 16:21:06.174798+08如果成功的话，可以看到类似以下的信息: 123456789101112131415161718┌─[sky@sky-linux] - [/ihome/db/postgresql] - [2016-09-19 04:29:22]└─[0] &lt;&gt; LOG: database system was interrupted; last known up at 2016-09-19 16:19:36 CSTLOG: starting point-in-time recovery to 2016-09-19 16:21:06.174798+08LOG: restored log file "000000010000000000000002" from archiveLOG: redo starts at 0/2000060LOG: consistent recovery state reached at 0/2000168LOG: restored log file "000000010000000000000003" from archiveLOG: restored log file "000000010000000000000004" from archiveLOG: recovery stopping before commit of transaction 666, time 2016-09-19 16:21:48.575228+08LOG: redo done at 0/4000120LOG: last completed transaction was at log time 2016-09-19 16:21:03.886997+08cp: cannot stat ‘/ihome/db/postgresql/pitr-data/archive_logs/00000002.history’: No such file or directoryLOG: selected new timeline ID: 2cp: cannot stat ‘/ihome/db/postgresql/pitr-data/archive_logs/00000001.history’: No such file or directoryLOG: archive recovery completeLOG: MultiXact member wraparound protections are now enabledLOG: database system is ready to accept connectionsLOG: autovacuum launcher started 12345678910111213[local]:5432 sky@postgres=# SELECT * from test_pitr ; id ----- 1 2 3 111 222 333(6 rows)Time: 0.224 ms[local]:5432 sky@postgres=# 可以看到1111, 2222, 3333这数据并没有了.]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
        <category>pitr</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
        <tag>pitr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis中缓存策略]]></title>
    <url>%2F2016%2F09%2F09%2FRedis%E4%B8%AD%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[Redis中缓存策略 volatile-lru：从数据集中，将设置了过期时间的key,按最近最少使用的数据淘汰。 volatile-ttl：从数据集中，只将设置了过期时间的key，按即将过期时间的最短的优先淘汰。即ttl key，结果最小的优先淘汰。 volatile-random：从数据集中，只将设置了过期时间的数据按随机淘汰 allkeys-lru：从数据集中（不管有没有设置过期时间）按最近最少使用的数据淘汰 allkeys-random：从数据集中（不管有没有设置过期时间）随机淘汰数据. no-enviction：禁用淘汰策略 默认的缓存策略为: 123# The default is:## maxmemory-policy noeviction 示例12345678910111213127.0.0.1:6379&gt; keys * 1) "heloo719999sfsadf" 2) "heloo71" 3) "heloo712" 4) "heloo89" 5) "heloo713" 6) "heloo717" 7) "heloo732" 8) "heloo731" 9) "heloo715"10) "heloo719999"127.0.0.1:6379&gt; CONFIG SET maxmemory-policy noevictionOK noeviction12127.0.0.1:6379&gt; set he wolsdkfasldkf(error) OOM command not allowed when used memory &gt; 'maxmemory'. allkeys-random1234127.0.0.1:6379&gt; CONFIG SET maxmemory-policy allkeys-randomOK127.0.0.1:6379&gt; set he123123 wolsdkfasldksdf21342134OK 可以看到，这种策略，一般是不会出现OOM的。因为它会不断的淘汰原有的key，释放内存给新的key. allkeys-lru1234127.0.0.1:6379&gt; CONFIG SET maxmemory-policy allkeys-lruOK127.0.0.1:6379&gt; set he123123123 wolsdkfasldksdf21342134123OK 可以看到，这种策略，一般是不会出现OOM的。因为它会不断的淘汰原有的key，释放内存给新的key.只是这个是以最近最少使用为原则. volatile-random12345678127.0.0.1:6379&gt; CONFIG SET maxmemory-policy volatile-randomOK127.0.0.1:6379&gt; set sdfhe123123123123 wolsdkfasldksdf21342134sdfasdfasdfsafasfasfsadfsdfsdfsdasdfsdfsdfsafsdf(error) OOM command not allowed when used memory &gt; 'maxmemory'.127.0.0.1:6379&gt; EXPIRE sdfhe123123123123 360(integer) 1127.0.0.1:6379&gt; set h1 wl2OK 其他的两个volatile-xxx的，也同理，只是一个是最近最少使用，一个是按ttl最短来淘汰.]]></content>
      <categories>
        <category>redis</category>
        <category>nosql</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>nosql</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境一次Redis导致OOM Killer的问题]]></title>
    <url>%2F2016%2F09%2F06%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%80%E6%AC%A1Redis%E5%AF%BC%E8%87%B4OOM-Killer%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Redis 引发系统OOM Killer昨晚（2016-9-5），生产环境的Redis发生警报，一段时间后，内存被降到50%多（之前一直在90%左右），然后发现Redis的进程挂了。第一时间看Redis的log文件，发现有如下信息: 12345678910866:M 05 Sep 20:15:19.711 # Background saving terminated by signal 910866:M 05 Sep 20:18:43.898 # Background saving terminated by signal 910866:M 05 Sep 20:26:46.434 # Background saving terminated by signal 910866:M 05 Sep 20:34:49.161 # Background saving terminated by signal 910866:M 05 Sep 20:42:52.406 # Background saving terminated by signal 910866:M 05 Sep 20:42:55.332 # Background saving terminated by signal 91758:M 05 Sep 21:28:11.114 # Background saving terminated by signal 91758:M 05 Sep 21:30:18.479 # Background saving terminated by signal 91758:M 05 Sep 21:32:55.275 # Background saving terminated by signal 9 可知Redis收到kill -9的信号终止了.然后，当时第一反应，应该是“有人”人工去kill Redis进程吗？不知道怎么的，当时自己就去查看操作系统日志dmesg -T | grep redis，真的发现是有内幕： 123456789101112dmesg -T | grep redis | grep "Out of memory"[Mon Sep 5 20:15:18 2016] Out of memory: Kill process 725 (redis-server) score 517 or sacrifice child[Mon Sep 5 20:18:42 2016] Out of memory: Kill process 786 (redis-server) score 517 or sacrifice child[Mon Sep 5 20:26:45 2016] Out of memory: Kill process 914 (redis-server) score 517 or sacrifice child[Mon Sep 5 20:34:48 2016] Out of memory: Kill process 1022 (redis-server) score 517 or sacrifice child[Mon Sep 5 20:42:50 2016] Out of memory: Kill process 1127 (redis-server) score 517 or sacrifice child[Mon Sep 5 20:42:52 2016] Out of memory: Kill process 10866 (redis-server) score 517 or sacrifice child[Mon Sep 5 20:50:57 2016] Out of memory: Kill process 1235 (redis-server) score 517 or sacrifice child[Mon Sep 5 20:50:57 2016] Out of memory: Kill process 10866 (redis-server) score 517 or sacrifice child[Mon Sep 5 21:28:10 2016] Out of memory: Kill process 1886 (redis-server) score 479 or sacrifice child[Mon Sep 5 21:30:17 2016] Out of memory: Kill process 1758 (redis-server) score 479 or sacrifice child[Mon Sep 5 21:32:54 2016] Out of memory: Kill process 1972 (redis-server) score 479 or sacrifice child 123dmesg -T | grep redis | grep "oom-killer"[Mon Sep 5 20:26:44 2016] redis-server invoked oom-killer: gfp_mask=0x10200da, order=0, oom_score_adj=0[Mon Sep 5 21:32:53 2016] redis-server invoked oom-killer: gfp_mask=0x8200da, order=0, oom_score_adj=0 当天查看的Redis内存信息如下: 12345678910111213141516# Memoryused_memory:7877146344used_memory_human:7.34Gused_memory_rss:8699490304used_memory_rss_human:8.10Gused_memory_peak:8462552976used_memory_peak_human:7.88Gtotal_system_memory:16828653568total_system_memory_human:15.67Gused_memory_lua:37888used_memory_lua_human:37.00Kmaxmemory:9573741824maxmemory_human:8.92Gmaxmemory_policy:noevictionmem_fragmentation_ratio:1.10mem_allocator:jemalloc-4.0.3 原因当时服务器还有个MySQL slave在进行复制备份，服务器一共16GB的内存，然后MySQL用掉了5GB，还有11GB内存，除去一些其他的简单的占用和消耗外，估计还有10GB的内存真正给Redis可用。 可以看到上面的INFO，当时分配给Redis最大的内存为差不多9GB，那应试还有1GB可用空间，那到底是什么导致了OS触发OOM Killer机制呢？ 原来，Redis当时开启了RDB功能，而Redis自身是通过fork()进程来处理RDB文件的。可以man fork知道，它是精确复制与父进程来处理RDB文件的。 Redis在后台的存储机制依赖于操作系统中fork的copy-on-write：也就是redis fork（创建一个子进程）是父进程的一个完整精确拷贝。子进程转储到磁盘上的数据库然后退出。理论上来说，子进程作为一个副本应该使用和父亲一样多的内存，但是实际上由于大部分现代操作系统的copy-on-write的实现，父进程和子进程将共享内存页。当他被父进程或者子进程改变的时候，一个内存页将被复制。因此，从理论上讲，当子进程存储的时候，所有内存页可能被改变，Linux不能提前告诉子进程多少内存被使用，所以如果overcommit_memory设置被设置为0，创建将会失败，除非有同样多的空闲内存。结果是，如果你有3GB的redis数据并且只有2GB的空闲内存，它将会失败。 把overcommit_memory设置为1来告诉Linux以更加乐观的方式来执行fork操作，并且这确实是你想要的。 参考资料: Redis FAQifeve redis faq中文翻译 overcommit_memory 对fork的影响我们可以来做一个实验，来一步一步理解这个参数到fork的影响.测试的环境是: 123456789┌─[sky@sky-linux] - [~] - [2016-09-06 02:43:37]└─[0] &lt;&gt; uname -aLinux sky-linux 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux┌─[sky@sky-linux] - [~] - [2016-09-06 02:46:14]└─[0] &lt;&gt; free -h total used free shared buffers cachedMem: 15G 10G 4.6G 750M 209M 3.8G-/+ buffers/cache: 7.0G 8.6GSwap: 0B 0B 0B 可以看到，还有8.6GB空闲内存。默认的情况下，overcommit_memory的值是： 123┌─[sky@sky-linux] - [~] - [2016-09-06 02:47:16]└─[0] &lt;&gt; cat /proc/sys/vm/overcommit_memory 0 即它是以试探式分配内存，如果不够的话，就直接拒绝该次的内存分配. 示例代码：父进程分配了5GB，这时再fork()一个子进程，看看会发生什么事： 12345678910111213141516171819202122232425262728293031323334#include&lt;stdio.h&gt;#include &lt;unistd.h&gt;int main()&#123; void *ptr_one; pid_t childPID; ptr_one = calloc(1342177280, sizeof(int)); if (ptr_one == 0) &#123; printf("ERROR: Out of memory\n"); return 1; &#125; childPID = fork(); if(childPID &gt;= 0) // fork was successful &#123; if(childPID == 0) // child process &#123; printf("\n child process\n"); sleep(60); &#125; else //Parent process &#123; printf("\n parent process\n"); sleep(60); &#125; &#125; else // fork failed &#123; printf("\n Fork failed, quitting!!!!!!\n"); return 1; &#125; return 0;&#125; overcommit_memory = 0编译运行： 12345678910┌─[sky@sky-linux] - [/tmp] - [2016-09-06 02:56:40]└─[0] &lt;&gt; gcc mall.c mall.c: In function ‘main’:mall.c:7:13: warning: incompatible implicit declaration of built-in function ‘calloc’ [enabled by default] ptr_one = calloc(1342177280, sizeof(int)); ^┌─[sky@sky-linux] - [/tmp] - [2016-09-06 02:56:44]└─[0] &lt;&gt; ./a.out Fork failed, quitting!!!!!! 因为空闲内存是8.6G，而父进程使用了5GB，这时再fork一个子进程的话，那5GB+5GB=10GB，这时是不够内存分配的，所以OS直接拒绝了该次内存申请. overcommit_memory = 112345678sky-linux# echo "1" &gt; /proc/sys/vm/overcommit_memory┌─[sky@sky-linux] - [/tmp] - [2016-09-06 02:56:48]└─[1] &lt;&gt; ./a.out parent process child process 这时查看内存使用情况: 1234sky-linux# free -h total used free shared buffers cachedMem: 15G 15G 227M 606M 116M 3.2G-/+ buffers/cache: 11G 3.6G 8.6GB-5GB=3.6GB，那为什么不是占用10GB，而只是5GB呢？这是因为Linux使用copy-on-write机制.它只对要修改的数据块进行copy-and-write。 overcommit_memory = 2 于禁止overcommit (vm.overcommit_memory=2) 还需要细说：首先，如何才算是overcommit呢？kernel设有一个阈值，申请的内存总数超过这个阈值就算overcommit，在/proc/meminfo中可以看到这个阈值的大小： 123456789# grep -i commit /proc/meminfoCommitLimit: 5967744 kBCommitted_AS: 5363236 kB123# grep -i commit /proc/meminfoCommitLimit: 5967744 kBCommitted_AS: 5363236 kB CommitLimit: 就是overcommit的阈值，申请的内存总数超过CommitLimit的话就算是overcommit。那么这个阈值是如何计算出来的呢？它既不是物理内存的大小，也不是free memory的大小，它是通过内核参数间接设置的，公式如下：CommitLimit = (Physical RAM * vm.overcommit_ratio / 100) + Swap 这个是非常严格的，这样子，因为它是never overcommit。运行上面的代码: 123┌─[sky@sky-linux] - [/tmp] - [2016-09-06 04:23:00]└─[1] &lt;&gt; ./a.outERROR: Out of memory 可以看到它直接报错了，即申请5GB内存不成功。因为CommitLimit=15GB * 50 /100 = 7.5GB，即最多可以分配7.5GB空间，但已经用了7GB，这时再申请5GB的话，已经超过了7.5GB的限制，所以OS直接拒绝了该次内存申请。 参考资料: linuxperf coolshell 解决 加内存咯（如果已经充分利用了Redis的存储结构来保存了最适合的数据，即Redis层已经最优了，不然的话，可以先优化Redis层先） 将Redis的Maxmemory调到可用的物理内存的3/5，并且将overcommit_memory=1，这样子虽然可以避免OOM，不过，这样子可以让我们知道，物理内存是瓶颈了。 调整Redis的OOM权重，即不能让OS的OOM机制Kill掉redis，但这样子会导致OOM Killer其他进程哦: 123456echo "-17" &gt; /proc/redis的进程IP/oom_adj新版本的Linux参数修改为：[Tue Sep 6 16:50:06 2016] echo (349): /proc/5360/oom_adj is deprecated, please use /proc/5360/oom_score_adj instead.即使用 oom_score_adj 来代替. OOM Killer是会kill掉 /proc/PID/oom_score（新版本为oom_score_adj)中分数越高的进程.(oom_score_adj的范围为-1000到1000) 可以模拟触发OOM： 1echo f &gt; /proc/sysrq-trigger 执行完上面的命令后，查看 1dmesg -T 查找出系统中首先会被Kill的进程1dstat --top-oom 1for i in /proc/*/oom_score; do pid=$(echo "$&#123;i&#125;" | cut -d/ -f3); echo "oom_score=$(cat "$&#123;i&#125;"), PID=$&#123;pid&#125;, exe=$(readlink -e /proc/$&#123;pid&#125;/exe)"; done 2&gt; /dev/null | sort -rn -t, -k 1.11 | head -n 50 参考资料 查看历史命令的执行时间1export HISTTIMEFORMAT="%d/%m/%y %T " 这有个问题，就是之前的历史命令，会统一为执行这个export的命令，然后之后的命令才会记录下时间.]]></content>
      <categories>
        <category>redis</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《番茄工作法图解》读书笔记]]></title>
    <url>%2F2016%2F09%2F01%2F%E3%80%8A%E7%95%AA%E8%8C%84%E5%B7%A5%E4%BD%9C%E6%B3%95%E5%9B%BE%E8%A7%A3%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[目标 番茄工作法是一套简单的工具和流程，用以提升你个人和所在团队的生产力，从而做到: 减轻时间焦虑 提升集中力和注意力，减少中断 增强决策意识 唤醒激励和持久激励 巩固达成目标的决心 完善预估流程，精确地保质保量 改进工作学习流程 强化决断力，快刀斩乱麻 所需工具 番茄钟一枚 铅笔一支（最好带橡皮） 纸质表格三张（白纸即可，横格更好） “今日待办” 表格 “活动清单” 表格 记录表格 术语番茄钟 厨房定时器，用来衡量25分钟的时间段，在这段时间内专注于一项工作。 活动 要完成的工作任务。番茄工作法适用于多种类型的活动 内部中断 番茄钟时间内，来自自身的干扰，想要离开座位拿点喝的，或用一分钟刷刷微博. 外部中断 番茄钟时间内，在社交场合工作的人士会遇到，同学找你问作业，电脑提醒收到新邮件，即时消息等外界干扰。 预估 预测某项目由哪些活动组成（定性预测），以及某活动需要多少番茄钟完成（定量预估）。通过长期实践番茄工作法努力减少预估误差。 基本方法 将要完成的活动全部填入活动清单表格，每天早晨，从其中选出数项要在今天进行的活动，抄入今日待办表格 开始工作: 在今日待办中选择一项最重要的活动 启动番茄钟，时间设定为25分钟 开始工作，直到番茄钟响铃 在今日待办表格该活动右侧标一个x 休息片刻(3-5分钟) 开始下一个番茄钟，继续工作，直到完成这项活动，在今日待办表格上划掉它 每四个番茄钟后，多休息一会儿（15-30分钟） 规则和技巧 番茄钟不可分割 如果一项活动要花花费超过5-7个番茄钟，则应拆分为更小的活动 如果一项活动的花费不足1番茄钟，则可与其他活动合并 一旦番茄钟启动，就必须走到响铃 下一个番茄钟会更好 番茄工作法不要用于假期和休息期间的活动，好好享受生活！ 中断处理内部中断 应使这一类中断清晰可见，每次你想要做其他活动，在要记录当前番茄钟的x旁边画一个撇号(‘) 在今日待办表格的计划外紧急区域记下这项活动，今天完成 或在活动清单表格中记下这项活动，改天完成（标U代表“计划外”，如需要还可写上最后期限） 再接再厉完成当前番茄钟，直到番茄钟响铃 外部中断 应使这一类中断清晰可见，每次有人打断你的工作，在要记录当前番茄钟的x位置旁边画一个减号(-) 采取告知-协商-回电策略与中断者沟通 应用与前述内部中断相同的步骤，记下相关活动，继续完成当前番茄钟 多数看似紧急的外部中断，其实可以推迟25分钟或2小时（4个番茄钟）再来处理 番茄钟期间，可以关闭电子邮件和即时通信软件.]]></content>
      <categories>
        <category>工作</category>
        <category>时间管理</category>
      </categories>
      <tags>
        <tag>工作</tag>
        <tag>时间管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL SQL收集]]></title>
    <url>%2F2016%2F08%2F30%2FPostgreSQL-SQL%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[查看是否存在无效索引1SELECT * FROM pg_class, pg_index WHERE pg_index.indisvalid = false AND pg_index.indexrelid = pg_class.oid; 查看大小查看表大小:1\d+ 查看数据库大小:1\l+ 查看表，索引及总大小1234567891011121314151617SELECT table_name, pg_size_pretty(table_size) AS table_size, pg_size_pretty(indexes_size) AS indexes_size, pg_size_pretty(total_size) AS total_sizeFROM ( SELECT table_name, pg_table_size(table_name) AS table_size, pg_indexes_size(table_name) AS indexes_size, pg_total_relation_size(table_name) AS total_size FROM ( SELECT (&apos;&quot;&apos; || table_schema || &apos;&quot;.&quot;&apos; || table_name || &apos;&quot;&apos;) AS table_name FROM information_schema.tables ) AS all_tables ORDER BY total_size DESC) AS pretty_sizes; 表访问统计123select schemaname,relname,seq_scan,idx_scan,cast(idx_scan as numeric) / (idx_scan + seq_scan) as idx_scan_pct from pg_stat_user_tables where (idx_scan +seq_scan) &gt;0 order by idx_scan_pct; 表I/O统计123select relname,cast(heap_blks_hit as numeric) /(heap_blks_hit +heap_blks_read) as hit_pct,heap_blks_hit,heap_blks_read from pg_statio_user_tables where (heap_blks_hit + heap_blks_read) &gt;0 order by hit_pct; 索引访问统计123select relname,cast(idx_blks_hit as numeric) /(idx_blks_hit + idx_blks_read ) as hit_pct,idx_blks_hit,idx_blks_read from pg_statio_user_tables where (idx_blks_hit +idx_blks_read) &gt;0 order by hit_pct; 索引I/O统计123select indexrelname,cast(idx_blks_hit as numeric) /( idx_blks_hit + idx_blks_read) as hit_pct,idx_blks_hit,idx_blks_read from pg_statio_user_indexes where (idx_blks_hit +idx_blks_read)&gt;0 order by hit_pct ; 按索引访问次统计123select schemaname,relname,indexrelname,idx_scan,pg_size_pretty(pg_relation_size(i.indexrelid)) as index_size from pg_stat_user_indexes i join pg_index using (indexrelid) where indisunique is false order by idx_scan,relname; 获取用户所属的schema1\dn+]]></content>
      <categories>
        <category>database</category>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL VS PostgreSQL 的alter table]]></title>
    <url>%2F2016%2F08%2F22%2FMySQL-VS-PostgreSQL-%E7%9A%84alter-table%2F</url>
    <content type="text"><![CDATA[版本PostgreSQL12345678[local]:5432 sky@sky=# select version(); version ----------------------------------------------------------------------------------------------------------- PostgreSQL 9.6beta4 on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4, 64-bit(1 row)Time: 0.407 ms[local]:5432 sky@sky=# MySQL123456789mysql&gt; select version();+-------------------------------------+| version() |+-------------------------------------+| 5.7.12-1~exp1+deb.sury.org~trusty+1 |+-------------------------------------+1 row in set (0.00 sec)mysql&gt; 测试表PostgreSQL: 1234567891011121314151617181920212223242526272829303132333435[local]:5432 sky@sky=# \d wb_status; Table "public.wb_status" Column | Type | Modifiers ------------------------+-----------------------------+-------------------------------------------------------- id | integer | not null default nextval('wb_status_id_seq'::regclass) sid | bigint | not null default '0'::bigint idstr | character varying(64) | not null default ''::character varying mid | bigint | default '0'::bigint user_id | bigint | user_screen_name | character varying(32) | not null default ''::character varying user_profile_image_url | character varying(128) | not null default ''::character varying text | character varying(512) | not null default ''::character varying source | character varying(256) | not null default ''::character varying thumbnail_pic | character varying(256) | not null default ''::character varying bmiddle_pic | character varying(256) | not null default ''::character varying original_pic | character varying(256) | not null default ''::character varying retweeted_status_id | character varying(32) | not null default ''::character varying geo | character varying(256) | default ''::character varying reposts_count | integer | default 0 comments_count | integer | default 0 attitudes_count | integer | default 0 visible | character varying(64) | not null default ''::character varying pic_urls | character varying(1024) | not null default ''::character varying create_at | timestamp without time zone | not null default now() update_at | timestamp without time zone | not null default now() ad | character varying(256) | not null default ''::character varying is_deleted | smallint | not null default '0'::smallint [local]:5432 sky@sky=# SELECT count(1) from wb_status; count --------- 1370996(1 row)Time: 84.686 ms MySQL: 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; desc wb_status;+------------------------+---------------+------+-----+---------------------+-----------------------------+| Field | Type | Null | Key | Default | Extra |+------------------------+---------------+------+-----+---------------------+-----------------------------+| id | int(11) | NO | PRI | NULL | auto_increment || sid | bigint(20) | NO | UNI | 0 | || idstr | varchar(64) | NO | | | || mid | bigint(20) | YES | | 0 | || user_id | bigint(20) | YES | MUL | NULL | || user_screen_name | varchar(64) | NO | | | || user_profile_image_url | varchar(128) | NO | | | || text | varchar(512) | NO | MUL | | || source | varchar(256) | NO | | | || thumbnail_pic | varchar(256) | NO | | | || bmiddle_pic | varchar(256) | NO | | | || original_pic | varchar(256) | NO | | | || retweeted_status_id | varchar(32) | NO | | | || geo | varchar(256) | YES | | | || reposts_count | int(11) | YES | | 0 | || comments_count | int(11) | YES | | 0 | || attitudes_count | int(11) | YES | | 0 | || visible | varchar(64) | NO | | | || pic_urls | varchar(1024) | NO | | | || create_at | timestamp | NO | | 1998-07-01 00:00:00 | || update_at | timestamp | NO | | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP || ad | varchar(256) | NO | | | || is_deleted | tinyint(4) | NO | | 0 | |mysql&gt; select count(1) from wb_status;+----------+| count(1) |+----------+| 1370996 |+----------+1 row in set (0.44 sec)mysql&gt; Alter table add column不带默认值,不带not null PostgreSQL123[local]:5432 sky@sky=# ALTER TABLE wb_status add column iii_id int;ALTER TABLETime: 1.599 ms MySQL123mysql&gt; alter table wb_status add column iii_id int;Query OK, 1370996 rows affected (14 min 7.60 sec)Records: 1370996 Duplicates: 0 Warnings: 0 alter table add column not null default 0PostgreSQL123[local]:5432 sky@sky=# ALTER TABLE wb_status add column ddd_id int not null default 0;ALTER TABLETime: 2223.007 ms MySQL12345mysql&gt; alter table wb_status add column eee_id int not null default 0;Query OK, 1370996 rows affected (12 min 31.77 sec)Records: 1370996 Duplicates: 0 Warnings: 0mysql&gt; 结论alter table xx add column如果不加default默认值，则PG是最快的。只需要在字典里添加一条数据，而对MySQL来说无论有没有，它都要重写整个表及数据. 不过，即使有not null default，PostgreSQL相对于MySQL来说，也是很快的.]]></content>
      <categories>
        <category>postgresql</category>
        <category>mysql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL添加字段以及vacuum full对表的影响]]></title>
    <url>%2F2016%2F08%2F22%2FPostgreSQL%E6%B7%BB%E5%8A%A0%E5%AD%97%E6%AE%B5%E4%BB%A5%E5%8F%8Avacuum-full%E5%AF%B9%E8%A1%A8%E7%9A%84%E5%BD%B1%E5%93%8D%2F</url>
    <content type="text"><![CDATA[PostgreSQL添加字段对表的影响12345678910111213141516171819202122232425262728293031323334353637383940[local]:5432 sky@sky=# select pg_relation_filepath('testcount'); pg_relation_filepath ---------------------- base/16384/18081(1 row)Time: 0.163 ms[local]:5432 sky@sky=# ALTER TABLE testcount ADD col[local]:5432 sky@sky=# ALTER TABLE testcount ADD column bb_id int;ALTER TABLETime: 0.917 ms[local]:5432 sky@sky=# select pg_relation_filepath('testcount'); pg_relation_filepath ---------------------- base/16384/18081(1 row)Time: 0.209 ms[local]:5432 sky@sky=# ALTER TABLE testcount ADD column cc_id int default 0;ALTER TABLETime: 6331.678 ms[local]:5432 sky@sky=# select pg_relation_filepath('testcount'); pg_relation_filepath ---------------------- base/16384/18085(1 row)Time: 0.240 ms[local]:5432 sky@sky=# ALTER TABLE testcount ADD column dd_id int not null default 0;ALTER TABLETime: 6242.897 ms[local]:5432 sky@sky=# select pg_relation_filepath('testcount'); pg_relation_filepath ---------------------- base/16384/18089(1 row)Time: 0.216 ms[local]:5432 sky@sky=# 仅仅是add column的话，如果没有默认值，那它是非常快的（只是在字典表里插入一条数据）。如果添加了default表示默认值的话，那要重写整个表（相当于创建一个新的表文件，创建好结构，然后将旧表的数据全迁移到这个文件中） Vacuum Full 对表的影响123456789101112131415161718192021[local]:5432 sky@sky=# VACUUM FULL ;VACUUMTime: 7287.372 ms[local]:5432 sky@sky=# select pg_relation_filepath('testcount'); pg_relation_filepath ---------------------- base/16384/18321(1 row)Time: 0.270 ms[local]:5432 sky@sky=# VACUUM FULL ;VACUUMTime: 7214.193 ms[local]:5432 sky@sky=# select pg_relation_filepath('testcount'); pg_relation_filepath ---------------------- base/16384/18679(1 row)Time: 0.490 ms[local]:5432 sky@sky=# 可以看到每次执行完vacuum full都要将表进行迁移到另一个全新的文件中的.]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Terminator启动时恢复layout并执行初始命令]]></title>
    <url>%2F2016%2F08%2F22%2FTerminator%E5%90%AF%E5%8A%A8%E6%97%B6%E6%81%A2%E5%A4%8Dlayout%E5%B9%B6%E6%89%A7%E8%A1%8C%E5%88%9D%E5%A7%8B%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[因为平时工作中要经常打开多个窗口，然后SSH登录服务器。最后发现到一个神器:Terminator，它可以分割窗口。平时都是一个一个分割窗口，然后再登录远程服务器。所以在想，能不能保存这些窗口布局，以便下次打开时，就不用每次都这样子执行这些重复的动作了。 保存layout先打开Terminator，然后分割成自己想要的布局。然后右键打开菜单选择Preferences-&gt;Layouts-&gt;add，然后填写自己的title，最后save-&gt;close即可。 每个窗口启动时执行自定义命令又打开Preferences-&gt;layouts -&gt; 在中间的Tpe类型中选择Terminal类型的，然后再在最右边的Custom command中填写启动时需要执行的命令。 这时千万要注意命令的格式是类似：df -h; zsh，即以;分隔，后面跟着你使用的shell类型.即可. 更详细配置vim ~/.config/terminator/config，然后在类似以下节点中编辑你自定义的title等信息即可： 12345678[[[terminal8]]] command = 想要执行的命令;zsh order = 1 parent = child6 profile = defautlt title = 你的标题 type = Terminal uuid = 350106f3-ab2c-4b3b-a970-f22bf43478f1]]></content>
      <categories>
        <category>bash</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bash</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL获取部分结果集中再获取最大值最小值的结果集]]></title>
    <url>%2F2016%2F08%2F19%2FPostgreSQL%E8%8E%B7%E5%8F%96%E9%83%A8%E5%88%86%E7%BB%93%E6%9E%9C%E9%9B%86%E4%B8%AD%E5%86%8D%E8%8E%B7%E5%8F%96%E6%9C%80%E5%A4%A7%E5%80%BC%E6%9C%80%E5%B0%8F%E5%80%BC%E7%9A%84%E7%BB%93%E6%9E%9C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[PostgreSQL获取部分结果集中再获取最大值最小值的结果集假设表结构如下。想要获取create_at在某时间范围的内的，最大的以及最小的use_id的值的所有结果. 1234567891011121314151617181920212223242526272829[local]:5432 sky@sky=# \d wb_status Table "public.wb_status" Column | Type | Modifiers ------------------------+-----------------------------+-------------------------------------------------------- id | integer | not null default nextval('wb_status_id_seq'::regclass) sid | bigint | not null default '0'::bigint idstr | character varying(64) | not null default ''::character varying mid | bigint | default '0'::bigint user_id | bigint | user_screen_name | character varying(32) | not null default ''::character varying user_profile_image_url | character varying(128) | not null default ''::character varying text | character varying(512) | not null default ''::character varying source | character varying(256) | not null default ''::character varying thumbnail_pic | character varying(256) | not null default ''::character varying bmiddle_pic | character varying(256) | not null default ''::character varying original_pic | character varying(256) | not null default ''::character varying retweeted_status_id | character varying(32) | not null default ''::character varying geo | character varying(256) | default ''::character varying reposts_count | integer | default 0 comments_count | integer | default 0 attitudes_count | integer | default 0 visible | character varying(64) | not null default ''::character varying pic_urls | character varying(1024) | not null default ''::character varying create_at | timestamp without time zone | not null default now() update_at | timestamp without time zone | not null default now() ad | character varying(256) | not null default ''::character varying is_deleted | smallint | not null default '0'::smallint[local]:5432 sky@sky=# SQL123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[local]:5432 sky@sky=# with tmp as (SELECT * from wb_status where create_at &gt;= '2015-03-15' and create_at &lt; '2015-03-16'), r as (select max(user_id) as mx, min(user_id) as mi from tmp) select * from tmp inner join r on tmp.user_id = r.mx or tmp.user_id = r.mi;Time: 128.032 ms[local]:5432 sky@sky=# explain (analyze, verbose, buffers) with tmp as (SELECT * from wb_status where create_at &gt;= '2015-03-15' and create_at &lt; '2015-03-16'), r as (select max(user_id) as mx, min(user_id) as mi from tmp) select * from tmp inner join r on tmp.user_id = r.mx or tmp.user_id = r.mi; QUERY PLAN --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Nested Loop (cost=83681.38..83694.49 rows=4 width=4932) (actual time=123.466..123.573 rows=2 loops=1) Output: tmp.id, tmp.sid, tmp.idstr, tmp.mid, tmp.user_id, tmp.user_screen_name, tmp.user_profile_image_url, tmp.text, tmp.source, tmp.thumbnail_pic, tmp.bmiddle_pic, tmp.original_pic, tmp.retweeted_status_id, tmp.geo, tmp.reposts_count, tmp.comments_count, tmp.attitudes_count, tmp.visible, tmp.pic_urls, tmp.create_at, tmp.update_at, tmp.ad, tmp.is_deleted, r.mx, r.mi Join Filter: ((tmp.user_id = r.mx) OR (tmp.user_id = r.mi)) Rows Removed by Join Filter: 763 Buffers: shared hit=2031 read=71628 CTE tmp -&gt; Gather (cost=1000.00..83672.02 rows=374 width=372) (actual time=0.156..122.751 rows=765 loops=1) Output: wb_status.id, wb_status.sid, wb_status.idstr, wb_status.mid, wb_status.user_id, wb_status.user_screen_name, wb_status.user_profile_image_url, wb_status.text, wb_status.source, wb_status.thumbnail_pic, wb_status.bmiddle_pic, wb_status.original_pic, wb_status.retweeted_status_id, wb_status.geo, wb_status.reposts_count, wb_status.comments_count, wb_status.attitudes_count, wb_status.visible, wb_status.pic_urls, wb_status.create_at, wb_status.update_at, wb_status.ad, wb_status.is_deleted Workers Planned: 2 Workers Launched: 2 Buffers: shared hit=2031 read=71628 -&gt; Parallel Seq Scan on public.wb_status (cost=0.00..82634.62 rows=156 width=372) (actual time=0.359..120.620 rows=255 loops=3) Output: wb_status.id, wb_status.sid, wb_status.idstr, wb_status.mid, wb_status.user_id, wb_status.user_screen_name, wb_status.user_profile_image_url, wb_status.text, wb_status.source, wb_status.thumbnail_pic, wb_status.bmiddle_pic, wb_status.original_pic, wb_status.retweeted_status_id, wb_status.geo, wb_status.reposts_count, wb_status.comments_count, wb_status.attitudes_count, wb_status.visible, wb_status.pic_urls, wb_status.create_at, wb_status.update_at, wb_status.ad, wb_status.is_deleted Filter: ((wb_status.create_at &gt;= '2015-03-15 00:00:00'::timestamp without time zone) AND (wb_status.create_at &lt; '2015-03-16 00:00:00'::timestamp without time zone)) Rows Removed by Filter: 456744 Buffers: shared hit=1825 read=71628 Worker 0: actual time=0.215..118.234 rows=71 loops=1 Buffers: shared hit=566 read=23219 Worker 1: actual time=0.855..121.365 rows=658 loops=1 Buffers: shared hit=575 read=24297 CTE r -&gt; Aggregate (cost=9.35..9.36 rows=1 width=16) (actual time=123.370..123.370 rows=1 loops=1) Output: max(tmp_1.user_id), min(tmp_1.user_id) Buffers: shared hit=2031 read=71628 -&gt; CTE Scan on tmp tmp_1 (cost=0.00..7.48 rows=374 width=8) (actual time=0.159..123.271 rows=765 loops=1) Output: tmp_1.id, tmp_1.sid, tmp_1.idstr, tmp_1.mid, tmp_1.user_id, tmp_1.user_screen_name, tmp_1.user_profile_image_url, tmp_1.text, tmp_1.source, tmp_1.thumbnail_pic, tmp_1.bmiddle_pic, tmp_1.original_pic, tmp_1.retweeted_status_id, tmp_1.geo, tmp_1.reposts_count, tmp_1.comments_count, tmp_1.attitudes_count, tmp_1.visible, tmp_1.pic_urls, tmp_1.create_at, tmp_1.update_at, tmp_1.ad, tmp_1.is_deleted Buffers: shared hit=2031 read=71628 -&gt; CTE Scan on r (cost=0.00..0.02 rows=1 width=16) (actual time=123.372..123.372 rows=1 loops=1) Output: r.mx, r.mi Buffers: shared hit=2031 read=71628 -&gt; CTE Scan on tmp (cost=0.00..7.48 rows=374 width=4916) (actual time=0.001..0.118 rows=765 loops=1) Output: tmp.id, tmp.sid, tmp.idstr, tmp.mid, tmp.user_id, tmp.user_screen_name, tmp.user_profile_image_url, tmp.text, tmp.source, tmp.thumbnail_pic, tmp.bmiddle_pic, tmp.original_pic, tmp.retweeted_status_id, tmp.geo, tmp.reposts_count, tmp.comments_count, tmp.attitudes_count, tmp.visible, tmp.pic_urls, tmp.create_at, tmp.update_at, tmp.ad, tmp.is_deleted Planning time: 0.108 ms Execution time: 124.163 ms(34 rows)(END)[local]:5432 sky@sky=# SELECT count(1) from wb_status; count --------- 1370996(1 row)Time: 91.415 ms]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL9.6并行查询]]></title>
    <url>%2F2016%2F08%2F18%2FPostgreSQL9-6%E5%B9%B6%E8%A1%8C%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[并行查询这个是PostgreSQL 9.6才开始有的。 测试环境是4核心的i5CPU，其他配置为PostgreSQL默认. 测试数据123456789[local]:5432 sky@sky=# CREATE TABLE testcount(id int);CREATE TABLETime: 2.733 ms[local]:5432 sky@sky=# INSERT INTO testcount VALUES (generate_series(1,15000000));INSERT 0 15000000Time: 11145.722 ms[local]:5432 sky@sky=# VACUUM FULL ;VACUUMTime: 8084.445 ms 非并行查询12345678910111213141516171819202122232425[local]:5432 sky@sky=# set max_parallel_workers_per_gather = 0;SETTime: 0.164 ms[local]:5432 sky@sky=# EXPLAIN (analyze, verbose, buffers) select count(1) from testcount ; QUERY PLAN ------------------------------------------------------------------------------------------------------------------------------------- Aggregate (cost=277932.75..277932.76 rows=1 width=8) (actual time=1982.173..1982.173 rows=1 loops=1) Output: count(1) Buffers: shared hit=896 read=65476 -&gt; Seq Scan on public.testcount (cost=0.00..235620.60 rows=16924860 width=0) (actual time=0.022..884.887 rows=15000000 loops=1) Output: id Buffers: shared hit=896 read=65476 Planning time: 0.029 ms Execution time: 1982.196 ms(8 rows)[local]:5432 sky@sky=# SELECT count(1) from testcount ; count ---------- 15000000(1 row)Time: 1005.757 ms 开启并行查询开启1个worker12345678910111213141516171819202122232425262728293031323334[local]:5432 sky@sky=# set max_parallel_workers_per_gather = 1;SETTime: 0.131 ms[local]:5432 sky@sky=# EXPLAIN (analyze, verbose, buffers) select count(1) from testcount ; QUERY PLAN -------------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=191819.61..191819.62 rows=1 width=8) (actual time=1016.820..1016.820 rows=1 loops=1) Output: count(1) Buffers: shared hit=1326 read=65124 -&gt; Gather (cost=191819.50..191819.61 rows=1 width=8) (actual time=1016.761..1016.817 rows=2 loops=1) Output: (PARTIAL count(1)) Workers Planned: 1 Workers Launched: 1 Buffers: shared hit=1326 read=65124 -&gt; Partial Aggregate (cost=190819.50..190819.51 rows=1 width=8) (actual time=1015.814..1015.814 rows=1 loops=2) Output: PARTIAL count(1) Buffers: shared hit=1248 read=65124 Worker 0: actual time=1014.972..1014.972 rows=1 loops=1 Buffers: shared hit=595 read=32170 -&gt; Parallel Seq Scan on public.testcount (cost=0.00..165930.00 rows=9955800 width=0) (actual time=0.029..500.854 rows=7500000 loops=2) Buffers: shared hit=1248 read=65124 Worker 0: actual time=0.027..491.502 rows=7404818 loops=1 Buffers: shared hit=595 read=32170 Planning time: 0.033 ms Execution time: 1017.595 ms(19 rows)[local]:5432 sky@sky=# SELECT count(1) from testcount ; count ---------- 15000000(1 row)Time: 660.512 m 开启2个worker123456789101112131415161718192021222324252627282930313233343536373839[local]:5432 sky@sky=# set max_parallel_workers_per_gather = 2;SETTime: 0.125 ms[local]:5432 sky@sky=# EXPLAIN (analyze, verbose, buffers) select count(1) from testcount ; QUERY PLAN -------------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=155522.53..155522.54 rows=1 width=8) (actual time=766.411..766.411 rows=1 loops=1) Output: count(1) Buffers: shared hit=1532 read=64996 -&gt; Gather (cost=155522.31..155522.52 rows=2 width=8) (actual time=766.365..766.406 rows=3 loops=1) Output: (PARTIAL count(1)) Workers Planned: 2 Workers Launched: 2 Buffers: shared hit=1532 read=64996 -&gt; Partial Aggregate (cost=154522.31..154522.32 rows=1 width=8) (actual time=764.665..764.665 rows=1 loops=3) Output: PARTIAL count(1) Buffers: shared hit=1376 read=64996 Worker 0: actual time=763.246..763.246 rows=1 loops=1 Buffers: shared hit=488 read=23400 Worker 1: actual time=764.496..764.496 rows=1 loops=1 Buffers: shared hit=514 read=23576 -&gt; Parallel Seq Scan on public.testcount (cost=0.00..136892.25 rows=7052025 width=0) (actual time=0.025..370.283 rows=5000000 loops=3) Buffers: shared hit=1376 read=64996 Worker 0: actual time=0.018..350.004 rows=5398688 loops=1 Buffers: shared hit=488 read=23400 Worker 1: actual time=0.020..372.743 rows=5444268 loops=1 Buffers: shared hit=514 read=23576 Planning time: 0.044 ms Execution time: 767.434 ms(23 rows)[local]:5432 sky@sky=# SELECT count(1) from testcount ; count ---------- 15000000(1 row)Time: 502.905 ms 开启3个worker123456789101112131415161718192021222324252627282930313233343536373839404142[local]:5432 sky@sky=# set max_parallel_workers_per_gather = 3;SETTime: 0.177 ms[local]:5432 sky@sky=# EXPLAIN (analyze, verbose, buffers) select count(1) from testcount ; QUERY PLAN -------------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=135617.72..135617.73 rows=1 width=8) (actual time=757.778..757.778 rows=1 loops=1) Output: count(1) Buffers: shared hit=1802 read=64804 -&gt; Gather (cost=135617.40..135617.71 rows=3 width=8) (actual time=757.021..757.775 rows=4 loops=1) Output: (PARTIAL count(1)) Workers Planned: 3 Workers Launched: 3 Buffers: shared hit=1802 read=64804 -&gt; Partial Aggregate (cost=134617.40..134617.41 rows=1 width=8) (actual time=753.981..753.981 rows=1 loops=4) Output: PARTIAL count(1) Buffers: shared hit=1568 read=64804 Worker 0: actual time=749.686..749.686 rows=1 loops=1 Buffers: shared hit=511 read=11359 Worker 1: actual time=753.743..753.743 rows=1 loops=1 Buffers: shared hit=481 read=16752 Worker 2: actual time=755.592..755.592 rows=1 loops=1 Buffers: shared hit=334 read=20173 -&gt; Parallel Seq Scan on public.testcount (cost=0.00..120968.32 rows=5459632 width=0) (actual time=0.019..357.230 rows=3750000 loops=4) Buffers: shared hit=1568 read=64804 Worker 0: actual time=0.015..315.006 rows=2682548 loops=1 Buffers: shared hit=511 read=11359 Worker 1: actual time=0.015..346.246 rows=3894658 loops=1 Buffers: shared hit=481 read=16752 Worker 2: actual time=0.015..408.609 rows=4634582 loops=1 Buffers: shared hit=334 read=20173 Planning time: 0.033 ms Execution time: 757.836 ms(27 rows)[local]:5432 sky@sky=# SELECT count(1) from testcount ; count ---------- 15000000(1 row)Time: 514.604 ms 开启4个worker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[local]:5432 sky@sky=# set max_parallel_workers_per_gather = 4;SETTime: 0.149 ms[local]:5432 sky@sky=# EXPLAIN (analyze, verbose, buffers) select count(1) from testcount ; QUERY PLAN -------------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=120262.61..120262.62 rows=1 width=8) (actual time=799.792..799.792 rows=1 loops=1) Output: count(1) Buffers: shared hit=2264 read=64420 -&gt; Gather (cost=120262.19..120262.60 rows=4 width=8) (actual time=799.782..799.789 rows=5 loops=1) Output: (PARTIAL count(1)) Workers Planned: 4 Workers Launched: 4 Buffers: shared hit=2264 read=64420 -&gt; Partial Aggregate (cost=119262.19..119262.20 rows=1 width=8) (actual time=791.188..791.188 rows=1 loops=5) Output: PARTIAL count(1) Buffers: shared hit=1952 read=64420 Worker 0: actual time=793.609..793.609 rows=1 loops=1 Buffers: shared hit=93 read=11941 Worker 1: actual time=783.423..783.423 rows=1 loops=1 Buffers: shared hit=352 read=12496 Worker 2: actual time=787.593..787.593 rows=1 loops=1 Buffers: shared hit=612 read=14750 Worker 3: actual time=791.640..791.640 rows=1 loops=1 Buffers: shared hit=528 read=14056 -&gt; Parallel Seq Scan on public.testcount (cost=0.00..108684.15 rows=4231215 width=0) (actual time=0.017..368.500 rows=3000000 loops=5) Buffers: shared hit=1952 read=64420 Worker 0: actual time=0.017..389.196 rows=2719684 loops=1 Buffers: shared hit=93 read=11941 Worker 1: actual time=0.016..379.447 rows=2903648 loops=1 Buffers: shared hit=352 read=12496 Worker 2: actual time=0.015..371.381 rows=3471812 loops=1 Buffers: shared hit=612 read=14750 Worker 3: actual time=0.014..315.571 rows=3295912 loops=1 Buffers: shared hit=528 read=14056 Planning time: 0.030 ms Execution time: 802.207 ms(31 rows)[local]:5432 sky@sky=# SELECT count(1) from testcount ; count ---------- 15000000(1 row)Time: 513.976 ms 与并行相关的参数德哥 阿里云栖社区 PostgreSQL 9.6 并行计算 优化器算法浅析]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL的psql配置]]></title>
    <url>%2F2016%2F08%2F18%2FPostgreSQL%E7%9A%84psql%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[~/.psqlrc内容如下: 12345678910111213141516171819202122232425-- Found this on thoughtbot here:-- https://robots.thoughtbot.com/improving-the-command-line-postgres-experience-- and it fixes problems with psql, some I didn't even know I had.---- Set up a nice friendly prompt\set PROMPT1 '%[%033[1m%]%M %n@%/%R%[%033[0m%]%# '\set PROMPT2 '[more] %R &gt; '-- By default, NULL displays as an empty space. Is it actually an empty-- string, or is it null? This makes that distinction visible.\pset null '[NULL]'-- Use table format (with headers across the top) by default, but switch to-- expanded table format when there's a lot of data, which makes it much-- easier to read.\x auto-- Verbose error reports.\set VERBOSITY verbose-- Use a separate history file per-database.\set HISTFILE ~/.psql_history- :DBNAME-- If a command is run more than once in a row, only store it once in the-- history.\set HISTCONTROL ignoredups-- Autocomplete keywords (like SELECT) in upper-case, even if you started-- typing them in lower case.\set COMP_KEYWORD_CASE upper\timing 上面设置完的psql提示样式如下: 1234567810.0.0.81 sky@sky=# SELECT * from hello limit 1; name ---------------------------------- c4ca4238a0b923820dcc509a6f75849b(1 row)Time: 0.226 ms10.0.0.81 sky@sky=# 另一份: 1234567891011121314151617181920212223242526\set QUIET 1\set PROMPT1 '%M:%[%033[1;31m%]%&gt;%[%033[0m%] %n@%/%R%#%x '\set PROMPT2 '%M %n@%/%R %# '\pset null '[null]'\set COMP_KEYWORD_CASE upper\timing\set HISTSIZE 2000\x auto\set VERBOSITY verbose\set QUIET 0\echo 'Welcome to PostgreSQL! \n'\echo 'Type :version to see the PostgreSQL version. \n' \echo 'Type :extensions to see the available extensions. \n'\echo 'Type \\q to exit. \n'\set version 'SELECT version();'\set extensions 'select * from pg_available_extensions;' psql提示样式如下: 123456789101112131415╭─sky@sky-linux /ihome/nodejs/blog ╰─➤ psql -U sky -W -h 10.0.0.81Password for user sky: Welcome to PostgreSQL! Type :version to see the PostgreSQL version. Type :extensions to see the available extensions. Type \q to exit. psql (9.5.0)Type "help" for help.10.0.0.81:5432 sky@sky=#]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL服务器参数配置]]></title>
    <url>%2F2016%2F08%2F12%2FPostgreSQL%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[内存相关shared_buffers这个参数决定了有多少内存将用于PostgreSQL的数据缓存.当多个会话从同一张表中请求相同数据时，shared_buffers保证了不需要在内在保留数据集的多个副本。这种方法减少了物理I/O。它在启动时被分配。PostgreSQL9.3以上为默认为128MB, 旧版为32MB. 这个参数对性能有显著的影响，因为直接影响服务器上物理I/O的使用量. 推荐为RAM的40% effective_cache_size这个值告诉PostgreSQL大约有多少内存可用于缓存机制（shared_buffers + 文件系统缓存）。 这个不是分配的。而是用于查询规划器进行查询预估的。并发的查询，将共享可用的空间。 主要作用： 当增加effective_cache_size时，规划器认为内存中可以获取更多的页面。这使得使用索引比顺序扫描更好。 如果设置太低，PostgreSQL则可能会认为顺序扫描更高效。 即一个较高的值， 会增加使用索引的可能性；而较低的值，则增加了顺序扫描的可能性。 work_mem推荐为 1work_mem = (available_ram * 0.25) / max_connections 这样子，可以确保所有连接的工作内存占总内存的1/4 RAM左右. 它可以在会话级别设置，如果你的SQL有明显的需要，可以为单个连接分配更多的内存。比如，在批量处理的情况下，对一张大表进行排序. 注意，这个内存是独立的，不与shared_buffers共享的。 maintenace_work_mem这个参数可用于自动清空进程， 索引和更改表语句中执行的。这个可以在会话级别设置。 可以将这个参数值，设置得比work_mem更高，因为服务器上一般不会有太多的维护操作同时发生。 查询规划相关default_statistics_target默认为100. 1234567sky=# show default_statistics_target ; default_statistics_target --------------------------- 100(1 row)sky=# PG会考虑（300*当前值）个页面来完成随机抽样。从这些样本中，填充pg_statistics。这些值将用于规划器。 如果explain analyze显示出实际成本与预估成本之间有明显差异，那可以适当增加这个值。 1234567891011121314151617181920212223242526272829303132333435sky=# select attstattarget, attname from pg_attribute where attrelid = 'wb_status'::regclass; attstattarget | attname ---------------+------------------------ -1 | user_id 0 | ctid 0 | xmin -1 | id -1 | sid -1 | idstr -1 | mid -1 | user_screen_name -1 | user_profile_image_url -1 | text -1 | source -1 | thumbnail_pic -1 | bmiddle_pic -1 | original_pic -1 | retweeted_status_id -1 | geo 0 | cmin 0 | xmax 0 | cmax 0 | tableoid -1 | reposts_count -1 | comments_count -1 | attitudes_count -1 | visible -1 | pic_urls -1 | create_at -1 | update_at -1 | ad -1 | is_deleted(29 rows)sky=# 为表的某些列，设置指定的statistics： 12345678910111213141516171819202122232425262728293031323334353637sky=# alter table wb_status alter COLUMN sid set statistics 200;ALTER TABLEsky=# select attstattarget, attname from pg_attribute where attrelid = 'wb_status'::regclass; attstattarget | attname ---------------+------------------------ -1 | user_id 0 | ctid 0 | xmin -1 | id 200 | sid -1 | idstr -1 | mid -1 | user_screen_name -1 | user_profile_image_url -1 | text -1 | source -1 | thumbnail_pic -1 | bmiddle_pic -1 | original_pic -1 | retweeted_status_id -1 | geo 0 | cmin 0 | xmax 0 | cmax 0 | tableoid -1 | reposts_count -1 | comments_count -1 | attitudes_count -1 | visible -1 | pic_urls -1 | create_at -1 | update_at -1 | ad -1 | is_deleted(29 rows)sky=# -1：表示默认值，增加这个值会导致更多的抽样，也就是更多的资源消耗。最好是在会话中设置这个值，可以看到分析表使用了多长时间，查询性能增加了多少，然后决定是否保留这个值。 seq_page_cost 与 random_page_costrandom_page_cost：默认为4,seq_page_cost：默认为1 即默认为4:1，如果调低到2:1，则可增加规划器使用索引的机会。（建议如果是SSD的话，可以调低为这个） 千万不要将random_page_cost设置得比seq_page_cost低。 查看所有影响规划器的cost如下: 123456789╭─sky@sky-linux /ihome/db/postgresql/postgresql-9.5.0/data ╰─➤ cat postgresql.conf | grep "cost = "#seq_page_cost = 1.0 # measured on an arbitrary scale#random_page_cost = 4.0 # same scale as above#cpu_tuple_cost = 0.01 # same scale as above#cpu_index_tuple_cost = 0.005 # same scale as above#cpu_operator_cost = 0.0025 # same scale as above╭─sky@sky-linux /ihome/db/postgresql/postgresql-9.5.0/data ╰─➤ enable_xxx12345678910111213╭─sky@sky-linux /ihome/db/postgresql/postgresql-9.5.0/data ╰─➤ cat postgresql.conf | grep "enable_"#enable_bitmapscan = on#enable_hashagg = on#enable_hashjoin = on#enable_indexscan = on#enable_indexonlyscan = on#enable_material = on#enable_mergejoin = on#enable_nestloop = on#enable_seqscan = on#enable_sort = on#enable_tidscan = on 上面的是各种查询方式。可以设置为off。注意，就算是设置为off，也不是表示PG绝对不用这种方式。只是尽最大的可能不去使用这种方式（它本质上，只是将这种扫描方式的cost设置得非常大而已） WAL 相关1234567╭─sky@sky-linux /ihome/db/postgresql/postgresql-9.5.0/data ╰─➤ cat postgresql.conf | grep -E "checkpoint|segments"#checkpoint_timeout = 5min # range 30s-1h#checkpoint_completion_target = 0.5 # checkpoint target duration, 0.0 - 1.0#checkpoint_warning = 30s # 0 disableswal_keep_segments = 32 # in logfile segments, 16MB each; 0 disables#log_checkpoints = off checkpoint_segments（或叫wal_keep_segments，PG9.0及以后版本）查看默认值: 1234567sky=# show wal_keep_segments ; wal_keep_segments ------------------- 32(1 row)sky=# 即一旦wal_keep_segments个WAL区段填充后，则出现一个checkpoint。 checkpoint_timeout超时值.（可以根据不同的单位来设置不同，参考上面的配置文件及说明） 如果超时了，也会出现一个checkpoint checkpoint_completion_target这个参数告诉PostgreSQL在每一次迭代过程中，以多快的速度来设法完成checkpoint的操作。默认为0.5。即PostgreSQL可以在下一个checkpoint开始之前，花费大约一半的时间来完成每个检查点。可以直观地理解为，以多激烈的硬盘写速度来完成checkpoint操作。越小，表示以最大的速度来完成checkpoint操作，越大，表示以最慢的速度来完成checkpoint操作。也即值越小，系统负载的峰值会瞬间非常高，值越大，系统负载就越倾向于平稳。 Windows下1update_process_title 将这个参数，设置为off，可以大幅提高Windows下的PostgreSQL性能？ 参考资料improve-postgresql-windows-performance-by-100 杂项autovacuum_analyze_threshold作用： 指定至少N个插入，更新或删除的无组时才需要触发 ANALYZE 去分析表. 查看系统默认值: 12345678localhost:5433 sky@sky=# show autovacuum_analyze_threshold ; autovacuum_analyze_threshold ------------------------------ 50(1 row)Time: 0.146 mslocalhost:5433 sky@sky=# 默认为50.（可在配置文件或命令行里设置，也可以独立修改某张表的阀值）： 1ALTER TABLE ... SET (autovacuum_analyze_threshold = ...); 如: 12345678910111213141516171819202122232425262728293031323334353637localhost:5433 sky@sky=# ALTER TABLE wb_status SET (autovacuum_analyze_threshold = 100);ALTER TABLETime: 1.194 mslocalhost:5433 sky@sky=# \d+ wb_status; Table "public.wb_status" Column | Type | Modifiers | Storage | Stats target | Description ------------------------+-----------------------------+--------------------------------------------------------+----------+--------------+------------- id | integer | not null default nextval('wb_status_id_seq'::regclass) | plain | | sid | bigint | not null default '0'::bigint | plain | | idstr | character varying(64) | not null default ''::character varying | extended | | mid | bigint | default '0'::bigint | plain | 10000 | user_id | bigint | | plain | | user_screen_name | character varying(32) | not null default ''::character varying | extended | | user_profile_image_url | character varying(128) | not null default ''::character varying | extended | | text | character varying(512) | not null default ''::character varying | extended | | source | character varying(256) | not null default ''::character varying | extended | | thumbnail_pic | character varying(256) | not null default ''::character varying | extended | | bmiddle_pic | character varying(256) | not null default ''::character varying | extended | | original_pic | character varying(256) | not null default ''::character varying | extended | | retweeted_status_id | character varying(32) | not null default ''::character varying | extended | | geo | character varying(256) | default ''::character varying | extended | | reposts_count | integer | default 0 | plain | | comments_count | integer | default 0 | plain | | attitudes_count | integer | default 0 | plain | | visible | character varying(64) | not null default ''::character varying | extended | | pic_urls | character varying(1024) | not null default ''::character varying | extended | | create_at | timestamp without time zone | not null default now() | plain | | update_at | timestamp without time zone | not null default now() | plain | | ad | character varying(256) | not null default ''::character varying | extended | | is_deleted | smallint | not null default '0'::smallint | plain | | Indexes: "wb_status_pkey" PRIMARY KEY, btree (id) "sid_wb_staus" UNIQUE, btree (sid) "user_id_wb_staus" btree (user_id)Options: autovacuum_analyze_threshold=100localhost:5433 sky@sky=# 查看所有表的状态信息1SELECT * FROM pg_stat_all_tables [where schemaname = 'public']; 查看所有用户定义的表的状态信息1SELECT * FROM pg_stat_user_tables; 执行一次analyze前后：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556localhost:5433 sky@sky=# SELECT * FROM pg_stat_all_tables where schemaname = 'public';-[ RECORD 1 ]-------+------------------------------relid | 17864schemaname | publicrelname | wb_statusseq_scan | 80seq_tup_read | 103252172idx_scan | 47idx_tup_fetch | 29580516n_tup_ins | 1370996n_tup_upd | 0n_tup_del | 0n_tup_hot_upd | 0n_live_tup | 1370996n_dead_tup | 0n_mod_since_analyze | 0last_vacuum | [null]last_autovacuum | [null]last_analyze | [null]last_autoanalyze | 2016-08-18 15:03:00.763547+08vacuum_count | 0autovacuum_count | 0analyze_count | 0autoanalyze_count | 1Time: 10.908 mslocalhost:5433 sky@sky=# ANALYZE wb_status ;ANALYZETime: 110883.966 mslocalhost:5433 sky@sky=# SELECT * FROM pg_stat_all_tables where schemaname = 'public';-[ RECORD 1 ]-------+------------------------------relid | 17864schemaname | publicrelname | wb_statusseq_scan | 80seq_tup_read | 103252172idx_scan | 47idx_tup_fetch | 29580516n_tup_ins | 1370996n_tup_upd | 0n_tup_del | 0n_tup_hot_upd | 0n_live_tup | 1370996n_dead_tup | 0n_mod_since_analyze | 0last_vacuum | [null]last_autovacuum | [null]last_analyze | 2016-09-26 18:02:29.72493+08last_autoanalyze | 2016-08-18 15:03:00.763547+08vacuum_count | 0autovacuum_count | 0analyze_count | 1autoanalyze_count | 1Time: 10.861 mslocalhost:5433 sky@sky=# 可以看到analyze_count+1了 delete一条数据123456789101112131415161718192021222324252627282930localhost:5433 sky@sky=# delete from wb_status where id = 185794019;DELETE 1Time: 0.975 mslocalhost:5433 sky@sky=# SELECT * FROM pg_stat_all_tables where schemaname = 'public';-[ RECORD 1 ]-------+------------------------------relid | 17864schemaname | publicrelname | wb_statusseq_scan | 80seq_tup_read | 103252172idx_scan | 49idx_tup_fetch | 29580518n_tup_ins | 1370996n_tup_upd | 0n_tup_del | 1n_tup_hot_upd | 0n_live_tup | 1370995n_dead_tup | 1n_mod_since_analyze | 1last_vacuum | [null]last_autovacuum | [null]last_analyze | 2016-09-26 18:02:29.72493+08last_autoanalyze | 2016-08-18 15:03:00.763547+08vacuum_count | 0autovacuum_count | 0analyze_count | 1autoanalyze_count | 1Time: 10.814 mslocalhost:5433 sky@sky=# 也可以看到n_dead_tup+1了. autoanalyze 与 autovacuum 的threshold123vacuum threshold = vacuum base threshold + vacuum scale factor * number of tuplesanalyze threshold = analyze base threshold + analyze scale factor * number of tuples 表膨胀的问题taobao 参考资料depesz runtime-config-autovacuum]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL中文全文搜索]]></title>
    <url>%2F2016%2F08%2F11%2FPostgreSQL%E4%B8%AD%E6%96%87%E5%85%A8%E6%96%87%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[安装 zhparserzhparser 使用创建测试表: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465create table ts (name varchar(1024));sky=# select * from ts limit 50; name ------------------------------ 中国人民 中国人民解放军 中国人民解放军，军队 中国军人 中国军队 中国军队1 中国军队一二三 中国军队一二三四 军队一二三四 中国军队一三四 中国军队一三 中国军队一 中国军队 中国 中 中国军 中国军 为什么 为国 中军队 中军队你 中军队，解放 中军队，解放军 中军队，解放军队 中军队，解放军军队 中军队，解放军军队呀 中军队，解放军军队呀哈哈 中军队，解放军军队呀哈哈哈 中军队，解放军军队呀哈哈哈哈 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好 你好....sky=# select count(1) from ts; count ------- 65565(1 row)sky=# 插入足够多的测试数据。这里是65565条数据。 创建索引 下面假设你已经安装并配置好了zhparser. zhparser.multi_short = on;设置为全局级别后再创建索引. 1alter role all set zhparser.multi_short=on; 创建索引: 1create index idx_name on ts using gin(to_tsvector('testzhcfg', name)); 全文搜索 VS LKIE1234567891011121314151617181920212223242526272829sky=# explain analyze select * from ts where to_tsvector('testzhcfg', name) @@ to_tsquery('testzhcfg', '军队'); QUERY PLAN --------------------------------------------------------------------------------------------------------------------- Bitmap Heap Scan on ts (cost=10.54..401.46 rows=328 width=7) (actual time=0.010..0.011 rows=20 loops=1) Recheck Cond: (to_tsvector('testzhcfg'::regconfig, (name)::text) @@ '''军队'''::tsquery) Heap Blocks: exact=1 -&gt; Bitmap Index Scan on idx_name (cost=0.00..10.46 rows=328 width=0) (actual time=0.007..0.007 rows=20 loops=1) Index Cond: (to_tsvector('testzhcfg'::regconfig, (name)::text) @@ '''军队'''::tsquery) Planning time: 0.071 ms Execution time: 0.026 ms(7 rows)sky=# LIKE:sky=# explain analyze select * from ts where name like '%军队%'; QUERY PLAN ------------------------------------------------------------------------------------------------ Seq Scan on ts (cost=0.00..1110.56 rows=3 width=7) (actual time=0.008..5.212 rows=20 loops=1) Filter: ((name)::text ~~ '%军队%'::text) Rows Removed by Filter: 65545 Planning time: 0.042 ms Execution time: 5.223 ms(5 rows)sky=# 看来还是挺不错的.]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL搭建复制启动报 invalid record length at]]></title>
    <url>%2F2016%2F08%2F11%2FPostgreSQL%E6%90%AD%E5%BB%BA%E5%A4%8D%E5%88%B6%E5%90%AF%E5%8A%A8%E6%8A%A5-invalid-record-length-at%2F</url>
    <content type="text"><![CDATA[信息123456789101112╭─sky@sky-linux /ihome/db/postgresql ╰─➤ ./current/bin/pg_ctl -D slave-data start 1 ↵server starting╭─sky@sky-linux /ihome/db/postgresql ╰─➤ LOG: database system was shut down in recovery at 2016-08-11 10:57:31 CSTLOG: entering standby modeLOG: consistent recovery state reached at 0/15000300LOG: redo starts at 0/15000300LOG: invalid record length at 0/150003E0LOG: database system is ready to accept read only connectionsLOG: started streaming WAL from primary at 0/15000000 on timeline 1... 问题本想搭建复制环境的, 按 /2015/01/24/翻译-手把手教你配置流复制/ ,slave启动时,报这个信息. 后来看到PostgreSQL官方有个官方回复. 原因postgresql.org 刚启动后， standby尝试读取并重放存放在standby的WAL文件， 然后它发现了无效的WAL记录，换句话说， 它不再能够坐本地读取WAL记录了， 它开始复制然后尝试从master里读取WAL文件。所以， 以上的日志信息invalid record...意味着在standby有无效的WAL记录，这会触发复制。从master复制流中获取有效的WAL记录后，你就不再需要担心这个日志信息了.]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL查看复制状态]]></title>
    <url>%2F2016%2F08%2F11%2FPostgreSQL%E6%9F%A5%E7%9C%8B%E5%A4%8D%E5%88%B6%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[查看复制状态在master上执行 1234567891011121314151617181920sky=# select * from pg_stat_replication;-[ RECORD 1 ]----+------------------------------pid | 13321usesysid | 17019usename | replicationapplication_name | walreceiverclient_addr | 10.0.0.81client_hostname | client_port | 42809backend_start | 2016-08-11 10:57:35.856289+08backend_xmin | state | streamingsent_location | 1/E0CE9750write_location | 1/E0CE9750flush_location | 1/E0CE9750replay_location | 1/E0CE9750sync_priority | 0sync_state | asyncsky=# pid： master的sender进程： 123╭─sky@sky-linux /ihome/db/postgresql ╰─➤ ps aux | grep 13321sky 13321 0.1 0.0 172320 2992 ? Ss 10:57 0:03 postgres: wal sender process replication 10.0.0.81(42809) streaming 1/E0CE9750 usesysid: 复制的用户ID(17019)usename : 用户名 123456789101112131415161718192021sky=# select * from pg_user;-[ RECORD 1 ]+------------usename | skyusesysid | 10usecreatedb | tusesuper | tuserepl | tusebypassrls | tpasswd | ********valuntil | useconfig | -[ RECORD 2 ]+------------usename | replicationusesysid | 17019usecreatedb | fusesuper | fuserepl | tusebypassrls | fpasswd | ********valuntil | useconfig | client_addr: slave的IP地址 client_port: slave的 wal receiver process的PID使用的端口 backend_start: 开始复制的时间 state: 同步状态. streaming : 同步 startup : 连接中 catchup: 同步中 sent_location:Master传送的WAL位置write_location:Slave接收WAL位置flush_location:Slave同步到磁盘的WAL位置replay_location:Slave同步到数据库的WAL位置 sync_priority:同步优先级. sync_state: 同步模式. async : 异步 sync : 同步 potential: 虽然现在是异步,但有可能提升到同步. 查看延迟多少在master上执行以下SQL可以查看滞后程度,以字节为单位. 1234567sky=# select pg_xlog_location_diff(sent_location, replay_location) from pg_stat_replication; pg_xlog_location_diff ----------------------- 0(1 row)sky=# 或者 在slave上执行以下SQL可以查看滞后时间. 12345678910sky=# SELECT CASE WHEN pg_last_xlog_receive_location() = pg_last_xlog_replay_location() THEN 0 ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp()) END AS log_delay; log_delay ----------- 0(1 row)sky=# 如果没输出就表示完全同步了. 查看是否处于recovery模式1234567sky=# select pg_is_in_recovery(); pg_is_in_recovery ------------------- t(1 row)sky=# 如果处于复制模式的话, select pg_last_xact_replay_timestamp();和select pg_last_xlog_replay_location();会一直增加. 123select pg_last_xact_replay_timestamp();select pg_last_xlog_replay_location();]]></content>
      <categories>
        <category>postgresql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>databasse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量操作中数据库死锁的解决方法]]></title>
    <url>%2F2016%2F08%2F08%2F%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AD%BB%E9%94%81%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原因在生产环境中, 发现数据库经常报死锁.排查问题后,发现是由于RabbitMQ监听器, 批量处理SQL: insert ... on duplicate key update ... 这类SQL引起. 解决在添加到队列之前(或出队之后), 进行重处理再进行批量操作.(比如,通过Redis缓存进行唯一键去重).]]></content>
      <categories>
        <category>mysql</category>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logback启动停留在 Registering current configuration as safe fallback point]]></title>
    <url>%2F2016%2F07%2F28%2Flogback%E5%90%AF%E5%8A%A8%E5%81%9C%E7%95%99%E5%9C%A8-Registering-current-configuration-as-safe-fallback-point%2F</url>
    <content type="text"><![CDATA[问题今天升级12Spring-data-redis(1.3.0 -&gt; 1.6.4).Jedis(2.3.2 -&gt; 2.7.3) 修改了Jar包的版本后,发现启动不了.启动信息一直停留在类似以下信息里: 1234517:00:05,421 |-INFO in ch.qos.logback.classic.joran.action.LoggerAction - Setting level of logger [com.weibosdk] to DEBUG17:00:05,421 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [STDOUT] to Logger[com.weibosdk]17:00:05,421 |-INFO in ch.qos.logback.classic.joran.action.LevelAction - ROOT level set to INFO17:00:05,421 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [STDOUT] to Logger[ROOT]17:00:05,422 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@cce672c - Registering current configuration as safe fallback point 或者 1Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@61ec2cb5: defining beans [xxxx]; root of factory hierarchy Google了好久, 也困扰了好久这个问题.直到今天才想到一个笨而实用的方法… 解决先将pom.xml切换回正常的版本. 然后查看一下它的依赖树: 1mvn dependency:tree &gt; /tmp/old.lib 然后将pom.xml切换到升级版本之后的内容,然后再查看一下它的依赖树: 1mvn dependency:tree &gt; /tmp/new.lib 然后对比一下它们的差异: 1diff /tmp/old.lib /tmp/new.lib 查看一下新的依赖引入了哪些新的jar包或者版本改变了, 导致启动不了. 然后, 将除了升级指定版本的依赖以外的依赖, 通过显式指定与正常版本相同的版本即可. 例子下面是我真实的例子, 一个是升级前的依赖,一个是升级后的依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788╭─sky@sky-linux ~ ╰─➤ diff /tmp/old.lib /tmp/new.lib161c161,165&lt; [INFO] | | \- org.springframework:spring-jdbc:jar:3.2.8.RELEASE:compile---&gt; [INFO] | | +- org.springframework:spring-core:jar:3.2.8.RELEASE:compile&gt; [INFO] | | +- org.springframework:spring-jdbc:jar:3.2.8.RELEASE:compile&gt; [INFO] | | \- org.springframework:spring-context:jar:3.0.6.RELEASE:compile&gt; [INFO] | | +- org.springframework:spring-expression:jar:3.0.6.RELEASE:compile&gt; [INFO] | | \- org.springframework:spring-asm:jar:3.0.6.RELEASE:compile176,177c180,181&lt; [INFO] +- org.springframework.data:spring-data-redis:jar:1.3.0.RELEASE:compile&lt; [INFO] | +- org.springframework:spring-tx:jar:3.2.9.RELEASE:compile---&gt; [INFO] +- org.springframework.data:spring-data-redis:jar:1.6.4.RELEASE:compile&gt; [INFO] | +- org.springframework:spring-tx:jar:4.1.9.RELEASE:compile178a183&gt; [INFO] | +- org.springframework:spring-oxm:jar:4.1.9.RELEASE:compile181,185c186,187&lt; [INFO] | +- org.springframework:spring-context-support:jar:3.2.8.RELEASE:compile&lt; [INFO] | +- org.springframework:spring-core:jar:3.2.8.RELEASE:compile&lt; [INFO] | \- org.springframework:spring-context:jar:3.2.9.RELEASE:compile&lt; [INFO] | \- org.springframework:spring-expression:jar:3.2.9.RELEASE:compile&lt; [INFO] +- redis.clients:jedis:jar:2.3.0:compile---&gt; [INFO] | \- org.springframework:spring-context-support:jar:3.2.8.RELEASE:compile&gt; [INFO] +- redis.clients:jedis:jar:2.7.3:compile221c223,227&lt; [INFO] | | | \- org.springframework:spring-jdbc:jar:3.2.8.RELEASE:compile---&gt; [INFO] | | | +- org.springframework:spring-core:jar:3.2.8.RELEASE:compile&gt; [INFO] | | | +- org.springframework:spring-jdbc:jar:3.2.8.RELEASE:compile&gt; [INFO] | | | \- org.springframework:spring-context:jar:3.0.6.RELEASE:compile&gt; [INFO] | | | +- org.springframework:spring-expression:jar:3.0.6.RELEASE:compile&gt; [INFO] | | | \- org.springframework:spring-asm:jar:3.0.6.RELEASE:compile236,237c242,243&lt; [INFO] | +- org.springframework.data:spring-data-redis:jar:1.3.0.RELEASE:compile&lt; [INFO] | | +- org.springframework:spring-tx:jar:3.2.9.RELEASE:compile---&gt; [INFO] | +- org.springframework.data:spring-data-redis:jar:1.6.4.RELEASE:compile&gt; [INFO] | | +- org.springframework:spring-tx:jar:4.1.9.RELEASE:compile238a245&gt; [INFO] | | +- org.springframework:spring-oxm:jar:4.1.9.RELEASE:compile241,245c248,249&lt; [INFO] | | +- org.springframework:spring-context-support:jar:3.2.8.RELEASE:compile&lt; [INFO] | | +- org.springframework:spring-core:jar:3.2.8.RELEASE:compile&lt; [INFO] | | \- org.springframework:spring-context:jar:3.2.9.RELEASE:compile&lt; [INFO] | | \- org.springframework:spring-expression:jar:3.2.9.RELEASE:compile&lt; [INFO] | +- redis.clients:jedis:jar:2.3.0:compile---&gt; [INFO] | | \- org.springframework:spring-context-support:jar:3.2.8.RELEASE:compile&gt; [INFO] | +- redis.clients:jedis:jar:2.7.3:compile269c273,277&lt; [INFO] | | | \- org.springframework:spring-jdbc:jar:3.2.8.RELEASE:compile---&gt; [INFO] | | | +- org.springframework:spring-core:jar:3.2.8.RELEASE:compile&gt; [INFO] | | | +- org.springframework:spring-jdbc:jar:3.2.8.RELEASE:compile&gt; [INFO] | | | \- org.springframework:spring-context:jar:3.0.6.RELEASE:compile&gt; [INFO] | | | +- org.springframework:spring-expression:jar:3.0.6.RELEASE:compile&gt; [INFO] | | | \- org.springframework:spring-asm:jar:3.0.6.RELEASE:compile282,283c290,291&lt; [INFO] | +- org.springframework.data:spring-data-redis:jar:1.3.0.RELEASE:compile&lt; [INFO] | | +- org.springframework:spring-tx:jar:3.2.9.RELEASE:compile---&gt; [INFO] | +- org.springframework.data:spring-data-redis:jar:1.6.4.RELEASE:compile&gt; [INFO] | | +- org.springframework:spring-tx:jar:4.1.9.RELEASE:compile284a293&gt; [INFO] | | +- org.springframework:spring-oxm:jar:4.1.9.RELEASE:compile287,291c296,297&lt; [INFO] | | +- org.springframework:spring-context-support:jar:3.2.8.RELEASE:compile&lt; [INFO] | | +- org.springframework:spring-core:jar:3.2.8.RELEASE:compile&lt; [INFO] | | \- org.springframework:spring-context:jar:3.2.9.RELEASE:compile&lt; [INFO] | | \- org.springframework:spring-expression:jar:3.2.9.RELEASE:compile&lt; [INFO] | +- redis.clients:jedis:jar:2.3.0:compile---&gt; [INFO] | | \- org.springframework:spring-context-support:jar:3.2.8.RELEASE:compile&gt; [INFO] | +- redis.clients:jedis:jar:2.7.3:compile326c332&lt; [INFO] | +- redis.clients:jedis:jar:2.3.0:compile---&gt; [INFO] | +- redis.clients:jedis:jar:2.7.3:compile351,352c357,359&lt; [INFO] +- org.springframework.data:spring-data-redis:jar:1.3.0.RELEASE:compile&lt; [INFO] | +- org.springframework:spring-tx:jar:3.2.9.RELEASE:compile---&gt; [INFO] +- org.springframework.data:spring-data-redis:jar:1.6.4.RELEASE:compile&gt; [INFO] | +- org.springframework:spring-tx:jar:4.1.9.RELEASE:compile&gt; [INFO] | +- org.springframework:spring-oxm:jar:4.1.9.RELEASE:compile 然后, 定位看到升级后, 除了jedis和spring-data-redis升级后, 还导致引入了一些额外的jar包.才导致以上的问题. 这时, 将升级后的pom.xml, 再添加上以下依赖就可以解决了: 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-oxm --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-oxm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; 修改后完,就可以启动了.]]></content>
      <categories>
        <category>java</category>
        <category>slf4j</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>logback</tag>
        <tag>slf4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下安装GNU工具集]]></title>
    <url>%2F2016%2F07%2F21%2FMac%E4%B8%8B%E5%AE%89%E8%A3%85GNU%E5%B7%A5%E5%85%B7%E9%9B%86%2F</url>
    <content type="text"><![CDATA[安装 Homebrew1ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 修改 .bashrc 或者 .zshrc添加以下内容 1export PATH="$(brew --prefix coreutils)/libexec/gnubin:/usr/local/bin:$PATH" 安装 GNU Core Command Line Tools123456789101112131415161718192021222324252627282930313233343536373839brew install coreutilsbrew install binutilsbrew install diffutilsbrew install ed --default-namesbrew install findutils --with-default-namesbrew install gawkbrew install gnu-indent --with-default-namesbrew install gnu-sed --with-default-namesbrew install gnu-tar --with-default-namesbrew install gnu-which --with-default-namesbrew install gnutlsbrew install grep --with-default-namesbrew install gzipbrew install screenbrew install watchbrew install wdiff --with-gettextbrew install wgetbrew install bashbrew install emacsbrew install gdb # gdb requires further actions to make it work. See `brew info gdb`.brew install gpatchbrew install m4brew install makebrew install nanobrew install file-formulabrew install gitbrew install lessbrew install opensshbrew install perl518 # must run "brew tap homebrew/versions" first!brew install pythonbrew install rsyncbrew install svnbrew install unzipbrew install vim --override-system-vibrew install macvim --override-system-vim --custom-system-iconsbrew install zsh 来源topbug 我这里做多一份来备份.]]></content>
      <categories>
        <category>mac</category>
        <category>linux</category>
        <category>gnu</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>linux</tag>
        <tag>gnu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis代码片段]]></title>
    <url>%2F2016%2F07%2F21%2FMybatis%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[批处理1234567891011121314151617&lt;select id="getAdsByGroupIds" resultMap="adInfoWithGroupId"&gt; SELECTai.*, gam.group_id FROMgroup_ad_mapping AS gam LEFT JOINad_info AS ai ONgam.creative_id = ai.creative_id WHEREgam.group_id in &lt;foreach collection="list" item="item" index="index" separator="," open="(" close=")"&gt; #&#123;item&#125; &lt;/foreach&gt; ORDER BYai.create_at DESC&lt;/select&gt; 一对多java类 1234567891011121314151617181920212223public class SalesLead &#123; private Long id; private Long clientId; private Integer userId; private Integer salesUserId; private Integer agentUserId; private Integer saleStatus = 0; private Integer isDeal = 0; private Integer isRead = 0; private BigDecimal totalMoney = new BigDecimal("0"); private BigDecimal prepaid = new BigDecimal("0"); private String memo = ""; private String fromOpenid = ""; private String toOpenid = ""; private String des = ""; private String title = ""; private Timestamp createTime = new Timestamp(System.currentTimeMillis()); private Timestamp updateTime = new Timestamp(System.currentTimeMillis()); private Timestamp closeTime; private List&lt;SalesLeadFollow&gt; follows; //getter and settter&#125; 123456789101112131415161718192021222324252627282930313233343536&lt;resultMap id="salesLeadMap" type="com.company.sales.pojo.SalesLead"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="clientId" column="client_id"/&gt; &lt;result property="userId" column="user_id"/&gt; &lt;result property="salesUserId" column="sales_user_id"/&gt; &lt;result property="agentUserId" column="agent_user_id"/&gt; &lt;result property="saleStatus" column="sale_status"/&gt; &lt;result property="isDeal" column="is_deal"/&gt; &lt;result property="isRead" column="is_read"/&gt; &lt;result property="totalMoney" column="total_money"/&gt; &lt;result property="prepaid" column="prepaid"/&gt; &lt;result property="memo" column="memo"/&gt; &lt;result property="fromOpenid" column="from_openid"/&gt; &lt;result property="toOpenid" column="to_openid"/&gt; &lt;result property="des" column="des"/&gt; &lt;result property="title" column="title"/&gt; &lt;result property="createTime" column="create_time"/&gt; &lt;result property="updateTime" column="update_time"/&gt; &lt;result property="closeTime" column="close_time"/&gt; &lt;collection property="follows" ofType="com.company.sales.pojo.SalesLeadFollow" column="id" select="selectFollow" /&gt;&lt;/resultMap&gt;&lt;resultMap id="salesLeadFollowMap" type="com.company.sales.pojo.SalesLeadFollow"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="userId" column="user_id"/&gt; &lt;result property="followUserId" column="follow_user_id"/&gt; &lt;result property="followType" column="follow_type"/&gt; &lt;result property="salesLeadId" column="sales_lead_id"/&gt; &lt;result property="timeline" column="timeline"/&gt; &lt;result property="createTime" column="create_time"/&gt;&lt;/resultMap&gt;&lt;select id="selectFollow" resultMap="salesLeadFollowMap"&gt; SELECT * from sales_lead_follow WHERE sales_lead_id = #&#123;id&#125; ORDER BY id DESC&lt;/select&gt; 一对一12345678910111213141516171819202122232425262728293031323334public class WbStatus extends BasePojo implements Serializable &#123; private static final Logger log = LoggerFactory.getLogger(WbStatus.class); private static final long serialVersionUID = 1L; private Integer id; private Long sid = 0L; private String idstr = ""; private Long mid = 0L; private Long userId = 0L; private String userScreenName = ""; private String userProfileImageUrl = ""; private String text = ""; private String source = ""; private String thumbnailPic = ""; private String bmiddlePic = ""; private String originalPic = ""; private String retweetedStatusId = ""; private String geo = ""; private Integer repostsCount = 0; private Integer commentsCount = 0; private Integer attitudesCount = 0; private String visible = ""; private String picUrls = ""; private Timestamp createAt; private Timestamp updateAt; private String ad = ""; private Integer isDeleted = 0; //逻辑字段，不是DB字段. private WbUser wbUser; public WbStatus() &#123; &#125; Mybatis的代码片段: 12345678910111213141516171819202122232425262728293031&lt;resultMap id="wbStatusResultMap" type="com.weibosdk.pojo.WbStatus"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="sid" column="sid"/&gt; &lt;result property="idstr" column="idstr"/&gt; &lt;result property="mid" column="mid"/&gt; &lt;result property="userId" column="user_id"/&gt; &lt;result property="userScreenName" column="user_screen_name"/&gt; &lt;result property="userProfileImageUrl" column="user_profile_image_url"/&gt; &lt;result property="text" column="text"/&gt; &lt;result property="source" column="source"/&gt; &lt;result property="thumbnailPic" column="thumbnail_pic"/&gt; &lt;result property="bmiddlePic" column="bmiddle_pic"/&gt; &lt;result property="originalPic" column="original_pic"/&gt; &lt;result property="retweetedStatusId" column="retweeted_status_id"/&gt; &lt;result property="geo" column="geo"/&gt; &lt;result property="repostsCount" column="reposts_count"/&gt; &lt;result property="commentsCount" column="comments_count"/&gt; &lt;result property="attitudesCount" column="attitudes_count"/&gt; &lt;result property="visible" column="visible"/&gt; &lt;result property="picUrls" column="pic_urls"/&gt; &lt;result property="createAt" column="create_at"/&gt; &lt;result property="updateAt" column="update_at"/&gt; &lt;result property="ad" column="ad"/&gt; &lt;result property="isDeleted" column="is_deleted"/&gt; &lt;association property="wbUser" javaType="com.weibosdk.pojo.WbUser" select="selectWbUser" column="user_id"&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;select id="selectWbUser" resultMap="com.weibosdk.dao.mapper.WbUserMapper.wbUserResultMap"&gt; SELECT * from wb_user WHERE u_id = #&#123;userId&#125; limit 1&lt;/select&gt;]]></content>
      <categories>
        <category>java</category>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC单元测试controller]]></title>
    <url>%2F2016%2F07%2F21%2FSpringMVC%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95controller%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.MediaType;import org.springframework.mock.web.MockHttpServletRequest;import org.springframework.mock.web.MockHttpSession;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import org.springframework.test.context.web.WebAppConfiguration;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.MvcResult;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.web.context.WebApplicationContext;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;/** * Created by sky on 16-7-20. */@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfiguration@ContextConfiguration("classpath:spring-servlet.xml")public class TestMVC &#123; @Autowired WebApplicationContext wac; @Autowired MockHttpSession session; @Autowired MockHttpServletRequest request; private MockMvc mockMvc; @Before public void setup() &#123; this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).build(); &#125; @Test public void add() throws Exception &#123; Users user = new Users(); user.setUserId(44048); session.setAttribute(SessionConstant.CURRENT_USER, user); MvcResult mvcResult = this.mockMvc.perform(post("/sales/add").param("clientId", "10").param("salesUserId", "23").param("fromOpenid", "123").param("toOpenid", "456") .param("des", "hello des") .param("title", "title1") .session(session) .accept(MediaType.APPLICATION_JSON)) .andExpect(status().isOk()) .andReturn(); System.out.println(mvcResult.getResponse().getContentAsString()); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM性能排查神器 greys-anatomy]]></title>
    <url>%2F2016%2F07%2F15%2FJVM%E6%80%A7%E8%83%BD%E6%8E%92%E6%9F%A5%E7%A5%9E%E5%99%A8-greys-anatomy%2F</url>
    <content type="text"><![CDATA[这里只是记录下这个工具, 而不是使用手册, 因为Github greys-anatomy上已经有了非常详细的手册.]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中USE INDEX 和 FORCE INDEX]]></title>
    <url>%2F2016%2F07%2F15%2FMySQL%E4%B8%ADUSE-INDEX-%E5%92%8C-FORCE-INDEX%2F</url>
    <content type="text"><![CDATA[问题在一次生产环境排查性能问题时, 发现有个请求在一些用户的数据量比较大的情况下, 最高耗时差不多要3s. 而且还是一个轮询的请求. 原因在排查问题时, 定位到是执行某条SQL时在用户的数据比较大的情况下, SQL执行耗时要1.5s. 1234567891011121314151617mysql&gt; SELECT count(1) -&gt; FROM -&gt; cc_session cs -&gt; LEFT JOIN users_platform cp ON cs.user_id = cp.user_id -&gt; AND cs.to_openid = cp.open_id -&gt; WHERE -&gt; cs.`status` = 0 -&gt; AND cs.user_id = 219 -&gt; AND cs.agent_user_id = 219 -&gt; AND cs.create_time &lt; DATE_SUB(now(), INTERVAL 10 MINUTE) -&gt; AND cp.cc_open = 1;+----------+| count(1) |+----------+| 0 |+----------+1 row in set (1.50 sec) 它的执行计划如下: 123456789mysql&gt; explain SELECT count(1) FROM cc_session cs LEFT JOIN users_platform cp ON cs.user_id = cp.user_id AND cs.to_openid = cp.open_id WHERE cs.`status` = 0 AND cs.user_id = 219 AND cs.agent_user_id = 219 AND cs.create_time &lt; DATE_SUB(now(), INTERVAL 10 MINUTE) AND cp.cc_open = 1;+----+-------------+-------+------+---------------------------------------+---------------------+---------+------------------------+------+------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+---------------------------------------+---------------------+---------+------------------------+------+------------------------------------+| 1 | SIMPLE | cp | ref | uid_opid | uid_opid | 4 | const | 50 | Using index condition; Using where || 1 | SIMPLE | cs | ref | id_from_to_close_uq,idx_user_agent_id | id_from_to_close_uq | 194 | uniweibo_v2.cp.open_id | 127 | Using index condition; Using where |+----+-------------+-------+------+---------------------------------------+---------------------+---------+------------------------+------+------------------------------------+2 rows in set (0.00 sec) 两张表的索引如下: 123456789101112131415161718192021222324mysql&gt; show index from cc_session;+------------+------------+---------------------+--------------+---------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+------------+------------+---------------------+--------------+---------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| cc_session | 0 | PRIMARY | 1 | id | A | 3279492 | NULL | NULL | | BTREE | | || cc_session | 0 | id_from_to_close_uq | 1 | to_openid | A | 25822 | NULL | NULL | | BTREE | | || cc_session | 0 | id_from_to_close_uq | 2 | from_openid | A | 3279492 | NULL | NULL | | BTREE | | || cc_session | 0 | id_from_to_close_uq | 3 | closed_time | A | 3279492 | NULL | NULL | | BTREE | | || cc_session | 1 | idx_user_agent_id | 1 | user_id | A | 513 | NULL | NULL | | BTREE | | || cc_session | 1 | idx_user_agent_id | 2 | agent_user_id | A | 1886 | NULL | NULL | | BTREE | | |+------------+------------+---------------------+--------------+---------------+-----------+-------------+----------+--------+------+------------+---------+---------------+6 rows in set (0.00 sec)mysql&gt; show index from users_platform;+----------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+----------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| users_platform | 0 | PRIMARY | 1 | id | A | 373 | NULL | NULL | | BTREE | | || users_platform | 1 | uid_opid | 1 | user_id | A | 373 | NULL | NULL | | BTREE | | || users_platform | 1 | uid_opid | 2 | open_id | A | 373 | NULL | NULL | | BTREE | | |+----------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+3 rows in set (0.00 sec)mysql&gt; 由执行计划可知,它分别使用了cc_session表的id_from_to_close_uq索引, 和users_platform表中的uid_opid索引. 使用 use index 建议MySQL使用其他索引修改之后的SQL如下: 1234567891011121314151617181920mysql&gt; SELECT count(1) -&gt; FROM -&gt; cc_session cs use index (idx_user_agent_id) -&gt; LEFT JOIN users_platform cp use INDEX (uid_opid) -&gt; ON cs.user_id = cp.user_id -&gt; AND cs.to_openid = cp.open_id -&gt; WHERE -&gt; cs.`status` = 0 -&gt; AND cs.user_id = 219 -&gt; AND cs.agent_user_id = 219 -&gt; AND cs.create_time &lt; DATE_SUB(now(), INTERVAL 10 MINUTE) -&gt; AND cp.cc_open = 1;+----------+| count(1) |+----------+| 0 |+----------+1 row in set (0.01 sec)mysql&gt; 耗时从1.5秒,降低到0.01秒 执行计划如下: 123456789101112131415161718192021mysql&gt; explain SELECT count(1) -&gt; FROM -&gt; cc_session cs use index (idx_user_agent_id) -&gt; LEFT JOIN users_platform cp use INDEX (uid_opid) -&gt; ON cs.user_id = cp.user_id -&gt; AND cs.to_openid = cp.open_id -&gt; WHERE -&gt; cs.`status` = 0 -&gt; AND cs.user_id = 219 -&gt; AND cs.agent_user_id = 219 -&gt; AND cs.create_time &lt; DATE_SUB(now(), INTERVAL 10 MINUTE) -&gt; AND cp.cc_open = 1;+----+-------------+-------+------+-------------------+-------------------+---------+--------------------------------+-------+------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+-------------------+-------------------+---------+--------------------------------+-------+------------------------------------+| 1 | SIMPLE | cs | ref | idx_user_agent_id | idx_user_agent_id | 8 | const,const | 22966 | Using where || 1 | SIMPLE | cp | ref | uid_opid | uid_opid | 180 | const,uniweibo_v2.cs.to_openid | 1 | Using index condition; Using where |+----+-------------+-------+------+-------------------+-------------------+---------+--------------------------------+-------+------------------------------------+2 rows in set (0.00 sec)mysql&gt; use index 和 force indexuse index : 是建议MySQL去使用这个索引.最后到底是用不用, 还是由MySQL来决定. 如果MySQL还是觉得全表扫描来得快, 那即使是有索引, 它还是会使用全表扫描.force index : 是强制MySQL去使用这个索引. 如果用不上, 就全表. 如果能用上, 就一定会使用该索引.]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git自动化部署项目]]></title>
    <url>%2F2016%2F07%2F13%2FGit%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[操作步骤创建一个裸仓库123mkdir /home/sky/auto/gitcd /home/sky/auto/gitgit init --bare . 添加一个git勾子(就是执行提交代码后的脚本, 这里可以用来执行你部署的脚本就完成自动部署啦.)创建完裸仓库后, 里有一个hooks的目录. 1cd /home/sky/auto/git/hooks 创建一个文件名为post-receive, 并且添加一个可执行的权限给它, 内容如下: 12345678910111213141516171819#!/bin/shexport PATH=自定义的命令行PATH:$PATH# 这个是用来部署的仓库目录DEPLOY_PATH="/home/sky/auto/deploy"cd /home/sky/auto/deployls -lahecho "before pull, pwd = " $( pwd ) ", whoiam" $( whoami)#这行不能删除哈,不然会报. fatal: Not a git repository (or any of the parent directories): .git 这样类似的错误.unset GIT_DIRgit pull origin master || exit 1$&#123;DEPLOY_PATH&#125;/deploy.shecho "deploy done" &gt;&gt; /tmp/auto-deploy.log 为项目添加一个远程仓库指向 裸仓库假设原项目仓库在/home/sky/git/myproject 12cd /home/sky/git/myprojectgit add remote auto-deploy 你的用户名@你的IP:/home/sky/auto/git 提交代码时,自动部署1git push auto-deploy 本地要部署的分支:master --force 这样子提交到裸仓库的远程地址时,就会触发post-receive脚本,然后在该脚本里进行自动化部署即可了.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven配置远程仓库]]></title>
    <url>%2F2016%2F07%2F13%2FMaven%E9%85%8D%E7%BD%AE%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[12345678910111213&lt;mirror&gt; &lt;id&gt;repo2&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://repo2.maven.org/maven2/&lt;/url&gt;&lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;&lt;/mirror&gt; 这个速度还可以.不知道为什么,它比repo1.maven.org访问更好.]]></content>
      <categories>
        <category>maven</category>
        <category>dependency</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>dependency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习九之远程调试Tomcat自身]]></title>
    <url>%2F2016%2F07%2F07%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%9D%E4%B9%8B%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95Tomcat%E8%87%AA%E8%BA%AB%2F</url>
    <content type="text"><![CDATA[如果我们想要在远程服务器上, 来调试Tomcat自身的话, 那应该如何做呢. 今天本想为Tomcat添加一个功能时, 发现配置一直没生效, 而且Tomcat一直就打印Found no logging.properties. 实在没办法, 就想到远程调试一下Tomcat自身. 修改启动参数复制一个startup.sh, 假设复制后的文件名为debug.startup.sh 将原文件的 1exec "$PRGDIR"/"$EXECUTABLE" start "$@" 修改为以下的内容: 123456export JPDA_TRANSPORT=dt_socketexport JPDA_ADDRESS=8000export JPDA_SUSPEND=yexec "$PRGDIR"/"$EXECUTABLE" jpda start "$@" 即可. 启动直接运行debug.startup.sh即可. 这时,你会发现, 它在启动的时候, 会停留在以下类似信息这里, 等待你的调试器的连接了: 1Listening for transport dt_socket at address: 8000 这时, 通过 IDE 来进行远程Debug即可. 关于如何将Tomcat源码导入到IDE中, 可以参考/2016/06/27/Tomcat-8-源码学习一之导入到IDEA/ 这时就可以进行你的debug了. 这样子,Tomcat出现的问题, 都可以非常清楚地通过Debug来详细了解Tomcat内部的处理情况了.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习八之Valve组件]]></title>
    <url>%2F2016%2F07%2F06%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E5%85%AB%E4%B9%8BValve%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Tomcat内部Valve组件,与我们普通使用的Filter, Interceptor这些概念非常类似.只不过,Valve只是针对Tomcat内部的.而Filter是Servlet的标准, Interceptor是框架层次上的概念. 它们的工作方式都是一种责任链的传递来拦截Request, Response然后进行自定义的处理. Valve 接口123456789101112131415161718192021package org.apache.catalina;import java.io.IOException;import javax.servlet.ServletException;import org.apache.catalina.comet.CometEvent;import org.apache.catalina.connector.Request;import org.apache.catalina.connector.Response;public interface Valve &#123; Valve getNext(); void setNext(Valve var1); void backgroundProcess(); void invoke(Request var1, Response var2) throws IOException, ServletException; void event(Request var1, Response var2, CometEvent var3) throws IOException, ServletException; boolean isAsyncSupported();&#125; 我们可以看到,Valve接口的参数,主要也是Request和Response,然后调用下一个Valve. 使用场景如果我们想添加一种对同一个Tomcat下所有的应用都生效的Filter,就可以使用Valve来处理了.而Filter, Interceptor这些,都只是在某个应用或框架中使用. 例子创建一个自定义Valve的项目.(打包成jar). 12345678910111213141516171819package org.emacsist.valve;import org.apache.catalina.connector.Request;import org.apache.catalina.connector.Response;import org.apache.catalina.valves.ValveBase;import javax.servlet.ServletException;import java.io.IOException;/** * Created by sky on 16-7-6. */public class ModifiedValve extends ValveBase &#123; public void invoke(Request request, Response response) throws IOException, ServletException &#123; // todo yourself logic getNext().invoke(request, response); &#125;&#125; 然后将项目打包, 然后放到Tomcat的lib目录下,然后再在conf/server.xml里配置Valve元素即可.例如: 12345678910111213141516171819 &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;!-- SingleSignOn valve, share authentication between web applications Documentation at: /docs/config/valve.html --&gt; &lt;!-- &lt;Valve className="org.apache.catalina.authenticator.SingleSignOn" /&gt; --&gt; &lt;!-- Access log processes all example. Documentation at: /docs/config/valve.html Note: The pattern used is equivalent to using pattern="common" --&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;&lt;Valve className="org.emacsist.valve.ModifiedValve" /&gt; &lt;/Host&gt;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习七之请求如何从Tomcat到我们的SpringMVC]]></title>
    <url>%2F2016%2F06%2F30%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B8%83%E4%B9%8B%E8%AF%B7%E6%B1%82%E5%A6%82%E4%BD%95%E4%BB%8ETomcat%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84SpringMVC%2F</url>
    <content type="text"><![CDATA[一次请求的调用栈 从上面的线程调用栈,可以看到一次请求的调用过程. 注意中间那些以Valve结尾的类,它是Tomcat的里的责任链的组件.每一个组件,在Tomcat里都有自己对请求时可以进行自定义的处理.比如AccessLogValve就是记录访问日志的Valve.Tomcat自带的Valve,可以在包org.apache.catalina.valves下可以看到所有的列表. 测试代码HelloServlet12345678910111213141516171819package com.example;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;/** * Created by sky on 16-6-30. */public class HelloServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; resp.getWriter().write("hello world"); resp.getWriter().flush(); resp.getWriter().close(); &#125;&#125; web.xml12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="ISO-8859-1"?&gt;&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.--&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1" metadata-complete="true"&gt; &lt;display-name&gt;Welcome to Tomcat&lt;/display-name&gt; &lt;description&gt; Welcome to Tomcat &lt;/description&gt; &lt;servlet&gt; &lt;servlet-name&gt;hello-servlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.example.HelloServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;hello-servlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/hello&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 解析HTTP协议Tomcat8默认使用 NIO 来处理HTTP了.看调用栈,可以知道,它通过org.apache.coyote.http11.AbstractInputBuffer.parseRequestLine()来解析请求头的. 请求头的内容,保存在以下这个字段里. 1234/*** Pointer to the current read buffer.*/protected byte[] buf; 解析完成后,就创建了一个org.apache.catalina.connector.Request对象. 调用相应的责任链通过Requset对象,再查找相应的Servlet(应该说是调用链,在Tomcat里,它用StandardWrapper对象表示, 在这里就是hello-servlet)(代码是 StandardWrapper wrapper = (StandardWrapper) getContainer(); )最后,Tomcat就会调用名为hello-servlet的Servlet来执行代码了. Tomcat到SpringMVC上面就已经执行到了我们自定义的hello-servlet了,只要将这个Servlet,替换成Spring的org.springframework.web.servlet.DispatcherServlet即可.它是SpringMVC的总控制及转发器(路由器,因为SpringMVC并不是使用传统的Servlet来对应每一个请求,而是使用Bean的某个方法来处理).]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习六之加载webapps]]></title>
    <url>%2F2016%2F06%2F29%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E5%85%AD%E4%B9%8B%E5%8A%A0%E8%BD%BDwebapps%2F</url>
    <content type="text"><![CDATA[Tomcat中的层次 123456Catalina -&gt; Server --- |---globalNamingResources |---namingContextListener |---多个Service --------------------| |---catalina.home |---Engine(每个Service最多一个) ---多个Container(比如host) |---catalina.base Tomcat有明显的层次关系上层只会对自己直接下一层的组件负责初始化,然后下一组件再对自己的子组件进行初始化. 可以看到,Tomcat中如果部署多个应用时,每一个Host,就代表了一主机.可以这样了比作: 12345Catalina或Server就是一个服务器.Host就是该服务器上的一个虚拟主机.Application就是虚拟主机上的一个应用.(webapss目录下的每一个目录就对应一个application,在Tomcat里,用 org.apache.catalina.startup.HostConfig 类的内部类 DeployedApplication 来表示.) 初始化一个 Host每一个Host,都有一个org.apache.catalina.startup.HostConfig对象代表.它会根据配置文件conf/server.xml中的&lt;host&gt;节点相匹配. 部署的代码为: 12345678910111213protected void deployApps() &#123; File appBase = host.getAppBaseFile(); File configBase = host.getConfigBaseFile(); String[] filteredAppPaths = filterAppPaths(appBase.list()); // Deploy XML descriptors from configBase deployDescriptors(configBase, configBase.list()); // Deploy WARs deployWARs(appBase, filteredAppPaths); // Deploy expanded folders deployDirectories(appBase, filteredAppPaths);&#125; 部署 deployDescriptors先部署deployDescriptors(),它的描述文件目录在conf/Catalina/localhost这个虚拟主机目录下.比如,创建一个文件名为myapp.xml,内容为: 1&lt;Context path="/myapp" docBase="/home/sky/ROOT" debug="0" privileged="true"&gt;&lt;/Context&gt; 它就会根据该目录下的myapp.xml文件配置来部署应用.比如上面的例子,它会部署一个path为/myapp, 部署的目录为/home/sky/ROOT.这样子,就可以通过http://localhost:8080/myapp来访问了.这种方式,可以不必将应用程序的目录,放到webapps目录下. 部署 wars它会根据在配置文件conf/server.xml中的&lt;host&gt;的appBase属性的值所在的目录(默认为webapps)下查找.war结尾的文件, 然后再判断是否需要解压(根据配置文件中的 unpackWARs 属性). 如果解压了,就和部署目录的逻辑是一样的. 部署 目录它的代码如下,可以看到,对于每个目录,它是通过多线程来进行部署的.每一个目录都有一条线程去负责部署.而且是利用Host的getStartStopExecutor来执行的. 1234567891011121314151617private static class DeployDirectory implements Runnable &#123; private HostConfig config; private ContextName cn; private File dir; public DeployDirectory(HostConfig config, ContextName cn, File dir) &#123; this.config = config; this.cn = cn; this.dir = dir; &#125; @Override public void run() &#123; config.deployDirectory(cn, dir); &#125;&#125; 部署的主要逻辑,是初始化一个StandardContext对象(还带有一个 ContextConfig 对象, 这个config对象,就是web.xml的代表. ).代表该应用的上下文对象.然后将host的listener(相当于host对所有应用都生效的listener,即对host来说是全局应用到每个应用的)添加到该application的Listener生命周期中.代码逻辑如下: 123456789Class&lt;?&gt; clazz = Class.forName(host.getConfigClass());LifecycleListener listener = (LifecycleListener) clazz.newInstance(); # 这里就添加了一个 ContextConfig 对象.它随着 StandardContext的生命周期一起存灭.context.addLifecycleListener(listener);context.setName(cn.getName());context.setPath(cn.getPath());context.setWebappVersion(cn.getVersion());context.setDocBase(cn.getBaseName());host.addChild(context); cn为ContextName,它的构造逻辑如下: 根据webapps目录下的目录名,创建相应的应用名(里面有个特殊判断,如果目录名为ROOT,这个名字是硬编码写死的.那么它的path为”/“,即不需要通过应用名即可访问.) ContextConfig 类它会解析 StandardContext 以及 Webxml , 逻辑在 init 方法中: 1234567891011121314151617protected void init() &#123; // Called from StandardContext.init() Digester contextDigester = createContextDigester(); contextDigester.getParser(); if (log.isDebugEnabled()) &#123; log.debug(sm.getString("contextConfig.init")); &#125; context.setConfigured(false); ok = true; contextConfig(contextDigester); webXmlParser = new WebXmlParser(context.getXmlNamespaceAware(), context.getXmlValidation(), context.getXmlBlockExternal()); # 解析web.xml &#125; 它和解析Tomcat的conf/server.xml这些类似,都是初始化相应的组件. web.xml所有组件,都在org.apache.tomcat.util.descriptor.web.WebRuleSet里可以看到.(这里只列出部分,以免占太多篇幅) 12345678910111213digester.addCallMethod(fullPrefix + "/servlet/servlet-class", "setServletClass", 0);digester.addCallMethod(fullPrefix + "/servlet/servlet-name", "setServletName", 0);digester.addObjectCreate(fullPrefix + "/servlet/multipart-config", "org.apache.tomcat.util.descriptor.web.MultipartDef");digester.addSetNext(fullPrefix + "/servlet/multipart-config", "setMultipartDef", "org.apache.tomcat.util.descriptor.web.MultipartDef");digester.addCallMethod(fullPrefix + "/servlet/multipart-config/location", "setLocation", 0); 比如Filter,Listener, Session参数等等. web.xml 的对应类 WebXmlWebXml类是web.xml的对应代表类. 各个 web.xml 版本对应的J2EE版本.org.apache.tomcat.util.descriptor.DigesterFactory 在这人类有明确的对照表. 参考资料CSDN aesop_wubo]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习五之Tomcat日志系统]]></title>
    <url>%2F2016%2F06%2F29%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%BA%94%E4%B9%8BTomcat%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[juli默认情况下，Tomcat使用自身的juli作为Tomcat内部的日志处理系统.它的源码，在Tomcat源码结构下的org.apache.juli包下. juli与JDK logger的关系juli是继承自JDK的logger的.通过源码可以确认这一点: 12public class ClassLoaderLogManager extends LogManager &#123;&#125; 如果想要开启juli日志自身的调试，可以设置一个JVM系统属性org.apache.juli.ClassLoaderLogManager.debug=true即可。 juli日志构架ClassLoaderLogManagerJULI的核心类,负责加载配置文件,以及初始化配置文件里的Handlers, Logger等信息. 可以看到，它的构造函数: 12345678public ClassLoaderLogManager() &#123; super(); try &#123; Runtime.getRuntime().addShutdownHook(new Cleaner()); &#125; catch (IllegalStateException ise) &#123; // We are probably already being shutdown. Ignore this error. &#125;&#125; 在JVM退出时，添加了一个shutdownHook，来进行日志框架自身的清理工作.它调用了LogManager.shutdown()方法. 它的公共方法有如下: 1234567891011ClassLoaderLogManager # 构造函数isUseShutdownHook # 判断是否使用shutdown勾子setUseShutdownHook # 设置是否使用shutdown勾子addLogger # 添加一个LoggergetLogger # 获取一个LoggergetLoggerNames # 获取所有的Logger名字getProperty # 获取属性readConfiguration # 读取配置文件 logging.properties,并初始化LoggerreadConfiguration # 读取配置文件 logging.properties,并初始化Loggerreset # 重置所有loggershutdown # 清理所有logger readConfiguration(ClassLoder)它读取logging.properties，并创建一个RootLogger(名字为””，即空字符串，不是NULL哈).并创建一个ClassLoaderLogInfo对象（与指定的ClassLoader匹配） 创建完成后，它再调用readConfiguration(InputStream is, ClassLoader classLoader)f方法，将logging.properties作为InputStream，再传入classLoader参数来调用继续初始化其他的Logger. readConfiguration(InputStream is, ClassLoader classLoader)获取根据参数(classLoader)来获取ClassLoaderLogInfo对象，看它的数据结构可知，它是整个ClassLoder的所有Loger结构对象. 1234567891011protected static final class ClassLoaderLogInfo &#123; final LogNode rootNode; final Map&lt;String, Logger&gt; loggers = new ConcurrentHashMap&lt;&gt;(); final Map&lt;String, Handler&gt; handlers = new HashMap&lt;&gt;(); final Properties props = new Properties(); ClassLoaderLogInfo(final LogNode rootNode) &#123; this.rootNode = rootNode; &#125;&#125; 包含RootLogger（它保存在rootNode节点中)，以及其他Loggers，Handlers，以及logging.properties的pros对象. 经过上面的处理，我们再来看下之后的逻辑： 根据logging.properties获取.handlers属性的值来获取所有的handlers对象.以默认的Tomcat的logging.properties为例，它的配置如下: .handlers = 1catalina.org.apache.juli.AsyncFileHandler, java.util.logging.ConsoleHandler .handlers：它是RootLogger默认的Handler 根据logging.properties获取handlers属性的值来获取非RootLogger的handlers对象.Tomcat中默认有以下几个: handlers = 1catalina.org.apache.juli.AsyncFileHandler, 2localhost.org.apache.juli.AsyncFileHandler, 3manager.org.apache.juli.AsyncFileHandler, 4host-manager.org.apache.juli.AsyncFileHandler, java.util.logging.ConsoleHandler 如果handlers的值为空（null），则将handlers的字符串进行处理.分别获取以下的值（这里以1catalina.org.apache.juli.AsyncFileHandler为例子，其他类似） handlerName：1catalina.org.apache.juli.AsyncFileHandler handlerClassName：catalina.org.apache.juli.AsyncFileHandler(它会删除handlerName数字开头的部分.剩下的就是handlerClassName) prefix：1catalina. 然后创建一个指定的handlerClassName的Handler，然后保存到ClassLoaderLogInfo对象中的handlers字段里，handlers属性是一个Map&lt;String,Hander&gt;，它的Key就是handlerName（这里的值为1catalina.org.apache.juli.AsyncFileHandler，value就是根据handlerClassName创建出来的Handler对象. 其他的handler以此类推. 到这里，根据配置文件初始化RootLogger以及配置文件里指定的Handler都已经初始化完毕了. LogFactoryprivate static final Log log = LogFactory.getLog(Bootstrap.class); 我们来看看这Log到底是如何实现的，上面这一行代码，获取了一个org.apache.juli.logging.Log对象。它是通过org.apache.juli.logging.LogFactory来获取一个实例的.整个调用栈为: 1LogFactory.getLog(name) -&gt; LogFactory.getInstance(name) -&gt; DirectJDKLog.getInstance(name) -&gt; new DirectJDKLog(name) 然后,在DirectJDKLog对象里,使用了JDK中的Logger来进行日志打印. 调用JDK的Logger时,会触发初始化juli的ClassLoaderLogManager(主要加载配置文件).(因为Tomcat启动时,会指定两个日志参数: 12-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager-Djava.util.logging.config.file=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/logging.properties Log Leveljava.util.logging.Level类记录了每个Log Level以及它们对应的int值.比较Leve时,就是通过比较它们的intValue来比较大小的. org.apache.juli.logging.Log它实质上是通过持有JDKjava.util.logging.Logger来实现日志打印的.所以,我们来看看这个JDK的Logger对象. 化繁为简,它主要有以下这几个(这里只是列出主要部分): 123private volatile LogManager manager; # 所属的LogManager, 因为JDK里,允许自定义LogManager,即Tomcat上面启动时指定的参数, -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManagerprivate String name; # Logger的名字 private final CopyOnWriteArrayList&lt;Handler&gt; handlers = new CopyOnWriteArrayList&lt;&gt;(); # 这个就是Logger的Handler, 日志就是通过它来控制输出的,比如输出到文件,终端,或者Socket等.这个在初始化 ClassLoaderLogManager 时加载. 更新2016-7-7今天再次调试了一下, 发现org.apache.juli.ClassLoaderLogManager.readConfiguration(ClassLoader classLoader)这个方法, 发现它加载的次数为: AppClassLoader.即加载以下以这些类: 12345678910111213141516171819202122232425262728--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/charsets.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/deploy.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/cldrdata.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/dnsns.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/jaccess.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/jfxrt.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/localedata.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/nashorn.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/sunec.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/sunjce_provider.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/sunpkcs11.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/ext/zipfs.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/javaws.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/jce.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/jfr.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/jfxswt.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/jsse.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/management-agent.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/plugin.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/resources.jar--&gt; url --&gt; file:/ihome/java/jdk/jdk1.8.0_60/jre/lib/rt.jar--&gt; url --&gt; file:/ihome/java/tomcat/apache-tomcat-7.0.70-src/target/classes/--&gt; url --&gt; file:/home/sky/.m2/repository/org/apache/ant/ant/1.7.0/ant-1.7.0.jar--&gt; url --&gt; file:/home/sky/.m2/repository/org/apache/ant/ant-launcher/1.7.0/ant-launcher-1.7.0.jar--&gt; url --&gt; file:/home/sky/.m2/repository/wsdl4j/wsdl4j/1.6.2/wsdl4j-1.6.2.jar--&gt; url --&gt; file:/home/sky/.m2/repository/javax/xml/jaxrpc-api/1.1/jaxrpc-api-1.1.jar--&gt; url --&gt; file:/home/sky/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.5/ecj-4.5.jar--&gt; url --&gt; file:/ihome/java/ide/idea-IU-145.258.11/lib/idea_rt.jar 这一次,一般会找不到logging.properties, 然后它会进入到以下判断中: 12345678910111213141516171819202122if ((is == null) &amp;&amp; (classLoader == ClassLoader.getSystemClassLoader())) &#123; String configFileStr = System.getProperty("java.util.logging.config.file"); if (configFileStr != null) &#123; try &#123; is = new FileInputStream(replace(configFileStr)); &#125; catch (IOException e) &#123; System.err.println("Configuration error"); e.printStackTrace(); &#125; &#125; // Try the default JVM configuration if (is == null) &#123; File defaultFile = new File(new File(System.getProperty("java.home"), "lib"), "logging.properties"); try &#123; is = new FileInputStream(defaultFile); &#125; catch (IOException e) &#123; System.err.println("Configuration error"); e.printStackTrace(); &#125; &#125; &#125; 这个就是加载Tomcat默认的logging.properties日志配置文件. URLClassLoader. 这个没有加载任何资源 WebappClassLoader 这个classloder会加载webapps目录下每一个应用, 即每一个应用,都会加载一次,并且读取该应用下的classpath中的logging.properties日志配置文件.它加载的资源为: webapps/appname/WEB-INF/classes目录和webapps/appname/WEB-INF/lib目录 Tomcat启动时报错SEVERE: Error listenerStart 或者 SEVERE: Error filterStart 等可以利用上面的说明, 在出现问题的应用上,假设你的应用叫demo, 那么,就可以在目录:webapps/demo/WEB-INF/classes下添加一个名为logging.properties的文件, 文件的内容为: 12345678910111213handlers = org.apache.juli.FileHandler, java.util.logging.ConsoleHandler############################################################# Handler specific properties.# Describes specific configuration info for Handlers.############################################################org.apache.juli.FileHandler.level = FINEorg.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logsorg.apache.juli.FileHandler.prefix = error-debug.java.util.logging.ConsoleHandler.level = FINEjava.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter 这时,Tomcat就会在控制台里打印详细的报错信息了. 参考资料CSDN qingkangxu iteye xpenxpen]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习四之Catalina类]]></title>
    <url>%2F2016%2F06%2F28%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E5%9B%9B%E4%B9%8BCatalina%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[StringManager每个包一个StringManager。这样子，对同一个包(以及同一个locale)来说，它只有一个实例的。实现原理: 1private static final Map&lt;String, Map&lt;Locale,StringManager&gt;&gt; managers = new Hashtable&lt;&gt;(); key：就是包名.value：就是它的由locale,StringManager组合的Map 它的作用，就是实现日志打印的国际化.比如，在包/org/apache/catalina/startup下，可以看到有以下几个国际化的资源文件: 123456╭─sky@sky-linux /ihome/java/tomcat/apache-tomcat-8.0.36-src/java/org/apache/catalina/startup ╰─➤ ls -al LocalStrings*-rw-r--r-- 1 sky sky 8590 6月 9 15:00 LocalStrings_es.properties-rw-r--r-- 1 sky sky 4536 6月 9 15:00 LocalStrings_fr.properties-rw-r--r-- 1 sky sky 6770 6月 9 15:00 LocalStrings_ja.properties-rw-r--r-- 1 sky sky 12332 6月 9 15:00 LocalStrings.properties ResourceBundleStringManager是封装了ResourceBundle的， ResourceBundle简单用法: 12345678910111213141516171819202122package com.example;import java.util.Locale;import java.util.ResourceBundle;/** * Created by sky on 16-6-28. */public class TestBundle &#123; public static void main(String[] args) &#123; String bundleName = "res"; Locale localeZH = new Locale("zh", "CN"); ResourceBundle resourceBundleZH = ResourceBundle.getBundle(bundleName, localeZH); System.out.println(resourceBundleZH.getString("hello")); Locale localeEN = new Locale("en", "US"); ResourceBundle resourceBundleEN = ResourceBundle.getBundle(bundleName, localeEN); System.out.println(resourceBundleEN.getString("hello")); &#125;&#125; 在classpath根目录下，创建两个文件:res_en_US.properties, res_zh_CN.properties res_en_US.properties文件内容: 1hello=hello world from en US res_zh_CN.properties文件内容: 1hello=hello world from zh CN 最后执行上面的代码，即可以看到它会输出下面的结果: 1234hello world from zh CNhello world from en USProcess finished with exit code 0 Catalina它的构造函数就一个，代码如下： 123public Catalina() &#123; setSecurityProtection(); &#125; setSecurityProtection()方法代码如下: 12345protected void setSecurityProtection()&#123; SecurityConfig securityConfig = SecurityConfig.newInstance(); securityConfig.setPackageDefinition(); securityConfig.setPackageAccess(); &#125; SecurityConfig它的作用是，再次保护Tomcat的包访问权限. 默认情况下它是获取catalina.properties文件中的package.definition和package.access两个属性的值.如果这两个值为空，则设置为该类中默认的PACKAGE_DEFINITION和PACKAGE_ACCESS值. 最后，将这两个值，设置到java.security.Security类中的属性时，Security类主要用于管理提供者. Oracle JavaSE Security文档 tutorialspoint 启动TomcatCatalina表示一个Tomcat服务器实例.现在我们来看看它的各种逻辑处理. start()启动前，会先判断有没有Server实例，即: 12345678if (getServer() == null) &#123; load();&#125;if (getServer() == null) &#123; log.fatal("Cannot start server. Server instance is not configured."); return;&#125; 可以看到，如果第二次判断还是null，就直接打印日志并退出了. 那我们再来看看 load() 方法加载server的逻辑是如何的. 1234561. initDirs() : 初始化 java.io.tmpdir 目录2. initNaming() : 初始化Java命名服务3. 使用 Digester 读取`server.xml`配置文件作为server instance配置.4. 设置server的catalina, catalinaHome, catalinaBase5. initStreams()： 设置标准输出和错误输出为 SystemLogHandler 接管.6. 最后调用 server.init() 方法来初始化server的生命周期阶段. 关于Tomcat组件的生命周期，它们是通过实现 Lifecyle 接口来进行处理的.经过上面的步骤处理后，server就算是启动完毕了. server.xml 解析器 Digester在org.apache.catalina.startup.Catalina.createStartDigester()方法上，可以看到整个xml的节点结构. 初始化的时候，就会调用这个方法然后初始化Server, GlobalNamingResources, Listener, Service, Executor, Connector, Engine等，然后它会调用相相关的setXXX方法来设置相应值。 例如: 123digester.addSetNext("Server/GlobalNamingResources", "setGlobalNamingResources", "org.apache.catalina.deploy.NamingResourcesImpl"); Server/GlobalNamingResources表示设置 Server 类的 globalNamingResources 属性.setGlobalNamingResources表示方法名org.apache.catalina.deploy.NamingResourcesImpl：表示参数类型. 其他类似. catalina.startServer() 获取或初化 StandardServer 注册关闭勾子（shutdownHook， JVM的一种勾子机制）。本质上是调用Catalina.stop()方法，然后Catalina.stop()方法的处理逻辑是：移除这个勾子，然后调用 Server.stop()，最后再调用 Server.destroy(). catalina.stopServer()通过源码可以看到，它本上是通过解析server.xml（通过 Digester digester = createStopDigester(); 获取stop时需要的节点元素及数据）然后向注册了关闭勾子的线程(shutdownHook)发送一个在server.xml里配置的shutdown的字符串的值发送到勾子线程监听的socket里，然后触发catalina.stop()方法的。（即在上面说的原理） 而这个shutdown字符串的值，是在server.xml里配置的. 1&lt;Server port="8005" shutdown="SHUTDOWN"&gt; 即，解析完server.xml后，获取这个shutdown属性的值（这里为SHUTDOWN)，然后发送到shutdownHook勾子里，让它触发catalina.stop()的方法. StandardServer 类启动Server启动的顺序，通过源码可知: org.apache.catalina.core.StandardServer中的下面方法. 123456789101112131415@Overrideprotected void startInternal() throws LifecycleException &#123; fireLifecycleEvent(CONFIGURE_START_EVENT, null); setState(LifecycleState.STARTING); globalNamingResources.start(); // Start our defined Services synchronized (servicesLock) &#123; for (int i = 0; i &lt; services.length; i++) &#123; services[i].start(); &#125; &#125;&#125; 即: Server -&gt; globalNamingResources.start(), Service.start()service -&gt; container.start()service -&gt; executors.start()service -&gt; listener.start()service -&gt; connector.start() 即每个组件初始化启动时，都会负责去启动自己内部组件的嵌套组件.比如上面的情况，通过debug源码，可以看到上面的层次关系. stopServerdestroyInternal()，源码如下： 123456789101112131415@Overrideprotected void destroyInternal() throws LifecycleException &#123; // Destroy our defined Services for (int i = 0; i &lt; services.length; i++) &#123; services[i].destroy(); &#125; globalNamingResources.destroy(); unregister(onameMBeanFactory); unregister(onameStringCache); super.destroyInternal();&#125; server -&gt; service.destroy()]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习三之SecurityClassLoad]]></title>
    <url>%2F2016%2F06%2F27%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B8%89%E4%B9%8BSecurityClassLoad%2F</url>
    <content type="text"><![CDATA[关于Java的 SecurityManager默认情况下,JVM是不会启用SecurityManager的，想要开启，则需要在启动时指定-Djava.security.manager，如果还想指定你的应用的策略文件，还可以添加多一个参数-Djava.security.policy=/path/to/my.policy Tomcat中的 SecurityClassLoad为了安全加载类，Tomcat中通过org.apache.catalina.security.SecurityClassLoad来预加载Tomcat自身的核心类（如果启用了SecurityManager的话，通过Tomcat的参数-security来开启），以免在之后触发AccessControlException的RuntimePermission. 错误在调试的时候，开启了-Djava.security.manager 12345678910-Dcatalina.home=/ihome/java/tomcat/apache-tomcat-8.0.36-src-Dcatalina.base=/ihome/java/tomcat/apache-tomcat-8.0.36-src-Djava.endorsed.dirs=/ihome/java/tomcat/apache-tomcat-8.0.36-src/endorsed-Djava.io.tmpdir=/ihome/java/tomcat/apache-tomcat-8.0.36-src/temp-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager-Djava.util.logging.config.file=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/logging.properties-Djava.security.manager-Djava.security.policy=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/catalina.policy-Didea.launcher.bin.path=/ihome/java/ide/idea-IU-145.258.11/bin 发现报如下错误: 1234567891011121314Connected to the target VM, address: '127.0.0.1:43769', transport: 'socket'Exception in thread "main" java.lang.ExceptionInInitializerError at org.apache.juli.logging.LogFactory.getInstance(LogFactory.java:115) at org.apache.juli.logging.LogFactory.getInstance(LogFactory.java:137) at org.apache.juli.logging.LogFactory.getLog(LogFactory.java:188) at org.apache.catalina.startup.Bootstrap.&lt;clinit&gt;(Bootstrap.java:52)Caused by: java.security.AccessControlException: access denied ("java.util.PropertyPermission" "java.util.logging.config.class" "read") at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) at java.security.AccessController.checkPermission(AccessController.java:884) at java.lang.SecurityManager.checkPermission(SecurityManager.java:549) at java.lang.SecurityManager.checkPropertyAccess(SecurityManager.java:1294) at java.lang.System.getProperty(System.java:717) at org.apache.juli.logging.DirectJDKLog.&lt;clinit&gt;(DirectJDKLog.java:40) ... 4 more 解决办法： 根据报错的提示，将相应的Permission添加到catalina.policy文件中，我的环境是Ubuntu 14.04 LTS 64位, JDK 1.8.修改后的policy文件内容为: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318// Licensed to the Apache Software Foundation (ASF) under one or more// contributor license agreements. See the NOTICE file distributed with// this work for additional information regarding copyright ownership.// The ASF licenses this file to You under the Apache License, Version 2.0// (the "License"); you may not use this file except in compliance with// the License. You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an "AS IS" BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.// ============================================================================// catalina.policy - Security Policy Permissions for Tomcat//// This file contains a default set of security policies to be enforced (by the// JVM) when Catalina is executed with the "-security" option. In addition// to the permissions granted here, the following additional permissions are// granted to each web application://// * Read access to the web application's document root directory// * Read, write and delete access to the web application's working directory// ============================================================================// ========== SYSTEM CODE PERMISSIONS =========================================// These permissions apply to javacgrant codeBase "file:$&#123;java.home&#125;/lib/-" &#123; permission java.security.AllPermission;&#125;;// These permissions apply to all shared system extensionsgrant codeBase "file:$&#123;java.home&#125;/jre/lib/ext/-" &#123; permission java.security.AllPermission;&#125;;// These permissions apply to javac when $&#123;java.home] points at $JAVA_HOME/jregrant codeBase "file:$&#123;java.home&#125;/../lib/-" &#123; permission java.security.AllPermission;&#125;;// These permissions apply to all shared system extensions when// $&#123;java.home&#125; points at $JAVA_HOME/jregrant codeBase "file:$&#123;java.home&#125;/lib/ext/-" &#123; permission java.security.AllPermission;&#125;;// ========== CATALINA CODE PERMISSIONS =======================================// These permissions apply to the daemon codegrant codeBase "file:$&#123;catalina.home&#125;/bin/commons-daemon.jar" &#123; permission java.security.AllPermission;&#125;;// These permissions apply to the logging API// Note: If tomcat-juli.jar is in $&#123;catalina.base&#125; and not in $&#123;catalina.home&#125;,// update this section accordingly.// grant codeBase "file:$&#123;catalina.base&#125;/bin/tomcat-juli.jar" &#123;..&#125;grant codeBase "file:$&#123;catalina.home&#125;/bin/tomcat-juli.jar" &#123; permission java.security.AllPermission;&#125;;// These permissions apply to the server startup codegrant codeBase "file:$&#123;catalina.home&#125;/bin/bootstrap.jar" &#123; permission java.security.AllPermission;&#125;;// These permissions apply to the servlet API classes// and those that are shared across all class loaders// located in the "lib" directorygrant codeBase "file:$&#123;catalina.home&#125;/lib/-" &#123; permission java.security.AllPermission;&#125;;// If using a per instance lib directory, i.e. $&#123;catalina.base&#125;/lib,// then the following permission will need to be uncommented// grant codeBase "file:$&#123;catalina.base&#125;/lib/-" &#123;// permission java.security.AllPermission;// &#125;;// ========== WEB APPLICATION PERMISSIONS =====================================// These permissions are granted by default to all web applications// In addition, a web application will be given a read FilePermission// for all files and directories in its document root.grant &#123; // Required for JNDI lookup of named JDBC DataSource's and // javamail named MimePart DataSource used to send mail permission java.util.PropertyPermission "java.home", "read"; permission java.util.PropertyPermission "java.naming.*", "read"; permission java.util.PropertyPermission "javax.sql.*", "read"; // OS Specific properties to allow read access permission java.util.PropertyPermission "os.name", "read"; permission java.util.PropertyPermission "os.version", "read"; permission java.util.PropertyPermission "os.arch", "read"; permission java.util.PropertyPermission "file.separator", "read"; permission java.util.PropertyPermission "path.separator", "read"; permission java.util.PropertyPermission "line.separator", "read"; // JVM properties to allow read access permission java.util.PropertyPermission "java.version", "read"; permission java.util.PropertyPermission "java.vendor", "read"; permission java.util.PropertyPermission "java.vendor.url", "read"; permission java.util.PropertyPermission "java.class.version", "read"; permission java.util.PropertyPermission "java.specification.version", "read"; permission java.util.PropertyPermission "java.specification.vendor", "read"; permission java.util.PropertyPermission "java.specification.name", "read"; permission java.util.PropertyPermission "java.vm.specification.version", "read"; permission java.util.PropertyPermission "java.vm.specification.vendor", "read"; permission java.util.PropertyPermission "java.vm.specification.name", "read"; permission java.util.PropertyPermission "java.vm.version", "read"; permission java.util.PropertyPermission "java.vm.vendor", "read"; permission java.util.PropertyPermission "java.vm.name", "read"; // Required for OpenJMX permission java.lang.RuntimePermission "getAttribute"; // Allow read of JAXP compliant XML parser debug permission java.util.PropertyPermission "jaxp.debug", "read"; // All JSPs need to be able to read this package permission java.lang.RuntimePermission "accessClassInPackage.org.apache.tomcat"; // Precompiled JSPs need access to these packages. permission java.lang.RuntimePermission "accessClassInPackage.org.apache.jasper.el"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.jasper.runtime"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.jasper.runtime.*"; // Precompiled JSPs need access to these system properties. permission java.util.PropertyPermission "org.apache.jasper.runtime.BodyContentImpl.LIMIT_BUFFER", "read"; permission java.util.PropertyPermission "org.apache.el.parser.COERCE_TO_ZERO", "read"; // The cookie code needs these. permission java.util.PropertyPermission "org.apache.catalina.STRICT_SERVLET_COMPLIANCE", "read"; permission java.util.PropertyPermission "org.apache.tomcat.util.http.ServerCookie.STRICT_NAMING", "read"; permission java.util.PropertyPermission "org.apache.tomcat.util.http.ServerCookie.FWD_SLASH_IS_SEPARATOR", "read"; // Applications using Comet need to be able to access this package permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.comet"; // Applications using WebSocket need to be able to access these packages permission java.lang.RuntimePermission "accessClassInPackage.org.apache.tomcat.websocket"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.tomcat.websocket.server"; // by sky start --- permission java.util.PropertyPermission "java.util.logging.config.class", "read"; permission java.util.PropertyPermission "java.util.logging.config.file", "read"; permission java.util.PropertyPermission "user.dir", "read"; permission java.util.PropertyPermission "user.home", "read"; permission java.util.PropertyPermission "java.*", "read"; permission java.util.PropertyPermission "javax.*", "read"; permission java.util.PropertyPermission "javax.net.ssl.trustStore", "read"; permission java.util.PropertyPermission "org.apache.juli.AsyncOverflowDropType", "read"; permission java.util.PropertyPermission "org.apache.juli.AsyncMaxRecordCount", "read"; permission java.util.PropertyPermission "org.apache.juli.AsyncLoggerPollInterval", "read"; permission java.util.PropertyPermission "org.apache.tomcat.*", "read"; permission java.util.PropertyPermission "catalina.base", "read"; permission java.util.PropertyPermission "catalina.base", "write"; permission java.util.PropertyPermission "catalina.home", "read"; permission java.util.PropertyPermission "catalina.home", "write"; permission java.util.PropertyPermission "catalina.*", "read"; permission java.util.PropertyPermission "catalina.useNaming", "write"; permission java.util.PropertyPermission "java.naming.factory.url.pkgs", "write"; permission java.util.PropertyPermission "java.naming.factory.initial", "write"; permission java.util.PropertyPermission "java.io.tmpdir", "read"; permission java.util.PropertyPermission "org.apache.tomcat.util.digester.PROPERTY_SOURCE", "read"; permission java.util.PropertyPermission "org.apache.catalina.*", "read"; permission java.util.PropertyPermission "tomcat.util.*", "read"; permission java.lang.RuntimePermission "shutdownHooks"; permission java.lang.RuntimePermission "setContextClassLoader"; //permission java.lang.RuntimePermission "accessClassInPackage.org.apache.tomcat.util.digester"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.tomcat"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.tomcat.*"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.startup"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.*"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.coyote"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.coyote.*"; permission java.lang.RuntimePermission "accessClassInPackage.sun.misc"; permission java.lang.RuntimePermission "accessClassInPackage.sun.misc.*"; permission java.lang.RuntimePermission "setIO"; permission java.lang.RuntimePermission "accessDeclaredMembers"; permission java.lang.RuntimePermission "org.apache.naming.ContextAccessController.setSecurityToken"; permission java.lang.RuntimePermission "org.apache.naming.factory.ResourceLinkFactory.setGlobalContext"; permission java.lang.RuntimePermission "modifyThread"; permission java.io.FilePermission "/usr/java/packages/lib/amd64/liblibtcnative-1.so", "read"; permission java.io.FilePermission "/usr/java/packages/lib/amd64/libtcnative-1.so", "read"; permission java.io.FilePermission "/usr/lib64/liblibtcnative-1.so", "read"; permission java.io.FilePermission "/usr/lib64/libtcnative-1.so", "read"; permission java.io.FilePermission "/lib64/liblibtcnative-1.so", "read"; permission java.io.FilePermission "/lib64/libtcnative-1.so", "read"; permission java.io.FilePermission "/lib/liblibtcnative-1.so", "read"; permission java.io.FilePermission "/lib/libtcnative-1.so", "read"; permission java.io.FilePermission "/usr/lib/liblibtcnative-1.so", "read"; permission java.io.FilePermission "/usr/lib/libtcnative-1.so", "read"; permission java.util.logging.LoggingPermission "control"; permission java.util.PropertyPermission "org.apache.coyote.USE_CUSTOM_STATUS_MSG_IN_HEADER", "read"; permission java.util.PropertyPermission "org.apache.tomcat.util.http.FastHttpDateFormat.CACHE_SIZE", "read"; permission java.security.SecurityPermission "getProperty.package.definition"; permission java.security.SecurityPermission "setProperty.package.definition"; permission java.security.SecurityPermission "getProperty.package.access"; permission java.security.SecurityPermission "setProperty.package.access"; permission javax.security.auth.AuthPermission "getPolicy"; permission java.lang.management.ManagementPermission "monitor"; permission javax.management.MBeanServerPermission "findMBeanServer"; permission javax.management.MBeanServerPermission "createMBeanServer"; permission javax.management.MBeanPermission "org.apache.tomcat.*", "registerMBean,unregisterMBean"; permission javax.management.MBeanPermission "org.apache.catalina.*", "registerMBean,unregisterMBean"; permission javax.management.MBeanPermission "-#-[-]", "queryNames"; permission javax.management.MBeanTrustPermission "register"; permission java.net.SocketPermission "localhost:8080", "listen,resolve"; permission java.net.SocketPermission "localhost:8009", "listen,resolve"; // by sky end ---&#125;;// These permissions apply to the daemon codegrant codeBase "file:$&#123;catalina.home&#125;/-" &#123; permission java.security.AllPermission;&#125;;// The Manager application needs access to the following packages to support the// session display functionality. These settings support the following// configurations:// - default CATALINA_HOME == CATALINA_BASE// - CATALINA_HOME != CATALINA_BASE, per instance Manager in CATALINA_BASE// - CATALINA_HOME != CATALINA_BASE, shared Manager in CATALINA_HOMEgrant codeBase "file:$&#123;catalina.base&#125;/webapps/manager/-" &#123; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.ha.session"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.manager"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.manager.util"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.util";&#125;;grant codeBase "file:$&#123;catalina.home&#125;/webapps/manager/-" &#123; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.ha.session"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.manager"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.manager.util"; permission java.lang.RuntimePermission "accessClassInPackage.org.apache.catalina.util";&#125;;// You can assign additional permissions to particular web applications by// adding additional "grant" entries here, based on the code base for that// application, /WEB-INF/classes/, or /WEB-INF/lib/ jar files.//// Different permissions can be granted to JSP pages, classes loaded from// the /WEB-INF/classes/ directory, all jar files in the /WEB-INF/lib/// directory, or even to individual jar files in the /WEB-INF/lib/ directory.//// For instance, assume that the standard "examples" application// included a JDBC driver that needed to establish a network connection to the// corresponding database and used the scrape taglib to get the weather from// the NOAA web server. You might create a "grant" entries like this://// The permissions granted to the context root directory apply to JSP pages.// grant codeBase "file:$&#123;catalina.base&#125;/webapps/examples/-" &#123;// permission java.net.SocketPermission "dbhost.mycompany.com:5432", "connect";// permission java.net.SocketPermission "*.noaa.gov:80", "connect";// &#125;;//// The permissions granted to the context WEB-INF/classes directory// grant codeBase "file:$&#123;catalina.base&#125;/webapps/examples/WEB-INF/classes/-" &#123;// &#125;;//// The permission granted to your JDBC driver// grant codeBase "jar:file:$&#123;catalina.base&#125;/webapps/examples/WEB-INF/lib/driver.jar!/-" &#123;// permission java.net.SocketPermission "dbhost.mycompany.com:5432", "connect";// &#125;;// The permission granted to the scrape taglib// grant codeBase "jar:file:$&#123;catalina.base&#125;/webapps/examples/WEB-INF/lib/scrape.jar!/-" &#123;// permission java.net.SocketPermission "*.noaa.gov:80", "connect";// &#125;; 从这个配置文件里，我们也可以看到，整个Tomcat如果开启了SecurityManager后，需要什么权限.可以大概知道整体的情况~~. 命令行启动的命令: 12345678910111213141516171819202122232425262728293031323334353637383940╭─sky@sky-linux /ihome/java/tomcat/apache-tomcat-8.0.36-src/target/classes ╰─➤ java -Dcatalina.home=/ihome/java/tomcat/apache-tomcat-8.0.36-src -Dcatalina.base=/ihome/java/tomcat/apache-tomcat-8.0.36-src -Djava.endorsed.dirs=/ihome/java/tomcat/apache-tomcat-8.0.36-src/endorsed -Djava.io.tmpdir=/ihome/java/tomcat/apache-tomcat-8.0.36-src/temp -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.util.logging.config.file=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/logging.properties -Djava.security.manager -Djava.security.policy=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/catalina.policy -Didea.launcher.bin.path=/ihome/java/ide/idea-IU-145.258.11/bin org.apache.catalina.startup.Bootstrap28-Jun-2016 11:58:47.274 WARNING [main] org.apache.catalina.startup.ClassLoaderFactory.validateFile Problem with directory [/ihome/java/tomcat/apache-tomcat-8.0.36-src/lib], exists: [false], isDirectory: [false], canRead: [false]28-Jun-2016 11:58:47.275 WARNING [main] org.apache.catalina.startup.ClassLoaderFactory.validateFile Problem with directory [/ihome/java/tomcat/apache-tomcat-8.0.36-src/lib], exists: [false], isDirectory: [false], canRead: [false]28-Jun-2016 11:58:47.275 WARNING [main] org.apache.catalina.startup.ClassLoaderFactory.validateFile Problem with directory [/ihome/java/tomcat/apache-tomcat-8.0.36-src/lib], exists: [false], isDirectory: [false], canRead: [false]28-Jun-2016 11:58:47.275 WARNING [main] org.apache.catalina.startup.ClassLoaderFactory.validateFile Problem with directory [/ihome/java/tomcat/apache-tomcat-8.0.36-src/lib], exists: [false], isDirectory: [false], canRead: [false]28-Jun-2016 11:58:47.536 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/@VERSION@28-Jun-2016 11:58:47.536 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: @VERSION_BUILT@28-Jun-2016 11:58:47.536 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server number: @VERSION_NUMBER@28-Jun-2016 11:58:47.536 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux28-Jun-2016 11:58:47.536 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.19.0-32-generic28-Jun-2016 11:58:47.536 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture: amd6428-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home: /ihome/java/jdk/jdk1.8.0_60/jre28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version: 1.8.0_60-b2728-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor: Oracle Corporation28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_BASE: /ihome/java/tomcat/apache-tomcat-8.0.36-src28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_HOME: /ihome/java/tomcat/apache-tomcat-8.0.36-src28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.home=/ihome/java/tomcat/apache-tomcat-8.0.36-src28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.base=/ihome/java/tomcat/apache-tomcat-8.0.36-src28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.endorsed.dirs=/ihome/java/tomcat/apache-tomcat-8.0.36-src/endorsed28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.io.tmpdir=/ihome/java/tomcat/apache-tomcat-8.0.36-src/temp28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager28-Jun-2016 11:58:47.537 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.config.file=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/logging.properties28-Jun-2016 11:58:47.538 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.security.manager28-Jun-2016 11:58:47.538 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.security.policy=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/catalina.policy28-Jun-2016 11:58:47.538 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Didea.launcher.bin.path=/ihome/java/ide/idea-IU-145.258.11/bin28-Jun-2016 11:58:47.538 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib28-Jun-2016 11:58:47.625 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler ["http-nio-8080"]28-Jun-2016 11:58:47.634 INFO [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read28-Jun-2016 11:58:47.635 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler ["ajp-nio-8009"]28-Jun-2016 11:58:47.637 INFO [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read28-Jun-2016 11:58:47.638 INFO [main] org.apache.catalina.startup.Catalina.load Initialization processed in 330 ms28-Jun-2016 11:58:47.650 INFO [main] org.apache.catalina.core.StandardService.startInternal Starting service Catalina28-Jun-2016 11:58:47.650 INFO [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet Engine: Apache Tomcat/@VERSION@28-Jun-2016 11:58:47.656 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory /ihome/java/tomcat/apache-tomcat-8.0.36-src/webapps/ROOT28-Jun-2016 11:58:47.830 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory /ihome/java/tomcat/apache-tomcat-8.0.36-src/webapps/ROOT has finished in 173 ms28-Jun-2016 11:58:47.831 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["http-nio-8080"]28-Jun-2016 11:58:47.838 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["ajp-nio-8009"]28-Jun-2016 11:58:47.839 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 200 ms 可以看到开启安全管理器后成功启动了. 为什么用Security Manager可以达到安全沙箱的目的？这是因为在JDK底层所有的api中，都已经加上了这种检验处理。举个例子，getProperty()方法，可以看到它的源码是： 123456789public static String getProperty(String key) &#123; checkKey(key); SecurityManager sm = getSecurityManager(); if (sm != null) &#123; sm.checkPropertyAccess(key); &#125; return props.getProperty(key);&#125; 即，如果开启了SecurityManager，则会根据policy策略文件来检查相应的权限.其他的api类似. 参考资料cnblogs xing901022 importnew CSDN kevinkevin epubit OSC xionghui]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习二之初始化classloader]]></title>
    <url>%2F2016%2F06%2F27%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%BA%8C%E4%B9%8B%E5%88%9D%E5%A7%8B%E5%8C%96classloader%2F</url>
    <content type="text"><![CDATA[Main函数启动源码org.apache.catalina.startup.Bootstrap这个是启动类，main函数就在这个类中. 第一件事，就是调用Bootstrap.init()方法，我们来看看这个方法做了什么处理. 首先初始化它的静态块代码，设置catalina.home, catalina.base等相应的环境变量. 调用 initClassLoaders() 将Tomcat当前主线程的ContextClassLoader设置为catalinaLoader 将SecurityClassLoader设置为catalinaLoader 通过catalinaLoader.loadClass来加载org.apache.catalina.startup.Catalina类并实例化一个该对象为startupInstance 然后，通过反射来设置startupInstance对象的setParentClassLoader方法来设置它的parent classloader为sharedLoader. 最后，将catalinaDaemon的值，设置为startupInstance. Tomcat的properties管理类 CatalinaProperties在进入classloader初始化之前，我们来看看Tomcat加载properties的管理类，就是org.apache.catalina.startup.CatalinaProperties类. Tomcat加载不同的classLoader，是通过String value = CatalinaProperties.getProperty(name + &quot;.loader&quot;);这个配置来加载类的. 而CatalinaProperties类，通过源码可知，它是加载tomcat目录下的conf/catalina.properties文件的. initClassLoaders() 方法123456789101112131415private void initClassLoaders() &#123; try &#123; commonLoader = createClassLoader("common", null); if( commonLoader == null ) &#123; // no config file, default to this loader - we might be in a 'single' env. commonLoader=this.getClass().getClassLoader(); &#125; catalinaLoader = createClassLoader("server", commonLoader); sharedLoader = createClassLoader("shared", commonLoader); &#125; catch (Throwable t) &#123; handleThrowable(t); log.error("Class loader creation threw exception", t); System.exit(1); &#125;&#125; 可以看到该方法初始化了三个classloder，分别是commonLoader, catalinaLoader, sharedLoader.而且commonLoader是catalinaLoader和sharedLoader的父classloader. commonLoader所以，我们看看这个配置文件中common.loader的value可知是如下: 1common.loader="$&#123;catalina.base&#125;/lib","$&#123;catalina.base&#125;/lib/*.jar","$&#123;catalina.home&#125;/lib","$&#123;catalina.home&#125;/lib/*.jar" 在这里，可以看到，Tomcat是单目录，多实例结构的。catalina.base是实例的目录位置,catalina.home是tomcat安装目录的位置.但一般情况下，我们的catalina.base与catalina.home是相同的. 所以，可以知道commonLoader负载加载上面指定的&quot;${catalina.base}/lib&quot;,&quot;${catalina.base}/lib/*.jar&quot;,&quot;${catalina.home}/lib&quot;,&quot;${catalina.home}/lib/*.jar&quot;这些类的. 根据这样子的情况，我们可以知道，如果想让一个依赖包，让所有的应用都加载的话，可以将这些依赖包，放到以上指定的目录中即可.（不过，一般情况下也不建议这样子做，一个Tomcat中多个应用要加载不同版本的jar包，这样子就会出问题了) catalinaLoader可以看到，该loader的父loader是commonLoader.所以通过catalinaLoader加载的类，都会让commonLoader先尝试加载。 该loader加载的是server.loader=这个配置指定的路径的.可以看到，默认情况下它是空的。 sharedLoader可以看到，该loader的父loader是commonLoader.所以通过sharedLoader加载的类，都会让commonLoader先尝试加载。 该loader加载的是shared.loader=这个配置指定的路径的.可以看到，默认情况下它是空的]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 8 源码学习一之导入到IDEA]]></title>
    <url>%2F2016%2F06%2F27%2FTomcat-8-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B9%8B%E5%AF%BC%E5%85%A5%E5%88%B0IDEA%2F</url>
    <content type="text"><![CDATA[导入Tomcat源码这里使用的Tomcat的版本为apache-tomcat-8.0.36，源码目录在/ihome/java/tomcat/apache-tomcat-8.0.36-src。在这个根目录下，创建一pom.xml文件，内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;Tomcat8.0&lt;/artifactId&gt; &lt;name&gt;Tomcat8.0&lt;/name&gt; &lt;version&gt;8.0&lt;/version&gt; &lt;build&gt; &lt;finalName&gt;Tomcat8.0&lt;/finalName&gt; &lt;sourceDirectory&gt;java&lt;/sourceDirectory&gt; &lt;testSourceDirectory&gt;test&lt;/testSourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;java&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;test&lt;/directory&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ant&lt;/groupId&gt; &lt;artifactId&gt;ant&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;wsdl4j&lt;/groupId&gt; &lt;artifactId&gt;wsdl4j&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml&lt;/groupId&gt; &lt;artifactId&gt;jaxrpc&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jdt.core.compiler&lt;/groupId&gt; &lt;artifactId&gt;ecj&lt;/artifactId&gt; &lt;version&gt;4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.easymock/easymock --&gt; &lt;dependency&gt; &lt;groupId&gt;org.easymock&lt;/groupId&gt; &lt;artifactId&gt;easymock&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 然后删除 test/util/TestCookieFilter.java 这个文件。 最后，在IDEA中选择File -&gt; New -&gt; Project from Existing Sources...，然后定位到/ihome/java/tomcat/apache-tomcat-8.0.36-src即可. 运行选择Run -&gt; Edit Configurations. Main class为org.apache.catalina.startup.Bootstrap VM options为-Dcatalina.home=/ihome/java/tomcat/apache-tomcat-8.0.36-src -Dcatalina.base=/ihome/java/tomcat/apache-tomcat-8.0.36-src -Djava.endorsed.dirs=/ihome/java/tomcat/apache-tomcat-8.0.36-src/endorsed -Djava.io.tmpdir=/ihome/java/tomcat/apache-tomcat-8.0.36-src/temp -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.util.logging.config.file=/ihome/java/tomcat/apache-tomcat-8.0.36-src/conf/logging.properties Working directory为：/ihome/java/tomcat/apache-tomcat-8.0.36-src 最后apply-&gt; OK即可。 然后点击Run就可以了。 Github如果大家不想这么麻烦，我已经将整理后的结构放到了 Github，你也可以直接clone下来，然后直接导致入IDE即可.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>source</tag>
        <tag>Tomcat源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven多模块中使用Sonar]]></title>
    <url>%2F2016%2F06%2F21%2FMaven%E5%A4%9A%E6%A8%A1%E5%9D%97%E4%B8%AD%E4%BD%BF%E7%94%A8Sonar%2F</url>
    <content type="text"><![CDATA[单模块使用pom.xml中添加 12345678910111213 &lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt;&lt;properties&gt; &lt;sonar.java.source&gt;1.7&lt;/sonar.java.source&gt;&lt;/properties&gt; 生成报告: 1mvn sonar:sonar -Dsonar.host.url=http://10.0.0.10:9000 一个项目多模块使用在父pom.xml里添加 12345678910111213 &lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt;&lt;properties&gt; &lt;sonar.java.source&gt;1.7&lt;/sonar.java.source&gt;&lt;/properties&gt; 生成报告 1mvn package sonar:sonar -Dsonar.host.url=http://10.0.0.10:9000 即模块前要添加package即可。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用SLF4J以及Spring中遇到的难以理解的问题]]></title>
    <url>%2F2016%2F06%2F20%2F%E4%BD%BF%E7%94%A8SLF4J%E4%BB%A5%E5%8F%8ASpring%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%9A%BE%E4%BB%A5%E7%90%86%E8%A7%A3%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题问题1 Registering current configuration as safe fallback point1219:48:05,562 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - End of configuration.19:48:05,564 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@5f7db6c4 - Registering current configuration as safe fallback point 问题2 root of factory hierarchySpringMVC启动时，就一直停留在这里 原因以上这两个问题，99% 是因为依赖包的版本没有兼容的问题！认真检查pom.xml文件中各个版本的兼容性问题。即最近是否修改过某些依赖的版本。 解决知道原因，也就容易解决了。请将依赖恢复到兼容的程度。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>slf4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Tomcat关闭时注意的问题]]></title>
    <url>%2F2016%2F06%2F17%2F%E5%85%B3%E4%BA%8ETomcat%E5%85%B3%E9%97%AD%E6%97%B6%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[测试环境: Spring Boot MVC + RabbitMQ + Task + Tomcat Controller层测试代码 12345678910@RequestMapping("/world") @ResponseBody public String hello() throws InterruptedException &#123; System.out.println("in controller"); for(int i=0; i&lt;100000000; i++)&#123; System.out.println("in " + i + " hehe"); &#125; System.out.println("out controller"); return "OK."; &#125; 关闭方式： shutdown1curl -X POST http://localhost:8080/shutdown 没有执行到out controller程序就退出了 kill1jps -vm | grep Demo | awk '&#123;print $1&#125;' | xargs kill 没有执行到out controller程序就退出了 Task测试代码 12345678@Scheduled(fixedRate = 1000 * 10)public void run() throws InterruptedException &#123; System.out.println("in task before " + Thread.currentThread().getName()); for (int i = 0; i &lt; 10000000; i++) &#123; System.out.println("in " + i + " task"); &#125; System.out.println("out task ok " + Thread.currentThread().getName());&#125; 关闭方式： shutdown1curl -X POST http://localhost:8080/shutdown 它会等待线程执行完毕程序再退出，即执行到了”out task ok xxx” kill1jps -vm | grep Demo | awk '&#123;print $1&#125;' | xargs kill 没有执行到out task ok xxx程序就退出了 listener 层测试代码 12345678@RabbitListener(queues = "test.queue")public void run() &#123; System.out.println("in listener"); for (int i = 0; i &lt; 10000000; i++) &#123; System.out.println("in " + i + " listener"); &#125; System.out.println("out listener");&#125; 关闭方式： shutdown1curl -X POST http://localhost:8080/shutdown 程序会等等执行完毕再退出，即执行到了out listener kill1jps -vm | grep Demo | awk '&#123;print $1&#125;' | xargs kill 没有执行到out listener程序就退出了 结论最好停止Tomcat的方式是: 通过Nginx加负载均衡，在Nginx上停用某个Tomcat的连接（upstream)，然后过一段时间后，再调用Tomcat的shutdown.sh，以尽可能减少数据的丢失。其他的方式来停止Tomcat，都会有风险。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境中禁止Redis执行Keys命令]]></title>
    <url>%2F2016%2F06%2F15%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%A6%81%E6%AD%A2Redis%E6%89%A7%E8%A1%8CKeys%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[配置文件将想要禁止的命令，按以下格式加入配置文件中 123rename-command FLUSHALL ""rename-command FLUSHDB ""rename-command KEYS "" 在Spring Data Redis 中使用Scan代替 keys注意： 版本要大于 1.6.0.RELEASE（不包括此版本！会有 NoSuchElements 的bugs） 12345678910111213141516171819202122232425public class RedisKeysPatternUtils &#123; private RedisKeysPatternUtils() &#123; &#125; public static final Set&lt;String&gt; getKeys(final RedisOperations&lt;String, ?&gt; redisOperations, final String keysPattern) &#123; Set&lt;String&gt; keys = redisOperations.execute(new RedisCallback&lt;Set&lt;String&gt;&gt;() &#123; @Override public Set&lt;String&gt; doInRedis(RedisConnection connection) throws DataAccessException &#123; Set&lt;String&gt; binaryKeys = new HashSet&lt;&gt;(); Cursor&lt;byte[]&gt; cursor = connection.scan(ScanOptions.scanOptions().match(keysPattern).count(5000).build()); while (cursor.hasNext()) &#123; byte[] key = cursor.next(); binaryKeys.add(new String(key, StandardCharsets.UTF_8)); &#125; try &#123; cursor.close(); &#125; catch (IOException e) &#123; &#125; return binaryKeys; &#125; &#125;); return keys; &#125;&#125; 后记请千万千万不要用keys这种命令！请千万千万不要用keys这种命令！请千万千万不要用keys这种命令！ 重要的事情，要说三次！]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源码安装MySQL 5.6.X]]></title>
    <url>%2F2016%2F06%2F07%2F%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85MySQL-5-6-X%2F</url>
    <content type="text"><![CDATA[下载Download MySQL 5.6.31 假设解压后的路径在 /home/name/mysql/mysql-5.6.31-src.准备安装到目录/home/name/mysql/mysql-5.6.31 安装依赖1sudo apt-get install cmake libncurses5-dev libreadline-dev libbison-dev 编译1cmake -DCMAKE_INSTALL_PREFIX=/home/name/mysql/mysql-5.6.31 -DMYSQL_UNIX_ADDR=/home/name/mysql/mysql-5.6.31/mysql.socket -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS:STRING=utf8,utf8mb4,gbk -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_READLINE=1 -DENABLED_LOCAL_INFILE=1 -DMYSQL_DATADIR=/home/name/mysql/data/ 安装1make install]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis合并两实例的数据]]></title>
    <url>%2F2016%2F06%2F02%2FRedis%E5%90%88%E5%B9%B6%E4%B8%A4%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[AOF 与 RDB这两个是Redis的备份方式。一个是快照（RDB），一个是记录所有的命令到文件（AOF,类似MySQL的binlog） RDB的备份与恢复查看备份存放的目录: CONFIG GET dir 查看备份的文件名：CONFIG GET dbfilename，默认为rdb.dump 备份然后执行save命令，就可以看到在备份存放的目录下，生成了${dbfilename}的文件了，这个就是执行save命令一瞬间的快照. 恢复原理：redis启动的时候，在dir目录下，查找${dbfilename}的文件，然后重新加载它（注意，它会删除原来的数据，然后以这个文件的数据加载） AOF的备份与恢复查看备份存放的目录: CONFIG GET dir 查看是否开启AOF：CONFIG GET appendonly，如果没有，就设置为开启CONFIG SET appendonly yes 查看AOF的文件：CONFIG GET appendfilename，默认为appendonly.aof，设置自定义名字CONFIG SET appendfilename myaof.aof 备份执行 BGREWRITEAOF 命令，强制重写AOF，即可. 恢复原理：redis启动的时候，在dir目录下，查找${appendfilename}的文件，然后重新执行文件里的命令来恢复数据（注意，它会删除原来的数据，然后以这个文件的数据加载）. RDB与AOF 同时启用时如果同时启用，则Redis以AOF为准. 合并两个不同实例的数据利用AOF备份（本质上它只是一系列Redis的命令文本）。假设有两台Redis（6379, 6479），它们的AOF文件名分别为(6379.aof, 6479.aof)，现在要将6379的数据，合并到6479.aof： 首先在6379服务器上，开启AOF，并保存，假设文件名为6379.aof然后在6479服务器上，开启AOF，并保存，假设文件名为6479.aof 注意 ：最好做下备份： cp 6379.aof 6379.aof.bak, cp 6479.aof 6479.aof.bak 然后将6379.aof的文件内容合并到6479.aof：cat 6379.aof 6479.aof &gt; new.aof &amp;&amp; mv new.aof 6479.aof。（这里，可以选择如果key冲突，那么以哪个redis的为准，即决定好cat后面的参数的顺序即可～）最后启下6479的服务器即可.]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logstash安装及使用]]></title>
    <url>%2F2016%2F06%2F01%2FLogstash%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[依赖：Java运行环境。这个就不多写了。 安装LogstashDownload Logstash 这时以2.3.1 带全插件的版本 下载完后，假设安装在目录/ihome/ELK/logstash-2.3.1目录下。 假设变量 logstash_home=/ihome/ELK/logstash-2.3.1 Hello World12345678910111213cd $&#123;logstash_home&#125;╭─sky@sky-linux /ihome/ELK/logstash-2.3.1 ╰─➤ bin/logstash -e 'input &#123; stdin &#123;&#125; &#125; output &#123; stdout &#123;codec=&gt;rubydebug&#125; &#125;'Settings: Default pipeline workers: 4Pipeline main startedhello world&#123; "message" =&gt; "hello world", "@version" =&gt; "1", "@timestamp" =&gt; "2016-06-01T10:39:20.879Z", "host" =&gt; "sky-linux"&#125; 使用配置文件方式:创建一个文件logstash.conf在${logstash_home}目录下，内容如下： 123456789input &#123; stdin &#123;&#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#123;&#125; &#125;&#125; 执行: 12345678910111213cd $&#123;logstash_home&#125;╭─sky@sky-linux /ihome/ELK/logstash-2.3.1 ╰─➤ bin/logstash -f logstash.confSettings: Default pipeline workers: 4Pipeline main startedHello World&#123; "message" =&gt; "Hello World", "@version" =&gt; "1", "@timestamp" =&gt; "2016-06-01T10:47:10.391Z", "host" =&gt; "sky-linux"&#125; logstash 配置文件语法Section, {}如: 1234input &#123; stdin &#123; &#125;&#125; 数据类型布尔： debug =&gt; true字符串： host =&gt; &quot;hostname&quot;数值： port =&gt; 123数组: match =&gt; [&quot;date&quot;, &quot;unix&quot;, &quot;ISO&quot;] 哈希:options =&gt; {k1 =&gt; “value1”, k2 =&gt; “value2”}` 字段引用[字段名]：即可得到字段的值了. 支持在字符串内格式化: &quot;Hello World %{[字段名]} 条件判断和表达式==, !=, &lt;, &gt;, &lt;=, &gt;= =~, !~ in, not in and, or, nand, xor !() 命令行参数-e：直接执行后面的内容：如上面的Hello World. -f或--config：执行后面参数代表的文件里的内容.如上面的Hello World带文件的例子。 -t或--configtest：测试配置文件语法是否正确.如: 123456╭─sky@sky-linux /ihome/ELK/logstash-2.3.1 ╰─➤ bin/logstash -t logstash.conf Configuration OK╭─sky@sky-linux /ihome/ELK/logstash-2.3.1 ╰─➤ bin/logstash --configtest logstash.confConfiguration OK -l或--log：默认情况下logstash输出到标准输出中。-l，可以指定件输出到文件. -w或--pipeline-workers：工作线程.-w 5。如: 1234╭─sky@sky-linux /ihome/ELK/logstash-2.3.1 ╰─➤ bin/logstash -f logstash.conf -w 5 Settings: User set pipeline workers: 5, Default pipeline workers: 4Pipeline main started -p或--pluginpath：插件路径.可以自己写插件，然后这样子加载它.-p /home/logstash/plugins --verbose：详细输出 --debug：调试 插件管理列出所有可用插件:${logstash_home}/bin/logstash-plugin list安装插件：${logstash_home}/bin/logstash-plugin install xxxPlugin升级插件：${logstash_home}/bin/logstash-plugin update xxxPlugin 如果插件是在本地文件系统，则改为绝对路径即可. 输入插件如果没有写明input，那么就会使用默认的logstash-input-stdin如果没有写明output，那么就会使用默认的logstash-output-stdout 即，上面的Hello World的例子，可以不用写，而直接运行${logstash_home}/bin/logstash -e即可。 type和tags是 logstash 中两个特殊的字段。type标识类型。tags由后面的插件来添加或删除. stdin标准输入. file文件输入. 1234567input &#123; file &#123; path =&gt; ["/path/to/file1", "/path/to/file2"] type =&gt; "system" start_position =&gt; "beginning" &#125;&#125; TCP输入1234567input &#123; tcp &#123; port =&gt; 8888 mode =&gt; "server" ssl_enable =&gt; false &#125;&#125; etc.. 后台运行nohup COMMAND &amp; 注意事项 logstash 一定要用一个input和output.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java并发操作MySQL数据库的读写注意]]></title>
    <url>%2F2016%2F06%2F01%2FJava%E5%B9%B6%E5%8F%91%E6%93%8D%E4%BD%9CMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AF%BB%E5%86%99%E6%B3%A8%E6%84%8F%2F</url>
    <content type="text"><![CDATA[情景模拟： 线程1是一个task,然后分批select数据，然后可能会对这些select的结果进行更新线程2是一个业务, 它也可能会对这些数据进行update. 问题：如果线程1首先拿到一个数据的快照（MySQL的MVCC），然后开始遍历每行数据来根据业务更新。这时，线程2修改了数据原来的状态。这时线程已经拿到的数据，就会是脏数据了。然后就会导致数据的不一致！ 解决办法方式1使用 select ... for udpate 来保证数据强一致性（即所谓的悲观锁），还要注意，这种SQL必须要使用到索引，不然会造成表锁。 不过，这容易造成死锁，以及降低性能。 方式2这种方式，要根据业务具体情况。而不是通用。 也可以在线程1 update的SQL语句中，加上严格的条件判断。比如，线程1只会更新status &lt; 2的数据。如果线程2修改了status为2,那么这时这次更新就不会再次更新了。线程1的SQL类似： 1update xxxx set ststus = (一个小于2的值) where id = xx and status != 2;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven打包可运行Jar]]></title>
    <url>%2F2016%2F05%2F31%2FMaven%E6%89%93%E5%8C%85%E5%8F%AF%E8%BF%90%E8%A1%8CJar%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;plugins&gt; &lt;!-- 复制依赖的插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib&lt;/outputDirectory&gt; &lt;overWriteReleases&gt;false&lt;/overWriteReleases&gt; &lt;overWriteSnapshots&gt;true&lt;/overWriteSnapshots&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;com.weibosdk.listener.boot.ListenerBootstrap&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;transformers&gt; &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt; &lt;!-- Main函数所在类 --&gt; &lt;mainClass&gt;com.weibosdk.listener.boot.ListenerBootstrap&lt;/mainClass&gt; &lt;/transformer&gt; &lt;!-- Spring相关的文件 --&gt; &lt;transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer"&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer"&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;/plugins&gt; 这样子，运行以下命令即可生成两种方式的jar包了。 1mvn clean package -Dmaven.test.skip=true 123456789101112╭─sky@sky-linux ~/git/weibosdk/wbsdk-listener/target ‹pre-release20160525*› ╰─➤ ls -alhtotal 11Mdrwxr-xr-x 7 sky sky 4.0K 6月 1 12:27 .drwxr-xr-x 4 sky sky 4.0K 6月 1 12:27 ..drwxr-xr-x 7 sky sky 4.0K 6月 1 12:27 classesdrwxr-xr-x 3 sky sky 4.0K 6月 1 12:27 generated-sourcesdrwxr-xr-x 2 sky sky 4.0K 6月 1 12:27 libdrwxr-xr-x 2 sky sky 4.0K 6月 1 12:27 maven-archiverdrwxr-xr-x 3 sky sky 4.0K 6月 1 12:27 maven-status-rw-r--r-- 1 sky sky 58K 6月 1 12:27 original-wbsdk-listener-1.0.0.jar-rw-r--r-- 1 sky sky 11M 6月 1 12:27 wbsdk-listener-1.0.0.jar 其中wbsdk-listener-1.0.0.jar是一个可独立运行的jar包，即直接执行以下命令： 1java -jar wbsdk-listener-1.0.0.jar 即可运行。可以copy到任何一台装有Java环境的服务器上运行。 而original-wbsdk-listener-1.0.0.jar则只是项目的文件，它还会依赖lib目录下的jar包文件。这样子将项目和依赖文件分开打包，好处是部署的时候，如果不更新依赖，就只需要更新项目文件即可（比如快点，不然每次上传几十MB的文件到服务器～～～） 参考资料chenzhou123520 iteye]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis常用技巧]]></title>
    <url>%2F2016%2F05%2F26%2Fredis%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[批量删除key1cat /tmp/keys.txst | xargs -I&#123;&#125; -P 3 -t -n 10 ./redis-cli -p 6379 -n 0 del &#123;&#125; 查询QPS1watch -n 60 '/home/redis/bin/redis-cli -h 10.*.*.* -p 6379 info |grep total_commands_processe &gt;&gt; /tmp/qps2.txt &amp;&amp; date &gt;&gt; /tmp/qps2.txt']]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java监控方法调用树以及方法性能]]></title>
    <url>%2F2016%2F05%2F23%2FJava%E7%9B%91%E6%8E%A7%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%A0%91%E4%BB%A5%E5%8F%8A%E6%96%B9%E6%B3%95%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[JETM 下载Download 使用1234567891011121314151617181920212223242526272829303132333435@Testpublic void hello() throws InterruptedException &#123; BasicEtmConfigurator.configure(true); etmMonitor.start(); EtmPoint etmPoint = etmMonitor.createPoint("SETest:hello"); System.out.println("hello world"); Thread.currentThread().sleep(2 * 1000); nested(); nested(); sayf(); etmPoint.collect(); // visualize results etmMonitor.render(new SimpleTextRenderer()); etmMonitor.stop();&#125;private static void nested() throws InterruptedException &#123; EtmPoint etmPoint = etmMonitor.createPoint("SETest:nested"); System.out.println("in nested"); Thread.currentThread().sleep(2*1000); etmPoint.collect();&#125;private static void sayf() throws InterruptedException &#123; EtmPoint etmPoint = etmMonitor.createPoint("SETest:sayf"); System.out.println("in nested"); Thread.currentThread().sleep(2*1000); nested(); etmPoint.collect();&#125; 输出结果: 1234567891011121314151617[INFO ] [EtmMonitor] JETM 1.2.3 started.hello worldin nestedin nestedin nestedin nested|-------------------|---|------------|------------|------------|------------|| Measurement Point | # | Average | Min | Max | Total ||-------------------|---|------------|------------|------------|------------|| SETest:hello | 1 | 10,000.900 | 10,000.900 | 10,000.900 | 10,000.900 || SETest:sayf | 1 | 4,000.296 | 4,000.296 | 4,000.296 | 4,000.296 || SETest:nested | 1 | 2,000.118 | 2,000.118 | 2,000.118 | 2,000.118 || SETest:nested | 2 | 2,000.159 | 2,000.136 | 2,000.182 | 4,000.317 ||-------------------|---|------------|------------|------------|------------|[INFO ] [EtmMonitor] Shutting down JETM.Process finished with exit code 0]]></content>
      <tags>
        <tag>java</tag>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis集群之twemproxy]]></title>
    <url>%2F2016%2F05%2F18%2FRedis%E9%9B%86%E7%BE%A4%E4%B9%8Btwemproxy%2F</url>
    <content type="text"><![CDATA[安装123456git clone https://github.com/twitter/twemproxy.gitcd twemproxyautoreconf -fvi./configure --enable-debug=full --prefix=/ihome/db/redis/twemproxymake -j8make install 安装完毕的结构： 1234567891011╭─sky@sky-linux /ihome/db/redis/twemproxy ╰─➤ tree ..├── sbin│ └── nutcracker└── share └── man └── man8 └── nutcracker.84 directories, 2 files 启动创建一个配置文件在安装目录的conf下，假设为: twemproxy.yml,内容如下: 123456789101112alpha: listen: 127.0.0.1:22121 hash: fnv1a_64 distribution: ketama auto_eject_hosts: true redis: true server_retry_timeout: 2000 server_failure_limit: 1 servers: - 127.0.0.1:6379:1 server1 - 127.0.0.1:6479:1 server2 测试配置文件的语法: 12345╭─sky@sky-linux /ihome/db/redis/twemproxy ╰─➤ ./sbin/nutcracker -t -c conf/twemproxy.yml nutcracker: configuration file 'conf/twemproxy.yml' syntax is ok╭─sky@sky-linux /ihome/db/redis/twemproxy ╰─➤ 启动: 12╭─sky@sky-linux /ihome/db/redis/twemproxy ╰─➤ ./sbin/nutcracker -d -c conf/twemproxy.yml -p twemproxy.pid -o twemproxy.log 然后直接连接到代理: 1234╭─sky@sky-linux /ihome/db/redis/redis-current/bin ╰─➤ ./redis-cli -p 22121127.0.0.1:22121&gt; get hello1"1" 即可. 支持和不支持的命令说明Github 说明如果集群的redis中有一台挂了，会导致使用不了.]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper之发布-订阅例子]]></title>
    <url>%2F2016%2F05%2F13%2FZooKeeper%E4%B9%8B%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[pubisher123456789101112public static void main(String[] args) throws Exception &#123; RetryPolicy retryPolicy = new RetryNTimes(3, 2 * 1000); CuratorFramework cf = CuratorFrameworkFactory.newClient("127.0.0.1:2181", retryPolicy); cf.start(); Stat stat = cf.checkExists().forPath("/topic"); if (stat == null) &#123; cf.create().forPath("/topic"); &#125; cf.setData().forPath("/topic", "hello new data".getBytes()); cf.close();&#125; subscriber1234567891011121314151617181920212223242526public static void main(String[] args) throws Exception &#123; RetryPolicy retryPolicy = new RetryNTimes(3, 2 * 1000); CuratorFramework cf = CuratorFrameworkFactory.newClient("127.0.0.1:2181", retryPolicy); cf.getCuratorListenable().addListener(new CuratorListener() &#123; @Override public void eventReceived(CuratorFramework client, CuratorEvent event) throws Exception &#123; System.out.println("root --&gt;" + event); &#125; &#125;); cf.start(); TreeCache treeCache = new TreeCache(cf, "/topic"); treeCache.getListenable().addListener(new TreeCacheListener() &#123; @Override public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception &#123; System.out.println("event --&gt;" + event); System.out.println("change data -&gt; " + new String(event.getData().getData())); &#125; &#125;); treeCache.start(); Thread.sleep(60 * 1000 * 5); System.out.println("Exit");&#125;]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper之分布式协调例子]]></title>
    <url>%2F2016%2F05%2F13%2FZooKeeper%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[首先，启动ZooKeeper集群模式或独立模式. 创建三个程序（即三个不同的Java进程，注意，是进程，不是线程）来模拟分布式协调 POM 依赖123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.10.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.10.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 程序112345678910111213141516171819202122232425public static void main(String[] args) throws Exception &#123; RetryPolicy retryPolicy = new RetryNTimes(3, 2 * 1000); CuratorFramework cf = CuratorFrameworkFactory.newClient("127.0.0.1:2182", retryPolicy); cf.start(); final InterProcessSemaphoreMutex interProcessSemaphoreMutex = new InterProcessSemaphoreMutex(cf, "/locks-new-1"); for (int i = 0; i &lt; 20; i++) &#123; new Thread(new Runnable() &#123; public void run() &#123; try &#123; interProcessSemaphoreMutex.acquire(); if (interProcessSemaphoreMutex.isAcquiredInThisProcess()) &#123; Thread.sleep(500); System.out.println(Thread.currentThread().getName() + " hello 1 --&gt; OK."); interProcessSemaphoreMutex.release(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; Thread.sleep(1 * 1000 * 60);&#125; 程序2123456789101112131415161718192021222324public static void main(String[] args) throws InterruptedException &#123; RetryPolicy retryPolicy = new RetryNTimes(3, 2 * 1000); CuratorFramework cf = CuratorFrameworkFactory.newClient("127.0.0.1:2181", retryPolicy); cf.start(); final InterProcessSemaphoreMutex interProcessSemaphoreMutex = new InterProcessSemaphoreMutex(cf, "/locks-new-1"); for (int i = 0; i &lt; 20; i++) &#123; new Thread(new Runnable() &#123; public void run() &#123; try &#123; interProcessSemaphoreMutex.acquire(); if (interProcessSemaphoreMutex.isAcquiredInThisProcess()) &#123; System.out.println(Thread.currentThread().getName() + " hello 2 --&gt; OK."); Thread.sleep(500); interProcessSemaphoreMutex.release(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; Thread.sleep(1 * 1000 * 60);&#125; 程序3123456789101112131415161718192021222324public static void main(String[] args) throws InterruptedException &#123; RetryPolicy retryPolicy = new RetryNTimes(3, 2 * 1000); CuratorFramework cf = CuratorFrameworkFactory.newClient("127.0.0.1:2181", retryPolicy); cf.start(); final InterProcessSemaphoreMutex interProcessSemaphoreMutex = new InterProcessSemaphoreMutex(cf, "/locks-new-1"); for (int i = 0; i &lt; 20; i++) &#123; new Thread(new Runnable() &#123; public void run() &#123; try &#123; interProcessSemaphoreMutex.acquire(); if (interProcessSemaphoreMutex.isAcquiredInThisProcess()) &#123; System.out.println(Thread.currentThread().getName() + " hello 3 --&gt; OK."); Thread.sleep(500); interProcessSemaphoreMutex.release(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; Thread.sleep(1 * 1000 * 60);&#125; 启动分布式系统ZooKeeper会保证程序的顺序性。即如果以程序1 -&gt; 程序2 -&gt; 程序3的程序分别启动的话，那ZooKeeper也会保证程序1先执行，完成后再执行程序2,2执行完成后再执行程序3.]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper服务器搭建]]></title>
    <url>%2F2016%2F05%2F12%2FZooKeeper%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[前提是要安装好Java环境 ^_^ 安装Download 然后解压到安装目录即可.这里假设是安装在/ihome/java/zookeeper-3.4.8 启动模式配置文件：解压后，在安装目录下的conf/zoo_sample.cfg样板配置文件。 独立模式创建数据目录（默认是在/tmp目录下，不过建议修改下）：mkdir -p /ihome/java/zookeeper-3.4.8/data/z1 然后复制一份配置文件到该目录下： cp /ihome/java/zookeeper-3.4.8/conf/zoo_sample.cfg /ihome/java/zookeeper-3.4.8/data/z1/zoo.cfg 修改一下数据目录的指向： 1dataDir=/ihome/java/zookeeper-3.4.8/data/z1 然后启动： 12╭─sky@sky-linux /ihome/java/zookeeper-3.4.8/data/z1 ╰─➤ /ihome/java/zookeeper-3.4.8/bin/zkServer.sh start ./zoo.cfg 这时，可以使用客户端登录即可： 12345678910111213╭─sky@sky-linux /ihome/java/zookeeper-3.4.8/data/z1 ╰─➤ /ihome/java/zookeeper-3.4.8/bin/zkCli.sh 130 ↵Connecting to localhost:21812016-05-12 18:29:52,341 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT2016-05-12 18:29:52,343 [myid:] - INFO [main:Environment@100] - Client environment:host.name=sky-linux2016-05-12 18:29:52,343 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_60...2016-05-12 18:29:52,409 [myid:] - INFO [main-SendThread(ip6-localhost:2181):ClientCnxn$SendThread@1299] - Session establishment complete on server ip6-localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x154a47364d60005, negotiated timeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: localhost:2181(CONNECTED) 0] 如果看到Session establishment complete on server就表示成功了。 集群模式假设有三个节点，数据目录分别为：/ihome/java/zookeeper-3.4.8/data/z1/ihome/java/zookeeper-3.4.8/data/z2/ihome/java/zookeeper-3.4.8/data/z3 节点z1节点z1的配置文件（/ihome/java/zookeeper-3.4.8/data/z1/zoo.cfg)： 1234567891011121314151617181920212223242526272829303132# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/ihome/java/zookeeper-3.4.8/data/z1# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to "0" to disable auto purge feature#autopurge.purgeInterval=1server.1=127.0.0.1:2222:2223server.2=127.0.0.1:3333:3334server.3=127.0.0.1:4444:4445 id文件为：（/ihome/java/zookeeper-3.4.8/data/z1/myid),内容为: 123╭─sky@sky-linux /ihome/java/zookeeper-3.4.8/data/z1 ╰─➤ cat myid 1 其他2个的配置文件类似，主要修改下： 每个节点都有以下节点配置信息： 123server.1=127.0.0.1:2222:2223server.2=127.0.0.1:3333:3334server.3=127.0.0.1:4444:4445 其中server.N，就是myid文件里的数字.127.0.0.1表示节点的IP地址，2222端口：用于仲裁通信，2223端口：用于群首选举. 然后每个节点的dataDir要修改为自己的：z2的配置文件,将数据目录修改为: 1dataDir=/ihome/java/zookeeper-3.4.8/data/z2 z2的配置文件，将客户端连接的端口修改为: 1clientPort=2182 z3的配置文件，将数据目录修改为: 1dataDir=/ihome/java/zookeeper-3.4.8/data/z3 z3的配置文件，将客户端连接的端口修改为： 1clientPort=2183 启动集群启动节点z1: 12╭─sky@sky-linux /ihome/java/zookeeper-3.4.8/data/z1 ╰─➤ /ihome/java/zookeeper-3.4.8/bin/zkServer.sh start ./zoo.cfg 启动节点z2: 12╭─sky@sky-linux /ihome/java/zookeeper-3.4.8/data/z2 ╰─➤ /ihome/java/zookeeper-3.4.8/bin/zkServer.sh start ./zoo.cfg 启动节点z3: 12╭─sky@sky-linux /ihome/java/zookeeper-3.4.8/data/z3 ╰─➤ /ihome/java/zookeeper-3.4.8/bin/zkServer.sh start ./zoo.cfg 连接集群12╭─sky@sky-linux /ihome/java/zookeeper-3.4.8 ╰─➤ ./bin/zkCli.sh -server 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183 即后面-server连接集群每个IP地址:客户端端口客户端端口，即是上面的clientPort. ZooKeeper的服务器搭建就这样子了.^_^]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL备份实践]]></title>
    <url>%2F2016%2F05%2F09%2FMySQL%E5%A4%87%E4%BB%BD%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[binlog查看是否开启了binlog123456789mysql&gt; show variables like 'log_bin';+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | OFF |+---------------+-------+1 row in set (0.00 sec)mysql&gt; 开启binlog在配置文件my.cnf里添加以下内容，然后重启mysql即可. 1log-bin=mysql-bin mysql-bin就是文件名前缀，可以写绝对路径，或相对路径.其他与binlog相关的参数及说明: 1234567891011121314#binlog的前缀log_bin = /var/log/mysql/mysql-bin.log#只保留最近N天的文件expire_logs_days = 10#每个binlog文件的最大大小max_binlog_size = 100M#只对指定的数据库进行binlog，多个DB时，请使用多个binlog_do_db，而不能在一行里然后逗号分隔!!以下同理binlog_do_db = include_database_name#忽略以下指定的binlog，多个DB时，请使用多行binlog_ignore_db.binlog_ignore_db = exclude_database_name 配置完后，再次查看binlog状态，可以看到已经开启了: sudo /etc/init.d/mysql restart 123456789101112131415161718192021222324252627282930313233mysql&gt; show variables like '%log_bin%';+---------------------------------+--------------------------------+| Variable_name | Value |+---------------------------------+--------------------------------+| log_bin | ON || log_bin_basename | /var/log/mysql/mysql-bin || log_bin_index | /var/log/mysql/mysql-bin.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || sql_log_bin | ON |+---------------------------------+--------------------------------+6 rows in set (0.00 sec)mysql&gt;mysql&gt; show variables like '%expire_logs%';+------------------+-------+| Variable_name | Value |+------------------+-------+| expire_logs_days | 10 |+------------------+-------+1 row in set (0.00 sec)mysql&gt;mysql&gt; show variables like '%binlog_size%';+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| max_binlog_size | 104857600 |+-----------------+-----------+1 row in set (0.00 sec)mysql&gt; 实时备份binlog在cron里，每分钟调用以下命令. 1sudo su -c "rsync -azvh /var/log/mysql/mysql-bin.* /tmp/mysql-backup" 全量备份[每周一个]Percona XtraBackup 的安装就不多说了，参考官方网站安装. 1innobackupex --defaults-file=/tmp/other-my.cnf --user=DBUSER --password=SECRET /path/to/backup/dir/ 其他选项有： 123-port: MySQL端口-socket: MySQL的Socket文件-host: MySQL主机 每小时增量备份先进行一次基础备份（仅需要一次）12345678910111213innobackupex --user=bkpuser --password=s3cret --socket=/usr/local/mysql-data/3306/3306.socket --defaults-file=/usr/local/mysql-data/3306/my.cnf /home/mysql/3306/baseInnoDB Backup Utility v1.5.1-xtrabackup; Copyright 2003, 2009 Innobase Oyand Percona LLC and/or its affiliates 2009-2013. All Rights Reserved.This software is published underthe GNU GENERAL PUBLIC LICENSE Version 2, June 1991.Get the latest version of Percona XtraBackup, documentation, and help resources:http://www.percona.com/xb/p...中间省略输出....一定要看到有以下一句才算是成功!150901 13:02:13 innobackupex: completed OK! 然后每小时执行一次以下使用1innobackupex --user=bkpuser --password=s3cret --socket=/usr/local/mysql-data/3306/3306.socket --defaults-file=/usr/local/mysql-data/3306/my.cnf --incremental-basedir=/home/mysql/3306/base/2015-09-01_13-02-10 --incremental /home/mysql/3306/incremental/one 下一小时的增量备份，以上一小时的备份目录为基础点: 1innobackupex --user=bkpuser --password=s3cret --defaults-file=/usr/local/mysql-data/3306/my.cnf --incremental-basedir=/home/mysql/3306/incremental/one/2015-09-01_13-07-29 --incremental /home/mysql/3306/incremental/two 搭建复制[在开启bin log前提下，无需重启开启复制]主：localhost:3306, /ihome/db/mysql/mysql-5.6 数据目录: /ihome/db/mysql/mysql-5.6/data从：localhost:3307 /ihome/db/mysql/mysql-5.6 数据目录：/ihome/db/mysql/mysql-5.6/data1 安装Percona的工具，这里以Ubuntu 14.04 X86_64 trusty 版本为例子1234wget https://repo.percona.com/apt/percona-release_0.1-3.trusty_all.debsudo dpkg -i percona-release_0.1-3.trusty_all.debsudo apt-get updatesudo aptitude install percona-xtrabackup-24 master 配置复制是依赖于binlog的，所以必须先开启binlog，然后还要配置下server-id 123[mysqld]log-bin=mysql-binserver-id=1 创建复制权限的用户123CREATE USER 'repl'@'%' IDENTIFIED BY '123456';GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';flush privileges; 然后执行以下命令全量备份master. 12345innobackupex --defaults-file=/ihome/db/mysql/mysql-5.6/my.cnf --user=root /tmp/mysql-backup....xtrabackup: Transaction log of lsn (1629755) to (1629755) was copied.160510 15:09:30 completed OK! 看到如果输出以上类似的信息表示基础备份完成. 然后将备份的目录，还原到slave里: 1234567891011121314151617准备阶段：innobackupex --defaults-file=/ihome/db/mysql/mysql-5.6/my.cnf --apply-log --use-memory=4G /tmp/mysql-backup/2016-05-10_15-09-25恢复阶段：先删除slave的数据目录rm /ihome/db/mysql/mysql-5.6/data1 -rf然后创建一个空的slave数据目录mkdir -p /ihome/db/mysql/mysql-5.6/data1还原innobackupex --defaults-file=/ihome/db/mysql/mysql-5.6/my.3307.cnf --copy-back --use-memory=4G /tmp/mysql-backup/2016-05-10_15-09-25...160510 15:17:32 [01] Copying ./xtrabackup_info to /ihome/db/mysql/mysql-5.6/data1/xtrabackup_info160510 15:17:32 [01] ...done160510 15:17:32 completed OK! slave 配置可以直接copy master的配置，然后修改下server-id，这里slave的配置文件名为my.3307.cnf 12345678[mysqld]server-id=2#如果需要slave为read-only，则添加以下（注意，该参数只是对 普通用户生效，对于复制用户，超级管理员权限他们还是可以进行写操作的)read-only = 1#这个是在联级复制时需要使用的，我个人认为最好也添加上，以防万一的确需要.log_slave_updates=1 如果Master里有内存表，这时在slave里启动时，内存表数据是会清空的。这时，如果进行复制的话，而master里的相关的内存表还有数据，并且在进行操作的话，就会导致复制中断。 启动slave: 1234567891011╭─sky@sky-linux /ihome/db/mysql/mysql-5.6╰─➤ ./bin/mysqld --defaults-file=my.3307.cnf &amp;[1] 3608╭─sky@sky-linux /ihome/db/mysql/mysql-5.6╰─➤ 2016-05-10 15:20:43 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).2016-05-10 15:20:43 0 [Note] ./bin/mysqld (mysqld 5.6.30-log) starting as process 3608 ...╭─sky@sky-linux /ihome/db/mysql/mysql-5.6╰─➤ lsof -i:3307COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmysqld 3608 sky 13u IPv6 1057274 0t0 TCP *:3307 (LISTEN) 查看从库slave的server_id: 123456789mysql&gt; show variables like 'server_id';+---------------+-------+| Variable_name | Value |+---------------+-------+| server_id | 2 |+---------------+-------+1 row in set (0.00 sec)mysql&gt; 在slave里配置master的信息先查看刚刚在master进行基础备份（全量备份的信息先）的bin log信息先: 12cat /tmp/mysql-backup/2016-05-10_15-09-25/xtrabackup_binlog_infomysql-bin.000002 490 然后在slave的实例上，执行以下命令: 123456789101112131415161718配置master的信息:mysql&gt; CHANGE MASTER TO MASTER_HOST='10.0.0.81', MASTER_USER='repl', MASTER_PASSWORD='123456', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=490;Query OK, 0 rows affected, 2 warnings (0.03 sec)mysql&gt;开始slavemysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt;查看slave状态mysql&gt; show slave status\GSlave_IO_Running: YesSlave_SQL_Running: Yes 要确认这两个都是YES的状态. 问题 Slave_SQL_Running: No 这一般是由于当前某条SQL执行失败导致的，如果允许跳过这次的回放，则： 123stop slave;set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;start slave; 如果一条也是这样子，可以重复上面的操作即可.或者用下面的脚本来一条一条地跳过. 自动跳过脚本123456789#!/bin/bashexport PATH="/home/yourname/mysql/mysql-5.6.17/bin:$PATH"export MySQLCMD="mysql -uroot -P3306 -p123456 -h127.0.0.1"until $&#123;MySQLCMD&#125; -e "show slave status\G;" | grep -i "Slave_SQL_Running: Yes";do $&#123;MySQLCMD&#125; -e "stop slave; SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1; start slave;"; sleep 1;done pt-table-checksum该命令是在master上执行. 检查主从是否一致： 首先在master，创建一个dsn的表，假设是在test.dsns： 12345678use test;CREATE TABLE `dsns` ( `id` int(11) NOT NULL AUTO_INCREMENT, `parent_id` int(11) DEFAULT NULL, `dsn` varchar(255) NOT NULL, PRIMARY KEY (`id`)); 然后插入slave库的dsn信息。： 1INSERT INTO dsns VALUES (1,NULL,"h=&lt;slave IP/hostname&gt;,P=&lt;slave port&gt;,u=root,p=&lt;password&gt;"); 最后检查master与各个slave的延迟情况 123456789101112╭─sky@sky-linux /ihome/db/mysql/mysql-5.6╰─➤ pt-table-checksum --socket=/ihome/db/mysql/mysql-5.6/data/3306.socket --ask-pass -uroot -d test --replicate --nocheck-replication-filters --replicate=test.checksums --recursion-method=dsn=D=test,t=dsnsEnter MySQL password:Enter MySQL password:Enter MySQL password:# A software update is available:# * The current version for Percona::Toolkit is 2.2.14. TS ERRORS DIFFS ROWS CHUNKS SKIPPED TIME TABLE05-10T17:35:14 0 0 1 1 0 0.006 test.dsns05-10T17:35:14 0 1 1 1 0 0.008 test.t1 --recursion-method=dsn=D=test,t=dsns：表示使用dns方式来监测slave，这个表示是master库中的test数据库下的dsns表（即上面创建的表）.--socket=/ihome/db/mysql/mysql-5.6/data/3306.socket --ask-pass -uroot -d test --replicat：表示连接到master的实例上，检测 test 数据库是否有延迟.（也可以指定特定的表 -t）. 结果中，如果DIFFS列不为0,则表示有延迟，如上面的test.t1有延迟1行的数据. pt-table-sync进行主从同步. 12345╭─sky@sky-linux ~╰─➤ pt-table-sync --ask-pass --replicate=test.checksums D=test,t=t1,h=localhost,u=root,P=3306,S=/ihome/db/mysql/mysql-5.6/data/3306.socket D=test,t=t1,h=localhost,u=root,P=3307,S=/ihome/db/mysql/mysql-5.6/data1/3307.socket --printEnter password for localhost:Enter password for localhost:REPLACE INTO `test`.`t1`(`id`) VALUES ('1') /*percona-toolkit src_db:test src_tbl:t1 src_dsn:D=test,P=3306,S=/ihome/db/mysql/mysql-5.6/data/3306.socket,h=localhost,p=...,t=t1,u=root dst_db:test dst_tbl:t1 dst_dsn:D=test,P=3307,S=/ihome/db/mysql/mysql-5.6/data1/3307.socket,h=localhost,p=...,t=t1,u=root lock:1 transaction:1 changing_src:test.checksums replicate:test.checksums bidirectional:0 pid:7294 user:sky host:sky-linux*/; 前面的配置是master的连接信息，后面的配置是配置slave连接信息的. 即，它建议在从库执行: 123REPLACE INTO `test`.`t1`(`id`) VALUES ('1');就可以与master同步了. 取消replication在slave上执行: 1234STOP SLAVE;RESET SLAVE; (Use RESET SLAVE ALL; for MySQL 5.5.16 and later)Edit the my.cnf and remove any information (if present) which refers to "master-..." or "replicate-..." options. ...Restart mysqld. 问题收集同步不了在一次生产环境里，要迁移几百GB的数据到阿里云，用innobackupex全量备份，然后copy到阿里云CS后，自己建立DB然后搭建复制环境（按上面的复制步骤来做），但是在启动复制时，一直有Slave_SQL_Running为No，然后不断地跳过，虽然都为YES了，但是发现数据过几秒后Slave_SQL_Running又为No了。 处理： 取消replication pt-table-sync --ask-pass --execute h=Master的IP及连接信息,P=3309,u=root --databases 要同步的DB h=Slave的IP及连接信息,P=3309,u=root :: 这个是将master的数据，完全同步到slave上. 再建立复制. 备份Dump只备份结构所有数据库: 1mysqldump -u root -h 127.0.0.1 --no-data -P3306 --all-databases --single-transaction -R -E &gt; schema.sql 只备份数据1nohup bash -c "mysqldump --no-create-info -h 127.0.0.1 -uroot -P 你的端口 -p你的密码 --all-databases --single-transaction &gt; data.sql" &amp; 还原数据12mysql -u root -h 127.0.0.1 --no-data -P3306 --single-transaction &lt; schema.sqlmysql -u root -h 127.0.0.1 --no-data -P3306 --single-transaction &lt; data.sql 查看MySQL某指定引擎的所有表比如，查看所有memory引擎的表: 1SELECT table_name, table_schema FROM INFORMATION_SCHEMA.TABLES WHERE engine = 'Memory' and table_schema not in ('information_schema', 'mysql'); Unknown table engine ‘InnoDB’ Error_code: 1286 错误stackoverflow 即:删除数据目录下的ib_logfile0, ib_logfile1。造成不要删除ibdata1，因为它是数据文件.然后重启mysql即可。 pt-table-checksum 完整用法master 上执行123456789101112131415161718192021222324252627282930313233GRANT SELECT,PROCESS,SUPER,REPLICATION SLAVE ON *.* TO slaveptcheck@'%' IDENTIFIED BY 'mypassword';CREATE DATABASE percona;use percona;CREATE TABLE checksums ( db char(64) NOT NULL, tbl char(64) NOT NULL, chunk int NOT NULL, chunk_time float NULL, chunk_index varchar(200) NULL, lower_boundary text NULL, upper_boundary text NULL, this_crc char(40) NOT NULL, this_cnt int NOT NULL, master_crc char(40) NULL, master_cnt int NULL, ts timestamp NOT NULL, PRIMARY KEY (db, tbl, chunk), INDEX ts_db_tbl (ts, db, tbl)) ENGINE=InnoDB;GRANT update,insert,delete ON percona.* TO 'slaveptcheck'@'%';CREATE TABLE `dsns` ( `id` int(11) NOT NULL AUTO_INCREMENT, `parent_id` int(11) DEFAULT NULL, `dsn` varchar(255) NOT NULL, PRIMARY KEY (`id`));INSERT INTO dsns VALUES (1,NULL,"h=&lt;slave IP/hostname&gt;,P=&lt;slave port&gt;,u=root,p=&lt;password&gt;"); 整个流程: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788mysql&gt; GRANT SELECT,PROCESS,SUPER,REPLICATION SLAVE ON *.* TO slaveptcheck@'%' IDENTIFIED BY 'mypassword';Query OK, 0 rows affected (0.07 sec)mysql&gt; CREATE DATABASE percona;Query OK, 1 row affected (0.09 sec)mysql&gt; use percona;Database changedmysql&gt; CREATE TABLE checksums ( -&gt; db char(64) NOT NULL, -&gt; tbl char(64) NOT NULL, -&gt; chunk int NOT NULL, -&gt; chunk_time float NULL, -&gt; chunk_index varchar(200) NULL, -&gt; lower_boundary text NULL, -&gt; upper_boundary text NULL, -&gt; this_crc char(40) NOT NULL, -&gt; this_cnt int NOT NULL, -&gt; master_crc char(40) NULL, -&gt; master_cnt int NULL, -&gt; ts timestamp NOT NULL, -&gt; PRIMARY KEY (db, tbl, chunk), -&gt; INDEX ts_db_tbl (ts, db, tbl) -&gt; ) ENGINE=InnoDB;Query OK, 0 rows affected (0.29 sec)mysql&gt; GRANT update,insert,delete ON percona.* TO 'slaveptcheck'@'%';Query OK, 0 rows affected (0.04 sec)mysql&gt; CREATE TABLE `dsns` ( -&gt; `id` int(11) NOT NULL AUTO_INCREMENT, -&gt; `parent_id` int(11) DEFAULT NULL, -&gt; `dsn` varchar(255) NOT NULL, -&gt; PRIMARY KEY (`id`) -&gt; );Query OK, 0 rows affected (0.42 sec)mysql&gt; INSERT INTO dsns VALUES (1,NULL,"h=127.0.0.1,P=,u=root,p=&lt;password&gt;")\cmysql&gt; show variables like 'port';+---------------+-------+| Variable_name | Value |+---------------+-------+| port | 3309 |+---------------+-------+1 row in set (0.00 sec)mysql&gt; INSERT INTO dsns VALUES (1,NULL,"h=127.0.0.1,P=3409,u=root,p=wei123kool");Query OK, 1 row affected (0.04 sec)mysql&gt; quitByehellovip@srv7:~/mysql/mysql-5.6.17-ccvip$ ./bin/mysql -h 127.0.0.1 -P3309 -uroot -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 10945Server version: 5.6.17-log Source distributionCopyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql&gt; show databases;+-----------------------+| Database |+-----------------------+| information_schema || callcenter || callcenter_1 || callcenter_2 || callcenter_3 || callcenter_4 || mysql || percona || performance_schema || test |+-----------------------+10 rows in set (0.00 sec)mysql&gt; quitByehellovip@srv7:~/mysql/mysql-5.6.17-ccvip$ pt-table-checksum --nocheck-replication-filters --databases=callcenter --replicate=percona.checksums --host=127.0.0.1 --port 3309 -uslaveptcheck -pmypassword --no-check-binlog-format --recursion-method=dsn=D=percona,t=dsns TS ERRORS DIFFS ROWS CHUNKS SKIPPED TIME TABLE08-31T15:42:22 0 0 0 1 0 0.211 callcenter.temp_id08-31T15:42:23 0 0 8 1 0 0.255 callcenter.ttt 可以看到它开始检查一致性了. 注意其实那张表checksums，可以由工具pt-table-checksum自动创建最好。默认情况下，如果参数--replicate指定的表不存在的话，会自动创建的. 查看不一致的表在slave上执行下面的语句即可显示. 1select db, tbl, sum(this_cnt) as total_rows, count(*)as chunks from checksums where ( master_cnt &lt;&gt; this_cnt OR master_crc &lt;&gt; this_crc OR isnull(master_crc) &lt;&gt; isnull(this_crc) ) group by db, tbl; pt-table-sync 完整用法打印要执行的语句:1pt-table-sync --print --sync-to-master h=127.0.0.1,P=4306,u=root,p='yourpassword' --replicate percona.checksums --charset=utf8 直接执行:1pt-table-sync --execute --sync-to-master h=127.0.0.1,P=4306,u=root,p='wei123kool' --replicate percona.checksums --charset=utf8 这里的h=127.0.0.1,P=4306这些是slave的，因为我们指定了sync-to-master，它会自动根据复制来连接master，--replicate percona.checksums，就是之前pt-table-checksum后的数据库和表信息，根据这个可以选择有差异的来进行同步. charset：千万要记得加上，这个要与自己DB里使用的一致.因为公司主要经营微博等社交服务多，所以这里填写utf8mb4!! 参考资料perconasegmentfaultsina blog]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>backup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Redis分布式锁Redisson使用例子]]></title>
    <url>%2F2016%2F05%2F06%2F%E5%9F%BA%E4%BA%8ERedis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81Redisson%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223@Testpublic void testDistributeLock() throws InterruptedException &#123; final CountDownLatch cdl = new CountDownLatch(10); long time = System.currentTimeMillis(); RedissonClient redisson = Redisson.create(); final RLock rLock = redisson.getLock("hello-lock"); final Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(1); map.put("hello", 0); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; rLock.lock(10, TimeUnit.SECONDS); map.put("hello", map.get("hello") + 1); rLock.unlock(); cdl.countDown(); &#125; &#125;).start(); &#125; cdl.await(); System.out.println("result -&gt;" + map.get("hello")); System.out.println(System.currentTimeMillis() - time);&#125; redisson lock]]></content>
      <categories>
        <category>java</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如果是我startup JavaWeb项目开发，我会这样子做]]></title>
    <url>%2F2016%2F04%2F29%2F%E5%A6%82%E6%9E%9C%E6%98%AF%E6%88%91startup-JavaWeb%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%EF%BC%8C%E6%88%91%E4%BC%9A%E8%BF%99%E6%A0%B7%E5%AD%90%E5%81%9A%2F</url>
    <content type="text"><![CDATA[Maven 模块化开发按功能模块？ 如果按功能分模块的话，比较复杂，难免会有代码循环依赖的问题。按分层模块？ 这个相对比较简单点。 然后还要区分不同的环境下的包（web与非web环境，为以后的task等非web代码部署时，不需要再依赖tomcat等容器） 日志的统一slf4j，不过不能配置将标准输出，重定向到Tomcat的catalina.out里。即不能这样子配置： 123456&lt;!-- 控制台输出 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;Pattern&gt;%C&#123;50&#125;.%M %L [%date&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] [%-5level] : %m%ex%n&lt;/Pattern&gt; &lt;/layout&gt; &lt;/appender&gt; 而应该将应用的所有输出，重定向到一个文件（然后根据该文件增长的快慢，来设置按天，小时，或分或切割文件），例如按天： 123456789101112131415&lt;appender name="STDOUT" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;LOG_HOME&#125;/console/console.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- daily rollover. Make sure the path matches the one in the file element or else the rollover logs are placed in the working directory. --&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/console/console_%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;Pattern&gt;%-10(%C&#123;40&#125;.%M %L) [%date&#123;yyyy-MM-dd HH:mm:ss&#125;] [%level]: %m%ex%n&lt;/Pattern&gt; &lt;/layout&gt; &lt;/appender&gt; 然后每种业务，添加一个统一的logger，再分别存在到不同的日志文件里，方便排查问题. 框架的选择SpringBoot + Redis + RabbitMQ + MySQL 然后部署时，配置多种profile，并且要简化xml冗余的问题。（通过import来避免重复的配置文件问题） 注意事项： redis：尽可能用pipeline，以及选择最优的数据类型来存取数据.不能使用keys命令，可参考Githubrabbitmq：添加用户和vhost来隔离（利用好交换机的类型，处理相应的业务，比如扇形交换机，可以模似做发布-订阅功能等，listener要不要ACK以提升性能等，Executor的配置计算好）MySQL：使用最新稳定版，做好备份和复制。（not null default, 每张表都要有create_time, update_time这些与业务无关的，但又很重要的信息, id auto_increment非业务主键）nginx：负载均衡（其他的负载均衡有 haproxy） 代码注意 将一些模块，写成服务。比如发邮件，写个统一的Service，由其他系统来调用（强调的是自治，以及自运行，这时可以有一个独立的redis+mq来为它服务）。 不同系统间的调用（比如请求多个HTTP，善于利用异步Future的方式来调用） 同一个方法里，避免多次查询DB，HTPP，Redis等调用（利用本地缓存来暂存） 千万不写如下类似代码！！！（即删除时，尽可能使用 Iterator来做） 123456List xxxxfor(int i=0 ;i&lt;10; i++)&#123; xxxx list.remove(i);&#125; HTTP请求时的超时设置（一般的类库，默认是无限） 因为spring里的对象，几乎都是单例的。所以，在操作时要特别注意，不要随便set这些单例的状态（如rabbitTemplate.setxxx，或者类似这种代码!!!!!） 统一 checkstyle: 这里以Google的 Java Style. Github 关于自动化部署脚本rsync + nginx做负载均衡（部署时自动切换下） 开发流程git flow Java编码规范 关于代码质量监控Sonar + Findbugs 结合，每周一次自我检测代码质量.不断完善. 关于Tomcat如果要进行远程调试，完成后，千万不要关闭远程调试再重启Tomcat！！不然，JVM极有可能会因为这个原因，而莫名停掉！ Tomcat启动前添加参数tomcat目录下添加bin/setenv.sh，内容如下: 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/shJAVA_HOME=/home/you/jdk/jdk1.7.0_79JRE_HOME=/home/you/jdk/jdk1.7.0_79/jre#CATALINA_OPTS="-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -XX:+PrintGCDetails -Xloggc:weibosdk-gc.log -XX:+DisableExplicitGC -Xdebug -Xrunjdwp:transport=dt_socket,address=9999,server=y,suspend=n"NOW="$(date +'%Y_%m_%d_%H_%M_%S')"JVM_TYPE=" -server"JVM_GC=" -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xloggc:weibosdk-gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M"JVM_DUMP=" -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/you/tomcat/product_wbsdk_jvm-dump.hprof"#JVM_GC_TYPE=" -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=90 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark"JVM_GC_TYPE=" "# 单位：秒JVM_DNS_CACHE=" -Dsun.net.inetaddr.ttl=60"# hostname如果为远程，则是外网的IPJVM_RMI=" "# survivorratio = eden / from 的比值#JVM_MEM=" -Xms2048m -Xmx2048m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:SurvivorRatio=8"JVM_MEM=" "#JVM_DEBUG=" -Xdebug -Xrunjdwp:transport=dt_socket,address=9999,server=y,suspend=n"JVM_DEBUG=" "JMX="-XX:+UnlockCommercialFeatures -XX:+FlightRecorder -Dcom.sun.management.jmxremote.port=7002 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=IP"CATALINA_OPTS=" -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager $&#123;JVM_TYPE&#125; $&#123;JVM_GC_TYPE&#125; $&#123;JVM_GC&#125; $&#123;JVM_DUMP&#125; $&#123;JVM_DNS_CACHE&#125; $&#123;JVM_RMI&#125; $&#123;JVM_MEM&#125; $&#123;JVM_DEBUG&#125; $&#123;JMX&#125;"echo "java opts = " $&#123;CATALINA_OPTS&#125; 12ulimit -c unlimitedtomcat_dir/bin/startup.sh Tomcat控制脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#!/bin/bash#################################################################author: Zhiyong Yang#date: 2015-12-4#################################################################set -x #作用 启动，停止，重启某tomcat，注意 ，tomcat使用绝对路径，并以/结束.#./tomcat_ct.sh /path/to/tomcat/ start|stop|restartTOMCAT_HOME_DIR=""if [ ! -z $1 ]; then TOMCAT_HOME_DIR=$1fiif [ -z $&#123;TOMCAT_HOME_DIR&#125; ]; then echo "no tomcat special..., so exit" &amp;&amp; exit 1fiTOMCAT_HOME_DIR_GREP="$&#123;TOMCAT_HOME_DIR/apache/[a]pache&#125;"echo "--&gt;$TOMCAT_HOME_DIR_GREP"function stop()&#123; if checkIsExist ; then "$&#123;TOMCAT_HOME_DIR&#125;"bin/shutdown.sh sleep 1 while checkIsExist ; do sleep 2 kill $(getPID) done fi&#125;function getPID()&#123; # replace the grep content with your tomcat path, start with [] #$PID=`ps aux | grep $&#123;TOMCAT_HOME_DIR_GREP&#125;` local PID=`ps aux | grep $&#123;TOMCAT_HOME_DIR_GREP&#125; | grep "[o]rg.apache.catalina.startup.Bootstrap" | awk '&#123;print $2&#125;'` echo $PID&#125;function start()&#123; if ! checkIsExist ; then "$&#123;TOMCAT_HOME_DIR&#125;"bin/startup.sh tail -f -n 100 "$&#123;TOMCAT_HOME_DIR&#125;"logs/catalina.out fi&#125;function checkIsExist()&#123; local P_ID=$(getPID) if [ -z $&#123;P_ID&#125; ]; then echo "not found running tomcat : $&#123;TOMCAT_HOME_DIR&#125;" return 1 else echo "found running tomcat pid = $&#123;P_ID&#125;" return 0 fi&#125;function usage()&#123; echo "Usage:" echo "$0 $1 start : for start tomcat, no repeat" echo "$0 $1 stop : for stop tomcat" echo "$0 $1 restart : for restart"&#125;if [ -z $2 ];then usage $1 exit 0fiif [ $2 = "stop" ]; then stopelif [ $2 = "start" ]; then startelif [ $2 = "restart" ]; then stop startelse usage $1fi 错误时发送警报(这些方面要尽可能完善, 及时发现问题, 然后修复问题.)在所有出现异常的地方, 都添加上通知 RabbitMQ + Email 的方式来发送警报. SpringMVC加上如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;import javax.servlet.http.HttpServletRequest;import java.util.HashMap;import java.util.Map;@ControllerAdvicepublic class ControllerExceptionAdvice &#123; @Autowired private RabbitMQService rabbitMQService; @ExceptionHandler(value = &#123;Exception.class, RuntimeException.class&#125;) @ResponseBody public Map&lt;String, Object&gt; defaultErrorHandler(HttpServletRequest request, Exception e) &#123; String requestUrl = request.getRequestURI(); Map&lt;String, String[]&gt; params = request.getParameterMap(); String stackMsg = getStack(e); rabbitMQService.sendEmail("yourmail", "subject", getFormatText(requestUrl, params, stackMsg)); Map&lt;String, Object&gt; json = new HashMap&lt;&gt;(); json.put(Constants.ERROR_CODE, 500); json.put(Constants.ERROR_MSG, "server interval error."); return json; &#125; private String getFormatText(String requestUrl, Map&lt;String, String[]&gt; params, String stackMsg) &#123; return String.format("请求的URL为 %s\n请求的参数为%s\n异常信息为:%s\n", requestUrl, params, stackMsg); &#125; private String getStack(Exception e) &#123; StackTraceElement[] stackTraceElements = e.getStackTrace(); StringBuilder sb = new StringBuilder(e.getMessage()); sb.append("\n"); for (StackTraceElement stackTraceElement : stackTraceElements) &#123; String className = stackTraceElement.getClassName(); String methodName = stackTraceElement.getMethodName(); int lineNum = stackTraceElement.getLineNumber(); String fileName = stackTraceElement.getFileName(); sb.append(className).append(".").append(methodName).append(" --&gt; ").append(fileName).append(":").append(lineNum); sb.append("\n"); &#125; return sb.toString(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中数据丢失概念及解决办法]]></title>
    <url>%2F2016%2F04%2F29%2FMySQL%E4%B8%AD%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%A6%82%E5%BF%B5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[概念即数据库告诉我这次事务成功了，但当我下次读取数据时，却发现数据不正确。这就是数据丢失. 原因看个场景, redo log丢失造成的主从不一致： bin-log写入所以从库能够执行事务。但主库中trx_prepare的日志没有被写入到ib_logifle中，导致主库不执行事务。这样就会出现主从不一致的情况—主库没执行事务，而从库执行。成的主从不一致 redo log 刷盘策略由 innodb_flush_log_at_trx_commit 参数控制: 0:每秒刷新一次1：每次commit刷新一次(默认值,MySQL5.6)2：每次commit都 write os cache，然后根据 innodb_flush_log_at_timeout 参数（默认为1s） flush disk 1234567891011121314151617mysql&gt; show variables like '%innodb_flush_log_at_trx_commit%';+--------------------------------+-------+| Variable_name | Value |+--------------------------------+-------+| innodb_flush_log_at_trx_commit | 1 |+--------------------------------+-------+1 row in set (0.00 sec)mysql&gt; show variables like '%innodb_flush_log_at_timeout%';+-----------------------------+-------+| Variable_name | Value |+-----------------------------+-------+| innodb_flush_log_at_timeout | 1 |+-----------------------------+-------+1 row in set (0.00 sec)mysql&gt; 说下事务日志（MySQL里是 redo log， Oracle是 transaction log， 但都是指同一样东西) bin log一般是在$DATADIR目录下的*hostname*-bin.index以及一些*hostname*-bin.00001文件。用于replication（复制，以及时间点恢复） redo在MySQL的$DATADIR（即数据目录）下的ib_logfile0 and ib_logfile1两个文件,就是redo log（用于 崩溃时恢复） ib_logfile文件个数由 innodb_log_files_in_group 配置决定，若为2，则在datadir目录下有两个文件，命令从0开始，分别为ib_logfile0和ib_logfile1. bin log 与 redo log 的区别1）二进制日志会记录所有与mysql有关的日志记录，包括InnoDB等其他存储引擎的日志，而InnoDB存储引擎的重做日志只记录有关其本身的事务日志. redo log是InnoDB特有的，而bin log（绝大部分）都是事务独立的，并且bin log是对于所有存储引擎的，但redo log并不是。比如， MyISAM可以写bin log，而InnoDB可以写bin log和redo log 2）记录的内容不同，不管你将二进制日志文件记录的格式设为哪一种，其记录的都是关于一个事务的具体操作内容，而InnoDB存储引擎的重做日志文件记录的关于每个页的更改的物理情况； 3）写入的时间也不同，二进制日志文件是在事务提交前进行记录的，而在事务进行的过程中，不断有重做日志条目被写入重做日志文件中。从日志缓冲写入磁盘上的重做日志文件的条件：在主线程中每秒会将重做日志缓冲写入磁盘的重做日志文件中，不论事务是否提交。另一个触发这个过程是由参数innodb_flush_log_at_trx_commit控制，表示在提交时，处理重做日志的方式。参数innodb_flush_log_at_trx_commit可设的值有0、1、2. 0代表当提交事务时，并不将事务的重做日志写入磁盘上的日志文件，而是等待主线程每秒的刷新，而1和2不同的地方在于： 1是在commit时将重做日志缓冲同步写到磁盘； 2是重做日志异步写到磁盘，即不能完全保证commit时肯定会写入重做日志文件，只是有这个动作。 简单说来，可选值的安全性从0-&gt;2-&gt;1递增，分别对应于mysqld 进程crash可能丢失 -&gt; OS crash可能丢失 -&gt; 事务安全 值得注意的一点：因为重做日志有个capacity变量，该值代表了最后的检查点不能超过这个阀值。 同步的策略 异步（这个无解） 半同步（主库会在自己完成事务后，等待备库接收事务日志）问题： 在master提交事务之后，而slave未来得及接收复制事件，这时候master crash的话，应用程序会切换到slave上，并重新发起事务，这正好是我们所需要的，满足高可用的初衷。但是这里存在一个缺陷，那就是在master恢复之后，原来的事务已经提交，这时候复制会出现问题。）（还存在数据丢失，只是丢失的数据量下降到每条线程最多一个事务丢失）2节点情况下：无解3节点情况下：更强（除非2个备库一起挂了。。。) 那么是不是半同步下，数据就不丢了呢？我们前面说过，当网络，和备库出现间歇性问题时，那么半同步会降级为异步，那么如果恰恰在此时，备库的IO线程正在追赶主库的binlog位点，但是还没有完全同步上，主库down了(也就是说此时出现延迟的情况下)，主备数据就会出现不一致。 强同步 参考资料stackexchange Mysql 重做日志及与二进制日志的区别 aliapp aliyun]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Percona的MySQL维护及监控工具使用]]></title>
    <url>%2F2016%2F04%2F25%2FPercona%E7%9A%84MySQL%E7%BB%B4%E6%8A%A4%E5%8F%8A%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[安装Doc 使用pt-mysql-summarypt-mysql-summary --host=127.0.0.1 --port=6606 --password=xxx 说明： 显示MySQL服务器的概况. pt-align将输出的文本对齐. 例子: 123456789#echo -e "hello owrld\n Hello world" | pt-align hello owrldHello world如果没有pt-align，则输出如下：#echo -e "hello owrld\n Hello world"hello owrld Hello world pt-archiver将mysql数据库中表的记录归档到另外一个表或者文件. 12pt-archiver --source h=127.0.0.1,D=dbName,t=tableName --user=root --password=123456 \--dest h=127.0.0.1,D=destDBName,t=destTableName --file '/var/log/logToFileName' --where "id&lt;=100000" --commit-each 默认会删除源表的数据. pt-config-diff配置文件比较工具 pt-config-diff my.conf1 my.conf2 ... pt-deadlock-logger死锁检测输出日志工具，这里将它输出到test数据库中的deadlocks表中. 1pt-deadlock-logger --ask-pass --run-time=10 --interval=3 --create-dest-table --dest D=test,t=deadlocks u=root,P=6606,h=127.0.0.1 pt-diskstats打印磁盘io统计信息 pt-duplicate-key-checker重复索引检测工具. 1pt-duplicate-key-checker --host=127.0.0.1 --user=root --databases=db1,db2,db3 --port=6606 --password=xxxx pt-fifo-split可以模拟切割文件，并通过管道传递给先入先出队列而不用真正的切割文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445源文件 /tmp/hello.world 内容cat /tmp/hello.world 1234567891011121314151617181920先创建fifo文件pt-fifo-split /tmp/hello.world --fifo=/tmp/hello.world.fifo --lines=3 &amp;然后就可以不断向 /tmp/cmbcc.fifo 文件读取文件了.结果如下：cat /tmp/hello.world.fifo 123cat /tmp/hello.world.fifo 456cat /tmp/hello.world.fifo 789... pt-find对MySQL的数据库或表进行类似GNU find的操作并执行一些命令 1234567891011121314打印MySQL中的所有数据库及表名pt-find --ask-pass --host=127.0.0.1 --user=root --port=6606打印指定数据库中的表pt-find --ask-pass --host=127.0.0.1 --user=root --port=6606 db1 db2 db3找出表大小超过100M的表pt-find --ask-pass --host=127.0.0.1 --user=root --port=6606 --tablesize +100M db1 db2显示所有表的大小并排序pt-find --ask-pass --host=127.0.0.1 --user=root --port=6606 --printf "%T\t%D.%N\n" | sort -rn 所有大小信息pt-find --ask-pass --host=127.0.0.1 --user=root --port=6606 --printf "DB=%D, TB=%N, Auto_increment=%a, Engine=%E, ROWS=%S, Row_format=%R, Max_data_length=%M, Avg_row_length=%A, Collation=%L, Data_length=%d, Index_length=%I, Table_length=%T\n\n" db1 db2 db3 | sort -rn 官方文档 pt-fingerprint将查询转化为带参查询 123pt-fingerprint --query "select a, b, c from users where id = 500"select a, b, c from users where id = ? pt-fk-error-logger提取和记录mysql外键错误信息. 1pt-fk-error-logger --ask-pass -h127.0.0.1 -P6606 --run-time=10 --interval=3 -uroot --dest D=test t=foreign_key_errors h=127.0.0.1,u=root,P=6606 pt-heartbeat监控MySQL复制延迟. 官方文档 pt-index-usage从慢查询中分析索引使用情况 1pt-index-usage /path/to/slow.log -h127.0.0.1 -uroot -P6606 --password=xxx pt-online-schema-change在线更改表结构，既不阻塞read，也不会阻塞写 1pt-online-schema-change --alter "ADD COLUMN c1 INT" D=sakila,t=actor 官方文档 pt-query-digest从日志，processlist, tcpdump分析MySQL的查询. 12345pt-query-digest slow.logpt-query-digest --processlist h=host1pt-query-digest --review h=host2 --no-report slow.log 官方文档 pt-show-grants显示服务器的用户及相应的权限 1pt-show-grants --user=root --port=6606 --host=127.0.0.1 --ask-pass pt-sift浏览由 pt-stalk 生成的文件 pt-stalk问题诊断工具. 123pt-stalk --collect-tcpdump --function status \--variable Threads_connected --threshold 2500 \--daemonize -- --user=root --password=YOURPASSWORD 当MySQL的参数 threads_connected 达到 2500 时， 就收集它的服务器状态信息. pt-table-checksum用于检测MySQL主、从库的数据是否一致 博客资料 pt-table-sync同于主从同步. pt-table-checksum 发现不一致时，就用它来进行同步. pt-variable-advisor查看变量及其提供建议. 1pt-variable-advisor --user=root --host=127.0.0.1 --port=6606 -p password h=127.0.0.1 pt-visual-explain可视化explain 1234567mysql -h127.0.0.1 -uroot -p -P6606 -D yourDbName -e "explain select * from users limit 1" | pt-visual-explain Enter password: Table scanrows 422+- Table table users]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>percona</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy安装及使用]]></title>
    <url>%2F2016%2F04%2F21%2FHAProxy%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[下载HA Proxy 编译，安装这里以1.6.4版本，ubuntu 14.04 LTS ，解压后的目录为/ihome/haproxy/haproxy-1.6.4，安装目录为/ihome/haproxy/haproxy 编译： 12make -j8 TARGET=linux2628 PREFIX=/ihome/haproxy/haproxymake install PREFIX=/ihome/haproxy/haproxy 配置HA这里结合 RabbitMQ 为例子，进行HA配置. 进入安装目录cd /ihome/haproxy/haproxy 创建配置文件touch rabbitmq.cfg 加入以下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445###########全局配置#########global daemon # 守护进程模式 nbproc 1 #后台进程数，这个要求是 daemon pidfile haproxy.pid########默认配置############defaults mode tcp #默认的模式mode &#123; tcp|http|health &#125;，tcp是4层，http是7层，health只会返回OK retries 2 #两次连接失败就认为是服务器不可用，也可以通过后面设置 option redispatch #当serverId对应的服务器挂掉后，强制定向到其他健康的服务器 option abortonclose #当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接 maxconn 4096 #默认的最大连接数 timeout connect 5000ms #连接超时 timeout client 30000ms #客户端超时 timeout server 30000ms #服务器超时 #timeout check 2000 #=心跳检测超时 log 127.0.0.1 local0 err #[err warning info debug]########统计页面配置########listen haproxy-admin bind 0.0.0.0:9990 #监听端口 mode http #http的7层模式 option httplog #采用http日志格式 #log 127.0.0.1 local0 err maxconn 5 stats refresh 30s #统计页面自动刷新时间 stats uri /stats #统计页面url stats realm XingCloud\ Haproxy #统计页面密码框上提示文本 stats auth admin:admin #统计页面用户名和密码设置 stats hide-version #隐藏统计页面上HAProxy的版本信息########rabbitmq配置#################listen test1 bind 0.0.0.0:9991 mode tcp #maxconn 4086 #log 127.0.0.1 local0 debug #以下三个是同一个集群里的三个节点. server s1 localhost:5672 server s2 localhost:5673 server s3 localhost:5674 HAProxy监控后台 admin 平滑重启HA proxy 1./sbin/haproxy -f rabbitmq.cfg -sf `cat haproxy.pid` RabbitMQ的集群，请参考我的另一篇Blog RabbitMQ的集群 参考资料 http://www.cnblogs.com/junw_china/archive/2011/03/22/1991167.html haproxy]]></content>
      <tags>
        <tag>haproxy</tag>
        <tag>ha</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 3.6 集群使用]]></title>
    <url>%2F2016%2F04%2F20%2FRabbitMQ-3-6-%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[创建集群 先把所有的插件都禁用先，避免因插件的端口问题导致集群启动不了. 集群节点启动集群节点 1RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=master /ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmq-server -detached 加入一个磁盘集群节点1234567891011-- 这样子，默认的节点名就是 node1@你的机器名 RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=node1 /ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmq-server -detached/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node1 stop_app/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node1 reset-- 第二个参数 master@sky-linux 是要填写完整的节点名/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node1 join_cluster master@sky-linux-- 启动node1节点/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node1 start_app 这时查看集群状态 1234567/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n master cluster_statusCluster status of node 'master@sky-linux' ...[&#123;nodes,[&#123;disc,['master@sky-linux','node1@sky-linux']&#125;]&#125;, &#123;running_nodes,['node1@sky-linux','master@sky-linux']&#125;, &#123;cluster_name,&lt;&lt;"master@sky-linux"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'node1@sky-linux',[]&#125;,&#123;'master@sky-linux',[]&#125;]&#125; 加入一个内存集群节点12345678910RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=node2 /ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmq-server -detached/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node2 stop_app/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node2 reset-- 加入集群/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node2 join_cluster master@sky-linux --ram-- 启动节点node2/ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n node2 start_app 这时再查看集群状态 1234567891011╭─sky@sky-linux /ihome/rabbitmq/rabbitmq_server-3.6.1 ╰─➤ /ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmqctl -n master cluster_statusCluster status of node 'master@sky-linux' ...[&#123;nodes,[&#123;disc,['master@sky-linux','node1@sky-linux']&#125;, &#123;ram,['node2@sky-linux']&#125;]&#125;, &#123;running_nodes,['node2@sky-linux','node1@sky-linux','master@sky-linux']&#125;, &#123;cluster_name,&lt;&lt;"master@sky-linux"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'node2@sky-linux',[]&#125;, &#123;'node1@sky-linux',[]&#125;, &#123;'master@sky-linux',[]&#125;]&#125;] 可以看到ram, [&#39;node2@sky-linux&#39;]表示它就是内存内存节点并且已经是running了. 到这里，就已经完成了2个磁盘节点+1个内存节点的单机集群已经OK了.]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
        <tag>cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 为生产环境在线添加字段]]></title>
    <url>%2F2016%2F04%2F11%2FMySQL-%E4%B8%BA%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E5%9C%A8%E7%BA%BF%E6%B7%BB%E5%8A%A0%E5%AD%97%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[123456789create table new_table_name like old_table_name;alter table new_table_name add column new_column int not null default 0 comment 'your comment';insert into new_table_name (col1, col2, col3...) select (col1, col2, col3...) from old_table_name where id &lt; xxxx;begin;insert into new_table_name (col1, col2, col3...) select (col1, col2, col3...) from old_table_name where id &gt;= xxxxrename old_table_name to old_table_bak, new_table_name to old_table_name;commit;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ生产环境部署]]></title>
    <url>%2F2016%2F03%2F30%2FRabbitMQ%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[安装 安装好erlang环境 1sudo apt-get install erlang erlang-dev 下载rabbitmq Download 解压到你想要存放的目录，例如~/rabbitmq/ rabbitmq 的管理配置好环境变量 1RABBITMQ_HOME="/ihome/rabbitmq/rabbitmq_server-3.6.1" 配置文件位置默认情况下，以下两个文件是不存在的。有需要的话，可以自行创建一个. 环境变量的配置文件在$RABBITMQ_HOME/etc/rabbitmq/rabbitmq-env.conf 属性的配置文件在在$RABBITMQ_HOME/etc/rabbitmq/rabbitmq.config 当然，如果想要改为像apt-get install时的目录构架，也可以在$RABBITMQ_HOME/sbin/rabbitmq-defaults文件里，修改以下的内容: 123SYS_PREFIX=$&#123;RABBITMQ_HOME&#125;修改为SYS_PREFIX= 即去掉这个前缀即可. 通过这个文件$RABBITMQ_HOME/sbin/rabbitmq-defaults也可以了解到MQ的加载文件的位置。 注意，这样子修改完之后，MQ查找的配置文件位置就是/etc/rabbitmq/目录下了，而不是原来的$RABBITMQ_HOME/etc/rabbitmq/了，因为删除了这个前缀. rabbitmq-env.conf 文件配置这个文件的特点是：在外部环境变量的，并且是以RABBITMQ_开头的环境变量名，在这个文件里就对应为去掉这个前缀的环境变量名。例如，在命令行里，如果有个外部环境变量，名为RABBITMQ_NODENAME=xxx，就对应这个文件的变量名NODENAME=xxx，即等同于这个文件的内容为: 1NODENAME=xxx RabbitMQ的环境变量列表 例如，如果想修改监听的指定IP，则可以添加以下内容到这个env文件里:1NODE_IP_ADDRESS=192.168.1.10 如果想监听2个或以个的IP，则需要在rabbitmq.config文件的tcp_listeners键里修改.内容类似如下: 1&#123;tcp_listeners, [&#123;"127.0.0.1",5672&#125;,&#123;"192.168.20.18",5672&#125;]&#125;, 修改监听的端口在rabbitmq-env.conf文件里添加: 1NODE_PORT=5672 修改节点名字在rabbitmq-env.conf文件里添加 1NODENAME=hello rabbitmq 获取变量的顺序 如果SHELL环境有一个名为RABBITMQ_var_name的变量名，那就使用这个. 否则如果在rabbitmq-env.conf里有一个名为var_name的变量名，那就使用这个. 最后则在系统级获取这默认值. rabbitmq.config 文件配置RabbitMQ rabbitmq.config配置项列表 RabbitMQ rabbitmq.config配置文件示例 比如，修改监听端口: 123[ &#123;rabbit, [&#123;tcp_listeners, [5673]&#125;]&#125; ]. 注意，最后还有一个英文句号. 全系列安装方式的配置文件位置列表 Generic UNIX - $RABBITMQ_HOME/etc/rabbitmq/ Debian - /etc/rabbitmq/ RPM - /etc/rabbitmq/ Mac OS X (Homebrew) - ${install_prefix}/etc/rabbitmq/, the Homebrew prefix is usually /usr/local Windows - %APPDATA%\RabbitMQ\ 默认的MQ使用端口情况 4369 (epmd), 25672 (Erlang distribution) 5672, 5671 (AMQP 0-9-1 without and with TLS) n15672 (if management plugin is enabled) 61613, 61614 (if STOMP is enabled) 1883, 8883 (if MQTT is enabled) 默认的用户名和密码默认的用户名为：guest默认的密码为:guest rabbitmq从3.3.0开始禁止使用guest/guest权限通过除localhost外的访问 启动非守护进程启动$RABBITMQ_HOME/sbin/rabbitmq-server 以守护进程启动$RABBITMQ_HOME/sbin/rabbitmq-server -detached 如果成功的话，它会显示类似以下的信息: 1completed with [n] plugins 停止$RABBITMQ_HOME/sbin/rabbitmqctl stop 查看状态$RABBITMQ_HOME/sbin/rabbitmqctl status 与项目结合配置 添加一个vhost: rabbitmqctl add_vhost /project_name 添加一个用户: rabbitmqctl add_user project_user_name project_user_passwd 添加权限: rabbitmqctl set_user_tags project_user_name management 开启web控制台: rabbitmq-plugins enable rabbitmq_management 设置用户访问vhost权限: rabbitmqctl set_permissions -p /project_name project_user_name &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 多实例管理实例node1的配置文件node1.config内容为: 12345[ &#123;rabbit, [ &#123;tcp_listeners, [5674]&#125;, &#123;collect_statistics_interval, 10000&#125; ] &#125;, &#123;rabbitmq_management, [&#123;listener, [&#123;port, 12345&#125;]&#125;] &#125;]. 实例node2的配置文件node2.config内容为: 12345[ &#123;rabbit, [ &#123;tcp_listeners, [5674]&#125;, &#123;collect_statistics_interval, 10000&#125; ] &#125;, &#123;rabbitmq_management, [&#123;listener, [&#123;port, 12345&#125;]&#125;] &#125;]. 启动多实例启动实例1: RABBITMQ_CONFIG_FILE=/ihome/rabbitmq/rabbitmq_server-3.6.1/etc/rabbitmq/node1 RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=node1 /ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmq-server -detached 启动实例2:RABBITMQ_CONFIG_FILE=/ihome/rabbitmq/rabbitmq_server-3.6.1/etc/rabbitmq/node2 RABBITMQ_NODE_PORT=5675 RABBITMQ_NODENAME=node2 /ihome/rabbitmq/rabbitmq_server-3.6.1/sbin/rabbitmq-server -detached 启动完毕，就可以看到以下端口都在监听了 12345678910111213141516171819╭─sky@sky-linux /ihome/rabbitmq/rabbitmq_server-3.6.1/etc/rabbitmq ╰─➤ lsof -i:12346COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbeam.smp 22069 sky 46u IPv4 14451143 0t0 TCP *:12346 (LISTEN)╭─sky@sky-linux /ihome/rabbitmq/rabbitmq_server-3.6.1/etc/rabbitmq ╰─➤ lsof -i:12345COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbeam.smp 21828 sky 46u IPv4 14447989 0t0 TCP *:12345 (LISTEN)╭─sky@sky-linux /ihome/rabbitmq/rabbitmq_server-3.6.1/etc/rabbitmq ╰─➤ lsof -i:5674 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbeam.smp 21828 sky 45u IPv6 14445397 0t0 TCP *:mrtd (LISTEN)╭─sky@sky-linux /ihome/rabbitmq/rabbitmq_server-3.6.1/etc/rabbitmq ╰─➤ lsof -i:5675COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbeam.smp 22069 sky 45u IPv6 14451141 0t0 TCP *:bgpsim (LISTEN) 它们web界面管理地址如下: node1 http://localhost:12345/#/ node 2http://localhost:12346/#/ 因为默认情况下，guest只能通过localhost访问，要想远程访问，最好添加一个远程访问用户，以减小权限的导致的问题. 查看节点状态123456╭─sky@sky-linux /ihome/rabbitmq/rabbitmq_server-3.6.1 ╰─➤ ./sbin/rabbitmqctl -n node1 statusStatus of node 'node1@sky-linux' ...[&#123;pid,21828&#125;, &#123;running_applications, ... 即在rabbitmqctl -n 节点名 status即可. 其他的操作，跟单节点时没什么区别，多节点时，只需要记得加上-n 节点名即可. 停止某节点123╭─sky@sky-linux /ihome/rabbitmq/rabbitmq_server-3.6.1 ╰─➤ ./sbin/rabbitmqctl -n node1 stop Stopping and halting node 'node1@sky-linux' ... 关于RabbitMQ的集群，目前还没有这种需求，所以也就没有继续深入了.有需要时，再补充下资料.]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL杂项资料收集]]></title>
    <url>%2F2016%2F03%2F08%2FMySQL%E6%9D%82%E9%A1%B9%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[关于 MySQL 5.6 ICP ICP（index condition pushdown） 参考资料: csdn-melody_mr 关于 字符串 与 整型对比 的查询与索引 查询中 number compare string： 如果有索引，那么就可以利用到索引。 查询中 string compare number： 就算有索引，也利用不到. 官方文档里这样子描述的: 对于用 number 与 string 比较(string &gt;|&lt;|&lt;=|&gt;= number), MySQL不能使用索引来快速查找数据。 如果str_col是一个string索引列，那么在下面这条查询语句中，就不能使用到索引: SELECT * FROM tbl_name WHERE str_col=1; 原因是： 有许多种string可以转换值为1,比如: &#39;1&#39;, &#39; 1&#39;, &#39;1a&#39;. stackoverflow以下是中文大概意思: 要点就是：如果数据库必须在table列进行转换，那么就不能利用到索引. 除此之外，数据库总是从string转换为number，因为这是确定性的。（不然，数字1可以被转换为字符串&#39;01&#39;, &#39;001&#39;）.所以，我们可以看以以下同两条SQL: 12-- index is usedEXPLAIN SELECT * FROM a_table WHERE int_column = '1'; 数据库转换&#39;1&#39;到数字1，然后执行这条SQL。最终，在比较符两边都是int，所以，它可以利用到索引. 12-- index is NOT used. WTF?EXPLAIN SELECT * FROM a_table WHERE str_column = 1; 再次，它又将string转换为numbers。然而，这次，它必须将表列的数据进行转换。事实上，你就像执行类似 cast(str_column as int) = 1的查询。这意味着，你不能再通过索引来查询了，所以不能使用到索引。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之复制]]></title>
    <url>%2F2016%2F03%2F06%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MySQL通过 3个线程来完成主从库间的数据复制：其中Binlog Dump线程跑在主库上， I/O线程和SQL线程跑在从库上。当在从库上启动复制（START SLAVE）时，首先创建 I/O线程连接主库，主库随后创建Binlog Dump线程读取数据库事件并发送给 I/O线程，I/O线程获取到事件数据后更新到从库的中继日志Relay Log中去，之后从库上的SQL线程读取中继日志Relay Log中更新的数据库事件并应用. MySQL 的复制是主库主动推送日志到从库去的，是属于“推”日志的方式来做同步 同样地，在从库上通过SHOW PROCESSLIST可以看到 I/O线程和SQL线程，I/O线程等待主库上的Binlog Dump线程发送事件并更新到中继日志Relay Log，SQL线程读取中继日志Relay Log并应用变更到数据库. 从MySQL的复制流程可以了解到MySQL的复制是异步的。从库上的数据和主库存在一定的延时。 二进制日志文件（Binlog）会把 MySQL 中的所有数据修改操作以二进制的形式记录到日志文件中，包括Create、Drop、Insert、Update、Delete操作等，但二进制日志文件（Binlog）不会记录Select操作，因为Select操作并不修改数据. 中继日志文件Relay Log的文件格式、内容和二进制日志文件Binlog一样，唯一的区别在于从库上的SQL线程在执行完当前中继日志文件Relay Log中的事件之后，SQL线程会自动删除当前中继日志文件Relay Log，避免从库上的中继日志文件Relay Log占用过多的磁盘空间。 为了保证从库Crash重启之后，从库的I/O线程和SQL线程仍然能够知道从哪里开始复制，从库上默认还会创建两个日志文件master.info和relay-log.info用来保存复制的进度。这两个文件在磁盘上以文件形式分别记录了从库的 I/O 线程当前读取主库二进制日志 Binlog 的进度和SQL线程应用中继日志Relay Log的进度。 在MySQL 5.5之前的异步复制时，主库执行完 Commit 提交操作后，在主库写入 Binlog 日志后即可成功返回客户端，无需等待Binlog日志传送给从库. 而半同步复制时，为了保证主库上的每一个 Binlog 事务都能够被可靠的复制到从库上，主库在每次事务成功提交时，并不及时反馈给前端应用用户，而是等待其中一个从库也接收到 Binlog事务并成功写入中继日志后，主库才返回Commit操作成功给客户端。半同步复制保证了事务成功提交后，至少有两份日志记录，一份在主库的 Binlog 日志上，另一份在至少一个从库的中继日志Relay Log上，从而更进一步保证了数据的完整性。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之锁]]></title>
    <url>%2F2016%2F03%2F06%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁类型 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 表级锁查看表级锁的争夺情况12345678mysql&gt; show global status like 'table_lock%';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| Table_locks_immediate | 201 || Table_locks_waited | 0 |+-----------------------+-------+2 rows in set (0.01 sec) 如果Table_locks_waited的值比较高，则说明存在着较严重的表级锁争用情况。 表级锁的模式MySQL的表级锁有两种模式： 表共享读锁（Table Read Lock） 表独占写锁（Table Write Lock） 对 MyISAM 表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；对 MyISAM 表的写操作，则会阻塞其他用户对同一表的读和写操作；MyISAM表的读操作与写操作之间，以及写操作之间是串行的!. 如何加表锁MySIAM 在select前, 会自动给所涉及的表加上读锁, 在执行更新操作时(update, delete, insert)前,会自动给涉及的表加写锁. 注意 : 当使用LOCK TABLES时，不仅需要一次锁定用到的所有表，而且，同一个表在SQL语句中出现多少次，就要通过与SQL语句中相同的别名锁定多少次，否则也会出错！ 在LOCK TABLES时加了local选项，其作用就是在满足MyISAM表并发插入条件的情况下，允许其他用户在表尾并发插入记录. MyISAM 的锁调度MyISAM存储引擎的读锁和写锁是互斥的，读写操作是串行的。那么，一个进程请求某个MyISAM表的读锁，同时另一个进程也请求同一表的写锁，MySQL如何处理呢？答案是写进程先获得锁。不仅如此，即使读请求先到锁等待队列，写请求后到，写锁也会插到读锁请求之前！这是因为MySQL认为写请求一般比读请求要重要。这也正是MyISAM表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。这种情况有时可能会变得非常糟糕！幸好我们可以通过一些设置来调节MyISAM的调度行为. 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低. 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。 MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会. InnoDB锁(行锁)并发事务带来的问题 更新丢失（Lost Update） 脏读（Dirty Reads） 不可重复读（Non-Repeatable Reads） 幻读（Phantom Reads） 事务隔离级别数据库实现事务隔离的方式, 基本上可以分为两种方式: 第一种: 在读取数据前, 对其加锁, 阻止其他事务对数据进行修改. 第二种: 不用加任何锁, 通过一定机制生成一个数据请求时间点的一致性数据快照.并用这个快照来提供一定级别(语句级或事务级)的一致性读取.从用户的角度来看, 好像数据库可以提供同一数据的多个版本, 因此, 这种技术叫做数据多版本并发控制(MVCC). 数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行. InnoDB行锁竞争情况1234567891011mysql&gt; show global status like '%innodb_row_lock%';+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| Innodb_row_lock_current_waits | 0 || Innodb_row_lock_time | 0 || Innodb_row_lock_time_avg | 0 || Innodb_row_lock_time_max | 0 || Innodb_row_lock_waits | 0 |+-------------------------------+-------+5 rows in set (0.00 sec) InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，可以通过查询 information_schema 数据库中相关的表来查看锁情况，或者通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。 查看innodb锁信息: select * from information_schema.innodb_locks\G 通过innodb monitors查看: CREATE TABLE innodb_monitor(a INT) ENGINE=INNODB 然后使用以下命令来查看: show engine innodb status\G 停止监视器:drop table innodb_monitor; 设置监视器后，在SHOW INNODB STATUS的显示内容中，会有详细的当前锁等待的信息，包括表名、锁类型、锁定记录的情况等，便于进行进一步的分析和问题的确定。打开监视器以后，默认情况下每15秒会向日志中记录监控的内容，如果长时间打开会导致.err文件变得非常巨大，所以用户在确认问题原因之后，要记得删除监控表以关闭监视器，或者通过使用“–console”选项来启动服务器以关闭写日志文件. InnoDB 的行锁及加锁方法行锁类型 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁 另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。 如果一个事务请求的锁模式与当前的锁兼容，InnoDB 就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。 意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句， InnoDB会自动给涉及数据集加排他锁（X）；对于普通SELECT语句，InnoDB不会加任何锁；事务可以通过以下语句显示给记录集加共享锁或排他锁。 共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。 排他锁（X）：SELECT * FROM table_name WHERE … FOR UPDATE。 用SELECT … IN SHARE MODE获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁. 对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁。 InnoDB实现行锁的方式InnoDB行锁是通过给索引上的索引项加锁来实现的，如果没有索引，InnoDB将通过隐藏的聚簇索引来对记录加锁。 行锁分三种情况: Record lock：对索引项加锁。 Gap lock：对索引项之间的“间隙”、第一条记录前的“间隙”或最后一条记录后的“间隙”加锁。 Next-key lock：前两种的组合，对记录及其前面的间隙加锁。 注意 : InnoDB这种行锁实现特点意味着：如果不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，实际效果跟表锁一样! 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。应用设计的时候要注意这一点。 当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。 即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB也会对所有记录加锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引. Next-Key锁当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB 会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP）”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的Next-Key锁。 举例来说，假如emp表中只有101条记录，其empid的值分别是1、2、…、100、101，下面的SQL： Select * from emp where empid &gt; 100 for update; 是一个范围条件的检索，InnoDB 不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁. InnoDB使用Next-Key锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要. 注意 很显然，在使用范围条件检索并锁定记录时，InnoDB 这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件. 还要特别说明的是，InnoDB除了通过范围条件加锁时使用Next-Key锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用Next-Key锁！. 恢复和复制对InnoDB锁机制的影响MySQL通过BINLOG记录执行成功的INSERT、UPDATE、DELETE等更新数据的SQL语句，并由此实现MySQL数据库的恢复和主从复制. MySQL 5.6支持 3种日志格式，即基于语句的日志格式SBL、基于行的日志格式RBL和混合格式. 基于SQL语句的复制SBR. 基于行数据的复制RBR. 混合复制模式 使用全局事务ID（GTIDs）的复制：主要是解决主从自动同步一致问题 对于insert into target_tab select * from source_tab where ... 和 create table new_tab...select ...from source_tab where ..(CTAS)这种SQL, 用户并没有对source_tab做任何更新操作, 但MySQL对这种SQL语句做了特别处理. 它会对source_tab加表锁. 可以通过设置innodb_locks_unsafe_for_binlog为on,这样就不会对source_tab加表锁了.注意 如果设置为了on, 就有可能导致进行复制时, 主从不一致. (详细看&lt;深入浅出MySQL&gt;第二版, 20.3.7节) 注意 : 如果上述的where是范围查询的话, 还会加上Next-key锁! 因此，INSERT…SELECT…和CREATE TABLE…SELECT…语句，可能会阻止对源表的并发更新。如果查询比较复杂，会造成严重的性能问题，读者在应用中应尽量避免使用。实际上，MySQL将这种 SQL叫做不确定（non-deterministic）的 SQL，属于“Unsafe SQL”，不推荐使用. 如果应用中一定要用这种 SQL 来实现业务逻辑，又不希望对源表的并发更新产生影响，可以采取以下3种措施: 一是采取上面示例中的做法，将 innodb_locks_unsafe_for_binlog 的值设置为“on”，强制MySQL使用多版本数据一致性读。但付出的代价是可能无法用BINLOG正确地恢复或复制数据，因此，不推荐使用这种方式. 二是通过使用“select * from source_tab … Into outfile”和“load data infile …”语句组合来间接实现，采用这种方式MySQL不会给source_tab加锁。 三是使用基于行的BINLOG格式和基于数据的复制. 什么时候使用表锁对InnoDB表, 绝大部分都应该使用行级锁. 但在个别特殊事务中，也可以考虑使用表级锁。 第一种情况是：事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度. 第二种情况是：事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁，减少数据库因事务回滚带来的开销.当然，应用中这两种事务不能太多，否则，就应该考虑使用MyISAM表了。 使用表锁要注意: 使用 LOCK TABLES虽然可以给 InnoDB加表级锁，但必须说明的是，表锁不是由 InnoDB 存储引擎层管理的，而是由其上一层─MySQL Server 负责的，仅当autocommit=0、innodb_table_locks=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，MySQL Server也才能感知 InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。 在用LOCK TABLES对 InnoDB表加锁时要注意，要将AUTOCOMMIT设为 0，否则MySQL不会给表加锁；事务结束前，不要用 UNLOCK TABLES释放表锁，因为 UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK并不能释放用LOCK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁. 关于死锁发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决。需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生. 通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小，以及访问数据库的 SQL 语句，绝大部分死锁都可以避免. 避免死锁的常用方法 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能. 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。 前面讲过，在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT…FOR UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可避免问题. 当隔离级别为 READ COMMITTED 时，如果两个线程都先执行 SELECT…FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第1个线程提交后，第2个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第3个线程又来申请排他锁，也会出现死锁。 对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁. 因此，在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯. InnoDB的行锁是基于索引实现的，如果不通过索引访问数据，InnoDB会对所有数据加锁。 给记录集显式加锁时，最好一次性请求足够级别的锁。比如要修改数据，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁； 尽量用相等条件访问数据，这样可以避免Next-Key锁对并发插入的影响； 不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁； 对于一些特定的事务，可以使用表锁来提高处理速度或减少发生死锁的几率。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之优化]]></title>
    <url>%2F2016%2F03%2F06%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[查看服务器SQL及连接状态 查看当前执行的各种SQL执行频率: 全局性: show global status like &#39;%Com_%&#39;; 当前会话: show status like &#39;%Com_%&#39;; 重点查看: Com_insert: insert次数 Com_select: select次数 Com_update: update次数 Com_delete: delete次数 Com_rollback: 事务回滚次数 Com_commit: 事务提交次数 以上是查看所有存储引擎的总次数.查看InnoDB引擎的如下: show global status like &#39;%Innodb_rows_%&#39;; 查看试图连接MySQL服务器的次数: show global status like &#39;%connections%&#39;; 查看启动时长: show global status like &#39;%uptime%&#39;; 查看慢查询条数: show global status like &#39;%Slow_queries%&#39;; 定位效率低的SQL慢查询日志通过慢查询日志定位那些执行效率较低的SQL语句，用 --log-slow-queries[= file_name] 选项启动时，mysqld写一个包含所有执行时间超过long_query_time秒的SQL语句的日志文件. 慢查询日志在查询结束以后才记录，所以在应用反映执行效率出现问题的时候查询慢查询日志并不能定位问题，可以使用 show processlist命令查看当前MySQL在进行的线程，包括线程的状态、是否锁表等，可以实时地查看 SQL 的执行情况，同时对一些锁表操作进行优化。 通过 explain select_type：表示SELECT的类型，常见的取值有SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION中的第二个或者后面的查询语句）、SUBQUERY（子查询中的第一个SELECT）等。 table：输出结果集的表。 type：表示MySQL在表中找到所需行的方式，或者叫访问类型， all &lt; index &lt; range &lt; ref &lt; eq_ref &lt; const, system &lt; NULL 从左到右, 性能由最差到最好. 1. type=ALL，全表扫描，MySQL遍历全表来找到匹配的行. 2. type=index，索引全扫描， 3. type=range，索引范围扫描，常见于&lt;、&lt;=、&gt;、&gt;=、between等操作符. 4. type=ref，使用非唯一索引扫或唯一索引的前缀扫描，返回匹配某个单独值的记录行. ref还经常出现在join操作中 5. type=eq_ref，类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配；简单来说，就是多表连接中使用 primary key或者 unique index作为关联条件 6. type=const/system，单表中最多有一个匹配行，查询起来非常迅速，所以这个匹配行中的其他列的值可以被优化 7. type=NULL，MySQL不用访问表或者索引，直接就能够得到结果 8. 类型type还有其他值，如ref_or_null（与ref类似，区别在于条件中包含对NULL的查询）、index_merge（索引合并优化）、unique_subquery（in 的后面是一个查询主键字段的子查询）、index_subquery（与 unique_subquery 类似，区别在于 in 的后面是查询非唯一索引字段的子查询） possible_keys：表示查询时可能使用的索引。 key：表示实际使用的索引。 key_len：使用到索引字段的长度。 rows：扫描行的数量。 Extra：执行情况的说明和描述，包含不适合在其他列中显示但是对执行计划非常重要的额外信息. Using where，表示优化器除了利用索引来加速访问之外，还需要根据索引回表查询数据 Using index，也就意味着，现在直接访问索引就足够获取到所需要的数据，不需要通过索引回表，Using index也就是平常说的覆盖索引扫描. Using index condition就表示MySQL使用了 ICP来进一步优化查询，在检索的时候，把条件customer_id的过滤操作下推到存储引擎层来完成，这样能够降低不必要的IO访问 提醒 : 通过 explain extended加上 show warnings 可以看到SQL真正被执行之前优化器做了哪些SQL改写. explain partitions: 命令查看SQL所访问的分区 通过 show profile分析SQL步骤: 查看是否支持: select @@have_profiling;. 会话级开启: set profiling = 1; 执行SQL 执行profile: show profiles; 查看具体某个query的profile: show profile for query N; Sending data: 状态表示MySQL线程开始访问数据行并把结果返回给客户端，而不仅仅是返回结果给客户端。由于在Sending data状态下，MySQL线程往往需要做大量的磁盘读取操作，所以经常是整个查询中耗时最长的状态 查看某个query的CPU耗时: show profile cpu for query N; 通过 trace (MySQL 5.6或更高)步骤 开启trace并设置格式为json, 以及trace最大使用内存: set optimizer_trace=&quot;enabled=on&quot;, end_markers_in_json=on;set optimizer_trace_max_mem_size=1000000; 执行你的SQL 查看trace: select * from information_schema.optimizer_trace\G 索引问题 索引是在MySQL的存储引擎层中实现的，而不是在服务器层实现的。所以每种存储引擎的索引都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型. Hash索引不适用范围查询，例如&lt;、&gt;、&lt;=、&gt;=这类操作。 需要注意B-Tree索引中的B 不代表二叉树（binary），而是代表平衡树（balanced）。B-Tree索引并不是一棵二叉树。 能使用索引的情况 匹配全值（Match the full value），对索引中所有列都指定具体值，即是对索引中的所有列都有等值匹配的条件。 匹配值的范围查询（Match a range of values），对索引的值能够进行范围查找 匹配最左前缀（Match a leftmost prefix），仅仅使用索引中的最左边列进行查找. 最左匹配原则可以算是MySQL中B-Tree索引使用的首要原则 仅仅对索引进行查询（Index only query），当查询的列都在索引的字段中时，查询的效率更高. 匹配列前缀（Match a column prefix），仅仅使用索引中的第一列，并且只包含索引第一列的开头一部分进行查找. 能够实现索引匹配部分精确而其他部分进行范围匹配（Match one part exactly and match a range on another part）。 如果列名是索引, 那么使用column is null 就会使用索引. MySQL 5.6引入了 Index Condition Pushdown（ICP）的特性，进步优化了查询。Pushdown表示操作下放，某些情况下的条件过滤操作下放到存储引擎. 存在索引, 但用不上的情况 以%开头的LIKE查询不能够利用B-Tree索引，执行计划中key的值为NULL表示没有使用索引 数据类型出现隐式转换的时候也不会使用索引，特别是当列类型是字符串，那么一定记得在 where 条件中把字符常量值用引号引起来，否则即便这个列上有索引，MySQL 也不会用到，因为MySQL默认把输入的常量值进行转换以后才进行检索 复合索引的情况下，假如查询条件不包含索引列最左边部分，即不满足最左原则Leftmost，是不会使用复合索引的 如果 MySQL 估计使用索引比全表扫描更慢，则不使用索引. 也就是在查询的时候，筛选性越高越容易使用到索引，筛选性越低越不容易使用索引 用or分割开的条件，如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到，因为 or 后面的条件列中没有索引，那么后面的查询肯定要走全表扫描，在存在全表扫描的情况下，就没有必要多一次索引扫描增加I/O访问，一次全表扫描过滤条件就足够了. 查看索引使用情况12345678910111213mysql&gt; show global status like '%handler_read%';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| Handler_read_first | 54 || Handler_read_key | 174 || Handler_read_last | 0 || Handler_read_next | 125 || Handler_read_prev | 0 || Handler_read_rnd | 6 || Handler_read_rnd_next | 18857 |+-----------------------+-------+7 rows in set (0.00 sec) 结果说明:Handler_read_key 的值将很高，这个值代表了一个行被索引值读的次数，很低的值表明增加索引得到的性能改善不高，因为索引并不经常使用。 Handler_read_rnd_next `的值高则意味着查询运行低效，并且应该建立索引补救。这个值的含义是在数据文件中读下一行的请求数。如果正进行大量的表扫描，Handler_read_rnd_next的值较高，则通常说明表索引不正确或写入的查询没有利用索引 简单实用的优化方法定期分析表和检查表 分析表: analyze table tbname1, tbname2 ... 检查表: check table tbname1, tbname2 ... 定期优化表 优化表: optimize table tbname1, tbname2 ... 注意, 以上的操作, 会导致锁表!. 常用SQL优化大批量导入数据MyISAM表的 load对于MyISAM存储引擎的表，可以通过以下方式快速地导入大量的数据。 123ALTER TABLE tbl_name DISABLE KEYS; loading the dataALTER TABLE tbl_name ENABLE KEYS; 对于InnoDB类型的表，这种方式并不能提高导入数据的效率. InnoDB表的 load 因为InnoDB类型的表是按照主键的顺序保存的，所以将导入的数据按照主键的顺序排列，可以有效地提高导入数据的效率. 在导入数据前执行SET UNIQUE_CHECKS=0，关闭唯一性校验，在导入结束后执行SET UNIQUE_CHECKS=1，恢复唯一性校验，可以提高导入的效率。 如果应用使用自动提交的方式，建议在导入前执行SET AUTOCOMMIT=0，关闭自动提交，导入结束后再执行SET AUTOCOMMIT=1，打开自动提交，也可以提高导入的效率。 优化 insert 语句 如果同时从同一客户插入很多行，应尽量使用多个值表的INSERT语句，这种方式将大大缩减客户端与数据库之间的连接、关闭等消耗，使得效率比分开执行的单个INSERT语句快（在大部分情况下，使用多个值表的 INSERT 语句能比单个 INSERT 语句快上好几倍）. 如果从不同客户插入很多行，可以通过使用 INSERT DELAYED语句得到更高的速度.DELAYED的含义是让INSERT语句马上执行，其实数据都被放在内存的队列中，并没有真正写入磁盘，这比每条语句分别插入要快得多；LOW_PRIORITY 刚好相反，在所有其他用户对表的读写完成后才进行插入。 如果进行批量插入，可以通过增加bulk_insert_buffer_size变量值的方法来提高速度，但是，这只能对MyISAM表使用 当从一个文本文件装载一个表时，使用 LOAD DATA INFILE。这通常比使用很多INSERT语句快20倍。 优化 order byMySQL排序方式: 第一种通过有序索引顺序扫描直接返回有序数据，这种方式在使用 explain 分析查询的时候显示为Using Index，不需要额外的排序，操作效率较高. 第二种是通过对返回数据进行排序，也就是通常说的 Filesort 排序，所有不是通过索引直接返回排序结果的排序都叫Filesort排序。Filesort并不代表通过磁盘文件进行排序，而只是说明进行了一个排序操作，至于排序操作是否使用了磁盘文件或临时表等，则取决于MySQL服务器对排序参数的设置和需要排序数据的大小。 Filesort是通过相应的排序算法，将取得的数据在sort_buffer_size系统变量设置的内存排序区中进行排序，如果内存装载不下，它就会将磁盘上的数据进行分块，再对各个数据块进行排序，然后将各个块合并成有序的结果集。sort_buffer_size 设置的排序区是每个线程独占的，所以同一个时刻，MySQL中存在多个 sort buffer排序区。 了解了MySQL排序的方式，优化目标就清晰了：尽量减少额外的排序，通过索引直接返回有序数据.尽量减少额外的排序，通过索引直接返回有序数据。WHERE条件和ORDER BY使用相同的索引，并且ORDER BY的顺序和索引顺序相同，并且ORDER BY的字段都是升序或者都是降序。否则肯定需要额外的排序操作，这样就会出现Filesort. 优化 Filesort MySQL 选择更优化的 Filesort排序算法。当然，假如max_length_for_sort_data设置过大，会造成CPU利用率过低和磁盘I/O过高，CPU和I/O利用平衡就足够了。 适当加大sort_buffer_size排序区，尽量让排序在内存中完成，而不是通过创建临时表放在文件中进行；当然也不能无限制加大sort_buffer_size排序区，因为sort_buffer_size参数是每个线程独占的，设置过大，会导致服务器SWAP严重，要考虑数据库活动连接数和服务器内存的大小来适当设置排序区。 尽量只使用必要的字段，SELECT具体的字段名称，而不是SELECT *选择所有字段，这样可以减少排序区的使用，提高SQL性能。 优化 group by默认情况下，MySQL对所有GROUP BY col1,col2,…的字段进行排序。这与在查询中指定ORDER BY col1,col2,…类似 如果查询包括GROUP BY但用户想避免排序结果的消耗，则可以指定ORDER BY NULL禁止排序. 优化嵌套查询有些情况下，子查询可以被更有效率的连接（JOIN）替代. 连接（JOIN）之所以更有效率一些，是因为MySQL不需要在内存中创建临时表来完成这个逻辑上需要两个步骤的查询工作. 优化 or 条件对于含有OR的查询子句，如果要利用索引，则OR之间的每个条件列都必须用到索引；如果没有索引，则应该考虑增加索引. 从执行计划的描述中，发现MySQL在处理含有OR字句的查询时，实际是对OR的各个字段分别查询后的结果进行了UNION操作. 优化分页 第一种优化思路 在索引上完成排序分页的操作，最后根据主键关联回原表查询所需要的其他列. 原SQL:select film_id, description from file order by title limit 50, 5; 优化后的SQL: select a.film_id, a.description from file a inner join (select file_id from file order by title limit 50, 5) b on a.film_id = b.film_id 这种方式是让MySQL扫描尽可能少的页面来提高分页效率. 第二种优化思路 把LIMIIT查询转换成某个位置的查询. 注意 : 这种方式是把limit m, n转换成limit n查询, 只适合在排序字段不会出现重复值的特定环境. 如果排序字段出现大量重复值, 而仍进行这种优化, 那么分页结果可能会丢失部分数据. 使用SQL提示 USE INDEX: 在查询语句中表名的后面，添加USE INDEX来提供希望MySQL去参考的索引列表，就可以让MySQL不再考虑其他可用的索引。 IGNORE INDEX: 如果用户只是单纯地想让MySQL忽略一个或者多个索引，则可以使用 IGNORE INDEX作为HINT. FORCE INDEX: 为强制MySQL使用一个特定的索引，可在查询中使用FORCE INDEX作为HINT。 SQL常用技巧 正则表达式 select &#39;abcdefg&#39; REGEXP &#39;^a&#39;; 随机行 select * from tbname order by rand() 使用 group by 的 with rollup 子句 利用GROUP BY的WITH ROLLUP子句 在SQL语句中，使用GROUP BY的WITH ROLLUP字句可以检索出更多的分组聚合信息，它不仅仅能像一般的GROUP BY语句那样检索出各组的聚合信息，还能检索出本组类的整体聚合信息 其实WITH ROLLUP反映的是一种OLAP思想，也就是说这一个GROUP BY语句执行完成后可以满足用户想要得到的任何一个分组以及分组组合的聚合信息值。 注意：当使用ROLLUP时，不能同时使用ORDER BY子句进行结果排序。换言之，ROLLUP和ORDER BY是互相排斥的。此外，LIMIT用在ROLLUP后面。 表名大小写问题数据库中的每个表至少对应数据库目录中的一个文件, 所以, 操作系统的大小写敏感性决定了数据库名和表名的大小写敏感性。在大多数UNIX环境中，由于操作系统对大小写的敏感性导致了数据库名和表名对大小写敏感性，而在 Windows中，由于操作系统本身对大小写不敏感，因此在Windows下的MySQL数据库名和表名对大小写也不敏感。 列、索引、存储子程序和触发器名在任何平台上对大小写不敏感。默认情况下，表别名在UNIX中对大小写敏感，但在Windows或Mac OS X中对大小写不敏感 使用外健注意在MySQL中，InnoDB存储引擎支持对外部关键字约束条件的检查。而对于其他类型存储引擎的表，当使用REFERENCES tbl_name(col_name)子句定义列时可以使用外部关键字，但是该子句没有实际的效果，只作为备忘录或注释来提醒用户目前正定义的列指向另一个表中的一个列.如果用InnoDB存储引擎建表的话，外键就会起作用. 用 show create table命令查看建表语句的时候，发现MyISAM存储引擎并不显示外键的语句，而InnoDB存储引擎就会显示外键语句. 优化表对象优化数据类型在MySQL中，可以使用函数PROCEDURE ANALYSE()对当前应用的表进行分析，该函数可以对数据表中列的数据类型提出优化建议，用户可以根据应用的实际情况酌情考虑是否实施优化.执行例子: 1234567mysql&gt; select * from t procedure analyse();+------------+-----------+-----------+------------+------------+------------------+-------+-------------------------+--------+------------------------+| Field_name | Min_value | Max_value | Min_length | Max_length | Empties_or_zeros | Nulls | Avg_value_or_avg_length | Std | Optimal_fieldtype |+------------+-----------+-----------+------------+------------+------------------+-------+-------------------------+--------+------------------------+| test.t.id | 1 | 2 | 1 | 1 | 0 | 0 | 1.3333 | 0.4714 | ENUM('1','2') NOT NULL |+------------+-----------+-----------+------------+------------+------------------+-------+-------------------------+--------+------------------------+1 row in set (0.01 sec) 拆分表垂直拆分即按列拆分. 如果一个表中某些列常用，而另一些列不常用，则可以采用垂直拆分. 水平拆分即按行拆分. 表中的数据本来就有独立性，例如，表中分别记录各个地区的数据或不同时期的数据，特别是有些数据常用，而另外一些数据不常用 逆规范化因为规范化越高，那么产生的关系就越多，关系过多的直接结果就是导致表之间的连接操作越频繁，而表之间的连接操作是性能较低的操作，直接影响到查询的速度，所以，对于查询较多的应用，就需要根据实际情况运用逆规范化对数据进行设计，通过逆规范化来提高查询的性能. 反规范的好处是降低连接操作的需求、降低外键和索引的数目，还可能减少表的数目，相应带来的问题是可能出现数据的完整性问题. 另外，逆规范技术需要维护数据的完整性。无论使用何种反规范技术，都需要一定的管理来维护数据的完整性，常用的方法是批处理维护、应用逻辑和触发器。 批处理维护是指对复制列或派生列的修改积累一定的时间后，运行一批处理作业或存储过程对复制或派生列进行修改，这只能在对实时性要求不高的情况下使用。 数据的完整性也可由应用逻辑来实现，这就要求必须在同一事务中对所有涉及的表进行增、删、改操作。用应用逻辑来实现数据的完整性风险较大，因为同一逻辑必须在所有的应用中使用和维护，容易遗漏，特别是在需求变化时，不易于维护。 另一种方式就是使用触发器，对数据的任何修改立即触发对复制列或派生列的相应修改。触发器是实时的，而且相应的处理逻辑只在一个地方出现，易于维护。一般来说，是解决这类问题比较好的办法. Server 优化MySQL线程 master thread：主要负责将脏缓存页刷新到数据文件，执行 purge操作，触发检查点，合并插入缓冲区等。 insert buffer thread：主要负责插入缓冲区的合并操作。 read thread：负责数据库读取操作，可配置多个读线程。 write thread：负责数据库写操作，可配置多个写线程。 log thread：用于将重做日志刷新到 logfile中。 purge thread：MySQL 5.5之后用单独的 purge thread执行 purge操作 lock thread：负责锁控制和死锁检测等。 错误监控线程：主要负责错误监控和错误处理. 查看这些线程的状态:show engine innodb status \G 内存优化 MyISAM的数据文件读取依赖于操作系统自身的IO缓存，因此，如果有MyISAM表，就要预留更多的内存给操作系统做IO缓存. 排序区、连接区等缓存是分配给每个数据库会话（session）专用的，其默认值的设置要根据最大连接数合理分配，如果设置太大，不但浪费内存资源，而且在并发连接较高时会导致物理内存耗尽. MyISAM MyISAM存储引擎使用 key buffer缓存索引块，以加速MyISAM索引的读写速度。对于MyISAM表的数据块，MySQL没有特别的缓存机制，完全依赖于操作系统的IO缓存。 key_buffer_size设置 key_buffer_size决定MyISAM索引块缓存区的大小，它直接影响MyISAM表的存取效率。 我们可以通过检查key_read_requests、key_reads、key_write_requests和key_writes等MySQL状态变量来评估索引缓存的效率。一般来说: 索引块物理读比率 key_reads / key_read_requests应小于 0.01。 索引块写比率 key_writes / key_write_requests 也应尽可能小，但这与应用特点有关，对于更新和删除操作特别多的应用，key_writes / key_write_requests 可能会接近 1，而对于每次更新很多行记录的应用，key_writes / key_write_requests就会比较小。 key buffer 使用率公式: 1 - ((key_blocks_unused * key_cache_block_size) / key_buffer_size) 一般来说，使用率在80%左右比较合适，大于80%，可能因索引缓存不足而导致性能下降；小于80%，会导致内存浪费。 如果经常顺序扫描MyISAM表, 可增大read_buffer_size, 但要注意它是每个session独占的. 如果经常要进行排序, 可增大read_rnd_buffer_size的值，也可以改善此类SQL的性能。但同样要注意的是：read_rnd_buffer_size也是按session分配的，默认值不能设置得太大。 InnoDB它的缓存机制: InnoDB用一块内存区做IO缓存池，该缓存池不仅用来缓存InnoDB的索引块，而且也用来缓存InnoDB的数据块，这一点与MyISAM不同. innodb_buffer_pool_size 决定 InnoDB 存储引擎表数据和索引数据的最大缓存区大小。和MyISAM存储引擎不同，Innod buffer pool同时为数据块和索引块提供数据缓存. 查看InnoDB buffer pool 情况: show global status like &#39;%innodb_buffer%&#39;; InnoDB缓存池命中率: (1 - innodb_buffer_pool_reads / innodb_buffer_pool_read_requests) * 100) 建议使用的buffer大小设置 123456789101112SELECT CONCAT(CEILING(RIBPS/POWER(1024,pw)),SUBSTR(' KMGT',pw+1,1))Recommended_InnoDB_Buffer_Pool_Size FROM( SELECT RIBPS,FLOOR(LOG(RIBPS)/LOG(1024)) pw FROM ( SELECT SUM(data_length+index_length)*1.1*growth RIBPS FROM information_schema.tables AAA, (SELECT 1 growth) BBB WHERE ENGINE='InnoDB' ) AA) A; 参考资料 dba.stackexchange.com 如果命中率太低，则应考虑扩充内存、增加innodb_buffer_pool_size的值 调整缓存池数量，减少内部对缓存池数据结构的争用 MySQL内部不同线程对InnoDB缓存池的访问在某些阶段是互斥的，这种内部竞争也会产生性能问题，尤其在高并发和 buffer pool较大的情况下。为解决这个问题，InnoDB的缓存系统引入了innodb_buffer_pool_instances配置参数，对于较大的缓存池，适当增大此参数的值，可以降低并发导致的内部缓存访问冲突，改善性能。InnoDB 缓存系统会将参数innodb_buffer_pool_size指定大小的缓存平分为 innodb_buffer_pool_instances个 buffer pool。 控制innodb buffer刷新速率 一个是innodb_max_dirty_pages_pct，它控制缓存池中脏页的最大比例，默认值是75%，如果脏页的数量达到或超过该值，InnoDB的后台线程将开始缓存刷新。 另一个是innodb_io_capacity，它代表磁盘系统的IO能力，其值在一定程度上代表磁盘每秒可完成 I/O 的次数。innodb_io_capacity 的默认值是 200，对于转速较低的磁盘，如7200RPM的磁盘，可将innodb_io_capacity的值降低到100，而对于固态硬盘和由多个磁盘组成的盘阵，innodb_io_capacity的值可以适当增大 若innodb_buffer_pool_wait_free的值增长较快，则说明InnoDB经常在等待空闲缓存页，如果无法增大缓存池，那么应将innodb_max_dirty_pages_pct的值调小，或将innodb_io_capacity的值提高，以加快脏页的刷新. 如果通过 show global status 看到 sort_merge_passes 的值很大，可以考虑通过调整参数sort_buffer_size的值来增大排序缓存区，以改善带有 order by子句或group子句SQL的性能. 对于无法通过索引进行连接操作的查询，可以尝试通过增大，join_buffer_size的值来改善性能。 注意 不过需要注意的是，sort buffer和 join buffer都是面向客户服务线程分配的，如果设置过大可能造成内存浪费，甚至导致内存交换。尤其是 join buffer，如果是多表关联的复杂查询，还可能会分配多个 join buffer，因此最好的策略是设置较小的全局 join_buffer_size，而对需要做复杂连接操作的session单独设置较大的join_buffer_size 日志 innodb_flush_log_at_trx_commit参数可以控制将 redo buffer中的更新时机. 如果这个参数设置为 0，在事务提交时，InnoDB 不会立即触发将缓存日志写到磁盘文件的操作，而是每秒触发一次缓存日志回写磁盘操作，并调用操作系统fsync刷新IO缓存。 如果这个参数设置为1，在每个事务提交时，InnoDB立即将缓存中的redo日志回写到日志文件，并调用操作系统fsync刷新IO缓存。 如果这个参数设置为2，在每个事务提交时，InnoDB立即将缓存中的redo日志回写到日志文件，但并不马上调用fsync来刷新IO缓存，而是每秒只做一次磁盘IO缓存刷新操作 将此参数设置成0，如果数据库崩溃，最后1秒钟的事务重做日志可能会由于未及写入磁盘文件而丢失，这种方式是效率最高的，但也是最不安全的。 将此参数设置成2，如果数据库崩溃，由于已执行重做日志写入磁盘操作，只是没有做磁盘 IO 刷新操作，因此，只要不发生操作系统崩溃，数据就不会丢失，这种方式是对性能和数据安全的折中，其性能和数据安全性介于其他两种方式之间 在某些情况下，我们需要尽量提高性能，并且可以容忍在数据库崩溃时丢失小部分数据，那么通过将参数innodb_flush_log_at_trx_commit设置成0或2都能明显减少日志同步IO，加快事务提交，从而改善性能。 innodb_flush_log_at_trx_commit参数的默认值是 1，即每个事务提交时都会从 log buffer写更新记录到日志文件，而且会实际刷新磁盘缓存，显然，这完全能满足事务的持久化要求，是最安全的，但这样会有较大的性能损失。 并发相关 innodb_log_buffer_size: 用来减少日志写磁盘操作，从而提高事务处理的性能。 如果状态变量connection_errors_max_connections不为零，并且一直在增长，就说明不断有连接请求因数据库连接数已达到最大允许的值而失败，应考虑增大max_connections的值。 每一个session操作MySQL数据库表都需要占用文件描述符，数据库连接本身也要占用文件描述符，因此，在增大max_connections时，也要注意评估open-files-limit的设置是否够用 调整 thread_cache_size 为加快连接数据库的速度，MySQL 会缓存一定数量的客户服务线程以备重用，通过参数thread_cache_size可控制MySQL缓存客户服务线程的数量。 可以通过计算线程cache的失效率threads_created/connections来衡量thread_cache_size的设置是否合适。该值越接近1，说明线程cache命中率越低，应考虑适当增加thread_cache_size的值。 innodb_lock_wait_timeout的设置 参数innodb_lock_wait_timeout可以控制InnoDB事务等待行锁的时间，默认值是50s，可以根据需要动态设置。对于需要快速反馈的交互式OLTP应用，可以将行锁等待超时时间调小，以避免事务长时间挂起；对于后台运行的批处理操作，可以将行锁等待超时时间调大，以避免发生大的回滚操作 应用优化 使用连接池 对于访问数据库来说，建立连接的代价比较昂贵，因此，我们有必要建立“连接池”以提高访问的性能。 减少对MySQL的访问 避免对同一数据做重复检索 应用中需要理清对数据库的访问逻辑。能够一次连接就能够提取出所有结果的，就不用两次连接，这样可以大大减少对数据库无谓的重复访问 MySQL的查询缓存（MySQL Query Cache）: show variables like &#39;%query_cache%&#39;; have_query_cache表明服务器在安装时是否已经配置了高速缓存。query_cache_size表明缓存区大小，单位为MBquery_cache_type, 变量值从0到2，含义分别为：0或者off（缓存关闭）、1或者on（缓存打开，使用SQL_NO_CACHE提示的SELECT除外）、2或者demand（只有带SQL_CACHE的SELECT语句提供高速缓存） 增加CACHE层 在应用中，我们可以在应用端加 CACHE层来达到减轻数据库负担的目的 负载均衡 负载均衡（Load Balance）是实际应用中使用非常普遍的一种优化方法，它的机制就是利用某种均衡算法，将固定的负载量分布到不同的服务器上，以此来减轻单台服务器的负载，达到优化的目的.]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之SQL模式]]></title>
    <url>%2F2016%2F03%2F06%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8BSQL%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[查看默认的SQL Mode1234567mysql&gt; select @@sql_mode;+-------------------------------------------------------------------------------------------------------------------------------------------+| @@sql_mode |+-------------------------------------------------------------------------------------------------------------------------------------------+| ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION |+-------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.01 sec) 设置模式SET [SESSION|GLOBAL] sql_mode=’modes’，其中SESSION选项表示只在本次连接中生效；而GLOBAL选项表示在本次连接中并不生效，而对于新的连接则生效，这种方法在MySQL 4.1开始有效。另外，也可以通过使用“–sql-mode=”modes””选项，在MySQL启动时设置sql_mode SQL 模式功能 验证日期的合法性.例如: 123456789101112131415161718192021222324mysql&gt; create table t_mode(t datetime);Query OK, 0 rows affected (0.02 sec)mysql&gt; set session sql_mode='ansi' -&gt; ;Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; insert into t_mode values('2007-04-32');Query OK, 1 row affected, 1 warning (0.01 sec)mysql&gt; select * from t_mode;+---------------------+| t |+---------------------+| 0000-00-00 00:00:00 |+---------------------+1 row in set (0.00 sec)mysql&gt; set session sql_mode='traditional';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; insert into t_mode values('2007-04-32');ERROR 1292 (22007): Incorrect datetime value: '2007-04-32' for column 't' at row 1mysql&gt; 在insert或update过程中, 如果sql mode处于traditional模式, mod(x,0)就会产生错误. 这是因为traditional也属于严格模式.在非严格模式下mod(x,0)返回的结果是NULL. 启用NO_BACKSLASH_ESCAPES: 使反斜线成为普通字符. 在导入数据时, 如果数据中含有反斜线, 那么启用NO_BACKSLASH_ESCAPES模式可以保证数据的正确性. 启用PIPES_AS_CONCAT: 将|视为字符串连接操作符.在Oracle中, |是字符串连接操作符, 所以在其他数据库中含有|操作符的SQL在MySQL中将无法执行, 为了解决这个问题, MySQL提供了PIPES_AS_CONCAT模式. 在MySQL与其他异构数据库之间有数据迁移的需求, 就可以利用sql mode来帮助迁移. MySQL SQL-MODE]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之事务控制和锁语句]]></title>
    <url>%2F2016%2F03%2F06%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%8E%A7%E5%88%B6%E5%92%8C%E9%94%81%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[MySQL支持对MyISAM和MEMORY存储引擎的表进行表级锁定，对BDB存储引擎的表进行页级锁定，对InnoDB存储引擎的表进行行级锁定。 锁表LOCK TABLES: 可以锁定用于当前线的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止. UNLOCK TABLES: 可以释放当前线程获得的任何锁定。当前线程执行另一个 LOCK TABLES时，或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁. 语法 12345678910111213mysql&gt; ? lockName: 'LOCK'Description:Syntax:LOCK TABLES tbl_name [[AS] alias] lock_type [, tbl_name [[AS] alias] lock_type] ...lock_type: READ [LOCAL] | [LOW_PRIORITY] WRITEUNLOCK TABLES 事务控制默认情况下, MySQL是自动提交事务的. 更详细的帮助, 可以查看: mysql&gt; ? start transaction 开启事务: start transaction 或 begin 提交或回滚: commit, rollback commit and chain: 立即启动一个新的事务, 并且和刚才的那个事务具有相同的隔离级别. release: 断开和客户端的连接. 如果定义了相同名字的 SAVEPOINT，则后面定义的SAVEPOINT 会覆盖之前的定义。 分布式事务 XA查看具体的帮助:mysql&gt; ? xa]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之索引设计]]></title>
    <url>%2F2016%2F03%2F06%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[InnoDB表的限制MySQL 5.7 InnoDB-restrictions MyISAM 表的限制MySQL 5.7 MyISAM-Storage-Engine 索引注意 索引的限制是以字节为单位的, 而表中的varchar等这些是以字符为单位的. 索引原则 搜索的索引列,不一定是所要选择的列.最适合索引的列是出现在WHERE子句中的列，或连接子句中指定的列，而不是出现在SELECT关键字后的选择列表中的列 使用唯一索引。考虑某列中值的分布。索引的列的基数越大，索引的效果越好 使用短索引。如果对字符串列进行索引，应该指定一个前缀长度，只要有可能就应该这样做。 利用最左前缀 不要过度索引 对于InnoDB存储引擎的表，记录默认会按照一定的顺序保存，如果有明确定义的主键，则按照主键顺序保存。如果没有主键，但是有唯一索引，那么就是按照唯一索引的顺序保存。如果既没有主键又没有唯一索引，那么表中会自动生成一个内部列，按照这个列的顺序保存。 另外，还需要注意，InnoDB 表的普通索引都会保存主键的键值，所以主键要尽可能选择较短的数据类型，可以有效地减少索引的磁盘占用，提高索引的缓存效果. 当对索引字段进行范围查询的时候，只有BTREE索引可以通过索引访问 注意如果需要访问大部分行，顺序读取要快得多，因为此时应避免磁盘搜索]]></content>
      <categories>
        <category>myql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之字符集处理]]></title>
    <url>%2F2016%2F03%2F06%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%97%E7%AC%A6%E9%9B%86%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[字符集 查看支持的字符集: show character set; 查看校对规则: show collation;, show collation like &#39;xxx&#39;, select * from infomation_schema.collations\G _ci: 大小写不敏感, _cs: 大小写敏感, _bin:二进制比较. 查看当前服务器的字符集: show variables like &#39;%character%&#39;; 查看当前服务器的校对规则: show variables like &#39;%collation%&#39; 查看某表的字符集和校对规则: show create table tbname\G 参数说明12345678910111213+--------------------------+------------------------------------------------------+| Variable_name | Value |+--------------------------+------------------------------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/local/Cellar/mysql/5.7.10/share/mysql/charsets/ |+--------------------------+------------------------------------------------------+8 rows in set (0.02 sec) character_set_client: 客户端字符集 character_set_connection: 连接字符集 character_set_results: 返回结果的字符集 设置my.conf12345[mysql]default-character-set=utf8[mysqld]default-charatcer-set=utf8 修改字符集修改数据库默认的字符集alter database test CHARACTER set &#39;gbk&#39;;: 这个不能对已有的数据进行修改, 而是对新的数据效. alter table tbname character set &#39;gbk&#39;: 这个也不能修改已有数据的字符, 只是对新插入的数据生效.12345678910111213141516171819202122232425mysql&gt; show create table t_p;+-------+------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------+| t_p | CREATE TABLE `t_p` ( `id` int(11) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)mysql&gt; alter table t_p character set 'gbk';Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t_p;+-------+-----------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-----------------------------------------------------------------------------------------------------------------------+| t_p | CREATE TABLE `t_p` ( `id` int(11) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=gbk |+-------+-----------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 如果需要对已有数据进行调整, 需要先将数据导出, 然后按新的字符集再进行导入才行.]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之存储引擎]]></title>
    <url>%2F2016%2F03%2F05%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[涉及的命令 查看表的默认引擎: show variables like &#39;table_type&#39;; 这个旧版本的用法,新的版本用法如下: 12345678910mysql&gt; show variables like '%engine%';+----------------------------------+--------+| Variable_name | Value |+----------------------------------+--------+| default_storage_engine | InnoDB || default_tmp_storage_engine | InnoDB || disabled_storage_engines | || internal_tmp_disk_storage_engine | InnoDB |+----------------------------------+--------+4 rows in set (0.00 sec) 查看支持的引擎: show engines\G 各引擎特点MyISAM MyISAM不支持事务、也不支持外键，其优势是访问的速度快，对事务完整性没有要求或者以 SELECT、INSERT 为主的应用基本上都可以使用这个引擎来创建表. 在旧版本的MySQL上, 它是默认的引擎. 但新版本的则以InnoDB默认引擎. 每个MyISAM在磁盘上存储成3个文件，其文件名都和表名相同，但扩展名分别是 .frm（存储表定义） .MYD（MYData，存储数据） .MYI（MYIndex，存储索引） 要指定索引文件和数据文件的路径，需要在创建表的时候通过 DATA DIRECTORY 和INDEX DIRECTORY语句指定，也就是说不同MyISAM表的索引文件和数据文件可以放置到不同的路径下。文件路径需要是绝对路径，并且具有访问权限 MyISAM的支持3种不同的存储格式, 分别是: 静态(固定长度)表(默认,注意, 这种会删除最的一空格字符的.) 动态表(频繁更新或删除时, 定期执行 optimize table 或 myisamcheck -r 命令来改善性能.) 压缩表(由myisampack工具创建) InnoDB 具有事务功能.在新版本的MySQL里, 它已经成为默认引擎了. 支持外键约束. 在创建外键时, 要求父表必须要有对应的索引, 子表在创建外键时, 也会自动创建索引.外键动作: RESTRICT、CASCADE、SET NULL和NO ACTIOIN 其中RESTRICT和NO ACTION相同，是指限制在子表有关联记录的情况下父表不能更新； CASCADE表示父表在更新或者删除时，更新或者删除子表对应记录； SET NULL 则表示父表在更新或者删除的时候，子表的对应字段被 SET NULL 存储方式 共享表空间:表定义保存在.frm文件中. 数据和索引保存在innodb_data_home_dir和innodb_data_file_path定义的表空间中.可以是多个文件. 多表空间: 表定义保存在.frm文件中. 但每个表的数据和索引单独保存在.ibd中.如果是分区表, 则每个分区表对应单独的.ibd文件, 文件名为表名+分区名.使用多表空间的存储方式, 需要设置参数innodb_file_per_table, 并且重启后才可以生效. 注意: 即便在多表空间的存储方式下, 共享表空间仍然是必须的, InnoDB把内部数据词典和在线重做日志放在这个文件中. MERGE MERGE存储引擎是一组MyISAM表的组合，这些MyISAM表必须结构完全相同，MERGE表本身并没有数据，对MERGE类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部的MyISAM表进行的。对于MERGE类型表的插入操作，是通过INSERT_METHOD子句定义插入的表，可以有3个不同的值，使用FIRST或LAST值使得插入操作被相应地作用在第一或最后一个表上，不定义这个子句或者定义为NO，表示不能对这个MERGE表执行插入操作。 数据类型处理 BLOB能用来保存二进制数据，比如照片；而TEXT只能保存字符数据， BLOB和TEXT值会引起一些性能问题，特别是在执行了大量的删除操作时. 建议定期使用OPTIMIZE TABLE功能对这类表进行碎片整理，避免因为“空洞”导致性能问题 在不必要的时候避免检索大型的BLOB或TEXT值 把BLOB或TEXT列分离到单独的表中 定点数不同于浮点数，定点数实际上是以字符串形式存放的，所以定点数可以更精确地保存数据 浮点数存在误差问题； 对货币等对精度敏感的数据，应该用定点数表示或存储]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记之常用命令]]></title>
    <url>%2F2016%2F03%2F05%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[帮助相关的 ? 要查看帮助的命令. 如 12345678910111213141516171819mysql&gt; ? create database;Name: 'CREATE DATABASE'Description:Syntax:CREATE &#123;DATABASE | SCHEMA&#125; [IF NOT EXISTS] db_name [create_specification] ...create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_nameCREATE DATABASE creates a database with the given name. To use thisstatement, you need the CREATE privilege for the database. CREATESCHEMA is a synonym for CREATE DATABASE.URL: http://dev.mysql.com/doc/refman/5.7/en/create-database.htmlmysql&gt; 查看支持的数据类型: ? data types 查看数据类型的信息及范围 1234567mysql&gt; ? intName: 'INT'Description:INT[(M)] [UNSIGNED] [ZEROFILL]A normal-size integer. The signed range is -2147483648 to 2147483647.The unsigned range is 0 to 4294967295. 查看与show命令相关的命令: ? show 查看与函数相关的帮助: ? functions 与DB相关的1234* 创建数据库: `create dbname`* 删除数据库: `drop database dbname`* 选择数据库: `use dbname`* 与表相关维护表元信息的操作 显示当前DB的所有表: show tables; 查看表的定义: desc tbname; 查看表的建表语句: show create table tbname\G 查看表的状态: show table status like &#39;tbname&#39; 删除表: drop table tbname; 修改字段名: ALTER TABLE tablename CHANGE [COLUMN] old_col_name column_definition [FIRST|AFTER col_name] 注: change 和 modify 都可以修改表的定义. 不同的是change后面需要写两次列名. 但是change可以修改列名, 而modify不能. 添加表字段: ALTER TABLE tablename ADD [COLUMN] column_definition [FIRST | AFTER col_name] 修改表结构: alter table tbname modify column col_definition [first | after other_col_name] 删除表字段: alter table tbname drop column col_name 注: 关于表的字段顺序问题: 默认情况下, change和modify都不会改变原表定义的字段顺序, 新添加的列默认是加在表的最后位置.如果想修改列的顺序, 可以在修改字段的最后加上[first | after 其他字段名]first表示在其他字段名的前面, after表示其他字段名的后面. 修改表名: ALTER TABLE tablename RENAME [TO] new_tablename 与表索引相关 创建索引: alter table tbname add [unique] index index_name (col1 [asc|desc], col2...) 创建索引: CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name [USING index_type] ON tbl_name (index_col_name,. .)index_col_name: col_name [(length)] [ASC | DESC]: 删除索引: drop index index_name on tbname; 表的DML语句 插入一行: insert into tbname (col1, col2) values (value1, value2); 插入多行: insert into tbname (col1, col2) values (value1, value2), (value3, value4), (value5, value6); 更新一张表的记录: update tbname set field1=value1, field2=value2 [where condition...] 更新多张表的记录: update t1, t2 set t1.field=value1, t2.field=value2 [where condition] 注意：多表更新的语法更多地用在了根据一个表的字段来动态地更新另外一个表的字段。 删除一张表的记录: delete from tbname [where condition] 删除多张表的记录: DELETE t1,t2,…,tn FROM t1,t2,…,tn [WHERE CONDITION] 注意: 如果from后面的表名用别名，则delete后面也要用相应的别名，否则会提语法错误. 不管是单表还是多表，不加where条件将会把表的所有记录删除，所以操作时一定要小心。 查询: select * from tbname [where condition] 查询不重复记录select distinct * from tbname with rollup: 用例子说明: 1234567891011121314151617181920mysql&gt; select hello, sum(id) from hello group by hello ;+--------+---------+| hello | sum(id) |+--------+---------+| hello | 18 || hello1 | 8 || hello2 | 10 |+--------+---------+3 rows in set (0.00 sec)mysql&gt; select hello, sum(id) from hello group by hello with rollup;+--------+---------+| hello | sum(id) |+--------+---------+| hello | 18 || hello1 | 8 || hello2 | 10 || NULL | 36 |+--------+---------+4 rows in set (0.00 sec) DCL 语句MySQL里的用户, 是由用户名@主机名来唯一匹配的. 即相同用户名,但主机名不同, 是被认为是不同的用户. 12345mysql&gt; create user 'yang'@'localhost' identified by '123';Query OK, 0 rows affected (0.01 sec)mysql&gt; create user 'yang'@'192.168.1.2' identified by '123';Query OK, 0 rows affected (0.00 sec) 用本地用户yang@localhost登录时, 可以看到: 1234567mysql&gt; select current_user;+----------------+| current_user |+----------------+| yang@localhost |+----------------+1 row in set (0.01 sec) 创建一个用户: CREATE USER &#39;monty&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;some_pass&#39;; 授权给一个用户: GRANT RELOAD,PROCESS ON *.* TO &#39;admin&#39;@&#39;localhost&#39;; 查看元信息以下的都是在information_schema数据库里的操作 查看拥有的数据库schemata1234567891011mysql&gt; select * from schemata;+--------------+--------------------+----------------------------+------------------------+----------+| CATALOG_NAME | SCHEMA_NAME | DEFAULT_CHARACTER_SET_NAME | DEFAULT_COLLATION_NAME | SQL_PATH |+--------------+--------------------+----------------------------+------------------------+----------+| def | information_schema | utf8 | utf8_general_ci | NULL || def | mysql | utf8 | utf8_general_ci | NULL || def | performance_schema | utf8 | utf8_general_ci | NULL || def | sys | utf8 | utf8_general_ci | NULL || def | test | utf8 | utf8_general_ci | NULL |+--------------+--------------------+----------------------------+------------------------+----------+5 rows in set (0.00 sec) show databases; 命令,就是从这里取结果的. 查看所有的表select * from tables; show tables 命令就是从这里取出信息的. 查看所有列select * from columns show columns from tbname 命令就是从这里取出信息的. 表索引信息select * from STATISTICS; show index from tbname 命令就是从这里取出信息的.]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记]]></title>
    <url>%2F2016%2F03%2F05%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[mysql命令行使用 命令的结束符，用“;”或者“\g”结束 通过help;或者\h命令来显示帮助内容，通过\c命令来清除命令行buffer 实践了下\c的用途类似于取消命令的执行.但不能是在;号后面.例如 123456789101112131415161718mysql&gt; select version();+-----------+| version() |+-----------+| 5.7.10 |+-----------+1 row in set (0.02 sec)mysql&gt; select version()\cmysql&gt; select version();\c+-----------+| version() |+-----------+| 5.7.10 |+-----------+1 row in set (0.01 sec)mysql&gt; 内建的数据库及用途 information_schema：主要存储了系统中的一些数据库对象信息，比如用户表信息、列信息、权限信息、字符集信息、分区信息等 mysql: 主要是与MySQL用户及权限相关的信息. performance_schema: 与性能相关的统计信息 sys: (MySQL 5.7.7 and higher includes the sys schema). 可以看成是对 performance_schema的各种友好的视图. 帮助DBA和开发人员更好的诊断性能等问题. test: 测试数据库(5.7里已经没有了.) 12345678910mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec) 定义表时的注意auto_increment只能用于整数类型, 并且一张表中最多只能有一个 auto_increment 列. 而且auto_increment的列还应该是主键或者是唯一索引列. 如果是在唯一索引上定义的auto_increment那它自动就是NOT NULL的了. 1234567891011121314mysql&gt; create table t_i (id int auto_increment unique, name varchar(10));Query OK, 0 rows affected (0.01 sec)mysql&gt; show create table t_i;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+| t_i | CREATE TABLE `t_i` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(10) DEFAULT NULL, UNIQUE KEY `id` (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 如果插入的是null或者0, auto_increment 实际会插入是增长后的值 . 特别注意 : 该强制的默认值是保留在内存中的，如果该值在使用之前数据库重新启动，那么这个强制的默认值就会丢失，就需要在数据库启动以后重新设置。 可以使用LAST_INSERT_ID()查询当前线程最后插入记录使用的值。如果一次插入了多条记录，那么返回的是第一条记录使用的自动增长值. 例子: 1234567891011121314mysql&gt; create table t (id int primary key auto_increment, id2 int);Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t (id2) values (1), (2), (3);Query OK, 3 rows affected (0.01 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select last_insert_id();+------------------+| last_insert_id() |+------------------+| 1 |+------------------+1 row in set (0.01 sec) auto_increment 在MyISAM与InnoDB的区别: 对于InnoDB, 自增长列必须是索引. 如果是组合索引, 也必须是组合索引的第一列.对于MyISAM, 自增长列可以是组合索引的其他列. 12345mysql&gt; create table t_my (id int, id2 int auto_increment, unique(id, id2)) engine=myisam;Query OK, 0 rows affected (0.02 sec)mysql&gt; create table t_inno (id int, id2 int auto_increment, unique(id, id2)) engine=innodb;ERROR 1075 (42000): Incorrect table definition; there can be only one auto column and it must be defined as a key 定点数它在MySQL内部是使用字符串保存的. 所以比浮点更精确, 适合用来保存货币等精度高的数据. 注意: 浮点数和定点数都可以用类型名称后加“(M,D)”的方式来进行表示，“(M,D)”表示该值一共显示M位数字（整数位+小数位），其中D位位于小数点后面，M和D又称为精度和标度。 timestampMySQL旧版本规定TIMESTAMP类型字段只能有一列的默认值为current_timestamp.但我在MySQL 5.7.10版本里发现, 它可以定义多个current_timestamp.如: 12345678910111213mysql&gt; create table hello11 (t timestamp not null default current_timestamp, t1 timestamp not null default current_timestamp);Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into hello11 values (null,null);Query OK, 1 row affected (0.01 sec)mysql&gt; select * from hello11;+---------------------+---------------------+| t | t1 |+---------------------+---------------------+| 2016-03-05 22:34:24 | 2016-03-05 22:34:24 |+---------------------+---------------------+1 row in set (0.00 sec) timestamp 还有个重要的特点, 就是与时间相关. 当插入日期时，会先转换为本地时区后存放；而从数据库里面取出时，也同样需要将日期转换为本地时区后显示。这样，两个不同时区的用户看到的同一个日期可能是不一样的 123456789101112131415161718mysql&gt; select * from hello11;+---------------------+---------------------+| t | t1 |+---------------------+---------------------+| 2016-03-05 22:34:24 | 2016-03-05 22:34:24 |+---------------------+---------------------+1 row in set (0.00 sec)mysql&gt; set time_zone='+9:00';Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from hello11;+---------------------+---------------------+| t | t1 |+---------------------+---------------------+| 2016-03-05 23:34:24 | 2016-03-05 23:34:24 |+---------------------+---------------------+1 row in set (0.00 sec) 而且timestamp的范围是: &#39;1970-01-01 00:00:01.000000&#39; UTC to &#39;2038-01-19 03:14:07.999999&#39; UTC,可以通过以下得知: 1234567mysql&gt; ? timestamp;Name: 'TIMESTAMP'Description:TIMESTAMP[(fsp)]A timestamp. The range is '1970-01-01 00:00:01.000000' UTC to'2038-01-19 03:14:07.999999' UTC. char, varcharchar会删除最后的空格, 而varchar不会. 12345678910111213mysql&gt; create table t_char (n char(4), nn varchar(4));Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t_char values ('he ', 'he ');Query OK, 1 row affected (0.01 sec)mysql&gt; select length(n), length(nn) from t_char;+-----------+------------+| length(n) | length(nn) |+-----------+------------+| 2 | 3 |+-----------+------------+1 row in set (0.00 sec) MyISAM存储引擎：建议使用固定长度的数据列代替可变长度的数据列。MEMORY 存储引擎：目前都使用固定长度的数据行存储，因此无论使用 CHAR 或VARCHAR列都没有关系。两者都是作为CHAR类型处理。InnoDB存储引擎：建议使用VARCHAR类型。对于InnoDB数据表，内部的行存储格式没有区分固定长度和可变长度列（所有数据行都使用指向数据列值的头指针），因此在本质上，使用固定长度的CHAR列不一定比使用可变长度VARCHAR列性能要好。因而，主要的性能因素是数据行使用的存储总量 enum1234567891011121314151617mysql&gt; create table t (gender enum('M', 'F'));Query OK, 0 rows affected (0.04 sec)mysql&gt; insert into t values ('M'), ('1'), ('f') , (null);Query OK, 4 rows affected (0.01 sec)Records: 4 Duplicates: 0 Warnings: 0mysql&gt; select * from t;+--------+| gender |+--------+| M || M || F || NULL |+--------+4 rows in set (0.00 sec) 从上面的例子中，可以看出ENUM类型是忽略大小写的，在存储“M”、“f”时将它们都转成了大写，还可以看出对于插入不在 ENUM 指定范围内的值时，并没有返回警告，而是插入了enum(‘M’,’F’)的第一个值“M”，这点用户在使用时要特别注意]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx常用操作]]></title>
    <url>%2F2016%2F02%2F26%2FNginx%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[重写HTTP 某些URL 为 HTTPS URL12345678910location = /res/static/index.html &#123; #方式一 #return 301 https://$http_host$request_uri$is_args$query_string; #方式二 return 301 https://$host$request_uri; #方式三 #rewrite ^/(.+) https://$host/$1 permanent;&#125; 将所有HTTP请求重写为HTTPS123server &#123; return 301 https://$host$request_uri;&#125;]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash处理日志文件脚本]]></title>
    <url>%2F2016%2F02%2F22%2FBash%E5%A4%84%E7%90%86%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[因为公司需要一个处理日志并迁移到指定服务器的脚本，所以就写了以下这个，虽然比较简陋，但还是可以使用的… 思路: 从指定的目录数组中(DIR_ARRAY) 查找这些目录下，所有以SUFFIX_ARRAY数组后缀，并且不是IGNORE_ARRAY中的文件名的所有文件并且进行每100MB进行切割和压缩.然后将切割和压缩的文件移动到SAVE_DIR目录里。 最后，将SAVE_DIR目录里的所有文件，同步到指定的LOG_SERVER上，成功后再删除这些文件. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#! /usr/bin/env bash#set -xNOW="$(date +'%Y-%m-%d_%H-%M-%S')"DELETE_FILE="/tmp/delete.file.list"DIR_ARRAY=('/home/your-name/logs')EX_FILE_NGINX_GREP="access.log"EX_FILE_TOMCAT_GREP="catalina.out"EX_FILE_PATTERN="-iname $&#123;EX_FILE_NGINX_GREP&#125; -o -iname $&#123;EX_FILE_TOMCAT_GREP&#125;"MOVE_FILE_NAME="/tmp/move.file.list"IN_FILE_PATTERN=" -mtime +0 -iname *.log -o -mtime +0 -iname *.txt"SAVE_DIR="/home/your-name/save-log"LOG_SERVER_USER="your-user-name"LOG_SERVER="your-ip"LOG_SERVER_SSH_PORT="your-port"LOG_SERVER_SAVE_DIR="/home/$&#123;LOG_SERVER_USER&#125;/all/logs"# 创建保存的目录function mkdirSaveLog()&#123; mkdir -p $&#123;SAVE_DIR&#125; echo "created dir $&#123;SAVE_DIR&#125;"&#125;# 清除要删除的文件列表内容function cleanDeleteFile()&#123; echo "" &gt; $&#123;DELETE_FILE&#125; echo "" &gt; $&#123;MOVE_FILE_NAME&#125; echo "clean delete file OK"&#125;# 要处理的文件名的后缀function getInclude()&#123; echo $&#123;IN_FILE_PATTERN&#125;&#125;# 不处理的指定文件名function getExclcude()&#123; echo $&#123;EX_FILE_PATTERN&#125;&#125;# 开始查找文件function findFile()&#123; #set -x for i in $&#123;DIR_ARRAY[@]&#125;; do find $&#123;i&#125; $(getInclude) -type f | grep -v "$&#123;EX_FILE_TOMCAT_GREP&#125;\$" | grep -v "$&#123;EX_FILE_NGINX_GREP&#125;\$" &gt;&gt; $&#123;DELETE_FILE&#125; done echo "delte file content:" cat $&#123;DELETE_FILE&#125; echo "find file OK."&#125;# 将忽略的文件名，复制备份function dump()&#123; for i in $&#123;DIR_ARRAY[@]&#125;; do# find $&#123;i&#125; $(getExclcude) -type f | xargs -I &#123;&#125; -n 1 -P 0 bash -c "cp &#123;&#125; &#123;&#125;.$&#123;NOW&#125;.log &amp;&amp; echo \"\" &gt; &#123;&#125;" find $&#123;i&#125; $(getExclcude) -type f | xargs -I &#123;&#125; -n 1 -P 0 bash -c "cp &#123;&#125; &#123;&#125;.$&#123;NOW&#125;.log" done echo "dump file OK"&#125;# 开始分割文件function splitFile()&#123; #set -x# cat $&#123;DELETE_FILE&#125; | xargs -t -n 1 -I &#123;&#125; -P 0 bash -c "split -d --bytes=100M --filter='gzip &gt; \$FILE.sync.gz' &#123;&#125; &#123;&#125;.$&#123;NOW&#125; &amp;&amp; rm -rf &#123;&#125;" cat $&#123;DELETE_FILE&#125; | xargs -t -n 1 -I &#123;&#125; -P 0 bash -c "split -d --bytes=100M --filter='gzip &gt; \$FILE.sync.gz' &#123;&#125; &#123;&#125;.$&#123;NOW&#125;" echo "split file ok"&#125;# 移动文件到指定的保存目录中function moveFile()&#123; for i in $&#123;DIR_ARRAY[@]&#125;; do find $&#123;i&#125; -type f \( -iname *.sync.gz \) &gt;&gt; $&#123;MOVE_FILE_NAME&#125; done echo "move file content:" cat $&#123;MOVE_FILE_NAME&#125; cat $&#123;MOVE_FILE_NAME&#125; | xargs -t -n 1 -I &#123;&#125; -P 0 dirname &#123;&#125; | sort -u | xargs -t -n 1 -I &#123;&#125; -P 0 mkdir -p "$&#123;SAVE_DIR&#125;&#123;&#125;" cat $&#123;MOVE_FILE_NAME&#125; | xargs -t -n 1 -I &#123;&#125; -P 0 dirname &#123;&#125; | sort -u | xargs -t -n 1 -I &#123;&#125; -P 0 bash -c "mv &#123;&#125;/*.sync.gz \"$&#123;SAVE_DIR&#125;&#123;&#125;/\"" echo "move file to save dir ok"&#125;# copy to serverfunction copyToServer()&#123; cd $&#123;SAVE_DIR&#125; ls *.sync.gz | xargs -t -n 1 -I &#123;&#125; -P 0 bash -c "rsync -avzh \"-e ssh -p $&#123;LOG_SERVER_SSH_PORT&#125;\" &#123;&#125; $&#123;LOG_SERVER_USER&#125;@$&#123;LOG_SERVER&#125;:$&#123;LOG_SERVER_SAVE_DIR&#125;/&#123;&#125; &amp;&amp; rm -rf &#123;&#125;" echo "copy to server ok"&#125;# 主函数function main()&#123; mkdirSaveLog cleanDeleteFile dump findFile splitFile moveFile #copyToServer&#125;# 执行main]]></content>
      <categories>
        <category>bash</category>
      </categories>
      <tags>
        <tag>bash</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spacemacs学习]]></title>
    <url>%2F2016%2F02%2F20%2FSpacemacs%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[说白了,spacemacs本质上也就是一个emacs的配置环境. 知道了本质, 也就容易理解了. 安装针对Mac 123$ brew tap railwaycat/homebrew-emacsmacport$ brew install emacs-mac --with-spacemacs-icon # OR, brew cask install emacs-mac$ brew linkapps 安装 123mv ~/.emacs.d ~/.emacs.d.bakgit clone https://github.com/syl20bnr/spacemacs ~/.emacs.d 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258;; -*- mode: emacs-lisp -*-;; This file is loaded by Spacemacs at startup.;; It must be stored in your home directory.(defun dotspacemacs/layers () "Configuration Layers declaration.You should not put any user code in this function besides modifying the variablevalues." (setq-default ;; Base distribution to use. This is a layer contained in the directory ;; `+distribution'. For now available distributions are `spacemacs-base' ;; or `spacemacs'. (default 'spacemacs) dotspacemacs-distribution 'spacemacs ;; List of additional paths where to look for configuration layers. ;; Paths must have a trailing slash (i.e. `~/.mycontribs/') dotspacemacs-configuration-layer-path '() ;; List of configuration layers to load. If it is the symbol `all' instead ;; of a list then all discovered layers will be installed. dotspacemacs-configuration-layers '( ;; ---------------------------------------------------------------- ;; Example of useful layers you may want to use right away. ;; Uncomment some layer names and press &lt;SPC f e R&gt; (Vim style) or ;; &lt;M-m f e R&gt; (Emacs style) to install them. ;; ---------------------------------------------------------------- ;; auto-completion ;; better-defaults emacs-lisp git markdown org html javascript (shell :variables shell-default-height 30 shell-default-position 'bottom) ;; spell-checking syntax-checking version-control ) ;; List of additional packages that will be installed without being ;; wrapped in a layer. If you need some configuration for these ;; packages, then consider creating a layer. You can also put the ;; configuration in `dotspacemacs/user-config'. dotspacemacs-additional-packages '() ;; A list of packages and/or extensions that will not be install and loaded. dotspacemacs-excluded-packages '() ;; If non-nil spacemacs will delete any orphan packages, i.e. packages that ;; are declared in a layer which is not a member of ;; the list `dotspacemacs-configuration-layers'. (default t) dotspacemacs-delete-orphan-packages t))(defun dotspacemacs/init () "Initialization function.This function is called at the very startup of Spacemacs initializationbefore layers configuration.You should not put any user code in there besides modifying the variablevalues." ;; This setq-default sexp is an exhaustive list of all the supported ;; spacemacs settings. (setq-default ;; If non nil ELPA repositories are contacted via HTTPS whenever it's ;; possible. Set it to nil if you have no way to use HTTPS in your ;; environment, otherwise it is strongly recommended to let it set to t. ;; This variable has no effect if Emacs is launched with the parameter ;; `--insecure' which forces the value of this variable to nil. ;; (default t) dotspacemacs-elpa-https t ;; Maximum allowed time in seconds to contact an ELPA repository. dotspacemacs-elpa-timeout 5 ;; If non nil then spacemacs will check for updates at startup ;; when the current branch is not `develop'. (default t) dotspacemacs-check-for-update nil ;; One of `vim', `emacs' or `hybrid'. Evil is always enabled but if the ;; variable is `emacs' then the `holy-mode' is enabled at startup. `hybrid' ;; uses emacs key bindings for vim's insert mode, but otherwise leaves evil ;; unchanged. (default 'vim) dotspacemacs-editing-style 'emacs ;; If non nil output loading progress in `*Messages*' buffer. (default nil) dotspacemacs-verbose-loading nil ;; Specify the startup banner. Default value is `official', it displays ;; the official spacemacs logo. An integer value is the index of text ;; banner, `random' chooses a random text banner in `core/banners' ;; directory. A string value must be a path to an image format supported ;; by your Emacs build. ;; If the value is nil then no banner is displayed. (default 'official) dotspacemacs-startup-banner 'official ;; List of items to show in the startup buffer. If nil it is disabled. ;; Possible values are: `recents' `bookmarks' `projects'. ;; (default '(recents projects)) dotspacemacs-startup-lists '(recents projects) ;; Number of recent files to show in the startup buffer. Ignored if ;; `dotspacemacs-startup-lists' doesn't include `recents'. (default 5) dotspacemacs-startup-recent-list-size 5 ;; Default major mode of the scratch buffer (default `text-mode') dotspacemacs-scratch-mode 'text-mode ;; List of themes, the first of the list is loaded when spacemacs starts. ;; Press &lt;SPC&gt; T n to cycle to the next theme in the list (works great ;; with 2 themes variants, one dark and one light) dotspacemacs-themes '(spacemacs-dark spacemacs-light solarized-light solarized-dark leuven monokai zenburn) ;; If non nil the cursor color matches the state color in GUI Emacs. dotspacemacs-colorize-cursor-according-to-state t ;; Default font. `powerline-scale' allows to quickly tweak the mode-line ;; size to make separators look not too crappy. dotspacemacs-default-font '("Source Code Pro" :size 13 :weight normal :width normal :powerline-scale 1.1) ;; The leader key dotspacemacs-leader-key "SPC" ;; The leader key accessible in `emacs state' and `insert state' ;; (default "M-m") dotspacemacs-emacs-leader-key "M-m" ;; Major mode leader key is a shortcut key which is the equivalent of ;; pressing `&lt;leader&gt; m`. Set it to `nil` to disable it. (default ",") dotspacemacs-major-mode-leader-key "," ;; Major mode leader key accessible in `emacs state' and `insert state'. ;; (default "C-M-m) dotspacemacs-major-mode-emacs-leader-key "C-M-m" ;; These variables control whether separate commands are bound in the GUI to ;; the key pairs C-i, TAB and C-m, RET. ;; Setting it to a non-nil value, allows for separate commands under &lt;C-i&gt; ;; and TAB or &lt;C-m&gt; and RET. ;; In the terminal, these pairs are generally indistinguishable, so this only ;; works in the GUI. (default nil) dotspacemacs-distinguish-gui-tab nil ;; (Not implemented) dotspacemacs-distinguish-gui-ret nil ;; The command key used for Evil commands (ex-commands) and ;; Emacs commands (M-x). ;; By default the command key is `:' so ex-commands are executed like in Vim ;; with `:' and Emacs commands are executed with `&lt;leader&gt; :'. dotspacemacs-command-key ":" ;; If non nil `Y' is remapped to `y$'. (default t) dotspacemacs-remap-Y-to-y$ t ;; Name of the default layout (default "Default") dotspacemacs-default-layout-name "Default" ;; If non nil the default layout name is displayed in the mode-line. ;; (default nil) dotspacemacs-display-default-layout nil ;; If non nil then the last auto saved layouts are resume automatically upon ;; start. (default nil) dotspacemacs-auto-resume-layouts nil ;; Location where to auto-save files. Possible values are `original' to ;; auto-save the file in-place, `cache' to auto-save the file to another ;; file stored in the cache directory and `nil' to disable auto-saving. ;; (default 'cache) dotspacemacs-auto-save-file-location 'cache ;; Maximum number of rollback slots to keep in the cache. (default 5) dotspacemacs-max-rollback-slots 5 ;; If non nil then `ido' replaces `helm' for some commands. For now only ;; `find-files' (SPC f f), `find-spacemacs-file' (SPC f e s), and ;; `find-contrib-file' (SPC f e c) are replaced. (default nil) dotspacemacs-use-ido nil ;; If non nil, `helm' will try to minimize the space it uses. (default nil) dotspacemacs-helm-resize nil ;; if non nil, the helm header is hidden when there is only one source. ;; (default nil) dotspacemacs-helm-no-header nil ;; define the position to display `helm', options are `bottom', `top', ;; `left', or `right'. (default 'bottom) dotspacemacs-helm-position 'bottom ;; If non nil the paste micro-state is enabled. When enabled pressing `p` ;; several times cycle between the kill ring content. (default nil) dotspacemacs-enable-paste-micro-state nil ;; Which-key delay in seconds. The which-key buffer is the popup listing ;; the commands bound to the current keystroke sequence. (default 0.4) dotspacemacs-which-key-delay 0.4 ;; Which-key frame position. Possible values are `right', `bottom' and ;; `right-then-bottom'. right-then-bottom tries to display the frame to the ;; right; if there is insufficient space it displays it at the bottom. ;; (default 'bottom) dotspacemacs-which-key-position 'bottom ;; If non nil a progress bar is displayed when spacemacs is loading. This ;; may increase the boot time on some systems and emacs builds, set it to ;; nil to boost the loading time. (default t) dotspacemacs-loading-progress-bar t ;; If non nil the frame is fullscreen when Emacs starts up. (default nil) ;; (Emacs 24.4+ only) dotspacemacs-fullscreen-at-startup nil ;; If non nil `spacemacs/toggle-fullscreen' will not use native fullscreen. ;; Use to disable fullscreen animations in OSX. (default nil) dotspacemacs-fullscreen-use-non-native nil ;; If non nil the frame is maximized when Emacs starts up. ;; Takes effect only if `dotspacemacs-fullscreen-at-startup' is nil. ;; (default nil) (Emacs 24.4+ only) dotspacemacs-maximized-at-startup nil ;; A value from the range (0..100), in increasing opacity, which describes ;; the transparency level of a frame when it's active or selected. ;; Transparency can be toggled through `toggle-transparency'. (default 90) dotspacemacs-active-transparency 90 ;; A value from the range (0..100), in increasing opacity, which describes ;; the transparency level of a frame when it's inactive or deselected. ;; Transparency can be toggled through `toggle-transparency'. (default 90) dotspacemacs-inactive-transparency 90 ;; If non nil unicode symbols are displayed in the mode line. (default t) dotspacemacs-mode-line-unicode-symbols t ;; If non nil smooth scrolling (native-scrolling) is enabled. Smooth ;; scrolling overrides the default behavior of Emacs which recenters the ;; point when it reaches the top or bottom of the screen. (default t) dotspacemacs-smooth-scrolling t ;; If non nil line numbers are turned on in all `prog-mode' and `text-mode' ;; derivatives. If set to `relative', also turns on relative line numbers. ;; (default nil) dotspacemacs-line-numbers 'relative ;; If non-nil smartparens-strict-mode will be enabled in programming modes. ;; (default nil) dotspacemacs-smartparens-strict-mode nil ;; Select a scope to highlight delimiters. Possible values are `any', ;; `current', `all' or `nil'. Default is `all' (highlight any scope and ;; emphasis the current one). (default 'all) dotspacemacs-highlight-delimiters 'all ;; If non nil advises quit functions to keep server open when quitting. ;; (default nil) dotspacemacs-persistent-server nil ;; List of search tool executable names. Spacemacs uses the first installed ;; tool of the list. Supported tools are `ag', `pt', `ack' and `grep'. ;; (default '("ag" "pt" "ack" "grep")) dotspacemacs-search-tools '("ag" "pt" "ack" "grep") ;; The default package repository used if no explicit repository has been ;; specified with an installed package. ;; Not used for now. (default nil) dotspacemacs-default-package-repository nil ;; Delete whitespace while saving buffer. Possible values are `all' ;; to aggressively delete empty line and long sequences of whitespace, ;; `trailing' to delete only the whitespace at end of lines, `changed'to ;; delete only whitespace for changed lines or `nil' to disable cleanup. ;; (default nil) dotspacemacs-whitespace-cleanup nil ))(defun dotspacemacs/user-init () "Initialization function for user code.It is called immediately after `dotspacemacs/init'. You are free to put almostany user code here. The exception is org related code, which should be placedin `dotspacemacs/user-config'." )(defun dotspacemacs/user-config () "Configuration function for user code.This function is called at the very end of Spacemacs initialization afterlayers configuration. You are free to put any user code." );; 自定义快捷键(global-set-key (kbd "C-@") nil)(global-set-key (kbd "C-SPC") nil)(global-set-key (kbd "C-@") 'set-mark-command);; Do not write anything past this comment. This is where Emacs will;; auto-generate custom variable definitions. 禁用https启动1emacs --insecure 如果出现问题, 可以先删除rm -rf ~/.emacs.d/elpa/ 再用上面的命令来启动. set-mark-command 不生效spacemacs 默认的set-mark-command的快捷键为C-SPC. 这个在mac里的弹出使用splotlight,所以我重定义了这个命令的按键(如上.) 如果发现这种情况, 请注意自己的 输入法状态.注意, 因为使用的是搜狗输入法, 这种情况下, 如果是搜狗输入法, 并且是英文输入状态(即按左Shift), 这时按C-@也是无效的! 必须是系统的英文状态才行! 这个问题, 折腾了我好久才发现!!!!!重要的事, 要一堆叹号强调才行!!!! mac 默认按键Meta键在spacemacs里, 改为了Command键, 而不是Option/Alt! 其他的暂时没有发现其他. 待继续… 查看所有按键绑定M-m ?, 在Mac下即是Command + m + ?. 撤消 或 重做 undo: 不再是C-/, 而是C-_. redo: M-_ 安装 Source Code Pro 字体Go]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java技术手册学习笔记-线程生命周期]]></title>
    <url>%2F2016%2F02%2F19%2FJava%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[Java线程状态NEW 已经创建线程,但还没在线程对象上调用 start() 方法。所有线程一开始都处于这个状态 RUNNABLE 线程正在运行,或者当操作系统调度线程时可以运行。 BLOCKED 线程中止运行,因为它在等待获得一个锁,以便进入声明为 synchronized 的方法或代码块。本节后面会详细介绍声明为 synchronized 的方法和代码块。 WAITING 线程中止运行,因为它调用了 Object.wait() 或 Thread.join() 方法。 TIMED_WAITING 线 程 中 止 运 行, 因 为 它 调 用 了 Thread.sleep() 方 法, 或 者 调 用 了 Object.wait() 或 Thread.join() 方法,而且传入了超时时间。 TERMINATED 线程执行完毕。线程对象的 run() 方法正常退出,或者抛出了异常 图解图片来源: 《Java技术手册（第六版）》 后记这只是我的看书摘录出来的.^_^]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>thread</tag>
        <tag>runnable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]Java 中正确使用 hashCode 和 equals 方法]]></title>
    <url>%2F2016%2F02%2F16%2F%E8%BD%AC-Java-%E4%B8%AD%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8-hashCode-%E5%92%8C-equals-%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文链接 在这篇文章中，我将告诉大家我对hashCode和equals方法的理解。我将讨论他们的默认实现，以及如何正确的重写他们。我也将使用Apache Commons提供的工具包做一个实现。目录： hashCode()和equals()的用法 重写默认实现 使用Apache Commons Lang包重写hashCode()和equals() 需要注意记住的事情 当使用ORM的时候特别要注意的 使用hashCode()和equals()hashCode()方法被用来获取给定对象的唯一整数。这个整数被用来确定对象被存储在HashTable类似的结构中的位置。默认的，Object类的hashCode()方法返回这个对象存储的内存地址的编号 重写默认的实现如果你不重写这两个方法，将几乎不遇到任何问题，但是有的时候程序要求我们必须改变一些对象的默认实现。 来看看这个例子，让我们创建一个简单的类Employee 1234567891011121314151617181920212223242526272829303132public class Employee&#123; private Integer id; private String firstname; private String lastName; private String department; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getFirstname() &#123; return firstname; &#125; public void setFirstname(String firstname) &#123; this.firstname = firstname; &#125; public String getLastName() &#123; return lastName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public String getDepartment() &#123; return department; &#125; public void setDepartment(String department) &#123; this.department = department; &#125;&#125; 上面的Employee类只是有一些非常基础的属性和getter、setter.现在来考虑一个你需要比较两个employee的情形。 1234567891011public class EqualsTest &#123; public static void main(String[] args) &#123; Employee e1 = new Employee(); Employee e2 = new Employee(); e1.setId(100); e2.setId(100); //Prints false in console System.out.println(e1.equals(e2)); &#125;&#125; 毫无疑问，上面的程序将输出false，但是，事实上上面两个对象代表的是通过一个employee。真正的商业逻辑希望我们返回true。为了达到这个目的，我们需要重写equals方法。 12345678910111213141516public boolean equals(Object o) &#123; if(o == null) &#123; return false; &#125; if (o == this) &#123; return true; &#125; if (getClass() != o.getClass()) &#123; return false; &#125; Employee e = (Employee) o; return (this.getId() == e.getId());&#125; 在上面的类中添加这个方法，EauqlsTest将会输出true。So are we done?没有，让我们换一种测试方法来看看。 12345678910111213141516171819202122import java.util.HashSet;import java.util.Set;public class EqualsTest&#123; public static void main(String[] args) &#123; Employee e1 = new Employee(); Employee e2 = new Employee(); e1.setId(100); e2.setId(100); //Prints 'true' System.out.println(e1.equals(e2)); Set&lt;Employee&gt; employees = new HashSet&lt;Employee&gt;(); employees.add(e1); employees.add(e2); //Prints two objects System.out.println(employees); &#125; 上面的程序输出的结果是两个。如果两个employee对象equals返回true，Set中应该只存储一个对象才对，问题在哪里呢？我们忘掉了第二个重要的方法hashCode()。就像JDK的Javadoc中所说的一样，如果重写equals()方法必须要重写hashCode()方法。我们加上下面这个方法，程序将执行正确 12345678@Override public int hashCode() &#123; final int PRIME = 31; int result = 1; result = PRIME * result + getId(); return result; &#125; 使用Apache Commons Lang包重写hashCode() 和equals()方法Apache Commons 包提供了两个非常优秀的类来生成hashCode()和equals()方法。看下面的程序。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import org.apache.commons.lang3.builder.EqualsBuilder;import org.apache.commons.lang3.builder.HashCodeBuilder;public class Employee &#123; private Integer id; private String firstname; private String lastName; private String department; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getFirstname() &#123; return firstname; &#125; public void setFirstname(String firstname) &#123; this.firstname = firstname; &#125; public String getLastName() &#123; return lastName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public String getDepartment() &#123; return department; &#125; public void setDepartment(String department) &#123; this.department = department; &#125; @Override public int hashCode() &#123; final int PRIME = 31; return new HashCodeBuilder(getId() % 2 == 0 ? getId() + 1 : getId(), PRIME). toHashCode(); &#125; @Override public boolean equals(Object o) &#123; if (o == null) return false; if (o == this) return true; if (o.getClass() != getClass()) return false; Employee e = (Employee) o; return new EqualsBuilder(). append(getId(), e.getId()). isEquals(); &#125;&#125; 如果你使用Eclipse或者其他的IDE，IDE也可能会提供生成良好的hashCode()方法和equals()方法。 需要注意记住的事情 尽量保证使用对象的同一个属性来生成hashCode()和equals()两个方法。在我们的案例中,我们使用员工id。 eqauls方法必须保证一致（如果对象没有被修改，equals应该返回相同的值） 任何时候只要a.equals(b),那么a.hashCode()必须和b.hashCode()相等。 两者必须同时重写。 当使用ORM的时候特别要注意的 如果你使用ORM处理一些对象的话，你要确保在hashCode()和equals()对象中使用getter和setter而不是直接引用成员变量。因为在ORM中有的时候成员变量会被延时加载，这些变量只有当getter方法被调用的时候才真正可用。 例如在我们的例子中，如果我们使用e1.id == e2.id则可能会出现这个问题，但是我们使用e1.getId() == e2.getId()就不会出现这个问题。 希望这篇文章能够帮助你。 自己总结 hashCode() 方法, 表示该对象在Map中的索引值. equals() 方法, 表示在对象在Map中的hashCode()对应索引位置的对象是否相等.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中关于数组转换成List的注意事项]]></title>
    <url>%2F2016%2F02%2F14%2FJava%E4%B8%AD%E5%85%B3%E4%BA%8E%E6%95%B0%E7%BB%84%E8%BD%AC%E6%8D%A2%E6%88%90List%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[问题代码123456789101112131415package org.emacsist;import java.util.Arrays;import java.util.List;/** * Created by sky on 16-2-14. */public class TestHello &#123; public static void main(String[] args) &#123; List&lt;String&gt; arg = Arrays.asList(args); arg.add("出现问题了."); System.out.println(arg); &#125;&#125; 一运行，就报如下错误 1234567891011Exception in thread "main" java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) at org.emacsist.TestHello.main(TestHello.java:12) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)Process finished with exit code 1 原因1Arrays.asList(args); 这个方法，根据JavaDoc 它返回的是一个固定大小的List，这意味着不支持任何修改的操作。比如add, remove等. 返回一个可修改的List12345678910111213141516package org.emacsist;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * Created by sky on 16-2-14. */public class TestHello &#123; public static void main(String[] args) &#123; List&lt;String&gt; arg = new ArrayList&lt;&gt;(Arrays.asList(args)); arg.add("不会出现问题了."); System.out.println(arg); &#125;&#125; 执行的结果如下: 123[不会出现问题了.]Process finished with exit code 0]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 学习之基本概念及使用]]></title>
    <url>%2F2016%2F02%2F14%2FSpring%20Boot%20%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[官方建议的代码目录 1234567891011121314com +- example +- myproject +- Application.java | +- domain | +- Customer.java | +- CustomerRepository.java | +- service | +- CustomerService.java | +- web +- CustomerController.java Application.java 典型的代码1234567891011121314151617package com.example.myproject;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;@Configuration@EnableAutoConfiguration@ComponentScanpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; @ComponentScan它会扫描(@Component, @Service, @Repository, @Controller）等这些注解，并自动注册为Spring Bean @SpringBootApplication等同于同时使用(@Configuration, @EnableAutoConfiguration, @Componentscan)这些注解. 运行Spring Boot12345678910java -jar target/myproject-0.0.1-SNAPSHOT.jar或者java -Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=8000,suspend=n -jar target/myproject-0.0.1-SNAPSHOT.jar或者export MAVEN_OPTS=-Xmx1024m -XX:MaxPermSize=128M -Djava.security.egd=file:/dev/./urandommvn spring-boot:run或者 默认的配置文件名1application.properties 父，子容器设置12345new SpringApplicationBuilder() .bannerMode(Banner.Mode.OFF) .sources(Parent.class) .child(Application.class) .run(args); Spring boot 中事件监听1SpringApplication.addListeners(…​) 通过注册监听器，来监听相应的事件 访问应用参数1234567891011@Componentpublic class MyBean &#123; @Autowired public MyBean(ApplicationArguments args) &#123; boolean debug = args.containsOption("debug"); List&lt;String&gt; files = args.getNonOptionArgs(); // if run with "--debug logfile.txt" debug=true, files=["logfile.txt"] &#125;&#125; Spring Boot 监控1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 添加这个依赖，然后就可以看到启动时加载的信息了: 12345678910111213141516troller.error(javax.servlet.http.HttpServletRequest)2016-02-14 15:38:21.371 INFO 30028 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2016-02-14 15:38:21.371 INFO 30028 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2016-02-14 15:38:21.405 INFO 30028 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2016-02-14 15:38:21.884 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.884 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/dump || /dump.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.885 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/env/&#123;name:.*&#125;],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)2016-02-14 15:38:21.885 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/env || /env.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.886 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/health || /health.json],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(java.security.Principal)2016-02-14 15:38:21.888 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/metrics/&#123;name:.*&#125;],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)2016-02-14 15:38:21.888 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/metrics || /metrics.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.890 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/beans || /beans.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.890 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/mappings || /mappings.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.890 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/configprops || /configprops.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.891 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/info || /info.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()2016-02-14 15:38:21.891 INFO 30028 --- [ main] o.s.b.a.e.mvc.EndpointHandlerMapping : Mapped "&#123;[/trace || /trace.json],methods=[GET],produces=[application/json]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke() 修改前缀 1management.contextPath=/my/manager 这样子，就要通过/my/manager/health这样子来访问了. Spring Adminmaven的依赖 12345678&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt;&lt;/dependency&gt; 在配置文件里添加 123spring.application.name=Spring Boot Admin Webspring.boot.admin.url=http://localhost:$&#123;server.port&#125;/adminspring.boot.admin.context-path=/admin 然后访问: Go 根据不同环境使用 properties123application.propertiesapplication-dev.propertiesapplication-pro.properties 然后设置spring.profiles.active=xxx，就可以使用相应的配置文件了.(-Dspring.profiles.active=production)注意，这里是有继承关系的.即application.properties是公共的，即无论在哪种环境，它都会加载的.如果spring.profiles.active=default，就只会加载application.properties.如果spring.profiles.active=dev，就会加载application.properties，然后再加载application-dev.properties.而且application-dev.properties的属性，会覆盖application.properties的. 而且，还可以向前引用变量。比如这样子: 12hello.world=defhello.world.parent=$&#123;hello.world&#125; from parent 使用 Bean 来映射properties文件 123456789101112131415@Component@ConfigurationProperties(prefix="person")public class ConnectionSettings &#123; private String firstName; public String getFirstName() &#123; return this.firstName; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125;&#125; 然后 properties 文件 里可以这样子写 1234567person.firstName=xxx或者person.first-name=xxx或者PERSON_FIRST_NAME=xxx 在 Java 代码里根据不同的环境来加载不同的 Bean1234567891011121314151617181920212223242526272829@Configuration@Import(&#123;Development.class, Production.class&#125;)public class MyApplicationConfiguration &#123;&#125;@Configuration@Profile("development")public class Development &#123;&#125;@Configuration@Profile // The defaultpublic class Production &#123;&#125;@Configurationpublic class MyApplicationConfiguration &#123; @Bean @Profile("development") public static PropertySourcesPlaceholderConfigurer developmentPropertyPlaceholderConfigurer() &#123; // instantiate and return configurer... &#125; @Bean @Profile // The default public static PropertySourcesPlaceholderConfigurer propertyPlaceholderConfigurer() &#123; // instantiate and return configurer... &#125;&#125; 在 XML 文件里根据不同的环境加载不同的 Bean1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:beans="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!-- ======================================= --&gt; &lt;!-- use varibles in bean definition --&gt; &lt;!-- ======================================= --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driver&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;/bean&gt; &lt;bean class="com.shengwang.demo.HelloWorldBean"&gt; &lt;constructor-arg value="$&#123;hellow.world.name&#125;" /&gt; &lt;/bean&gt; &lt;!-- ====================================================== --&gt; &lt;!-- import different variables according to active profile --&gt; &lt;!-- ====================================================== --&gt; &lt;beans profile="development"&gt; &lt;context:property-placeholder ignore-resource-not-found="true" location="classpath*:/META-INF/development.properties" /&gt; &lt;/beans&gt; &lt;beans profile="test"&gt; &lt;context:property-placeholder ignore-resource-not-found="true" location="classpath*:/META-INF/test.properties" /&gt; &lt;/beans&gt; &lt;beans profile="production"&gt; &lt;context:property-placeholder ignore-resource-not-found="true" location="classpath*:/META-INF/production.properties" /&gt; &lt;/beans&gt;&lt;/beans&gt; 配置自定义Bean1234567891011@Configurationpublic class MyConfiguration &#123; @Bean public HttpMessageConverters customConverters() &#123; HttpMessageConverter&lt;?&gt; additional = ... HttpMessageConverter&lt;?&gt; another = ... return new HttpMessageConverters(additional, another); &#125;&#125; 关于静态资源的处理 这是Spring boot 默认情况下配置. 默认情况下，在classpath路径下的/static (or /public or /resources or /META-INF/resources)这些目录，是被看作是静态资源的存放路径的.也可以通过spring.resources.staticLocations参数来指定. 打包为普通的 war 包形式HelloWorldSpringBoot.java 12345678910111213141516171819202122232425262728package org.emacsist;import de.codecentric.boot.admin.config.EnableAdminServer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.context.web.SpringBootServletInitializer;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * Created by sky on 16-2-14. */@SpringBootApplication@EnableAdminServer@EnableDiscoveryClientpublic class HelloWorldSpringBoot extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(HelloWorldSpringBoot.class); &#125; public static void main(String[] args) throws Exception &#123; SpringApplication app = new SpringApplication(HelloWorldSpringBoot.class); app.run(args); &#125;&#125; 修改pom 1234567891011121314&lt;packaging&gt;war&lt;/packaging&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;start-class&gt;org.emacsist.HelloWorldSpringBoot&lt;/start-class&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 项目的目录结构改为 123456src | |-main |-webapp |-WEB-INF其他的按普通的项目目录处理即可. 优雅关闭 Spring Boot在application.properties里添加以下配置 1endpoints.shutdown.enabled=true 启动时就可以看到以下加载信息了 1Mapped "&#123;[/shutdown || /shutdown.json],methods=[POST]&#125;" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.ShutdownMvcEndpoint.invoke() 然后可以这样子关闭: 123╭─sky@sky-linux ~╰─➤ curl -d "" http://localhost:8080/shutdown&#123;"message":"Shutting down, bye..."&#125;% 自定义监控health12345678910111213@Componentpublic class ExecutorHeal implements HealthIndicator &#123; @Override public Health health() &#123; Object dataSource = null; if (dataSource == null) &#123; return Health.down().status("DOWN").outOfService().withDetail("msg", "datasource is null").build(); &#125; else &#123; return Health.up().status("UP").withDetail("max connections", "100").build(); &#125; &#125;&#125; Metrics12345678910111213141516171819202122232425262728293031package org.emacsist;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.actuate.metrics.CounterService;import org.springframework.boot.actuate.metrics.GaugeService;import org.springframework.stereotype.Component;/** * Created by sky on 16-2-16. */@Componentpublic class MyMetric &#123; private final CounterService counterService; private final GaugeService gaugeService; @Autowired public MyMetric(CounterService counterService, GaugeService gaugeService) &#123; this.counterService = counterService; this.gaugeService = gaugeService; &#125; public void loginCounter() &#123; this.counterService.increment("login.count"); // reset each minute &#125; public void cacheGauge() &#123; this.gaugeService.submit("cache.hit", 80.0); &#125;&#125; spring 中使用 logback根据不同的环境，配置不同的日志方式文件名是logback-spring.xml 123456789101112&lt;springProfile name="staging"&gt; &lt;!-- configuration to be enabled when the "staging" profile is active --&gt;&lt;/springProfile&gt;&lt;springProfile name="dev, staging"&gt; &lt;!-- configuration to be enabled when the "dev" or "staging" profiles are active --&gt;&lt;/springProfile&gt;&lt;springProfile name="!production"&gt; &lt;!-- configuration to be enabled when the "production" profile is not active --&gt;&lt;/springProfile&gt; spring 非 web 以守护进程方式启动12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.compay.wxsdk.listener;import org.springframework.boot.CommandLineRunner;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.velocity.VelocityAutoConfiguration;import org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import java.io.IOException;import java.util.concurrent.CountDownLatch;@SpringBootApplication@ComponentScan("com.compay.wxsdk")@EnableAutoConfiguration(exclude = &#123;WebMvcAutoConfiguration.class, VelocityAutoConfiguration.class&#125;)@Configurationpublic class ListenerApplication implements CommandLineRunner &#123; public static void main(String[] args) throws IOException, InterruptedException &#123;// Enumeration&lt;URL&gt; roots = WebApplication.class.getClassLoader().getResources("");// while (roots.hasMoreElements()) &#123;// URL url = roots.nextElement();// File root = new File(url.getPath());// for (File file : root.listFiles()) &#123;// System.out.println(file.getAbsolutePath() + " ==&gt; " + file.getName());// &#125;// &#125; System.out.println("start ....listener app"); ConfigurableApplicationContext configurableApplicationContext = new SpringApplicationBuilder(ListenerApplication.class).web(false).run(args); configurableApplicationContext.registerShutdownHook(); configurableApplicationContext.start(); final CountDownLatch closeLatch = configurableApplicationContext.getBean(CountDownLatch.class); Runtime.getRuntime().addShutdownHook(new Thread() &#123; @Override public void run() &#123; closeLatch.countDown(); &#125; &#125;); closeLatch.await(); System.out.println("shutdown...."); &#125; @Override public void run(String... strings) throws Exception &#123; &#125; @Bean public CountDownLatch closeLatch() &#123; return new CountDownLatch(1); &#125;&#125; Spring boot自定义Error Page 以及记录异常日志自定义ErrorPgae123456789101112131415161718192021222324252627package com;import org.springframework.boot.context.embedded.ConfigurableEmbeddedServletContainer;import org.springframework.boot.context.embedded.EmbeddedServletContainerCustomizer;import org.springframework.boot.web.servlet.ErrorPage;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.http.HttpStatus;/** * Created by emacsist on 2017/3/7. */@Configurationpublic class MvcConfiguration &#123; @Bean public EmbeddedServletContainerCustomizer containerCustomizer() &#123; return new EmbeddedServletContainerCustomizer() &#123; @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.addErrorPages(new ErrorPage(HttpStatus.BAD_REQUEST, "/400")); container.addErrorPages(new ErrorPage(HttpStatus.INTERNAL_SERVER_ERROR, "/500")); container.addErrorPages(new ErrorPage(HttpStatus.NOT_FOUND, "/404")); &#125; &#125;; &#125;&#125; 记录异常日志12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com;import com.utils.Loggers;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.ByteArrayOutputStream;import java.io.PrintWriter;import java.nio.charset.StandardCharsets;import java.util.Enumeration;/** * Controller 统一异常、错误处理 * Created by emacsist on 2017/3/7. */@ControllerAdvicepublic class GlobalControllerExceptionHandler &#123; @ExceptionHandler(value = Exception.class) public String defaultErrorHandler(HttpServletRequest request, HttpServletResponse response, Exception e) throws Exception &#123; ByteArrayOutputStream bao = new ByteArrayOutputStream(1024); PrintWriter printWriter = new PrintWriter(bao); printWriter.append(getRequestInfo(request)); e.printStackTrace(printWriter); printWriter.flush(); String stack = bao.toString(StandardCharsets.UTF_8.name()); Loggers.ERROR_LOGGER.error("&#123;&#125;", stack); return "forward:/500"; &#125; private String getRequestInfo(HttpServletRequest request)&#123; String lineSepartor = System.getProperty("line.separator"); StringBuilder sb = new StringBuilder(1024); sb.append("Request URL : ").append(request.getRequestURL()).append(lineSepartor); sb.append("Request Method: ").append(request.getMethod()).append(lineSepartor); sb.append("Request Paramter: ").append(lineSepartor); Enumeration params = request.getParameterNames(); while(params.hasMoreElements())&#123; String paramName = (String)params.nextElement(); sb.append(paramName).append("=").append(request.getParameter(paramName)).append(lineSepartor); &#125; return sb.toString(); &#125;&#125; 参考资料 Spring Boot ithao123 spring-boot logging]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 学习之Hello World（一）]]></title>
    <url>%2F2016%2F02%2F14%2FSpring-Boot-%E5%AD%A6%E4%B9%A0%E4%B9%8BHello-World%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[POM 文件12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;myproject&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.BUILD-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;!-- Additional lines to be added here... --&gt; &lt;!-- (you don't need this if you are using a .RELEASE version) --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; HelloWorldSpringBoot.java123456789101112131415161718192021222324package org.emacsist;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * Created by sky on 16-2-14. */@RestController@EnableAutoConfigurationpublic class HelloWorldSpringBoot &#123; @RequestMapping("/") String home() &#123; return "Hello World! from spring boot. "; &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(HelloWorldSpringBoot.class, args); &#125;&#125; 启动1234567891011121314151617181920212223242526272829303132333435363738394041 . ____ _ __ _ _ /\\ / ___'_ __ _ _(_)_ __ __ _ \ \ \ \( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.3.2.RELEASE)2016-02-14 11:23:59.957 INFO 18301 --- [ main] org.emacsist.HelloWorldSpringBoot : Starting HelloWorldSpringBoot on sky-linux with PID 18301 (/home/sky/git/spring-boot/target/classes started by sky in /home/sky/git/spring-boot)2016-02-14 11:23:59.963 INFO 18301 --- [ main] org.emacsist.HelloWorldSpringBoot : No active profile set, falling back to default profiles: default2016-02-14 11:24:00.013 INFO 18301 --- [ main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b67034: startup date [Sun Feb 14 11:24:00 CST 2016]; root of context hierarchy2016-02-14 11:24:00.679 INFO 18301 --- [ main] o.s.b.f.s.DefaultListableBeanFactory : Overriding bean definition for bean 'beanNameViewResolver' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration; factoryMethodName=beanNameViewResolver; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/web/ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter; factoryMethodName=beanNameViewResolver; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter.class]]2016-02-14 11:24:00.696 WARN 18301 --- [ main] o.m.s.mapper.ClassPathMapperScanner : No MyBatis mapper was found in '[org.emacsist]' package. Please check your configuration.2016-02-14 11:24:00.902 INFO 18301 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.amqp.rabbit.annotation.RabbitBootstrapConfiguration' of type [class org.springframework.amqp.rabbit.annotation.RabbitBootstrapConfiguration$$EnhancerBySpringCGLIB$$311259ed] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2016-02-14 11:24:01.064 INFO 18301 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$27aac97f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2016-02-14 11:24:01.353 INFO 18301 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)2016-02-14 11:24:01.362 INFO 18301 --- [ main] o.apache.catalina.core.StandardService : Starting service Tomcat2016-02-14 11:24:01.363 INFO 18301 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.0.302016-02-14 11:24:01.433 INFO 18301 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2016-02-14 11:24:01.433 INFO 18301 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1422 ms2016-02-14 11:24:01.674 INFO 18301 --- [ost-startStop-1] o.s.b.c.e.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]2016-02-14 11:24:01.686 INFO 18301 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]2016-02-14 11:24:01.687 INFO 18301 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: 'springSessionRepositoryFilter' to: [/*]2016-02-14 11:24:01.687 INFO 18301 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]2016-02-14 11:24:01.687 INFO 18301 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: 'httpPutFormContentFilter' to: [/*]2016-02-14 11:24:01.687 INFO 18301 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: 'requestContextFilter' to: [/*]2016-02-14 11:24:01.844 INFO 18301 --- [ main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b67034: startup date [Sun Feb 14 11:24:00 CST 2016]; root of context hierarchy2016-02-14 11:24:01.886 INFO 18301 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "&#123;[/]&#125;" onto java.lang.String org.emacsist.HelloWorldSpringBoot.home()2016-02-14 11:24:01.888 INFO 18301 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "&#123;[/error],produces=[text/html]&#125;" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)2016-02-14 11:24:01.889 INFO 18301 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "&#123;[/error]&#125;" onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)2016-02-14 11:24:01.920 INFO 18301 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2016-02-14 11:24:01.920 INFO 18301 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2016-02-14 11:24:01.947 INFO 18301 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2016-02-14 11:24:02.426 INFO 18301 --- [ main] o.s.w.s.v.velocity.VelocityConfigurer : ClasspathResourceLoader with name 'springMacro' added to configured VelocityEngine2016-02-14 11:24:02.436 INFO 18301 --- [ main] o.s.ui.velocity.SpringResourceLoader : SpringResourceLoader for Velocity: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b67034: startup date [Sun Feb 14 11:24:00 CST 2016]; root of context hierarchy] and resource loader paths [classpath:/templates/]2016-02-14 11:24:02.557 WARN 18301 --- [ main] o.s.b.a.v.VelocityAutoConfiguration : Cannot find template location: classpath:/templates/ (please add some templates, check your Velocity configuration, or set spring.velocity.checkTemplateLocation=false)2016-02-14 11:24:02.603 INFO 18301 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup2016-02-14 11:24:02.610 INFO 18301 --- [ main] o.s.c.support.DefaultLifecycleProcessor : Starting beans in phase -21474826482016-02-14 11:24:02.610 INFO 18301 --- [ main] o.s.c.support.DefaultLifecycleProcessor : Starting beans in phase 21474836472016-02-14 11:24:02.669 INFO 18301 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)2016-02-14 11:24:02.674 INFO 18301 --- [ main] org.emacsist.HelloWorldSpringBoot : Started HelloWorldSpringBoot in 3.022 seconds (JVM running for 3.46) 访问123╭─sky@sky-linux /ihome/nodejs/blog╰─➤ curl http://localhost:8080Hello World! from spring boot.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL的各种join]]></title>
    <url>%2F2016%2F02%2F01%2FSQL%E7%9A%84%E5%90%84%E7%A7%8Djoin%2F</url>
    <content type="text"><![CDATA[测试表数据t11234567891011121314151617sky=# select * from t1; id | name----+------ 1 | n1 2 | n2 3 | n3 4 | n4 5 | n5 6 | n6 7 | n7 8 | n8 9 | n9 10 | n10 1 | n11(11 rows)sky=# t212345678910111213141516sky=# select * from t2; id | age | t1_id----+-----+------- 1 | 11 | 1 2 | 12 | 1 7 | 17 | 2 3 | 13 | 4 4 | 14 | 4 5 | 15 | 5 6 | 16 | 5 8 | 18 | 7 9 | 19 | 7 10 | 20 | 7(10 rows)sky=# inner join1234567891011121314151617181920212223242526272829303132333435363738394041424344454647sky=# explain analyze verbose select * from t1 inner join t2 on t1.id = t2.t1_id; QUERY PLAN--------------------------------------------------------------------------------------------------------------------- Merge Join (cost=223.19..406.47 rows=11832 width=54) (actual time=0.015..0.018 rows=12 loops=1) Output: t1.id, t1.name, t2.id, t2.age, t2.t1_id Merge Cond: (t1.id = t2.t1_id) -&gt; Sort (cost=80.64..83.54 rows=1160 width=42) (actual time=0.010..0.011 rows=9 loops=1) Output: t1.id, t1.name Sort Key: t1.id Sort Method: quicksort Memory: 25kB -&gt; Seq Scan on public.t1 (cost=0.00..21.60 rows=1160 width=42) (actual time=0.003..0.005 rows=11 loops=1) Output: t1.id, t1.name -&gt; Sort (cost=142.54..147.64 rows=2040 width=12) (actual time=0.003..0.004 rows=12 loops=1) Output: t2.id, t2.age, t2.t1_id Sort Key: t2.t1_id Sort Method: quicksort Memory: 25kB -&gt; Seq Scan on public.t2 (cost=0.00..30.40 rows=2040 width=12) (actual time=0.002..0.002 rows=10 loops=1) Output: t2.id, t2.age, t2.t1_id Planning time: 0.055 ms Execution time: 0.035 ms(17 rows)sky=#sky=# explain analyze verbose select * from t1, t2 where t1.id = t2.t1_id; QUERY PLAN--------------------------------------------------------------------------------------------------------------------- Merge Join (cost=223.19..406.47 rows=11832 width=54) (actual time=0.016..0.020 rows=12 loops=1) Output: t1.id, t1.name, t2.id, t2.age, t2.t1_id Merge Cond: (t1.id = t2.t1_id) -&gt; Sort (cost=80.64..83.54 rows=1160 width=42) (actual time=0.009..0.009 rows=9 loops=1) Output: t1.id, t1.name Sort Key: t1.id Sort Method: quicksort Memory: 25kB -&gt; Seq Scan on public.t1 (cost=0.00..21.60 rows=1160 width=42) (actual time=0.004..0.005 rows=11 loops=1) Output: t1.id, t1.name -&gt; Sort (cost=142.54..147.64 rows=2040 width=12) (actual time=0.004..0.005 rows=12 loops=1) Output: t2.id, t2.age, t2.t1_id Sort Key: t2.t1_id Sort Method: quicksort Memory: 25kB -&gt; Seq Scan on public.t2 (cost=0.00..30.40 rows=2040 width=12) (actual time=0.001..0.001 rows=10 loops=1) Output: t2.id, t2.age, t2.t1_id Planning time: 0.052 ms Execution time: 0.036 ms(17 rows)sky=# 由此可知：inner join与from t1,t2 where t1.xx = t2.xx是一样的. 它的结果行数=SUM(t1中的每一行 * t2中的每一行中t2.xx=t1.xx)比如，上面的结果()，它就是（结果行数12 = t1中1的为2行，t2中的1也为2行即22=4,t1中的2为1行, t2中的2也为1行，即11 = 1t1中的4为1行，t2中的4为2行,即12 = 2t1中的5为1行，t2中的5为2行，即12 = 2t1中的7为1行，t2中的7为3行，即1*3 = 3所以，总行数=4+1+2+2+3=12行. left join1234567891011121314151617181920212223sky=# explain analyze verbose select * from t1 left join t2 on t1.id = t2.t1_id; QUERY PLAN--------------------------------------------------------------------------------------------------------------------- Merge Left Join (cost=223.19..406.47 rows=11832 width=54) (actual time=0.025..0.028 rows=17 loops=1) Output: t1.id, t1.name, t2.id, t2.age, t2.t1_id Merge Cond: (t1.id = t2.t1_id) -&gt; Sort (cost=80.64..83.54 rows=1160 width=42) (actual time=0.018..0.018 rows=11 loops=1) Output: t1.id, t1.name Sort Key: t1.id Sort Method: quicksort Memory: 25kB -&gt; Seq Scan on public.t1 (cost=0.00..21.60 rows=1160 width=42) (actual time=0.012..0.013 rows=11 loops=1) Output: t1.id, t1.name -&gt; Sort (cost=142.54..147.64 rows=2040 width=12) (actual time=0.004..0.004 rows=12 loops=1) Output: t2.id, t2.age, t2.t1_id Sort Key: t2.t1_id Sort Method: quicksort Memory: 25kB -&gt; Seq Scan on public.t2 (cost=0.00..30.40 rows=2040 width=12) (actual time=0.002..0.002 rows=10 loops=1) Output: t2.id, t2.age, t2.t1_id Planning time: 0.060 ms Execution time: 0.046 ms(17 rows)sky=#]]></content>
  </entry>
  <entry>
    <title><![CDATA[一次生产环境Java应用性能排查]]></title>
    <url>%2F2016%2F01%2F27%2F%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83Java%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[问题 生产环境上，有客户反应某个页面，点击时非常慢 然后，有个测试同事，这个测试的账号给我登录，然后亲自重现排查下原因。发现，该页面，第一次加载入去时，点击[对话]的响应时间还可以接受。但是过了几十秒之后，再点击就变得非常之慢了（有时整个请求耗时差不多1分钟….，这种情况，只有再现大量数据时，才会呈现这种问题） 排查一开始，我以为是点击时请求[对话]某URL的原因，然后线上hot fix加入方法调用时间的统计，发现非常慢的时候，前端还一直在等待，但服务器却没有打印出我的加入时间统计的日志，等完成时，却发现一个非常奇怪的现象： 前端显示该请求的 responseTime 为 51s 但后端统计调用该方法直到返回，整个处理耗时为100ms 为何会差别如此之大？ 实在不得已，然后请了前端的同事，过来帮忙看看原因。然后同事再次打开浏览器调试工具，发现非常慢的那段时间，有不少其他的请求一直是等待状态，服务器响应未完成。 这……. 经前端同事的指出，才知道Google Chrome浏览器，同一个tab对同一域名的最大同时连接数是有限制的.可以通过如下方式查看: 123在浏览器地址栏输入以下:chrome://net-internals/#sockets 解决经过这次排查，发现自己一开始时的排查方向都是错的。因为问题的根源，并不是点击[对话]的URL的后端处理导致的。而是由于其他的URL，导致服务器没有能及时响应，而这些又是前端轮询的。所以，当服务器出现不能及时响应时，就会造成不少同时连接到同一域名，从而达到浏览器的连接上限，其他的请求，就只有挂起了。所以，才看到整个处理时间，前端与后端差别这么大。 找到根源的那个URL请求，然后优化了下该代码就好了。 总结知识点 浏览器对同一域名，最大同时连接数是有限制的 前端的http请求，没有添加 timeout 这次慢的原因，是因为后端代码的redis遍历问题，而且还是（1）获取某个zset的memebers –&gt; （2）获取每个memebers的对象（当时是有2W多个Key），这在以后用redis要特别注意.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>server</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 缓存图解]]></title>
    <url>%2F2016%2F01%2F27%2FHTTP-%E7%BC%93%E5%AD%98%E5%9B%BE%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[也不知道自己理解的对不对，有不正确的地方，还请网友指正下。谢谢]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java常见应用的性能优化]]></title>
    <url>%2F2016%2F01%2F26%2FJava%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[总诀式 减少网络连接次数 减小网络传输数据 添加缓存 分布式 Redis 式 在同一线程的操作里，尽可能合并redis的操作(pipeline)（减少网络连接次数） 对象尽可能用 hash 保存，然后按需获取 hashKey 的值（减小网络传输数据) 用合适的数据类型，保存相应的数据 Java 式 添加redis缓存（不过，要防止缓存穿透的问题） 在for循环里使用redis判断时，可以在Java里再次添加二级缓存（Java Memory），而不是每次直接再连接redis（减少网络连接次数） 连接要设置 (connectionTimeout，或其他相关的timeout的问题) 一下子加载的数据太多，可以先加载第一页的数据，其他页的数据，可以开启一个线程，去完成。（先满足用户第一页的数据请求先，后面的数据，再异步去处理） 线程池 + 异步处理 DB 式 优化SQL 只选择需要的列（减小网络传输数据） 大量数据，可以分批处理]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx平滑升级]]></title>
    <url>%2F2016%2F01%2F25%2FNginx%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[原版本1234567891011121314╭─sky@sky-linux /ihome/nginx/nginx-1.8╰─➤ ./sbin/nginx -Vnginx version: nginx/1.8.0built by gcc 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)configure arguments: --prefix=/ihome/nginx/nginx-1.8╭─sky@sky-linux /ihome/nginx/nginx-1.8╰─➤╭─sky@sky-linux /ihome/nginx/nginx-1.8╰─➤ ps aux | grep "[n]ginx"root 22369 0.0 0.0 28464 556 ? Ss 17:00 0:00 nginx: master process ./sbin/nginxnobody 22370 0.0 0.0 28888 2684 ? S 17:00 0:00 nginx: worker process╭─sky@sky-linux /ihome/nginx/nginx-1.8╰─➤ 编译新版本12345678./configure --prefix=旧版本的nginx目录make -j 8将旧版本的nginx二进制文件备份下cp /旧版本nginx目录/sbin/nginx /旧版本ningx目录/sbin/nginx.old将新编译好的nginx二进制文件复制到旧版本的nginx目录sbin下cp /新版本编译目录/objs/nginx /旧版本nginx目录/sbin/nginx 平滑升级切换pid123╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ sudo kill -USR2 `cat logs/nginx.pid`╭─sky@sky-linux 成功后，就可以看到 123456789╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ ll logstotal 44K-rw-r--r-- 1 sky sky 25K 1月 25 17:17 access.log-rw-r--r-- 1 sky sky 625 1月 25 17:16 error.log-rw-r--r-- 1 root root 6 1月 25 17:16 nginx.pid-rw-r--r-- 1 root root 6 1月 25 17:13 nginx.pid.oldbin╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ 它生成了一个nginx.pid.oldbin 这时，可以看到有两个nginx进程了 12345678╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ ps aux | grep "[n]ginx"root 25690 0.0 0.0 28464 2160 ? Ss 17:13 0:00 nginx: master process ./sbin/nginxnobody 25691 0.0 0.0 28888 2572 ? S 17:13 0:00 nginx: worker processroot 26668 0.0 0.0 28468 3520 ? S 17:16 0:00 nginx: master process ./sbin/nginxnobody 26671 0.0 0.0 28880 2416 ? S 17:16 0:00 nginx: worker process╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ 新版本的nginx也已经启动了. 1234567╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ ./sbin/nginx -Vnginx version: nginx/1.9.9built by gcc 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)configure arguments: --prefix=/ihome/nginx/nginx-current╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ 停止旧nginx的worker1234╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ sudo kill -WINCH `cat logs/nginx.pid.oldbin`╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ 停止旧nginx的master1234╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ sudo kill -QUIT `cat logs/nginx.pid.oldbin`╭─sky@sky-linux /ihome/nginx/nginx-current╰─➤ 这样子就OK了.]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“[翻译]用Java实现自定义的线程池”]]></title>
    <url>%2F2016%2F01%2F25%2F%E7%94%A8Java%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[原文 让我们用Java来实现自定义的线程池. 让我们首先定义一个类，它拥有两个方法enqueue和dequeue. 这个类的dequeue方法将充当一个阻塞队列。即，当队列里有数据时，阻塞所有调用dequeue方法，否则就一直等待。 123456789package com.pract.threadpool;public interface CustomQueue&lt;E&gt;&#123; public void enqueue(E e); public E dequeue();&#125; 以下是实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.pract.threadpool;import java.util.LinkedList;import java.util.Queue;public class MyQueue&lt;E&gt; implements CustomQueue&lt;E&gt;&#123; // queue backed by a linkedlist private Queue&lt;E&gt; queue = new LinkedList&lt;E&gt;(); /** * Enqueue will add an object to this queue, and will notify any waiting * threads that now there is an object available. * * In enqueue method we just adding the elements not caring of size, * we can even introduce some check of size here also. */ @Override public synchronized void enqueue(E e) &#123; queue.add(e); // Wake up anyone waiting on the queue to put some item. notifyAll(); &#125; /** * Make a blocking call so that we will only return when the queue has * something on it, otherwise wait until something is put on it. */ @Override public synchronized E dequeue()&#123; E e = null; while(queue.isEmpty())&#123; try &#123; wait(); &#125; catch (InterruptedException e1) &#123; return e; &#125; &#125; e = queue.remove(); return e; &#125;&#125; 现在，让我们思考下线程池管理器，通过名称以及工作线程的大小参数，即线程池大小。并且，worker线程应该监听该任务被提交到的队列。 以下是实现: 12345678910111213141516171819202122232425package com.pract.threadpool;public class ThreadPoolManager &#123; private final int THREADPOOL_CAPACITY; private MyQueue&lt;Runnable&gt; myQueue = new MyQueue&lt;Runnable&gt;(); public ThreadPoolManager(int capacity)&#123; this.THREADPOOL_CAPACITY = capacity; initAllConsumers(); &#125; private void initAllConsumers()&#123; for(Integer i = 0; i &lt; THREADPOOL_CAPACITY; i++)&#123; Thread thread = new Thread(new Worker(myQueue, i.toString())); thread.start(); &#125; &#125; public void submitTask(Runnable r)&#123; myQueue.enqueue(r); &#125;&#125; 如果你检查上面的实现，你就会发现我们已经初始化的队列为MyQueue: 1MyQueue&lt;Runnable&gt; myQueue = new MyQueue&lt;Runnable&gt;(); MyQeueue队列会一直保持所有任务会被我们的worker线程执行。基于上面，我们也创建一个Worker类. Worker类是我们的工作者，它会一直监听队列然后处理提交的任务。 以下是Worker的实现: 12345678910111213141516171819202122232425package com.pract.threadpool;public class Worker implements Runnable&#123; private MyQueue&lt;Runnable&gt; myQueue; private String name; public Worker(MyQueue&lt;Runnable&gt; myQueue, String name)&#123; this.myQueue = myQueue; this.name = name; &#125; @Override public void run() &#123; while(true)&#123; Runnable r = myQueue.dequeue(); // print the dequeued item System.out.println(" Taken Item by thread name:" + this.name ); // run it r.run(); System.out.println(" Task completed of thread:" + this.name); &#125; &#125;&#125; 现在，让我们测试下我们以上的实现： 1234567891011121314151617181920212223242526272829303132333435package com.pract.threadpool;public class TestThreadPoolManager &#123; public static void main(String[] args) &#123; ThreadPoolManager poolManager = new ThreadPoolManager(10); //now lets submit task poolManager.submitTask(new Runnable() &#123; @Override public void run() &#123; System.out.println("Starting Task A...."); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("Task A Completed...."); &#125; &#125;); poolManager.submitTask(new Runnable() &#123; @Override public void run() &#123; System.out.println("Starting Task B...."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("Task B Completed...."); &#125; &#125;); &#125;&#125; 以下是输出: 1234567891011Taken Item by thread name:9Taken Item by thread name:0Starting Task A....Starting Task B....Task B Completed....Task completed of thread:0Task A Completed....Task completed of thread:9]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>thread pool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL备份pg_dump与恢复pg_restore]]></title>
    <url>%2F2016%2F01%2F22%2FPostgreSQL%E5%A4%87%E4%BB%BDpg-dump%E4%B8%8E%E6%81%A2%E5%A4%8Dpg-restore%2F</url>
    <content type="text"><![CDATA[备份某个数据库pg_dump-a或者--data-only： 只备份数据，不备份schema（即数据定义，包括表，序列，自定义数据类型等） -b或者--blobs：dump时包括大对象，除了指定--schema, --table或者--schema-only这些选项外，它默认包括大对象的. -c或者--clean：先删除对象，然后再创建新的（除非指定--if-exists，否则在恢复的时候，如果不存在任何一个数据库中的对象时，可能会产生一些错误消息）。 注意，这个选项只有对于 plain-text 格式的备份才有效。对于archive格式，当你调用pg_restore时，可以指定这些选项. -C或者--create： 在开始输出命令时，创建数据库本身，然后重新连接到这个指定的数据库。这个选择只对plain-text格式有效。对于archive格式，你可以在调用pg_restore时指定选项. -E encoding或者--encoding=encoding：以指定编码来备份。默认情况下，它是database的编码。 -f file或者--file=file：输出到指定文件。不能是已经存在的文件. -F format或者--format=format：指定备份的格式。 p : 纯文本.(默认的行为，即输出SQL语句） c : custom 格式。默认情况下它会被压缩的. d : directory 格式。 t : tar 格式 -j njobs或者--jobs=njobs：以njobs并行执行.虽然可以减少备份时间，但会增加服务器的负载.（注意，这个参数仅可用于directory格式的备份才有效，因为只有这种格式才可以在同一时间多个进程来写数据)。pg_dump会开启njobs+1条连接来连接数据库，所以，请确认你的max_connection的设置是足够处理所有连接的. -n schema或者--schema=schema：仅备份匹配的schema。当不指定这个选项时，对于目标database的所有非系统的schema都会被备份。多个模式，可以同时使用多个-n参数来指定.可以使用通配符来匹配。 -N schema或者--exclude-schema=schema： 不要备份这个参数指定的schema. -o或者--oids：备份每张表的对象的id。只有在你的应用会引用OID列时才使用这个选项，否则，不应该使用这个选项. -O或者--no-owner：备份时，不要设置对象的拥有者. -s或者--schema-only: 只备份对象定义.不备份数据. -S username或者--superuser=username：当禁用触发器时指定超级用户名. -t table或者--table=table：仅备份匹配的表.多表，可以通过多个-t参数来指定. -T table或者--exclude-table：不备份这些指定的表。可以通过多个-T参数来指定. -v或者--verbose：详细模式 -V或者--version：打印版本号并退出 -x或者--no-privileges或者--no-acl：不要备份访问的权限信息.(即grant,revoke这些命令) -Z 0..9或者--compress=0..9：指定压缩级别。0：即不压缩。对于custom格式：压缩每张表的数据段进行压缩，默认级别为中等级别。对于plain格式：压缩整个输出的文件，尽管它已经通过gzip压缩了，默认为不压缩。对于archive格式，目前还不支持压缩. --column-inserts或者attribute-inserts: 备份的数据带有显式的列名。这会导致恢复时非常慢，它通常用于将备份的数据还原到非PostgreSQL数据库中。 --disable-dollar-quoting： 该选项禁用$美元符作为函数体。 --disable-triggers：禁用触发器 --enable-row-security：启用行安全。 --exclude-table-data=table： 不备份指定表的数据。 --if-exists： 添加if exists子句.不能同时与--clean使用. --inserts：以insert命令备份，而不是COPY.这会导致恢复时非常慢. --lock-wait-timeout=timeout： 锁等待时间. --no-security-labels：不备份安全标签. --no-synchronized-snapshots：该选项允许对于9.2版本之前的服务器执行pg_dump -j --no-tablespaces：备份时，不指定表空间。在恢复时，它会还原到被恢复服务器的默认的表空间中。 --no-tablespaces：不备份unlog的表数据. --quote-all-identifiers：强制所有的标识符带有引号. --section=sectionname：值可以为pre-data, data, post-data.可以同时多次指定.默认为所有.data:包含实际表数据，大对象数据以及序列值。post-data：包含索引定义，触发器，规则以及约束。pre-data：除了data和post-data外的所有数据. --serializable-deferrable：使用serializable事务来备份. pg_restorepg_restore [connection-option...] [option...] [filename] filename：要恢复的文件，不指定就是标准输入. -a或者--data-only：仅还原数据，不还原数据定义.即表数据，大对象以及序列值会被还原. -c或者--clean：重新创之前清除数据库对象。 -C或者--create：恢复之前创建数据库。 -d dbname或者--dbname=dbname：连接到指定db然后直接还原到该DB -e或者--exit-on-error：遇到错误时退出. -f filename或者--file=filename：指定输出文件。默认为标准输出. -F format或者--format=format：指定要恢复文件的格式c:custom, d:directory, t:tar -I index或者-index=index：仅还原指定的索引。可以同时使用多个-I来指定多个索引 -j number-of-jobs或者--jobs=number-of-jobs：并发数.如果使用了--single-transaction，并发就会无效.并且只有custom或者directory格式才有效. -l或者--list：只列出要恢复的文件的内容. -L list-file或者--use-list=list-file：仅恢复在list-file文件里的元素. -n namespace或者--schema=schema：仅仅恢复这些指定的schema对象.可以使用多个-n来指定. -O或者--no-owner：不设置owner. -P function-name(argtype [,...])或者--function=function-name(argtype [, ...])：仅恢复指定的函数.可以使用多个-P来恢复. -s或者--schema-only：仅恢复定义，不恢复数据。 -S usrname或者--superuser=username：指定超级用户名.仅在同时使用--disable-triggers才有用. -t table或者--table=table：仅恢复指定表的定义和数据 -T trigger或者--trigger=trigger：仅恢复指定的触发器。可以使用多个-T. -v或者--verbose：详细模式. -V或者--version： 打印版本号并退出. -x或者--no-privileges或者--no-acl：不恢复权限访问信息. -1或者--single-transaction：这个是数字1.使用单事务进行恢复。 --disable-triggers：禁用触发器。 --enable-row-security：启用行安全. --if-exists： --no-data-for-failed-tables： --no-security-labels： --no-tablespaces： --section=sectionname：]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
        <tag>pg_dump</tag>
        <tag>pg_retore</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache AB 简单压力测试]]></title>
    <url>%2F2016%2F01%2F20%2FApache-AB-%E7%AE%80%E5%8D%95%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[以下的测试使用环境为ubuntu 安装ab工具1sudo apt-get install apache2-utils 使用直接写入到 requestBody1ab -T "Content-Type: application/json" -p /tmp/ab.data.user -n 1000 -c 500 http://localhost:8080/hello/action.do GET1ab -n 1000 -c 500 http://localhost:8080/hello/action.do POST1ab -T "application/x-www-form-urlencoded" -p /tmp/ab.data.user -n 1000 -c 500 http://localhost:8080/hello/action.do ab.data.user为key=value&amp;key1=value1的形式`]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>nginx</tag>
        <tag>ab</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx SSL 结合Tomcat 重定向URL变成HTTP的问题]]></title>
    <url>%2F2016%2F01%2F19%2FNginx-SSL-%E7%BB%93%E5%90%88Tomcat-%E9%87%8D%E5%AE%9A%E5%90%91URL%E5%8F%98%E6%88%90HTTP%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题由于要配置服务器(Nginx + Tomcat）的SSL的问题（Nginx同时监听HTTP和HTTPS)，但是，如果用户访问的是HTTPS协议，然后Tomcat进行重定向的时候，却变成了HTTP. 解决办法Nginx 配置12345678代理的配置，要添加以下内容proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;# mustproxy_set_header X-Forwarded-Proto $scheme; 然后重新加载一下配置文件即可sudo nginx -s reload Tomcat 配置在server.xml的Engine模块下面配置多一个以下的Valve 1&lt;Valve className="org.apache.catalina.valves.RemoteIpValve" remoteIpHeader="X-Forwarded-For" protocolHeader="X-Forwarded-Proto" protocolHeaderHttpsValue="https"/&gt; 然后重启一下Tomcat即可. 代码不用做任何修改. 参考资料 Sina Blog]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>nginx</tag>
        <tag>ssl</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL中创建自定义类型及其运算符]]></title>
    <url>%2F2016%2F01%2F18%2FPostgreSQL%E4%B8%AD%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[创建一个person的数据类型123sky=# create type person as (name varchar(10), age int);CREATE TYPEsky=# 使用person这个数据类型123sky=# create table use_person (id serial, o person);CREATE TABLEsky=# 插入示例数据123456789101112sky=# insert into use_person (o) values (row('yzy', 18));INSERT 0 1sky=# insert into use_person (o) values (row('girl', 19));INSERT 0 1sky=# select * from use_person; id | o----+----------- 1 | (yzy,18) 2 | (girl,19)(2 rows)sky=# 定义比较运算符这里只定义一种，就是&lt;比较运算符。定义如下: 1234567CREATE OR REPLACE FUNCTION person_age_smaller(left_o person, right_o person) RETURNS BOOLEAN AS$$ SELECT (left_o).age &lt; (right_o).age$$LANGUAGE sql;CREATE OPERATOR &lt;(PROCEDURE = person_age_smaller, LEFTARG = person, RIGHTARG = person, COMMUTATOR = &lt;); 使用12345678910111213sky=# SELECT (SELECT o from use_person WHERE id = 1) &lt; (SELECT o from use_person WHERE id = 2); ?column?---------- t(1 row)sky=# SELECT (SELECT o from use_person WHERE id = 2) &lt; (SELECT o from use_person WHERE id = 1); ?column?---------- f(1 row)sky=#]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源码安装PostgreSQL 9.5]]></title>
    <url>%2F2016%2F01%2F12%2F%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85PostgreSQL-9-5%2F</url>
    <content type="text"><![CDATA[下载源码12345678910# 安装目录mkdir -p /ihome/db/postgresql/postgresql-9.5.0# 存放解压源码的目录mkdir -p /ihome/db/postgresql/buildcd /ihome/db/postgresqlwget -c https://ftp.postgresql.org/pub/source/v9.5.0/postgresql-9.5.0.tar.bz2tar -xvf /ihome/db/postgresql/postgresql-9.5.0.tar.bz2 -C /ihome/db/postgresql/buildcd /ihome/db/postgresql/build/postgresql-9.5.0 安装依赖1sudo apt-get install libreadline-dev 编译12./configure --prefix=/ihome/db/postgresql/postgresql-9.5.0make -j 8 成功后，会提示如下: 1All of PostgreSQL successfully made. Ready to install. 安装1234make installcd /ihome/db/postgresqlln -s postgresql-9.5.0 current 成功后会提示如下: 1PostgreSQL installation complete. 配置环境变量12345678emacs ~/.zshrc添加以下:PG_HOME=/ihome/db/postgresql/currentPATH=$PG_HOME/bin:$PATHexport PATHsource ~/.zshrc 初始化数据库创建数据目录(data)1mkdir /ihome/db/postgresql/postgresql-9.5.0/data 初始化数据目录1initdb /ihome/db/postgresql/current/data 启动数据库123456789101112pg_ctl -D /ihome/db/postgresql/current/data -l /ihome/db/postgresql/current/pg.start.log start启动成功后，可以看到以下进程了:╭─sky@sky-linux /ihome/db/postgresql╰─➤ ps aux | grep "[p]ostgres"sky 28448 0.0 0.1 171644 16700 pts/3 S 16:51 0:00 /ihome/db/postgresql/postgresql-9.5.0/bin/postgres -D /ihome/db/postgresql/current/datasky 28454 0.0 0.0 171644 2876 ? Ss 16:51 0:00 postgres: checkpointer processsky 28455 0.0 0.0 171644 3740 ? Ss 16:51 0:00 postgres: writer processsky 28456 0.0 0.0 171644 2876 ? Ss 16:51 0:00 postgres: wal writer processsky 28457 0.0 0.0 172048 5156 ? Ss 16:51 0:00 postgres: autovacuum launcher processsky 28458 0.0 0.0 26652 2948 ? Ss 16:51 0:00 postgres: stats collector process╭─sky@sky-linux 连接到PG123456789╭─sky@sky-linux /ihome/db/postgresql╰─➤ psqlpsql: FATAL: database "sky" does not exist╭─sky@sky-linux /ihome/db/postgresql╰─➤ psql -d postgres 2 ↵psql (9.5.0)Type "help" for help.postgres=# 注意，默认情况下，psql是连接一个名为你当前用户名的数据库的.这时，可以指定-d postgres来连接postgres的数据库（这个是初始化时默认的) 默认的数据库只有三个: 123456789101112postgres=# \l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges-----------+-------+----------+-------------+-------------+------------------- postgres | sky | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | sky | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | =c/sky + | | | | | sky=CTc/sky template1 | sky | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | =c/sky + | | | | | sky=CTc/sky(3 rows)postgres=# postgres：默认的数据库template0：模板数据库0, 最纯洁的（就是最原始的）数据库模板.这个最好就不要做任何修改.template1：模板数据库1, 默认情况下，我们执行create database的时候，就是以template1为模板来创建数据库的. 然后创建一个与当前用户名同名的数据库: 1create database sky; 下次就可以直接使用psql连接了. 停止PostgreSQL1pg_ctl -D /ihome/db/postgresql/current/data -l /ihome/db/postgresql/current/pg.start.log stop 安装所有扩展包123cd /ihome/db/postgresql/build/postgresql-9.5.0/contribls -d */ | xargs -n 1 -P 0 sh -c 'cd &#123;&#125;; make ; make install;' 哈哈，就一条命令，就可以执行所有的扩展包的安装啦。*nix的工具，真的是神器….大爱.]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]Java -XX:+PrintFlagsFinal命令行参数详解]]></title>
    <url>%2F2016%2F01%2F11%2F%E7%BF%BB%E8%AF%91-Java-XX-PrintFlagsFinal%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文出处 可能要翻墙…你懂的… 昨天在Google了一些与GC调优相关的资料后, 我无意中发现一些JVM标识是我从来没有见到过的. -XX:+PrintFlagsFinal 所以,我尝试了一下我能想到的最简单的Java命令: java -XX:+PrintFlagsFinal -version 我不打算贴出这条命令的输出结果, 因为它几乎有700多行. 除了打印标准版本的信息之外,它还可以打印一个几乎是你JDK构建的版本的所有JVM参数列表,它是一个拥有5列的表格, 这是我这篇文章所要讲解的. Type | Name | Operator | Value | Application 来看单个参数的例子 123java -XX:+PrintFlagsFinal -version | grep UseConcMarkSweepGCbool UseConcMarkSweepGC := true &#123;product&#125; 你可以看到 boolean 标识, UseConcMarkSweepGC, 它的值被修改为 true 并且它适用于所有情况. 利用一些 *nix 魔术, 我们可以看到每一列的唯一的值 12345678910java -XX:+PrintFlagsFinal -version | awk '&#123;if (NR!=1) &#123;print $1&#125;&#125;' | sort | uniqboolccstrccstrlistdoubleintintxuint64_tuintx 这些类型(type列)是自解释的. 修改上面的命令中的$1为$2,你会获取所有可用的没带有想着元信息的标识名. 继续修改为$3, 结果只有以下两行 12:== :=意味着值是被修改的, =表示默认值. 只获取唯一值的列表是没什么用的, 所以我会继续用一个特定的适用的参数. 由于空格是不规则的, 我们需要一个稍微不同的方式: 123456789101112java -XX:+PrintFlagsFinal -version | awk -F '\\&#123;' '&#123;if(NR!=1) &#123;print "\&#123;"$2&#125;&#125;' | sort | uniq&#123;C1 pd product&#125;&#123;C1 product&#125;&#123;C2 diagnostic&#125;&#123;C2 pd product&#125;&#123;C2 product&#125;&#123;lp64_product&#125;&#123;manageable&#125;&#123;pd product&#125;&#123;product rw&#125;&#123;product&#125; 这些目录是由 复合标识符 来描述一个给定的标识符的适用情况.在进行一些深入挖掘后, 我在源码里发现它们的意思 product – 官方支持, JVM内部选项 rw – 可动态写入的. C1 – Client JIT 编译器 C2 – Server JIT 编译器 pd – platform Dependent 平台独立 lp64 – 仅 64 位JVM manageable – 外部定义的并且是可动态写入的. diagnostic – 用于虚拟机debug的 experimental – 非官方支持的 有了这些新知识, 你可以开始看看client与server虚拟机的不同之处: 12345678910111213141516171819202122232425262728293031323334353637diff &lt;(java -XX:+PrintFlagsFinal -server -version) &lt;(java -XX:+PrintFlagsFinal -client -version)&lt; bool CMSCleanOnEnter = true &#123;product&#125;&gt; bool CMSCleanOnEnter = false &#123;product&#125;&lt; uintx ConcGCThreads = 0 &#123;product&#125;&gt; uintx ConcGCThreads = 2 &#123;product&#125;&lt; uintx InitialHeapSize := 268435456 &#123;product&#125;&gt; uintx InitialHeapSize = 0 &#123;product&#125;&lt; uintx MaxHeapSize := 4294967296 &#123;product&#125;&gt; uintx MaxHeapSize = 132120576 &#123;product&#125;&lt; uintx MaxNewSize = 18446744073709486080&#123;product&#125;&gt; uintx MaxNewSize := 174456832 &#123;product&#125;&lt; intx MaxTenuringThreshold = 15 &#123;product&#125;&gt; intx MaxTenuringThreshold := 4 &#123;product&#125;&lt; intx NewRatio = 2 &#123;product&#125;&lt; uintx NewSize = 1310720 &#123;product&#125;&gt; intx NewRatio := 7 &#123;product&#125;&gt; uintx NewSize := 21757952 &#123;product&#125;&lt; uintx OldPLABSize = 1024 &#123;product&#125;&gt; uintx OldPLABSize := 16 &#123;product&#125;&lt; uintx OldSize = 5439488 &#123;product&#125;&gt; uintx OldSize := 65404928 &#123;product&#125;&lt; bool ParGCUseLocalOverflow = false &#123;product&#125;&gt; bool ParGCUseLocalOverflow = true &#123;product&#125;&lt; uintx ParallelGCThreads := 8 &#123;product&#125;&gt; uintx ParallelGCThreads = 8 &#123;product&#125;&lt; bool UseAdaptiveSizePolicy = true &#123;product&#125;&gt; bool UseAdaptiveSizePolicy = false &#123;product&#125;&lt; bool UseConcMarkSweepGC = false &#123;product&#125;&gt; bool UseConcMarkSweepGC := true &#123;product&#125;&lt; bool UseParNewGC = false &#123;product&#125;&gt; bool UseParNewGC := true &#123;product&#125;&lt; bool UseParallelGC := true &#123;product&#125;&gt; bool UseParallelGC = false &#123;product&#125;&lt; uintx YoungPLABSize = 4096 &#123;product&#125;&gt; uintx YoungPLABSize = 1024 &#123;product&#125; 或者在我的例子里, 我可以看到当-XX:+AggressiveOpts参数设置时,导致的参数更改. 这是在Google搜索时使我使用了这条途径: 12345678910111213141516diff &lt;(java -XX:+PrintFlagsFinal -XX:+AggressiveOpts -version) &lt;(java -XX:+PrintFlagsFinal -version) | grep "&gt;\|&lt;"&lt; bool AggressiveOpts := true &#123;product&#125;&gt; bool AggressiveOpts = false &#123;product&#125;&lt; intx AutoBoxCacheMax = 20000 &#123;C2 product&#125;&gt; intx AutoBoxCacheMax = 128 &#123;C2 product&#125;&lt; intx BiasedLockingStartupDelay = 500 &#123;product&#125;&gt; intx BiasedLockingStartupDelay = 4000 &#123;product&#125;&lt; bool EliminateAutoBox = true &#123;C2 diagnostic&#125;&gt; bool EliminateAutoBox = false &#123;C2 diagnostic&#125;&lt; bool OptimizeFill = true &#123;C2 product&#125;&lt; bool OptimizeStringConcat = true &#123;C2 product&#125;&gt; bool OptimizeFill = false &#123;C2 product&#125;&gt; bool OptimizeStringConcat = false &#123;C2 product&#125;&lt; bool UseFPUForSpilling = true &#123;C2 product&#125;&gt; bool UseFPUForSpilling = false &#123;C2 product&#125; 要切记的是 AggressiveOpts 参数在每一个Java的minor(次)版本中都可能是不同的. 后记以上的命令, 我自己也亲自运行了一次, 都是可以执行的. 实践才出真知, 不然翻译出来, 别人发现运行不了这些命令就不好了. 注意, 以上的命令是基于*nix系统的.在我的Mac上的例子如下: 12345678910111213141516171819yangzhiyong@yangzhiyongdeMacBook-Pro:~&gt; diff &lt;(java -XX:+PrintFlagsFinal -XX:+AggressiveOpts -version) &lt;(java -XX:+PrintFlagsFinal -version) | grep "&gt;\|&lt;"java version "1.8.0_31"Java(TM) SE Runtime Environment (build 1.8.0_31-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.31-b07, mixed mode)java version "1.8.0_31"Java(TM) SE Runtime Environment (build 1.8.0_31-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.31-b07, mixed mode)&lt; bool AggressiveOpts := true &#123;product&#125;&gt; bool AggressiveOpts = false &#123;product&#125;&lt; intx AutoBoxCacheMax = 20000 &#123;C2 product&#125;&gt; intx AutoBoxCacheMax = 128 &#123;C2 product&#125;&lt; intx BiasedLockingStartupDelay = 500 &#123;product&#125;&gt; intx BiasedLockingStartupDelay = 4000 &#123;product&#125;&lt; bool UseFPUForSpilling = true &#123;C2 product&#125;&gt; bool UseFPUForSpilling = false &#123;C2 product&#125;yangzhiyong@yangzhiyongdeMacBook-Pro:~&gt; java -XX:+UnlockExperimentalVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal：这条命令可以解放隐藏的参数。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境部署Tomcat配置]]></title>
    <url>%2F2016%2F01%2F11%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2Tomcat%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[操作系统设置limit123456789101112131415161718╭─sky@sky-linux ~╰─➤ ulimit -a-t: cpu time (seconds) unlimited-f: file size (blocks) unlimited-d: data seg size (kbytes) unlimited-s: stack size (kbytes) 8192-c: core file size (blocks) 0-m: resident set size (kbytes) unlimited-u: processes 63555-n: file descriptors 1024-l: locked-in-memory size (kbytes) 64-v: address space (kbytes) unlimited-x: file locks unlimited-i: pending signals 63555-q: bytes in POSIX msg queues 819200-e: max nice 0-r: max rt priority 0-N 15: unlimited 会话级别如果不想全局设置limit，可以在会话级别设置，即在启动程序之前，设置好limit后再启动程序 12345678# 硬设置ulimit -Hc unlimitedulimit -Hn 65535# 软设置ulimit -Sc unlimitedulimit -Sn 65535 全局设置limit编辑 /etc/security/limits.conf 文件.添加或修改为如下 1234* soft core unlimited* hard core unlimited* soft nofile 65535* hard nofile 65535 Tomcat自身设置统一UTF-81&lt;Connector port="8095" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" URIEncoding="UTF-8" useBodyEncodingForURI="true"/&gt; 关闭 auto-deploy1&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="false"&gt; Tomcat线程池 threadPriority： 线程的优先级 minSpareThreads：最小一定存活线程数，这个是会一直保持的，默认为25 maxThreads: 最大同时存活线程数，默认为200 daemon：是否是守护线程，默认为true. maxIdleTime： 最大空闲时间，单位是毫秒。即线程达到了这个时间后，就会shutdown，直到线程数达到了minSpareThreads数. maxQueueSize：最大任务队列数。默认值为Integer.MAX_VALUE prestartminSpareThreads： 启动时，是否初化minSpareThreads的线程。默认为false. threadRenewalDelay: 重建线程池的线程的时间间隔。（前提是配置了ThreadLocalLeakPreventionListener。 默认为1000ms。如果为负，则不重建. namePrefix：线程名前的前缀 1&lt;Executor name="tomcatThreadPool" namePrefix="mytomcat-exec-" maxThreads="150" minSpareThreads="4"/&gt; 然后在Connector里配置使用线程池 1&lt;Connector port="8095" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" URIEncoding="UTF-8" useBodyEncodingForURI="true" executor="tomcatThreadPool" /&gt; Tomcat文档 JVM 配置1234567891011121314151617181920212223#!/bin/shJVM_TYPE = " -server"JVM_GC=" -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xloggc:/tmp/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M"JVM_DUMP=" -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/jvm-dump-`date`.hprof"JVM_GC_TYPE=" -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=90 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark"# 单位：秒JVM_DNS_CACHE=" -Dsun.net.inetaddr.ttl=60"# hostname如果为远程，则是外网的IPJVM_RMI=" -Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote.port=8888 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"# survivorratio = eden / from 的比值JVM_MEM=" -Xms512m -Xmx1024m -XX:PermSize=512m -XX:MaxPermSize=1024m -Xmn300m -XX:SurvivorRatio=8"JVM_DEBUG=" -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n"CATALINA_OPTS=" -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager $&#123;JVM_TYPE&#125; $&#123;JVM_GC_TYPE&#125; $&#123;JVM_GC&#125; $&#123;JVM_DUMP&#125; $&#123;JVM_DNS_CACHE&#125; $&#123;JVM_RMI&#125; $&#123;JVM_MEM&#125; $&#123;JVM_DEBUG&#125; "]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>server</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx添加免费SSL]]></title>
    <url>%2F2016%2F01%2F11%2FNginx%E6%B7%BB%E5%8A%A0%E5%85%8D%E8%B4%B9SSL%2F</url>
    <content type="text"><![CDATA[前提条件： 你的Nginx要有--with-http_ssl_module（即HTTPS模块） 申请免费HTTPS证书Go Instantssl 步骤提交你的CSR CSR: CSR是一个证书签名请求，是客户的服务器软件所生成的一串文本字符。客户在注册的过程中首先要在WEB服务器上生成CSR，并把这串字符提供给证书认证中心。CSR包括以下内容：a) 您的组织信息（组织名称、国家等等）, b) 您的Web服务器的域名等 生成申请的CSR文件命令: openssl req -new -nodes -keyout server.key -out server.csr 示例： 123456789101112131415161718192021222324252627╭─sky@sky-linux /tmp╰─➤ openssl req -new -nodes -keyout server.key -out server.csrGenerating a 2048 bit RSA private key..................................+++..............................................................+++writing new private key to 'server.key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [AU]:CNState or Province Name (full name) [Some-State]:GuangDongLocality Name (eg, city) []:GuangZhouOrganization Name (eg, company) [Internet Widgits Pty Ltd]:yourcompanyOrganizational Unit Name (eg, section) []:R and DCommon Name (e.g. server FQDN or YOUR name) []:emacsist.github.io （注意，这里最好写 xxx.xxx 的域名，不要包括二级子域名）Email Address []:your@email.comPlease enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []:╭─sky@sky-linux /tmp 说明 字段说明 示例 Country Name | ISO国家代码（两位字符）| CN |State or Province Name | 所在省份 | Guangdong |Locality Name | 所在城市 | Guangzhou |Organization Name | 公司名称 | 你的公司名 |Organizational Unit Name | 部门名称 | R and D |Common Name | 申请证书的域名 | emacsist.github.io |Email Address | 邮箱地址 | 可以不输入 |A challenge password | 密码 | 可以不输入 | 执行完毕后，就将server.csr这个文件的内容，复制到: 123ree SSL Certificate 90 daysStep 1: Provide your CSR 这个表单的输入框里. 选择你的服务器类型12. Select the server software used to generate the CSR: 这里我们选择nginx，这个看你服务器使用的类型. 选择你的加密算法13. Select the hash algorithm you would prefer us to use when signing your Certificate: 我们选择SHA-2，这个看你自己的需求啦. 然后Next 输入其他详细信息省略…（按要求输入即可，这里个有用户名和密码等信息，用于登录下载证书等） 验证你的网站拥有权这个步骤，它会发送一个验证码封邮件到你的域名邮箱里（注册域名时的那个邮箱地址），然后获取验证码，再粘贴到验证框里即可。 这样子，证书的申请就完毕了，等待审核结果。通过的话，就继续往下看： 证书配置如果上面的申请审核通过后，你就可以登录该网站，去下载你的证书文件，下载回来后，解压后会有四个crt文件，然后进行以下操作: 1cat www_yourdomain_com.crt COMODORSADomainValidationSecureServerCA.crt COMODORSAAddTrustCA.crt AddTrustExternalCARoot.crt &gt; ssl-bundle.crt 然后将这个ssl-bundle.crt和server.key复制到你的服务器上，进行nginx配置即可。 注意，因为我这申请的是个人免费的证书，其他类型的证书可能操作上会有所不同，请参考以下资料 nginx 安装 证书步骤 配置 Nginx将以下配置，复制到你的站点配置里即可： 12345678910111213141516server &#123;listen 443;server_name mysite.com;ssl on;# 下面两个地址改为你的证书的正确位置ssl_certificate /etc/ssl/certs/ssl-bundle.crt;ssl_certificate_key /etc/ssl/private/mysite.key;#enables all versions of TLS, but not SSLv2 or 3 which are weak and now deprecated.ssl_protocols TLSv1 TLSv1.1 TLSv1.2;#Disables all weak ciphersssl_ciphers "ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4";ssl_prefer_server_ciphers on;&#125; 重启nginx，即可. 存在问题如果你的站点存在有外站的URL，就会导致HTTPS混合HTTP的问题。 如果有好的解决方案，也可以留言给我，谢谢。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
        <tag>ssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]SQL 中各种join]]></title>
    <url>%2F2016%2F01%2F07%2F%E8%BD%AC-SQL-%E4%B8%AD%E5%90%84%E7%A7%8Djoin%2F</url>
    <content type="text"><![CDATA[一图胜千言 来源stackoverflow.com]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>java</tag>
        <tag>sql</tag>
        <tag>join</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL获取分组后每组最大的数据]]></title>
    <url>%2F2016%2F01%2F07%2FMySQL%E8%8E%B7%E5%8F%96%E5%88%86%E7%BB%84%E5%90%8E%E6%AF%8F%E7%BB%84%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[需求获取分组后每组数据中，ID最大的数据 表数据table: hhh 12345678id name1 hello2 hello13 hello24 hello5 hello26 hello37 hello1 想要的结果12345id name4 hello5 hello26 hello37 hello1 SQL实现1123select * from hhh where id in ( SELECT substring_index(group_concat(id order by id desc SEPARATOR ','),",",1) from hhh GROUP BY name); 这个比较灵活，可以在group by 后，再按结果集里的再进行自己想要的字段排序等。 这个可以自由实现获取分组后，第N大的数据。比如，分组后，第N大的数据： 123select * from hhh where id in ( SELECT substring_index(substring_index(group_concat(id order by id desc SEPARATOR ','),",",N), ",",-1) from hhh GROUP BY name); 将N改为你自己想要的数字即可. 实现2123SELECT * from hhh WHERE id in ( select max(id) from hhh GROUP BY name); 这种只能实现最大，或者最小。]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
        <tag>group by</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 以另一张表的值来设置某表的值]]></title>
    <url>%2F2016%2F01%2F07%2FSQL-%E4%BB%A5%E5%8F%A6%E4%B8%80%E5%BC%A0%E8%A1%A8%E7%9A%84%E5%80%BC%E6%9D%A5%E8%AE%BE%E7%BD%AE%E6%9F%90%E8%A1%A8%E7%9A%84%E5%80%BC%2F</url>
    <content type="text"><![CDATA[需求表1table: h112345id name1 hello12 hello23 hello114 hello22 表2table: h2 12345678h1_id name1213324 想要的结果12345678h1_id name1 hello12 hello21 hello13 hello113 hello112 hello24 hello22 SQLMySQL1UPDATE h2 INNER JOIN h1 on h1.id = h2.h1_id set h2.name = h1.name; PostgreSQL1update h2 set name = h1.name from h1 where h1.id = h1_id; 注意，在PostgreSQL里，不能写成 1update h2 set h2.name = h1.name from h1 where h1.id = h2.h1_id; 对于h2的列，要直接写成name，而不是h2.name，否则就会报如下错误: 12345postgres=# update h2 set h2.name = h1.name from h1 where h1.id = h2.h1_id;ERROR: column "h2" of relation "h2" does not existLINE 1: update h2 set h2.name = h1.name from h1 where h1.id = h2.h1_... ^postgres=# 注意事项如果是想update全表，并且数据量非常大的话，可以采取分而治之的方法。比如：一次update 1000条，如此下去。比如： MySQL1UPDATE h2 INNER JOIN h1 on h1.id = h2.h1_id set h2.name = h1.name where h2.h1_id &gt;=0 and h2.h1_id &lt;= 1000; PostgreSQL1update h2 set name = h1.name from h1 where h1.id = h1_id and h1_id &gt;=0 and h1_id &lt;= 1000;]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Thread中的线程执行控制]]></title>
    <url>%2F2016%2F01%2F05%2FJava-Thread%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%89%A7%E8%A1%8C%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[join是Thread对象里的方法.签名如下: 123public final void join() throws InterruptedException &#123; join(0);&#125; 它的作用是: 当某个Thread调用join方法时，其他线程，必须要等待这个线程(即调用join的线程）运行完毕（正常执行完，或者抛出异常，但它不会影响其他线程正常执行），才能继续执行. Talk is cheap , show me the code.12345678910111213141516171819202122232425262728293031323334353637 public static void main(String[] args) throws InterruptedException &#123; MyThread t1 = new MyThread(); t1.setName("t1--thread"); t1.start(); t1.join(); MyThread t2 = new MyThread(); t2.setName("t2--thread"); t2.start(); t2.join(); Thread.sleep(1 * 1000); MyThread t3 = new MyThread(); t3.setName("t3--thread"); t3.start(); t3.join(); &#125; public static class MyThread extends Thread &#123; @Override public void run() &#123; int i = 5; while (i-- &gt; 0) &#123; System.out.println("in thread " + Thread.currentThread().getName()); try &#123; Thread.sleep(1*1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;// if( i == 4 &amp;&amp; Thread.currentThread().getName().equalsIgnoreCase("t1--thread"))&#123;// throw new RuntimeException("error for t1--thread");// &#125; &#125; &#125; &#125; 它的执行结果是: 1234567891011121314151617in thread t1--threadin thread t1--threadin thread t1--threadin thread t1--threadin thread t1--threadin thread t2--threadin thread t2--threadin thread t2--threadin thread t2--threadin thread t2--threadin thread t3--threadin thread t3--threadin thread t3--threadin thread t3--threadin thread t3--threadProcess finished with exit code 0 如果中间线程出现异常时: 123456789101112131415in thread t1--threadException in thread "t1--thread" java.lang.RuntimeException: error for t1--thread at com.spring.pojo.BasePojo$MyThread.run(BasePojo.java:117)in thread t2--threadin thread t2--threadin thread t2--threadin thread t2--threadin thread t2--threadin thread t3--threadin thread t3--threadin thread t3--threadin thread t3--threadin thread t3--threadProcess finished with exit code 0 可以看到，第一条线程的异常，并不会影响其他线程的执行. 延伸CountDownLatch这个是某条线程，等待 CountDownLatch 计数完毕后才执行.注意，这个计数器是不能重用的. code: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public static void main(String[] args) throws InterruptedException &#123; final int COUNT = 3; CountDownLatch countDownLatch = new CountDownLatch(COUNT); for(int i=0; i&lt;COUNT; i++)&#123; new MyThread(countDownLatch).start(); &#125; MyCountDownLatch myCountDownLatch = new MyCountDownLatch(countDownLatch); myCountDownLatch.start(); &#125; public static class MyCountDownLatch extends Thread&#123; CountDownLatch countDownLatch; public MyCountDownLatch(CountDownLatch countDownLatch)&#123; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; try &#123; //等待计数器变成0,它会一直阻塞，直到计数器为0 countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.printf("wait for other thread finish."); &#125; &#125; public static class MyThread extends Thread &#123; CountDownLatch countDownLatch; public MyThread(CountDownLatch countDownLatch)&#123; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; int i = 5; while (i-- &gt; 0) &#123; System.out.println("in thread " + Thread.currentThread().getName()); try &#123; Thread.sleep(1*1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //将计数器减1 countDownLatch.countDown(); &#125; &#125; 执行结果如下: 1234567891011121314151617in thread Thread-0in thread Thread-1in thread Thread-2in thread Thread-0in thread Thread-1in thread Thread-2in thread Thread-0in thread Thread-1in thread Thread-2in thread Thread-0in thread Thread-1in thread Thread-2in thread Thread-0in thread Thread-1in thread Thread-2wait for other thread finish.Process finished with exit code 0 CyclicBarrier 它是一个可重用的计数器屏障。 它有两个构造函数: 构造函数一 它表示parties条线程都到达某个状态时，就执行barrierAction线程的内容. 123456public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;&#125; 构造函数二 它表示parties条线程都到达某个状态时，什么也不执行（可以看到，调用第一个构造函数，并且第二人Runnable的参数为null） 123public CyclicBarrier(int parties) &#123; this(parties, null);&#125; 例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static void main(String[] args) throws InterruptedException, BrokenBarrierException &#123; final int COUNT = 3; CyclicBarrier cyclicBarrier = new CyclicBarrier(COUNT, new Runnable() &#123; @Override public void run() &#123; System.out.println("all done."); &#125; &#125;); for (int i = 0; i &lt; COUNT; i++) &#123; new MyThread(cyclicBarrier).start(); &#125;&#125;public static class MyThread extends Thread &#123; CyclicBarrier cyclicBarrier; public MyThread(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println("in thread " + Thread.currentThread().getName()); try &#123; int j = new Random().nextInt(10); System.out.println("thread " + Thread.currentThread().getName() + " sleep " + j + " s"); Thread.sleep(j * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //通知 CyclicBarrier 该线程已经完成（或者说到了状态），等待其他线程到达了这个状态，再继续执行. System.out.println("thread " + Thread.currentThread().getName() + " done."); try &#123; //这个表示无限等待，等其他所有线程都完毕后，才能继续执行下面的. cyclicBarrier.await(); //，还有个重载方法：它表示通知 CyclicBarrier，它已经到达了某状态，再等1分钟，然后就继续执行下面的方法体了. //cyclicBarrier.await(1, TimeUnit.MINUTES); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行的结果如下: 123456789101112in thread Thread-0in thread Thread-1thread Thread-0 sleep 8 sthread Thread-1 sleep 4 sin thread Thread-2thread Thread-2 sleep 9 sthread Thread-1 done.thread Thread-0 done.thread Thread-2 done.all done.Process finished with exit code 0 可用重例子1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public static void main(String[] args) throws InterruptedException, BrokenBarrierException &#123; final int COUNT = 3; CyclicBarrier cyclicBarrier = new CyclicBarrier(COUNT, new Runnable() &#123; @Override public void run() &#123; System.out.println("all done."); &#125; &#125;); for (int i = 0; i &lt; COUNT; i++) &#123; new MyThread(cyclicBarrier).start(); &#125; //让上面的先执行，然后再重用 cyclicBarrier Thread.sleep(1*1000); for (int i = 0; i &lt; COUNT; i++) &#123; new MyThread(cyclicBarrier).start(); &#125;&#125;public static class MyThread extends Thread &#123; CyclicBarrier cyclicBarrier; public MyThread(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println("in thread " + Thread.currentThread().getName()); try &#123; int j = new Random().nextInt(10); System.out.println("thread " + Thread.currentThread().getName() + " sleep " + j + " s"); Thread.sleep(j * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //通知 CyclicBarrier 该线程已经完成（或者说到了状态），等待其他线程到达了这个状态，再继续执行. System.out.println("thread " + Thread.currentThread().getName() + " done."); try &#123; //这个表示无限等待，等其他所有线程都完毕后，才能继续执行下面的. cyclicBarrier.await(); //，还有个重载方法：它表示通知 CyclicBarrier，它已经到达了某状态，再等1分钟，然后就继续执行下面的方法体了. //cyclicBarrier.await(1, TimeUnit.MINUTES); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果如下: 12345678910111213141516171819202122in thread Thread-0in thread Thread-1in thread Thread-2thread Thread-0 sleep 4 sthread Thread-1 sleep 0 sthread Thread-2 sleep 6 sthread Thread-1 done.in thread Thread-3thread Thread-3 sleep 3 sin thread Thread-4thread Thread-4 sleep 0 sthread Thread-4 done.in thread Thread-5thread Thread-5 sleep 6 sthread Thread-0 done.all done.thread Thread-3 done.thread Thread-2 done.thread Thread-5 done.all done.Process finished with exit code 0 可以看到，CountDownLatch只保证(执行构造函数里的Runnable线程之前，肯定是有3条线程执行完毕的)。如此循环. Semaphore 即信号量，通过 acquire() 方法获得使用资源的权限，通过 release() 方法释放资源占用. 例如，网吧只有5台电脑，但有10个人要上网。这样子，我们就可以用Semaphore来模拟这种情况，代码如下: 123456789101112131415161718192021222324252627282930313233343536public static void main(String[] args) throws InterruptedException, BrokenBarrierException &#123; //只有 5台电脑 final int COUNT = 5; final int PERSON = 10; final Semaphore semaphore = new Semaphore(COUNT, true); for (int i = 0; i &lt; PERSON; i++) &#123; new MyThread(semaphore).start(); &#125;&#125;public static class MyThread extends Thread &#123; Semaphore semaphore; public MyThread(final Semaphore semaphore) &#123; this.semaphore = semaphore; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); int time = new Random().nextInt(10); System.out.println("小混混 " + Thread.currentThread().getName() + " 要使用电脑" + time + "小时 正在使用电脑"); Thread.sleep(time * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); System.out.println("小混混 " + Thread.currentThread().getName() + " 用完了电脑"); &#125; &#125;&#125; 执行结果如下: 12345678910111213141516171819202122小混混 Thread-0 要使用电脑1小时 正在使用电脑小混混 Thread-1 要使用电脑9小时 正在使用电脑小混混 Thread-2 要使用电脑2小时 正在使用电脑小混混 Thread-3 要使用电脑6小时 正在使用电脑小混混 Thread-4 要使用电脑9小时 正在使用电脑小混混 Thread-0 用完了电脑小混混 Thread-5 要使用电脑2小时 正在使用电脑小混混 Thread-2 用完了电脑小混混 Thread-6 要使用电脑8小时 正在使用电脑小混混 Thread-5 用完了电脑小混混 Thread-7 要使用电脑8小时 正在使用电脑小混混 Thread-3 用完了电脑小混混 Thread-8 要使用电脑9小时 正在使用电脑小混混 Thread-1 用完了电脑小混混 Thread-9 要使用电脑5小时 正在使用电脑小混混 Thread-4 用完了电脑小混混 Thread-6 用完了电脑小混混 Thread-7 用完了电脑小混混 Thread-9 用完了电脑小混混 Thread-8 用完了电脑Process finished with exit code 0]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP 学习]]></title>
    <url>%2F2016%2F01%2F05%2FSpring-AOP-%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[AOP 面向切面编程.百度百科里的定义是：在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 在Spring中使用AOP定义一个组件1234567891011121314package com.spring.service.aop;import org.springframework.stereotype.Component;/** * Created by sky on 16-1-5. */@Componentpublic class Hello &#123; public String sayHello()&#123; return "hello world from hello"; &#125;&#125; 组件的使用123456@Autowiredprivate Hello hello;public String index() &#123; return hello.sayHello();&#125; 在其他组件中，调用Hello组件. 使用AOP进行无侵入记录调用Hello.sayHello的日志12345678910111213141516171819package com.spring.service.aop;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Aspect;import org.springframework.stereotype.Component;/** * Created by sky on 16-1-5. */@Aspect@Componentpublic class HelloAop &#123; @After("execution(* com.spring.service.aop.Hello.sayHello() )") public void sayAfter()&#123; System.out.println("aop after sayHello"); &#125;&#125; Spring配置123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:task="http://www.springframework.org/schema/task" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:p="http://www.springframework.org/schema/p" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd"&gt; &lt;context:annotation-config /&gt; &lt;context:component-scan base-package="com.spring" /&gt; &lt;!-- 使用CGLIB 方式进行代理，这样子可以在普通类上，也可以进行切入，而不需要接口--&gt; &lt;aop:aspectj-autoproxy proxy-target-class="true" /&gt;&lt;/beans&gt; 当其他组件调用Hello.sayHello时，就会打印出如下文本: 1aop after sayHello 注意事项 要切入的组件（Hello.sayHello()) 必须是Spring接管的（这里使用了@Component，让Spring扫描到，然后放到BeanFactory里） AOP的用途上面的例子，只是简单的记录下日志，那AOP最常见的用途是什么呢？在Spring里，最常用的，可能是声明式事务了，即(@Transactional)这个注解。 实现声明式事务定义一个事务注解1234567891011121314package com.spring.aop;import java.lang.annotation.*;/** * Created by sky on 16-1-5. */@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface MyTransactional &#123;&#125; 定义一个DB Service1234567891011121314151617181920212223242526272829package com.spring.aop;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import javax.sql.DataSource;import java.sql.Connection;import java.sql.SQLException;/** * Created by sky on 16-1-5. */@Componentpublic class MyService &#123; @Autowired private DataSource dataSource; @MyTransactional public void doDB(String hello) throws SQLException &#123; Connection connection = TransactionAOP.connectionThreadLocal.get(); if(connection==null)&#123; connection = dataSource.getConnection(); TransactionAOP.connectionThreadLocal.set(connection); &#125; // do with connection. System.out.println("update db for table " + hello); &#125;&#125; 定义一个事务的AOP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.spring.aop;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import javax.sql.DataSource;import java.sql.Connection;import java.sql.SQLDataException;import java.sql.SQLException;/** * Created by sky on 16-1-5. */@Aspect@Componentpublic class TransactionAOP &#123; @Pointcut("@annotation(com.uniweibov2.aop.MyTransactional)") public void transactionPointCut() &#123; &#125; @Autowired private DataSource dataSource; private static final ThreadLocal&lt;Connection&gt; connectionThreadLocal = new ThreadLocal&lt;&gt;(); @Before("transactionPointCut()") public void doTransaction() throws SQLException &#123; Connection connection = connectionThreadLocal.get(); if (connection == null) &#123; connection = dataSource.getConnection(); connectionThreadLocal.set(connection); &#125; connection.setAutoCommit(false); System.out.println("开启事务"); &#125; @After("transactionPointCut()") public void commit() throws SQLException &#123; Connection connection = connectionThreadLocal.get(); if (connection != null) &#123; connection.commit(); connection.close(); System.out.println("提交事务，并关闭连接"); &#125; else &#123; throw new SQLDataException("connection is closed ..."); &#125; &#125;&#125; Controller 层使用Db service123456@RequestMapping("/index")public String index() throws SQLException &#123; myService.doDB("[hello world]"); return "hello";&#125; 执行结果如下: 123开启事务update db for table [hello world]提交事务，并关闭连接 这样子，我们就完成了一个简单的声明式事务管理啦.当然，还有很多要完善的地方，这里只是演示下，如何实现.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL设置wait_timeout注意事项]]></title>
    <url>%2F2016%2F01%2F04%2FMySQL%E8%AE%BE%E7%BD%AEwait-timeout%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[wait_timeout 是服务器等待客户端多久没有活动时，就关闭连接的时间，单位是秒. 查看1234567891011121314151617181920212223242526272829303132333435363738394041424344-- global levelmysql&gt; show global variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 120 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 28800 |+-----------------------------+----------+12 rows in set (0.00 sec)-- session levelmysql&gt; show variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 120 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 120 |+-----------------------------+----------+12 rows in set (0.00 sec)mysql&gt; 有global时，是查看全局，没有global时，是查看session级别. 设置全局wait_timeout1234mysql&gt; set global wait_timeout = 280000;Query OK, 0 rows affected (0.00 sec)mysql&gt; 开启新会话，再查看: 1234567891011121314151617181920212223242526272829303132333435363738394041424344-- session levelmysql&gt; show variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 120 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 120 |+-----------------------------+----------+12 rows in set (0.01 sec)-- global levelmysql&gt; show global variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 120 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 280000 |+-----------------------------+----------+12 rows in set (0.00 sec)mysql&gt; 这里奇怪的是，为什么新会话的wait_timieout会话级别的值，不是之前设置的全局变量的值。 原因查看了一下官方文档，如下: On thread startup, the session wait_timeout value is initialized from the global wait_timeout value or from the global interactive_timeout value, depending on the type of client (as defined by the CLIENT_INTERACTIVE connect option to mysql_real_connect()). See also interactive_timeout. 大意是说: wait_timeout的会话初始值，根据mysql客户端的类型不同，而选择使用全局 wait_timeout的值，或者使用全局 interactive_timeout 的值. global wait_timeout： 是指那些非交互式的客户端，比如用JDBC连接的。global interactive_timeout： 是指那些交互式的客户端，比如使用了命令行的mysql. 这就可以理解这里为什么我们的会话级别的wait_timeout的初始值，不是我们之前设置的280000，而是120了。因为全局的interactive_timeout=120，而我们又是使用交互式客户端。 设置如果想让MySQL无论从哪种客户端都能让wait_timeout一致，那就要同时设置global wait_timeout和global interactive_timeout了。例如: 1234567mysql&gt; set global wait_timeout = 280000;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global interactive_timeout = 280000;Query OK, 0 rows affected (0.00 sec)mysql&gt; 这样了，新打开的会话的wait_timeout就会是280000了.如： 1234567891011121314151617181920212223-- session levelmysql&gt; show variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 280000 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 280000 |+-----------------------------+----------+12 rows in set (0.00 sec)mysql&gt;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java使用Javassist修改class文件]]></title>
    <url>%2F2015%2F12%2F31%2FJava%E4%BD%BF%E7%94%A8Javassist%E4%BF%AE%E6%94%B9class%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[修改方法12345678910111213141516package org.test;/** * Created by sky on 15-12-31. */public class Bool &#123; public static void main(String[] args) throws InterruptedException &#123; new Bool().run(); &#125; public void run() throws InterruptedException &#123; Thread.sleep(1000 * 5); System.out.println("default"); &#125;&#125; 为方法前后添加性能统计时间12345678910111213141516171819202122232425262728293031323334353637383940414243package org.javassist.demo;import javassist.*;import java.io.IOException;/** * Created by sky on 15-12-31. */public class ReadByteCode &#123; public static void main(String[] args) throws NotFoundException, CannotCompileException, IOException &#123; ClassPool classPool = ClassPool.getDefault(); classPool.importPackage("org.test"); CtClass ctClass = null; try &#123; ctClass = classPool.get("org.test.Bool"); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; CtMethod[] methods = ctClass.getDeclaredMethods(); for (int i = 0; i &lt; methods.length; i++) &#123; CtMethod method = methods[i]; String methodName = method.getName(); String oldMethodName = methodName + "$$old"; if (!"main".equalsIgnoreCase(methodName)) &#123; CtMethod newMehtod = CtNewMethod.copy(method, ctClass, null); method.setName(oldMethodName); StringBuilder sb = new StringBuilder(100); sb.append("&#123;\nlong s = System.currentTimeMillis();\n"); sb.append(oldMethodName + "($$);\n"); sb.append("System.out.println(\"Call to method " + methodName + " took \" +\n (System.currentTimeMillis()-s) + " + "\" ms.\");\n"); sb.append("&#125;"); newMehtod.setBody(sb.toString()); newMehtod.setName(methodName); ctClass.addMethod(newMehtod); &#125; &#125; ctClass.writeFile("/tmp/hello"); &#125;&#125; 运行完后，就可以看到/tmp/hello目录下有个class文件了，如下: 1234567└─[0] &lt;&gt; tree /tmp/hello/tmp/hello└── org └── test └── Bool.class2 directories, 1 file 运行结果如下: 123└─[0] &lt;&gt; java org.test.BooldefaultCall to method run took 5001 ms.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>class</tag>
        <tag>javassist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http 协议中的Range请求头例子]]></title>
    <url>%2F2015%2F12%2F29%2FHttp-%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84Range%E8%AF%B7%E6%B1%82%E5%A4%B4%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[HTTP 请求头 Range 请求资源的部分内容(不包括响应头的大小), 单位是byte,即字节,从0开始. 如果服务器能够正常响应的话，服务器会返回206 Partial Content的状态码及说明.如果不能处理这种Range的话，就会返回整个资源以及响应状态码为200 OK.（这个要注意，要分段下载时，要先判断这个） 比如：类似下面的 12345678910111213141516171819202122232425➜ /tmp curl -H "Range: bytes=0-10" http://127.0.0.1:8180/bg-upper.png -v* Hostname was NOT found in DNS cache* Trying 127.0.0.1...* Connected to 127.0.0.1 (127.0.0.1) port 8180 (#0)&gt; GET /bg-upper.png HTTP/1.1&gt; User-Agent: curl/7.35.0&gt; Host: 127.0.0.1:8180&gt; Accept: */*&gt; Range: bytes=0-10&gt;&lt; HTTP/1.1 206 Partial Content* Server Apache-Coyote/1.1 is not blacklisted&lt; Server: Apache-Coyote/1.1&lt; Accept-Ranges: bytes&lt; ETag: W/"3103-1435633968000"&lt; Last-Modified: Tue, 30 Jun 2015 03:12:48 GMT&lt; Content-Range: bytes 0-10/3103&lt; Content-Type: image/png&lt; Content-Length: 11&lt; Date: Tue, 29 Dec 2015 09:18:36 GMT&lt;PNG* Connection #0 to host 127.0.0.1 left intact➜ 响应头就是HTTP/1.1 206 Partial Content Range 请求头格式1Range: bytes=start-end 例如： Range: bytes=10-：第10个字节及最后个字节的数据Range: bytes=40-100：第40个字节到第100个字节之间的数据. 注意，这个表示[start,end]，即是包含请求头的start及end字节的，所以，下一个请求，应该是上一个请求的[end+1, nextEnd] 响应头Content-RangeContent-Range: bytes 0-10/3103 这个表示，服务器响应了前(0-10)个字节的数据，该资源一共有(3103)个字节大小。 Content-TypeContent-Type: image/png 表示这个资源的类型 Content-LengthContent-Length: 11 表示这次服务器响应了11个字节的数据（0-10） Last-ModifiedLast-Modified: Tue, 30 Jun 2015 03:12:48 GMT 表示资源最近修改的时间（分段下载时要注意这个东西，因为如果修改了，分段下载可能就要重新下载了） ETagETag: W/&quot;3103-1435633968000&quot; 这个响应头表示资源版本的标识符，通常是消息摘要(类似MD5一样）（分段下载时要注意这个东西，或者缓存控制也要注意这个东西） 注意，每种服务器对生成ETag的算法不同，这个要特别注意 如果使用分布式缓存，要特别要保证每台服务器生成的ETag算法是一致的. 缓存的过期，要同时结合(ETag + Last-Modified)这两个响应头来判断. 强ETag只要实体发生任何改变，都会改变ETag值.如: ETag: &quot;1234234234&quot; 弱ETag它在前面会有个W/，如： ETag: W/&quot;12342423&quot; 分段下载利用这个特点，我们可以使用分段下载（多线程下载，分布式下载） 思想:先请求一个HEAD方法的请求，获取总文件大小： HEAD 请求1234567891011121314151617181920212223➜ /tmp curl -X HEAD http://127.0.0.1:8180/bg-upper.png -v* Hostname was NOT found in DNS cache* Trying 127.0.0.1...* Connected to 127.0.0.1 (127.0.0.1) port 8180 (#0)&gt; HEAD /bg-upper.png HTTP/1.1&gt; User-Agent: curl/7.35.0&gt; Host: 127.0.0.1:8180&gt; Accept: */*&gt;&lt; HTTP/1.1 200 OK* Server Apache-Coyote/1.1 is not blacklisted&lt; Server: Apache-Coyote/1.1&lt; Accept-Ranges: bytes&lt; ETag: W/"3103-1435633968000"&lt; Last-Modified: Tue, 30 Jun 2015 03:12:48 GMT&lt; Content-Type: image/png&lt; Content-Length: 3103&lt; Date: Tue, 29 Dec 2015 10:16:16 GMT&lt;* transfer closed with 3103 bytes remaining to read* Closing connection 0curl: (18) transfer closed with 3103 bytes remaining to read➜ /tmp 那个响应头的Content-Length就是总字节大小了（3103）字节. 多线程下载假设分2条线程 线程1 下载12345678910111213141516171819202122232425262728293103 / 2 = 1551➜ /tmp curl -H "Range: bytes=0-1551" http://127.0.0.1:8180/bg-upper.png -v -o 0-1151.png* Hostname was NOT found in DNS cache* Trying 127.0.0.1... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Connected to 127.0.0.1 (127.0.0.1) port 8180 (#0)&gt; GET /bg-upper.png HTTP/1.1&gt; User-Agent: curl/7.35.0&gt; Host: 127.0.0.1:8180&gt; Accept: */*&gt; Range: bytes=0-1551&gt;&lt; HTTP/1.1 206 Partial Content* Server Apache-Coyote/1.1 is not blacklisted&lt; Server: Apache-Coyote/1.1&lt; Accept-Ranges: bytes&lt; ETag: W/"3103-1435633968000"&lt; Last-Modified: Tue, 30 Jun 2015 03:12:48 GMT&lt; Content-Range: bytes 0-1551/3103&lt; Content-Type: image/png&lt; Content-Length: 1552&lt; Date: Tue, 29 Dec 2015 10:19:43 GMT&lt;&#123; [data not shown]100 1552 100 1552 0 0 1376k 0 --:--:-- --:--:-- --:--:-- 1515k* Connection #0 to host 127.0.0.1 left intact➜ /tmp 这样子，线程1就下载了（0-1551）字节的数据了. 线程2 下载1234567891011121314151617181920212223242526➜ /tmp curl -H "Range: bytes=1552-3103" http://127.0.0.1:8180/bg-upper.png -v -o 1552-end.png* Hostname was NOT found in DNS cache* Trying 127.0.0.1... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Connected to 127.0.0.1 (127.0.0.1) port 8180 (#0)&gt; GET /bg-upper.png HTTP/1.1&gt; User-Agent: curl/7.35.0&gt; Host: 127.0.0.1:8180&gt; Accept: */*&gt; Range: bytes=1552&gt;&lt; HTTP/1.1 416 Requested Range Not Satisfiable* Server Apache-Coyote/1.1 is not blacklisted&lt; Server: Apache-Coyote/1.1&lt; Accept-Ranges: bytes&lt; Content-Range: bytes */3103&lt; Content-Type: text/html;charset=utf-8&lt; Content-Language: en&lt; Content-Length: 954&lt; Date: Tue, 29 Dec 2015 10:26:18 GMT&lt;&#123; [data not shown]100 954 100 954 0 0 457k 0 --:--:-- --:--:-- --:--:-- 931k* Connection #0 to host 127.0.0.1 left intact➜ /tmp 合并1cat 0-1151.png 1552-end.png &gt; filename.png 这样子就OK了. HTTP 请求头注意根据HTTP规范，HTTP的消息头部的字段名，是不区分大小写的. 3.2. Header Fields Each header field consists of a case-insensitive field name followed by a colon (“:”), optional leading whitespace, the field value, and optional trailing whitespace. RFC7230]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>tcp</tag>
        <tag>header</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 基本概念]]></title>
    <url>%2F2015%2F12%2F28%2FTomcat-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[框架图纯手工打造… 123456789 |----service1(最少要有一个service) |----service2 |------connector1(http) |---host1 |----service3 |------connector2(https) |---host2Server ----|----service4---------|------connector3（可以有多个connector，创建request,response) |---host3 |--context1 |--wrapper1 |----service5 |------container(只有一个container，负责处理servlet) ---------------Engine---|---host4-----------|--context2---|--wrapper2(即一个servlet) |----service6 |------connector4 |---host5 |--context3 |--wrapper3 |----service7 |------connector5 |---host6 后一部分，共享前一部分. Server即对应一个Tomcat实例. Service即Tomcat中提供的服务.它是由一个或多个connector共享一个container组成的. Container 或 engine一个service只能有一个container（即engine)。它处理所有的connector的request和response请求.（host是共享connector的) 它用于管理多个詀点. host即一个虚拟主机.也就是一个詀点. context表示詀点中的一个应用. wrapper表示一个servlet.因为Java EE是servlet标准的。 后记不知道自己有没有理解错，还请各位看到的，指正一下。谢谢.]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 中文响应处理]]></title>
    <url>%2F2015%2F12%2F28%2FSpring-%E4%B8%AD%E6%96%87%E5%93%8D%E5%BA%94%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[为什么 CharacterEncodingFilter 没有生效1234567891011121314151617&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 这个配置， 只有在 Controller 里，调用 HttpServletResponse 直接写数据时才会生效的 .如果是直接利用HttpServletResponse，就不能再用@ResponseBody了，例如下面这样子写就会报错: 123456@RequestMapping("/index")@ResponseBodypublic String index(HttpServletResponse response) throws IOException &#123; response.getWriter().write("你好，中文"); return "中文";&#125; 错误为： 12345Caused by:java.lang.IllegalStateException: WRITER at org.eclipse.jetty.server.Response.getOutputStream(Response.java:706) at javax.servlet.ServletResponseWrapper.getOutputStream(ServletResponseWrapper.java:142) at org.springframework.session.web.http.OnCommittedResponseWrapper.getOutputStream(OnCommittedResponseWrapper.java:124) 直接用 HttpServletResponse 写数据12345678 @RequestMapping("/index") public void index(HttpServletResponse response) throws IOException &#123; response.getWriter().write("你好，中文"); &#125;➜ ~ curl http://localhost:8080/index你好，中文➜ ~ 使用@ResponseBody12345678 @RequestMapping("/index") @ResponseBody public String index(HttpServletResponse response) throws IOException &#123; return "你好，中文"; &#125;➜ ~ curl http://localhost:8080/index?????% ➜ ~ 可以看到，返回的是乱码了. 原因因为默认情况下，如果Controller返回的是String的@ResponseBody话，Spring会调用默认的StringHttpMessageConverter来返回String，而这个StringHttpMessageConverter默认情况下，只是使用public static final Charset DEFAULT_CHARSET = Charset.forName(&quot;ISO-8859-1&quot;);这个字符集，所以就会报错了. 解决方法一：添加指定的MessageConverter12345678&lt;mvc:annotation-driven&gt; &lt;!-- register custom converter that returns UTF-8 encoded response-body by defualt --&gt; &lt;mvc:message-converters register-defaults="true"&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"&gt; &lt;constructor-arg index="0" name="defaultCharset" value="UTF-8"/&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 注意register-defaults这表示是否也注册默认的HttpMessageConverter（默认也是true） 这样子，就注册多了一个StringHttpMessageConverter了，默认情况下的HttpMessageConverter有以下9个: 默认注册的 HttpMessageConverter 1234567890 = &#123;ByteArrayHttpMessageConverter@6398&#125;1 = &#123;StringHttpMessageConverter@6399&#125;2 = &#123;ResourceHttpMessageConverter@6400&#125;3 = &#123;SourceHttpMessageConverter@6401&#125;4 = &#123;AllEncompassingFormHttpMessageConverter@6402&#125;5 = &#123;AtomFeedHttpMessageConverter@6403&#125;6 = &#123;RssChannelHttpMessageConverter@6404&#125;7 = &#123;Jaxb2RootElementHttpMessageConverter@6405&#125;8 = &#123;MappingJacksonHttpMessageConverter@6406&#125; 注意Jackson的，要添加相关的Jackson的依赖包. 现在添加多了一个的话，就有10个了: 12345678910111213141516171819200 = &#123;StringHttpMessageConverter@6398&#125; defaultCharset = &#123;UTF_8@6408&#125; "UTF-8" availableCharsets = &#123;ArrayList@6409&#125; size = 170 writeAcceptCharset = true logger = &#123;SLF4JLocationAwareLog@6410&#125; supportedMediaTypes = &#123;ArrayList@6411&#125; size = 21 = &#123;ByteArrayHttpMessageConverter@6399&#125;2 = &#123;StringHttpMessageConverter@6400&#125; defaultCharset = &#123;ISO_8859_1@6413&#125; "ISO-8859-1" availableCharsets = &#123;ArrayList@6414&#125; size = 170 writeAcceptCharset = false logger = &#123;SLF4JLocationAwareLog@6410&#125; supportedMediaTypes = &#123;ArrayList@6415&#125; size = 23 = &#123;ResourceHttpMessageConverter@6401&#125;4 = &#123;SourceHttpMessageConverter@6402&#125;5 = &#123;AllEncompassingFormHttpMessageConverter@6403&#125;6 = &#123;AtomFeedHttpMessageConverter@6404&#125;7 = &#123;RssChannelHttpMessageConverter@6405&#125;8 = &#123;Jaxb2RootElementHttpMessageConverter@6406&#125;9 = &#123;MappingJacksonHttpMessageConverter@6407&#125; 可以看到，我们自己定义的StringHttpMessageConverter放在第一位了，字符集为UTF-8，而Spring默认的SpringHttpMessageConverter为ISO-8859。 这时可以看到可以返回正常的中文了: 12345678 @RequestMapping("/index") @ResponseBody public String index(HttpServletResponse response) throws IOException &#123; return "你好，中文"; &#125;➜ ~ curl http://localhost:8080/index你好，中文% ➜ ~ 方法二：指定 produces12345678 @RequestMapping(value = "/index", produces = "text/plain; charset=utf-8") @ResponseBody public String index(HttpServletResponse response) throws IOException &#123; return "你好，中文"; &#125;➜ ~ curl http://localhost:8080/index你好，中文% ➜ ~ 这样子，就算不配置指定UTF-8字符集的StringHttpMessageConverter，也可以正常返回中文了。因为源码里有处理，如果有指定charset的话，就会使用指定的字符集来写数据.这里以StringHttpMessageConverter为例: 12345678@Overrideprotected void writeInternal(String s, HttpOutputMessage outputMessage) throws IOException &#123; if (this.writeAcceptCharset) &#123; outputMessage.getHeaders().setAcceptCharset(getAcceptedCharsets()); &#125; Charset charset = getContentTypeCharset(outputMessage.getHeaders().getContentType()); StreamUtils.copy(s, charset, outputMessage.getBody());&#125; 其他对象的转换器同理. 参考资料 Spring HttpMessageConverter cnblogs fangjian0423 Cihatkeser pigg]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中添加@ControllerAdvice增强Controller]]></title>
    <url>%2F2015%2F12%2F28%2FSpring%E4%B8%AD%E6%B7%BB%E5%8A%A0-ControllerAdvice%E5%A2%9E%E5%BC%BAController%2F</url>
    <content type="text"><![CDATA[@ControllerAdvice 注解，会应用到所有的Controller中的@RequestMapping注解的方法中. 配置 要注意，经自己测试，这个注解的类，要被 org.springframework.web.servlet.DispatcherServlet的contextConfigLocation中扫描到，如果是放在application context里扫描，是没有效果的. java 文件内容ControllerAdviceHandler.java 12345678910111213141516@ControllerAdvicepublic class ControllerAdviceHandler &#123; private static final Logger log = LoggerFactory.getLogger(ControllerAdviceHandler.class); @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) @ExceptionHandler(value = Exception.class) @ResponseBody public Object exceptionHandler(HttpServletRequest request, HttpServletResponse response, Exception e) &#123; Map&lt;String, Object&gt; hello = new HashMap&lt;&gt;(2); hello.put("hello", "helllo msg"); hello.put("msg", e.getMessage()); log.error("error in url:&#123;&#125;, reason: &#123;&#125;", request.getRequestURI().toString(), e); return hello; &#125;&#125; xml 配置在DispatcherServlet的contextconfigLocation参数值的配置文件里，添加以下: 1234567891011&lt;mvc:annotation-driven /&gt;&lt;!-- Scans for annotated @Controllers in the classpath --&gt;&lt;context:component-scan base-package="com.uniweibov2.web" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:include-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt;&lt;/context:component-scan&gt; &lt;!-- 启动对@AspectJ注解的支持 --&gt;&lt;aop:aspectj-autoproxy /&gt;&lt;!--通知spring使用cglib而不是jdk的来生成代理方法 AOP可以拦截到Controller--&gt;&lt;aop:aspectj-autoproxy proxy-target-class="true" /&gt; 使用在某个Controller的拥有@RequestMapping注解的方法拥有抛出的异常： 12345678910@RequestMapping("/index")@SystemControllerLog(module = FunctionBlockContants.SYSTEM, function = FunctionBlockContants.INDEX_PAGE)public ModelAndView index() &#123; if (index.equals("login")) &#123; throw new RuntimeException("error in index"); //return new ModelAndView("redirect:/" + index); &#125; return null; //return new ModelAndView(index);&#125; 这样子，就会被@ControllerAdvice的类的@ExceptionHandler注解的方法处理异常了（比如，可以在这里记录log!） 示例12➜ ~ curl http://localhost:8080/index&#123;"msg":"error in index","hello":"helllo msg"&#125; ➜ ~ 控制台打印： 1error in url:/index, reason: java.lang.RuntimeException: error in index]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 报 'MySQL server has gone away']]></title>
    <url>%2F2015%2F12%2F28%2FMySQL-%E6%8A%A5-MySQL-server-has-gone-away%2F</url>
    <content type="text"><![CDATA[问题经常在终端里连接MySQL，它经常报如下问题: 12ERROR 2006 (HY000): MySQL server has gone awayNo connection. Trying to reconnect... 原因MySQL服务器超时并且关闭了这次的连接.即相关的超时参数设置得太小.也有可能是你的packet太大，MySQL掉弃该包. 解决超时问题wait_timeout查看当前的wait_timeout值123456789101112131415161718mysql&gt; show variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 120 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 120 |+-----------------------------+----------+12 rows in set (0.01 sec) 从这，可以看到wait_timeout时间太小了（120秒，它表示服务器在关闭一条连接时，它的非活动时间，即在wat_timeout秒内没有活动过，MySQL就会将它关闭。默认是28800秒，即8小时） 设置session级别的wait_timeout1234567891011121314151617181920212223mysql&gt; set wait_timeout = 280000;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 120 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 280000 |+-----------------------------+----------+12 rows in set (0.00 sec)mysql&gt; 设置全局级别的wait_timeout1234567891011121314151617181920212223mysql&gt; set global wait_timeout = 280000;Query OK, 0 rows affected (0.00 sec)mysql&gt; show global variables like '%timeout%';+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 30 || innodb_rollback_on_timeout | OFF || interactive_timeout | 120 || lock_wait_timeout | 600 || net_read_timeout | 3 || net_write_timeout | 6 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 30 || wait_timeout | 280000 |+-----------------------------+----------+12 rows in set (0.00 sec)mysql&gt; 设置永久性的wait_timeout123配置文件`my.conf`里的[mysqld]中，添加或修改wait_timeout = 280000 设置 packetmax_allowed_packet查看当前max_allowed_packet12345678910mysql&gt; show global variables like '%max_allowed_packet%';+--------------------------+------------+| Variable_name | Value |+--------------------------+------------+| max_allowed_packet | 1073741824 || slave_max_allowed_packet | 1073741824 |+--------------------------+------------+2 rows in set (0.00 sec)mysql&gt; 它的作用是：包或任何生成的/中间字符串的最大大小。 它的单位是byte，即字节。(1073741824 / 1024 / 1024 = 1GB)。 最小允许值是1024,最大为1073741824 设置同wait_timeout 设置类似. 参考资料 MySQL 5.7 官方文档]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL Rank()窗口函数和Row_number()窗口函数的区别]]></title>
    <url>%2F2015%2F12%2F25%2FPostgreSQL-Rank-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E5%92%8CRow-number-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[创建测试表和数据123456789101112131415postgres=# create table test(n int);CREATE TABLEpostgres=# insert into test(n) values (1);INSERT 0 1postgres=# insert into test(n) values (1);INSERT 0 1postgres=# insert into test(n) values (2);INSERT 0 1postgres=# insert into test(n) values (3);INSERT 0 1postgres=# insert into test(n) values (4);INSERT 0 1postgres=# insert into test(n) values (5);INSERT 0 1postgres=# rank() 和 row_number()有order by123456789101112postgres=# select n, rank() over(order by n asc), row_number() over(order by n asc) from test; n | rank | row_number---+------+------------ 1 | 1 | 1 1 | 1 | 2 2 | 3 | 3 3 | 4 | 4 4 | 5 | 5 5 | 6 | 6(6 rows)postgres=# 不加order by123456789101112postgres=# select n, rank() over(), row_number() over() from test; n | rank | row_number---+------+------------ 1 | 1 | 1 1 | 1 | 2 2 | 1 | 3 3 | 1 | 4 4 | 1 | 5 5 | 1 | 6(6 rows)postgres=# 总结 rank()：排名函数，相同的排名，rank()的值是相同的，然后到间隔数值到下一名.（比如上面例子中的n，假设是分数，即1,1的排名是相同，都是第一名，2就是就三名了） row_number()：含义是行号，它是按出现的顺序来显示的（比如上面的例子，说法是1,2,3这样子下去） rank()的结果，是依赖于窗口中的over()这部分，这部分不同，会导致rank()的结果也不同。 参考资料 PostgreSQL tutorial-window PostgreSQL 窗口函数]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL与PostgreSQL的 SELECT FOR UPDATE]]></title>
    <url>%2F2015%2F12%2F24%2FMySQL%E4%B8%8EPostgreSQL%E7%9A%84-SELECT-FOR-UPDATE%2F</url>
    <content type="text"><![CDATA[MySQL的行级锁MySQL 版本: 123456789mysql&gt; select version();+------------+| version() |+------------+| 5.6.17-log |+------------+1 row in set (0.00 sec)mysql&gt; 创建测试表1234567891011CREATE TABLE `shortlink` (`id` bigint(20) NOT NULL AUTO_INCREMENT ,`long_url` varchar(6000) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,`create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ,`update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP ,PRIMARY KEY (`id`))ENGINE=InnoDBDEFAULT CHARACTER SET=utf8 COLLATE=utf8_general_ciROW_FORMAT=COMPACT; 插入测试数据123INSERT INTO `test`.`shortlink` (`id`, `long_url`, `create_time`, `update_time`) VALUES ('1', 'long1', '2015-12-21 15:03:41', '2015-12-21 15:03:41');INSERT INTO `test`.`shortlink` (`id`, `long_url`, `create_time`, `update_time`) VALUES ('2', 'long2', '2015-12-21 15:30:56', '2015-12-21 15:30:56');INSERT INTO `test`.`shortlink` (`id`, `long_url`, `create_time`, `update_time`) VALUES ('3', 'long3', '2015-12-21 15:35:48', '2015-12-21 15:35:48'); 测试SELECT FOR UPDATEwhere 没有索引 for updatesession1: 123456789101112mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from shortlink where long_url = 'long2' for update;+----+----------+---------------------+---------------------+| id | long_url | create_time | update_time |+----+----------+---------------------+---------------------+| 2 | long2 | 2015-12-21 15:30:56 | 2015-12-24 17:25:27 |+----+----------+---------------------+---------------------+1 row in set (0.00 sec)mysql&gt; 这时开启另一个session2，更新id=2的数据 123mysql&gt; update shortlink set long_url = 'new long url' where id = 2;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; 发现它一直在等待. 又另一个session3，更新id=3的数据 123mysql&gt; update shortlink set long_url = 'new long url3' where id = 3;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; 发现它也是一直在等待 where 有索引 for updatesession1: 123456789101112mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from shortlink where id = 2 for update;+----+----------+---------------------+---------------------+| id | long_url | create_time | update_time |+----+----------+---------------------+---------------------+| 2 | long2 | 2015-12-21 15:30:56 | 2015-12-24 17:25:27 |+----+----------+---------------------+---------------------+1 row in set (0.00 sec)mysql&gt; 这时开启另一个session2，更新id=2的数据 123mysql&gt; update shortlink set long_url = 'new long url' where id = 2;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; 这时开启另一个session3，更新id=3的数据（即非id=2的都可以) 12345mysql&gt; update shortlink set long_url = 'new long url3' where id = 3;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 这时，发现，它可以立即更新. MySQL for update 总结 只有 select for update 语句中使用了索引，才会是行级锁。否则就是全表锁. select for update 必须放在事务里才有效. PostgreSQL 行级锁PostgreSQL版本： 1234567postgres=# select version(); version------------------------------------------------------------------------------------------------------- PostgreSQL 9.4.0 on x86_64-unknown-linux-gnu, compiled by gcc (Ubuntu 4.4.3-4ubuntu5.1) 4.4.3, 64-bit(1 row)postgres=# 创建测试表123postgres=# create table shortlink (id serial primary key, long_url varchar(6000) not null, create_time timestamp not null default CURRENT_TIMESTAMP, update_time timestamp not null default CURRENT_TIMESTAMP);CREATE TABLEpostgres=# 注意，PG里的serial类型，并不会自动加索引的. 插入测试数据1234567postgres=# insert into shortlink (id, long_url, create_time, update_time) values (1, 'long1', '2015-12-21 15:03:41', '2015-12-21 15:03:41');INSERT 0 1postgres=# insert into shortlink (id, long_url, create_time, update_time) values (2, 'long2', '2015-12-21 15:30:56', '2015-12-21 15:30:56');INSERT 0 1postgres=# insert into shortlink (id, long_url, create_time, update_time) values (3, 'long3', '2015-12-21 15:35:48', '2015-12-21 15:35:48');INSERT 0 1postgres=# 测试 SELECT FOR UPDATEwhere 没有索引 for updatesession1 123456789postgres=# begin ;BEGINpostgres=# select * from shortlink where long_url = 'long2' for update; id | long_url | create_time | update_time----+----------+---------------------+--------------------- 2 | long2 | 2015-12-21 15:30:56 | 2015-12-21 15:30:56(1 row)postgres=# 这时开启另一个session2，更新select for update里的某条数据. 123456postgres=# set lock_timeout = 5000;SETpostgres=# update shortlink set long_url = 'long_url2' where id = 2;ERROR: canceling statement due to lock timeoutCONTEXT: while updating tuple (0,2) in relation "shortlink"postgres=# 注意，设置一下lock_timeout，默认是0,即无限等待.这时，发现它是被锁住了. 又开启另一个session3，更新非select for udpate里的数据. 123postgres=# update shortlink set long_url = 'long_url2' where id = 3;UPDATE 1postgres=# 可以发现，它是立即更新的. where 有索引 for updatesession1: 123456789postgres=# begin ;BEGINpostgres=# select * from shortlink where id = 2 for update; id | long_url | create_time | update_time----+----------+---------------------+--------------------- 2 | long2 | 2015-12-21 15:30:56 | 2015-12-21 15:30:56(1 row)postgres=# 这时，开启另一个session去更新select for update中的某条数据: 1234postgres=# update shortlink set long_url = 'long_url222' where id = 2;ERROR: canceling statement due to lock timeoutCONTEXT: while updating tuple (0,2) in relation "shortlink"postgres=# 又开启另一个session3，去更新非select for update中的某条数据: 123postgres=# update shortlink set long_url = 'long_url333' where id = 3;UPDATE 1postgres=# 发现它是可以立即更新的. PostgreSQL for update 总结根据测试，PostgreSQL的行级锁控制得更好点.无论where有没有触发到索引，都是行级锁. 总结MySQL的select for update： 要有索引for update才是行级锁，否则就是全表锁.PostgreSQL的selct for update: 只会锁select for update那部分的结果. 感觉PostgreSQL靠谱点.哈哈. 参考资料 InnoDb locks set PostgreSQL runtime config client]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底了解Spring-中-RabbitMQ配置的concurrency-和-task-executor（异步)]]></title>
    <url>%2F2015%2F12%2F18%2F%E5%BD%BB%E5%BA%95%E4%BA%86%E8%A7%A3Spring-%E4%B8%AD-RabbitMQ%E9%85%8D%E7%BD%AE%E7%9A%84concurrency-%E5%92%8C-task-executor%EF%BC%88%E5%BC%82%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[上一篇只是说了同步彻底了解Spring 中 RabbitMQ配置的concurrency 和 task-executor. 现在来了解异步的情况.（感谢同事聪哥的指引) 如果listener的方法，添加了@Async，就表示是异步执行了.具体如下: rabbitmq的配置12345&lt;task:executor id="myExecutor" pool-size="12-15" queue-capacity="100" rejection-policy="CALLER_RUNS"/&gt;&lt;rabbit:listener-container connection-factory="rabbitConnectionFactory" error-handler="MessageErrorHandler" concurrency="2" task-executor="myExecutor" &gt; &lt;rabbit:listener ref="initCcDataListener" method="init" queue-names="hello.world.test.queue" /&gt;&lt;/rabbit:listener-container&gt; 注意，要在initCcDataListener这个对象的init方法上，添加@Async注解，才会开启异步执行（即，一般情况下，listener监听队列，然后将执行消息的方法传递给线程池的其他线程来执行，listener现在负责转发） 这时的逻辑，才会真正体现出线程池的并发优势： 首先，concurrency为2,这时它会一直占用线程池2条线程（假设为myExecutor-1, myExecutor-2），但还没有达到corePoolSize(这里是12)。这时开始监听数据，假设有300条数据。这时，myExecutor-1, myExecutor-2就会先将前两条数据取出来，然后提交到线程池里其他的线程来执行（这时，myExecutor就会new出myExecutor-3, myExecutor-4来执行），如此循环取出2条（假设myExecutor-3, myExecutor-4还没有执行完），又会new两条线程(myExecutor-5, myExecutor-6)，线程数一直达到(corePoolSize 12)。 这时，还有数据（300-(12-2)=290条），但是myExecutor-1, myExecutor-2还是会一直取出数据，但是这时发现线程数量达到了corePoolSize，所以它就会将这剩下的数据，放到queue-capacity里（这里是100），这时corePoolSize以及capacity-queue都已经占用完了，但还有（290-100=190）条数据。这时，就会开始new超过corePoolSize数量的线程来继续处理新数据(myExecutor-13, myExecutor-14…一直到myExecutor-20），但也只是处理了7条，还剩下（190-（20-13）=183）条数据。 这时，myExecutor-1， myExecutor-2还会继续出队，但发现线程池corePoolSize已经全部满了，线程池的任务队列（capacity-queue)也已经用完了，而且线程数量也已经达到了maxPoolSize。 注意，这里的优先级顺序（即优先使用未达到corePoolSize线程数量来处理数据，如果corePoolSize已经满了，就使用线程池的任务队列来暂存队列数据（相当于缓冲区），如果这时任务队列也已经满了，就再new新的线程，一直到maxPoolSize。 这时，就会触发rejection了（即拒绝策略），默认是ABORT（即放弃不执行） 其实这本质上，就是JDK里的ThreadPoolTaskExecutor的行为了. executor 拒绝策略对rabbitmq的影响ThreadPoolExecutor.AbortPolicy这个拒绝策略，会导致消息会重新进队（如果队列要求有ack确认的话）（即可以保证数据被正确消费掉）。因为它的拒绝策略的实现代码为: 123456789101112/** * Always throws RejectedExecutionException. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task * @throws RejectedExecutionException always */public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException("Task " + r.toString() + " rejected from " + e.toString());&#125; 即抛出异常，这样子RabbitMQ会认为你没有成功处理该条数据，所以在有ACK的情况下，它就会重新进队 ThreadPoolExecutor.CallerRunsPolicy由调用者来执行.（即listener监听的那条线程来执行）。可以保证所有数据都会被正确消费. 123456789101112/** * Executes task r in the caller's thread, unless the executor * has been shut down, in which case the task is discarded. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125;&#125; ThreadPoolExecutor.DiscardOldestPolicy即丢弃最旧的任务空出线程来执行现在的任务.（这个比较危险，因为会直接丢弃数据，如果要求所有数据都要正确处理，并且不能有丢弃，就不要用这个策略).即不保证所有数据都会被正确消费. 123456789101112131415/** * Obtains and ignores the next task that the executor * would otherwise execute, if one is immediately available, * and then retries execution of task r, unless the executor * is shut down, in which case task r is instead discarded. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125;&#125; ThreadPoolExecutor.DiscardPolicy即直接丢弃（即不保证所有数据都会被正确消费掉） 12345678/** * Does nothing, which has the effect of discarding task r. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;&#125; ThreadPoolTaskExecutor这里摘自JDK1.6中文文档说明，当自己做个提醒了. java.util.concurrent 类 ThreadPoolExecutor123456789101112java.lang.Object 继承者 java.util.concurrent.AbstractExecutorService 继承者 java.util.concurrent.ThreadPoolExecutor所有已实现的接口：Executor, ExecutorService直接已知子类：ScheduledThreadPoolExecutorpublic class ThreadPoolExecutor extends AbstractExecutorService 一个 ExecutorService，它使用可能的几个池线程之一执行每个提交的任务，通常使用 Executors 工厂方法配置。 线程池可以解决两个不同问题：由于减少了每个任务调用的开销，它们通常可以在执行大量异步任务时提供增强的性能，并且还可以提供绑定和管理资源（包括执行任务集时使用的线程）的方法。每个 ThreadPoolExecutor 还维护着一些基本的统计数据，如完成的任务数。 为了便于跨大量上下文使用，此类提供了很多可调整的参数和扩展钩子 (hook)。但是，强烈建议程序员使用较为方便的 Executors 工厂方法 Executors.newCachedThreadPool()（无界线程池，可以进行自动线程回收）、Executors.newFixedThreadPool(int)（固定大小线程池）和 Executors.newSingleThreadExecutor()（单个后台线程），它们均为大多数使用场景预定义了设置。否则，在手动配置和调整此类时，使用以下指导： 核心和最大池大小ThreadPoolExecutor 将根据 corePoolSize（参见 getCorePoolSize()）和 maximumPoolSize（参见 getMaximumPoolSize()）设置的边界自动调整池大小。当新任务在方法 execute(java.lang.Runnable) 中提交时，如果运行的线程少于 corePoolSize，则创建新线程来处理请求，即使其他辅助线程是空闲的。如果运行的线程多于 corePoolSize 而少于 maximumPoolSize，则仅当队列满时才创建新线程。如果设置的 corePoolSize 和 maximumPoolSize 相同，则创建了固定大小的线程池。如果将 maximumPoolSize 设置为基本的无界值（如 Integer.MAX_VALUE），则允许池适应任意数量的并发任务。在大多数情况下，核心和最大池大小仅基于构造来设置，不过也可以使用 setCorePoolSize(int) 和 setMaximumPoolSize(int) 进行动态更改。 按需构造默认情况下，即使核心线程最初只是在新任务到达时才创建和启动的，也可以使用方法 prestartCoreThread() 或 prestartAllCoreThreads() 对其进行动态重写。如果构造带有非空队列的池，则可能希望预先启动线程。 创建新线程使用 ThreadFactory 创建新线程。如果没有另外说明，则在同一个 ThreadGroup 中一律使用 Executors.defaultThreadFactory() 创建线程，并且这些线程具有相同的 NORM_PRIORITY 优先级和非守护进程状态。通过提供不同的 ThreadFactory，可以改变线程的名称、线程组、优先级、守护进程状态，等等。如果从 newThread 返回 null 时 ThreadFactory 未能创建线程，则执行程序将继续运行，但不能执行任何任务。 保持活动时间如果池中当前有多于 corePoolSize 的线程，则这些多出的线程在空闲时间超过 keepAliveTime 时将会终止（参见 getKeepAliveTime(java.util.concurrent.TimeUnit)）。这提供了当池处于非活动状态时减少资源消耗的方法。如果池后来变得更为活动，则可以创建新的线程。也可以使用方法 setKeepAliveTime(long, java.util.concurrent.TimeUnit) 动态地更改此参数。使用 Long.MAX_VALUE TimeUnit.NANOSECONDS 的值在关闭前有效地从以前的终止状态禁用空闲线程。默认情况下，保持活动策略只在有多于 corePoolSizeThreads 的线程时应用。但是只要 keepAliveTime 值非 0， allowCoreThreadTimeOut(boolean) 方法也可将此超时策略应用于核心线程。 排队所有 BlockingQueue 都可用于传输和保持提交的任务。可以使用此队列与池大小进行交互：如果运行的线程少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。如果运行的线程等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。 排队有三种通用策略：直接提交。工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。无界队列。使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。有界队列。当使用有限的 maximumPoolSizes 时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 被拒绝的任务当 Executor 已经关闭，并且 Executor 将有限边界用于最大线程和工作队列容量，且已经饱和时，在方法 execute(java.lang.Runnable) 中提交的新任务将被 拒绝。在以上两种情况下， execute 方法都将调用其 RejectedExecutionHandler 的 RejectedExecutionHandler.rejectedExecution(java.lang.Runnable, java.util.concurrent.ThreadPoolExecutor) 方法。下面提供了四种预定义的处理程序策略：在默认的 ThreadPoolExecutor.AbortPolicy 中，处理程序遭到拒绝将抛出运行时 RejectedExecutionException。在 ThreadPoolExecutor.CallerRunsPolicy 中，线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。在 ThreadPoolExecutor.DiscardPolicy 中，不能执行的任务将被删除。在 ThreadPoolExecutor.DiscardOldestPolicy 中，如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程）。定义和使用其他种类的 RejectedExecutionHandler 类也是可能的，但这样做需要非常小心，尤其是当策略仅用于特定容量或排队策略时。钩子 (hook) 方法此类提供 protected 可重写的 beforeExecute(java.lang.Thread, java.lang.Runnable) 和 afterExecute(java.lang.Runnable, java.lang.Throwable) 方法，这两种方法分别在执行每个任务之前和之后调用。它们可用于操纵执行环境；例如，重新初始化 ThreadLocal、搜集统计信息或添加日志条目。此外，还可以重写方法 terminated() 来执行 Executor 完全终止后需要完成的所有特殊处理。如果钩子 (hook) 或回调方法抛出异常，则内部辅助线程将依次失败并突然终止。 队列维护方法 getQueue() 允许出于监控和调试目的而访问工作队列。强烈反对出于其他任何目的而使用此方法。 remove(java.lang.Runnable) 和 purge() 这两种方法可用于在取消大量已排队任务时帮助进行存储回收。 终止程序 AND 不再引用的池没有剩余线程会自动 shutdown。如果希望确保回收取消引用的池（即使用户忘记调用 shutdown()），则必须安排未使用的线程最终终止：设置适当保持活动时间，使用 0 核心线程的下边界和/或设置 allowCoreThreadTimeOut(boolean)。 扩展示例。此类的大多数扩展可以重写一个或多个受保护的钩子 (hook) 方法。例如，下面是一个添加了简单的暂停/恢复功能的子类： 1234567891011121314151617181920212223242526272829303132333435363738class PausableThreadPoolExecutor extends ThreadPoolExecutor &#123; private boolean isPaused; private ReentrantLock pauseLock = new ReentrantLock(); private Condition unpaused = pauseLock.newCondition(); public PausableThreadPoolExecutor(...) &#123; super(...); &#125; protected void beforeExecute(Thread t, Runnable r) &#123; super.beforeExecute(t, r); pauseLock.lock(); try &#123; while (isPaused) unpaused.await(); &#125; catch(InterruptedException ie) &#123; t.interrupt(); &#125; finally &#123; pauseLock.unlock(); &#125; &#125; public void pause() &#123; pauseLock.lock(); try &#123; isPaused = true; &#125; finally &#123; pauseLock.unlock(); &#125; &#125; public void resume() &#123; pauseLock.lock(); try &#123; isPaused = false; unpaused.signalAll(); &#125; finally &#123; pauseLock.unlock(); &#125; &#125;&#125; 从以下版本开始：1.5]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>concurrency</tag>
        <tag>task-executor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx负载均衡Tomcat切换注意事项]]></title>
    <url>%2F2015%2F12%2F17%2FNginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1Tomcat%E5%88%87%E6%8D%A2%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[在生产环境使用nginx+tomcat做负载均衡。众所周知，tomcat的shutdown在生产环境是很慢的，如果这时候，不先修改nginx的upstream模块，先让要停止的那台tomcat成为shuotdown或者直接注释掉，而直接shutdown了tomcat的话，这样子，如果有刚好请求分配到了这个要停止的tomcat，就会导致用户的连接是一直等待中了.~~ nginx的负载均衡虽然会自动切换，但是默认情况下它会一直等待到那台tomcat完全shutdown了，才会将请求转交给另一台服务器.所以，才会导致用户请求一直在等待中. 建议先在nginx配置文件里，注释掉要停止的tomcat的那台服务器的upstream 的iP配置，然后sudo nginx -s reload一下. nginx负载均衡问题还有个注意问题，使用ip_hash算法做均衡，还是有比较大问题（如果做了分布式session除外）并且如果没有做session共享，这样子用户会非常容易提示重新登录。 其实这个要根据网络运营商的具体情况，我自己就测试过所住的地方，IP是几秒钟变一次的，如果这时使用了ip_hash算法，还是很容易导致用户要不停的重新登录（如果没有用session，或者使用了session共享的，可以忽略这个问题）。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>nginx</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java for-each 修改问题]]></title>
    <url>%2F2015%2F12%2F17%2FJava-for-each-%E4%BF%AE%E6%94%B9%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题有一次在测试时，发现程序报如下类似错误: 123Exception in thread "main" java.util.ConcurrentModificationException at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:901) at java.util.ArrayList$Itr.next(ArrayList.java:851) 原因这是因为在使用for-each时，修改了for-each的对象(比如调用了remove())等。问题重现: 123456789101112public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(100); for (int i = 0; i &lt; 100; i++) &#123; list.add(i); &#125; for (Integer i : list) &#123; if (i % 2 == 0) &#123; list.remove(i); &#125; &#125;&#125; 一时写代码，又忘记这些基础了，归根结底，还是基础不够扎实。～～for-each只适合于遍历，则不能删除. 解决如果确实想要修改，可以改为for(int i=0; i&lt;list.size(); i++)这种形式.如: 1234567891011public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(100); for (int i = 0; i &lt; 100; i++) &#123; list.add(i); &#125; for (int i = 0; i &lt; list.size(); i++) &#123; if (i % 2 == 0) &#123; list.remove(i); &#125; &#125;&#125; 或者使用iterator.如: 1234567891011121314public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(100); for (int i = 0; i &lt; 100; i++) &#123; list.add(i); &#125; Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; Integer i = iterator.next(); if(i%2==0)&#123; iterator.remove(); &#125; &#125; System.out.println(list);&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL MAX()和Order by DESC limit 1]]></title>
    <url>%2F2015%2F12%2F17%2FPostgreSQL-MAX-%E5%92%8COrder-by-DESC-limit-1%2F</url>
    <content type="text"><![CDATA[准备数据1234567postgres=# create table tmax (id int);CREATE TABLEpostgres=# insert into tmtmax tmp1postgres=# insert into tmax values (generate_series(1,100000000));INSERT 0 100000000postgres=# 一亿条无索引1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253postgres=# explain analyze verbose select max(id) from tmax ; QUERY PLAN------------------------------------------------------------------------------------------------------------------------------------- Aggregate (cost=1692478.40..1692478.41 rows=1 width=4) (actual time=32215.384..32215.385 rows=1 loops=1) Output: max(id) -&gt; Seq Scan on public.tmax (cost=0.00..1442478.32 rows=100000032 width=4) (actual time=4.656..18766.501 rows=100000000 loops=1) Output: id Planning time: 0.132 ms Execution time: 32215.441 ms(6 rows)postgres=# explain analyze verbose select id from tmax order by id desc limit 1 ; QUERY PLAN-------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=1942478.48..1942478.48 rows=1 width=4) (actual time=32789.641..32789.641 rows=1 loops=1) Output: id -&gt; Sort (cost=1942478.48..2192478.56 rows=100000032 width=4) (actual time=32789.640..32789.640 rows=1 loops=1) Output: id Sort Key: tmax.id Sort Method: top-N heapsort Memory: 25kB -&gt; Seq Scan on public.tmax (cost=0.00..1442478.32 rows=100000032 width=4) (actual time=15.948..18095.096 rows=100000000 loops=1) Output: id Planning time: 0.101 ms Execution time: 32789.678 ms(10 rows)postgres=# explain analyze verbose select max(id) from tmax ; QUERY PLAN-------------------------------------------------------------------------------------------------------------------------------------- Aggregate (cost=1692478.40..1692478.41 rows=1 width=4) (actual time=32411.383..32411.383 rows=1 loops=1) Output: max(id) -&gt; Seq Scan on public.tmax (cost=0.00..1442478.32 rows=100000032 width=4) (actual time=10.210..18996.920 rows=100000000 loops=1) Output: id Planning time: 0.125 ms Execution time: 32411.436 ms(6 rows)postgres=# explain analyze verbose select id from tmax order by id desc limit 1 ; QUERY PLAN------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=1942478.48..1942478.48 rows=1 width=4) (actual time=33312.476..33312.477 rows=1 loops=1) Output: id -&gt; Sort (cost=1942478.48..2192478.56 rows=100000032 width=4) (actual time=33312.474..33312.474 rows=1 loops=1) Output: id Sort Key: tmax.id Sort Method: top-N heapsort Memory: 25kB -&gt; Seq Scan on public.tmax (cost=0.00..1442478.32 rows=100000032 width=4) (actual time=8.584..18551.514 rows=100000000 loops=1) Output: id Planning time: 0.100 ms Execution time: 33312.514 ms(10 rows)postgres=# 看执行结果是max快 一亿条，有索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061postgres=# create index id_tmax_index on tmax (id);CREATE INDEXpostgres=#postgres=# explain analyze verbose select max(id) from tmax ; QUERY PLAN--------------------------------------------------------------------------------------------------------------------------------------------------------------------- Result (cost=0.60..0.61 rows=1 width=0) (actual time=0.041..0.042 rows=1 loops=1) Output: $0 InitPlan 1 (returns $0) -&gt; Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.035..0.035 rows=1 loops=1) Output: tmax.id -&gt; Index Only Scan Backward using id_tmax_index on public.tmax (cost=0.57..3289257.57 rows=100000000 width=4) (actual time=0.033..0.033 rows=1 loops=1) Output: tmax.id Index Cond: (tmax.id IS NOT NULL) Heap Fetches: 1 Planning time: 0.198 ms Execution time: 0.092 ms(11 rows)postgres=# explain analyze verbose select id from tmax order by id desc limit 1 ; QUERY PLAN------------------------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.029..0.030 rows=1 loops=1) Output: id -&gt; Index Only Scan Backward using id_tmax_index on public.tmax (cost=0.57..3039257.57 rows=100000000 width=4) (actual time=0.027..0.027 rows=1 loops=1) Output: id Heap Fetches: 1 Planning time: 0.143 ms Execution time: 0.065 ms(7 rows)postgres=# explain analyze verbose select max(id) from tmax ; QUERY PLAN--------------------------------------------------------------------------------------------------------------------------------------------------------------------- Result (cost=0.60..0.61 rows=1 width=0) (actual time=0.042..0.043 rows=1 loops=1) Output: $0 InitPlan 1 (returns $0) -&gt; Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.036..0.037 rows=1 loops=1) Output: tmax.id -&gt; Index Only Scan Backward using id_tmax_index on public.tmax (cost=0.57..3289257.57 rows=100000000 width=4) (actual time=0.034..0.034 rows=1 loops=1) Output: tmax.id Index Cond: (tmax.id IS NOT NULL) Heap Fetches: 1 Planning time: 0.199 ms Execution time: 0.092 ms(11 rows)postgres=# explain analyze verbose select id from tmax order by id desc limit 1 ; QUERY PLAN------------------------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.030..0.030 rows=1 loops=1) Output: id -&gt; Index Only Scan Backward using id_tmax_index on public.tmax (cost=0.57..3039257.57 rows=100000000 width=4) (actual time=0.029..0.029 rows=1 loops=1) Output: id Heap Fetches: 1 Planning time: 0.144 ms Execution time: 0.073 ms(7 rows)postgres=# 有索引，就是order by 快一点点. 有索引，并且是倒序索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061postgres=# create index id_tmax_index on tmax (id desc);CREATE INDEXpostgres=#postgres=# explain analyze verbose select max(id) from tmax ; QUERY PLAN------------------------------------------------------------------------------------------------------------------------------------------------------------ Result (cost=0.60..0.61 rows=1 width=0) (actual time=0.076..0.076 rows=1 loops=1) Output: $0 InitPlan 1 (returns $0) -&gt; Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.071..0.071 rows=1 loops=1) Output: tmax.id -&gt; Index Only Scan using id_tmax_index on public.tmax (cost=0.57..3289257.57 rows=100000000 width=4) (actual time=0.069..0.069 rows=1 loops=1) Output: tmax.id Index Cond: (tmax.id IS NOT NULL) Heap Fetches: 1 Planning time: 0.200 ms Execution time: 0.128 ms(11 rows)postgres=# explain analyze verbose select max(id) from tmax ; QUERY PLAN------------------------------------------------------------------------------------------------------------------------------------------------------------ Result (cost=0.60..0.61 rows=1 width=0) (actual time=0.075..0.076 rows=1 loops=1) Output: $0 InitPlan 1 (returns $0) -&gt; Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.068..0.069 rows=1 loops=1) Output: tmax.id -&gt; Index Only Scan using id_tmax_index on public.tmax (cost=0.57..3289257.57 rows=100000000 width=4) (actual time=0.067..0.067 rows=1 loops=1) Output: tmax.id Index Cond: (tmax.id IS NOT NULL) Heap Fetches: 1 Planning time: 0.184 ms Execution time: 0.123 ms(11 rows)postgres=# explain analyze verbose select id from tmax order by id desc limit 1 ; QUERY PLAN---------------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.055..0.055 rows=1 loops=1) Output: id -&gt; Index Only Scan using id_tmax_index on public.tmax (cost=0.57..3039257.57 rows=100000000 width=4) (actual time=0.053..0.053 rows=1 loops=1) Output: id Heap Fetches: 1 Planning time: 0.133 ms Execution time: 0.098 ms(7 rows)postgres=# explain analyze verbose select id from tmax order by id desc limit 1 ; QUERY PLAN---------------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=0.57..0.60 rows=1 width=4) (actual time=0.054..0.054 rows=1 loops=1) Output: id -&gt; Index Only Scan using id_tmax_index on public.tmax (cost=0.57..3039257.57 rows=100000000 width=4) (actual time=0.052..0.052 rows=1 loops=1) Output: id Heap Fetches: 1 Planning time: 0.135 ms Execution time: 0.098 ms(7 rows)postgres=# 有索引，并且是倒序索引，也还是order by 快一点点 推测max在无索引，还是有索引，综合好一点，所以统一习惯写max().]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底了解Spring 中 RabbitMQ配置的concurrency 和 task-executor]]></title>
    <url>%2F2015%2F12%2F17%2F%E5%BD%BB%E5%BA%95%E4%BA%86%E8%A7%A3Spring-%E4%B8%AD-RabbitMQ%E9%85%8D%E7%BD%AE%E7%9A%84concurrency-%E5%92%8C-task-executor%2F</url>
    <content type="text"><![CDATA[问题在生产环境中，突然发现有个Tomcat报如下类似错误: 1234567891011Caused by: org.springframework.amqp.UncategorizedAmqpException: java.util.concurrent.TimeoutException: Timed out waiting for startup at org.springframework.amqp.rabbit.connection.RabbitUtils.convertRabbitAccessException(RabbitUtils.java:118) at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:106) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.start(AbstractMessageListenerContainer.java:365) at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:167) ... 59 common frames omittedCaused by: java.util.concurrent.TimeoutException: Timed out waiting for startup at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.getStartupException(SimpleMessageListenerContainer.java:512) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doStart(SimpleMessageListenerContainer.java:337) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.start(AbstractMessageListenerContainer.java:363) ... 60 common frames omitted 原因项目里的rabbitmq的配置大致如下: 12345678&lt;task:annotation-driven scheduler="myScheduler"/&gt;&lt;task:executor id="myExecutor" pool-size="8" /&gt;&lt;task:scheduler id="myScheduler" pool-size="5" /&gt;&lt;rabbit:listener-container connection-factory="rabbitConnectionFactory" error-handler="MessageErrorHandler" concurrency="10" task-executor="myExecutor"&gt;...&lt;/rabbit:listener&gt; 刚开始，我以为这个task-executor只是负责调用listener方法的（即，只有真正执行listener的时候，才会提交该task到task-executor线程池去执行的. 但是，如果真的是按预期的来执行的话，是不应该报这个错误的。可知，真正执行的与理解的，还是有一定的差距。这时，只好看看JVM底层的线程情况才能真正知道它到底是如何执行的了。 情况1pool-size: 8concurrency: 8并且使用task-executor，listener-container里只有一个listener 这时可以正常启动，也可以正常出队. 情况2pool-size: 7concurrency: 8并且使用task-executor，listener-container里只有一个listener 启动就会报上面的那些类似错误。 推论1：concurrency的线程，是包含在task-executor内部的.而且是会一直使用的，并不会释放的.推论2：pool-size &gt;= concurrency（所有配置了concurrency的总和 &lt;= 使用同一个executor线程池大小），这只是最低限度. 情况3使用concurrency,但是没有task-executor，它使用的是默认的SimpleAsyncTaskExecutor来适应concurrency（默认是1，即对于每个listener的并发都是1,注意，它是对每个listener都生效的，这时要特别注意线程池的大小）SimpleAsyncTaskExecutor，注意它并不是线程池，它是在启动的时候，由concurrency的参数来决定数量的. 解决方法1可以添加concurrency，然后计算一下，所有使用该executor的配置估计下至少要使用多少条线程。最好使用弹性的线程池（pool-size=”3-5”）这种配置，不过这样子的话，就一定要配置execuotr的queue-capacity. 方法2可以添加concurrency，但去掉executor即可.这样了，Spring就会按需自动new线程了. 参考资料 http://docs.spring.io/spring-amqp/reference/htmlsingle/ 更新2015-12-18 ： 这情况，只是适用于listener的方法没有添加@Async的情况下.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>concurrency</tag>
        <tag>task-executor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OkHttp 中注意事项]]></title>
    <url>%2F2015%2F12%2F15%2FOkHttp-%E4%B8%AD%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[问题 在生产环境中，突然发现RabbitMQ中的某条队列的数据没有被消费掉，而是一直停留在那里，并到好几个小时了，消息一直在Unacknowledged中.查看Tomcat的日志，也没有发现报异常，只是日志的log一直停留在那里，没有任何滚动。 查找原因然后到生产环境，执行jstack -l TOMCAT_PID &gt; /tmp/TOMCAT_PID.stack.log想找出此时的进程内的线程栈结构。发现又报如下错误: 1jstack error attaching to core file can't attach to the core file 这个问题，可以参考我的另一篇blog: 使用Java监控工具出现 Can’t attach to the process 然后找到对应的队列，所在的listener调用的方法，然后在/tmp/TOMCAT_PID.stack.log文件里搜索到相关的栈内容.比如我的: 12345678910111213141516171819202122232425"SimpleAsyncTaskExecutor-1" prio=10 tid=0x00007f5984cca000 nid=0x399 runnable [0x00007f59c1cae000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.read(SocketInputStream.java:150) at java.net.SocketInputStream.read(SocketInputStream.java:121) at sun.security.ssl.InputRecord.readFully(InputRecord.java:312) at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:424) at sun.security.ssl.InputRecord.read(InputRecord.java:379) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:927) - locked &lt;0x0000000784e3e858&gt; (a java.lang.Object) at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:884) at sun.security.ssl.AppInputStream.read(AppInputStream.java:102) - locked &lt;0x0000000784e3d9f0&gt; (a sun.security.ssl.AppInputStream) at okio.Okio$2.read(Okio.java:136) at okio.AsyncTimeout$2.read(AsyncTimeout.java:211) at okio.RealBufferedSource.read(RealBufferedSource.java:50) at com.squareup.okhttp.internal.http.HttpConnection$FixedLengthSource.read(HttpConnection.java:457) at okio.RealBufferedSource.exhausted(RealBufferedSource.java:60) at okio.InflaterSource.refill(InflaterSource.java:96) at okio.InflaterSource.read(InflaterSource.java:62) at okio.GzipSource.read(GzipSource.java:80) at okio.Buffer.writeAll(Buffer.java:574) at okio.RealBufferedSource.readByteArray(RealBufferedSource.java:87) at com.squareup.okhttp.ResponseBody.bytes(ResponseBody.java:56) at com.squareup.okhttp.ResponseBody.string(ResponseBody.java:82) 这条线程就是执行该listener的方法的，发现线程的状态一直是RUNNABLE，但是消息又一直没有进行确认，好几个小时了，一直是这样子，日志也没有见抛出什么异常. 然后，我到 OkHttp Github 提交了个issue，不过作者说那里只是一个bug以及feature的提交点，并不是作为question，建议我到stackoverflow.com提问下. 然后我就没有然后了。不过作者回复的挺快. 研究源码查看com.squareup.okhttp.OkHttpClient的源码. 可以看到有6个（包括get,set）与timeout相关的设置.他们的单位都是毫秒. 12345678setConnectTimeoutgetConnectTimeoutsetReadTimeoutgetReadTimeoutsetWriteTimeoutgetWriteTimeout 然后，打印其默认值: 12345678private static final OkHttpClient ok = new OkHttpClient();@Testpublic void okinof() &#123; System.out.println("connect timeout -&gt;" + ok.getConnectTimeout()); System.out.println("read timeout -&gt;" + ok.getReadTimeout()); System.out.println("write timeout -&gt;" + ok.getWriteTimeout());&#125; 结果如下: 123connect timeout -&gt;0read timeout -&gt;0write timeout -&gt;0 再看其源码的Java Doc说明: 123/** * Sets the default write timeout for new connections. A value of 0 means no timeout. */ 如果值为0，就意味着没有超时时间，就一直等待.而默认值就是0. 因为在看到jstack时，它的线程状态为RUNABLE，而不是WAITING，所以排除死锁的情况.而且它一直是停留在 123456789101112131415161718192021222324252627282930private static Source source(final InputStream in, final Timeout timeout) &#123; if (in == null) throw new IllegalArgumentException("in == null"); if (timeout == null) throw new IllegalArgumentException("timeout == null"); return new Source() &#123; @Override public long read(Buffer sink, long byteCount) throws IOException &#123; if (byteCount &lt; 0) throw new IllegalArgumentException("byteCount &lt; 0: " + byteCount); timeout.throwIfReached(); Segment tail = sink.writableSegment(1); int maxToCopy = (int) Math.min(byteCount, Segment.SIZE - tail.limit); int bytesRead = in.read(tail.data, tail.limit, maxToCopy); //停留在这里 if (bytesRead == -1) return -1; tail.limit += bytesRead; sink.size += bytesRead; return bytesRead; &#125; @Override public void close() throws IOException &#123; in.close(); &#125; @Override public Timeout timeout() &#123; return timeout; &#125; @Override public String toString() &#123; return "source(" + in + ")"; &#125; &#125;; &#125; 所以，它应该是在读取数据流的时候，一直在等待，又因为没有设置超时时间，所以是无限等待. 解决12345678private final static OkHttpClient client = new OkHttpClient();static &#123; //设置超时时时间，因为默认情况下是无限. client.setReadTimeout(5, TimeUnit.MINUTES); client.setWriteTimeout(5, TimeUnit.MINUTES); client.setConnectTimeout(1, TimeUnit.MINUTES);&#125; 超时时间，要根据具体的逻辑情况来决定。 参考资料 Okhttp Set timeout Okhttp connection OkhttpClient set connection timeout with okhttp]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>http</tag>
        <tag>spring</tag>
        <tag>okhttp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 与 RabbitMQ 结合配置以及注意事项]]></title>
    <url>%2F2015%2F12%2F14%2FSpring-%E4%B8%8E-RabbitMQ-%E7%BB%93%E5%90%88%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[主要是listener-container配置12&lt;rabbit:listener-container connection-factory="rabbitConnectionFactory" error-handler="MessageErrorHandler" task-executor="myExecutor" concurrency="10"&gt;&lt;/rabbit:listener-container&gt; 属性说明task-executor这个属性表示，在执行listener时，使用的线程行为。默认为SimpleAsyncTaskExecutor，即每执行一个listener，都创建一条新的线程。 concurrency这个表示每个listener创建多少个消费者（会创建多少个线程来消费） 所以，如果想要多线程执行，就要配置concurrency，因为默认情况下，它是1. 如果还配置了task-executor，就要特别注意task-executor要有足够的线程来满足执行. 建议配置这个为&gt;1，因为如果只有一个进程的话，会阻塞后面的消息队列。但如果有多个消费者的话，那一个线程的阻塞，并不会导致其他线程的阻塞. task-executor1&lt;task:executor id="myExecutor" pool-size="20" /&gt; 这个表示固定的线程池.属性有: 属性说明keep-alive单位是秒.这个主要在pool-size为弹性的时候才有效. pool-size如果只是写一个数字，那就表示是固定的。如果是N-M，表示最少会保持N条活动线程池，然后最大可以扩展到M条线程.然后根据keep-alive来销毁不活动的线程. 如果设置为N-M的形式，那就一定要设置queue-capacity这个属性. queue-capacity表示队列容量大小.如果pool-size为可变的，那么这个属性就一定要设置. rejection-policy当队列满时，进行的策略.它是一个java.util.concurrent.RejectedExecutionHandler类型. 一共有: ABORT（缺省）：抛出TaskRejectedException异常，然后不执行 DISCARD：不执行，也不抛出异常 DISCARD_OLDEST：丢弃queue中最旧的那个任务 CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行 建议设置为CALLER_RUNS. 建议配置为12345&lt;task:executor id="myExecutor" pool-size="20-100" keep-alive="600" queue-capacity="2000" rejection-policy="CALLER_RUNS" /&gt;&lt;rabbit:listener-container connection-factory="rabbitConnectionFactory" error-handler="MessageErrorHandler" concurrency="10" task-executor="myExecutor"&gt;&lt;/rabbit:listener-container&gt; 关于排查问题最好在 rabbitmq 的 connection 和 channel 上，都注册一个 addShutdownListener，例如下面的例子： 1234567891011121314try &#123; rabbitConnection = rabbitConnectionFactory.newConnection(); rabbitConnection.addShutdownListener(new ShutdownListener() &#123; @Override public void shutdownCompleted(ShutdownSignalException cause) &#123; Loggers.ERROR_LOG.error("rabbitmq connection already close. reason: &#123;&#125;", cause); &#125; &#125;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; 让它打印出关闭的原因. 遇到过的问题Caused by: com.rabbitmq.client.AlreadyClosedException: channel is already closed due to clean channel shutdown.com.rabbitmq.client.AlreadyClosedException: connection is already closed due to connection error; cause: com.rabbitmq.client.impl.UnknownChannelException: Unknown channel number xxx解决思路 为每个 Connection 和 Channel 注册相应的生命周期的事件通知。然后打印相应的线程栈，最后定位问题代码和排查问题。 比如，我们遇到了 Unknown channel number xxx 的异常，一开始时，虽然打印出这些问题代码，但是还是比如模糊。最后，我们为每个 Connection 添加相应的 listener ，然后打印相应的线程栈。（按上面那个 shutdownListener 的伪代码即可） 最后，我们发现是我们的同事，在使用底层的 Channel 时，没有正确关闭资源，导致这些问题的。错误的伪代码如下: 12345678910111213141516try &#123; AMQP.Queue.DeclareOk declareOk = channel.queueDeclare(monitorQueue, true, false, false, null); if (declareOk.getMessageCount() == 0) &#123; //over if there's no message in queue channel.close(); return; &#125;&#125; finally &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; Loggers.ERROR_LOG.error("monitor log dequeue close channel IOException. ", e); &#125; catch (TimeoutException e) &#123; Loggers.ERROR_LOG.error("monitor log dequeue close channel TimeoutException. ", e); &#125;&#125; 最后修改为了如下： 1234567891011121314151617try &#123; AMQP.Queue.DeclareOk declareOk = channel.queueDeclare(monitorQueue, true, false, false, null); if (declareOk.getMessageCount() == 0) &#123; //over if there's no message in queue return; &#125;&#125; finally &#123; if (channel != null &amp;&amp; channel.isOpen()) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; Loggers.ERROR_LOG.error("monitor log dequeue close channel IOException. ", e); &#125; catch (TimeoutException e) &#123; Loggers.ERROR_LOG.error("monitor log dequeue close channel TimeoutException. ", e); &#125; &#125;&#125; 这样子线上就没有再因为这个原因，而不断报类似上面的异常了。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL将时间转换为Unix时间戳]]></title>
    <url>%2F2015%2F12%2F14%2FPostgreSQL%E5%B0%86%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E4%B8%BAUnix%E6%97%B6%E9%97%B4%E6%88%B3%2F</url>
    <content type="text"><![CDATA[今天在群里，有个群友问: 请教一个问题，在pgsql中要怎么把2015-11-17 15:31:36.966+08这样的日期转换成Unix时间戳啊？ 这个在PostgreSQL里，有个时间函数，只不过可能没有MySQL的unix_timestamp()这么方便，但功能是一样的。PostgreSQL的函数，灵活性比较大（灵活的言外之意，就是复杂~~~哈哈） 废话就不多说了，直接上码示例 创建一张示例表12345postgres=# create table ttt (dt timestamptz);CREATE TABLEpostgres=# insert into ttt values ('2015-11-17 15:31:36.966+08');INSERT 0 1 SQL12345678910111213141516171819postgres=# select * from ttt; dt---------------------------- 2015-11-17 15:31:36.966+08(1 row)postgres=# select (date_part('epoch', dt)) from ttt; date_part---------------- 1447745496.966(1 row)postgres=# select (date_part('epoch', dt))::bigint from ttt; date_part------------ 1447745497(1 row)postgres=# 即使用函数: date_part(&#39;epoch&#39;, 时间字段(date,timestamp等)) PostgreSQL 日期/时间 函数手册Manual]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
        <tag>unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 远程调试]]></title>
    <url>%2F2015%2F12%2F10%2Ftomcat-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[配置tomcat环境变量123cd $TOMCAT_HOME/bin/添加或编辑`setenv.sh` setenv.sh 文件内容123#!/bin/shCATALINA_OPTS="-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -XX:+PrintGCDetails -Xloggc:gc.log -XX:+DisableExplicitGC -Xdebug -Xrunjdwp:transport=dt_socket,address=8888,server=y,suspend=n" 参数说明-Xdebug表示开启debug address 调试监听的地址和端口。直接写的话，就是端口，也可以是 address=IP:port 如果server为y，那address可以不必设置.如果server为n，就一定要设置address. serverdebugger进程是否以监听的方式启动. 如果server为y，那address可以不必设置.否则就一定要设置address. 如果server为y，而且address又没有设置（如果设置了address，则以address为准），那比较麻烦。 先查出应用监听的所有端口: 123456789➜ ~ lsof -p 16995 -Pan -ilsof: WARNING: can't stat() fuse.gvfsd-fuse file system /home/yang/.gvfs Output information may be incomplete.COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 16995 yang 5u IPv4 1382347 0t0 TCP *:56969 (LISTEN)java 16995 yang 50u IPv6 1382352 0t0 TCP *:8080 (LISTEN)java 16995 yang 51u IPv6 1382353 0t0 TCP *:8009 (LISTEN)java 16995 yang 57u IPv6 1382359 0t0 TCP 127.0.0.1:8005 (LISTEN)➜ ~ 然后去掉tomcat自身监听的端口（可在server.xml里找到)，剩下的那个端口，就是debugger server的监听端口了（这里是56969端口）。然后执行:12345➜ ~ jdb -attach localhost:56969设置未捕获的java.lang.Throwable设置延迟的未捕获的java.lang.Throwable正在初始化jdb...&gt; 注意，执行完这句后，就会在应用的标准输出里，会打印如何类似语句: 1Listening for transport dt_socket at address: 42524 后面的端口，是随机的，这个是新的监听端口.也可以连接到42524。 这时，就可以使用IDE连接这个端口，来进行调试了。 这样子的好处是：端口不是固定的，而是随机的。 transport建立通信的方式. dt_socket可用于Solaris, Linux, and Microsoft Windows platforms dt_shmem只能用于Microsoft Windows platform 连接调试 debugger 服务器IDEA123Run -&gt; Edit Configuration -&gt; + -&gt; Remote然后填写`host`（debugger 服务器所在主机，即tomcat运行的那个主机）和`port`（监听端口）的值就可以了 参考资料 Oracle JavaSE Transports 命令行帮助 1234567891011121314151617181920212223242526272829303132333435363738394041424344➜ ~ java -agentlib:jdwp=help Java Debugger JDWP Agent Library -------------------------------- (see http://java.sun.com/products/jpda for more information)jdwp usage: java -agentlib:jdwp=[help]|[&lt;option&gt;=&lt;value&gt;, ...]Option Name and Value Description Default--------------------- ----------- -------suspend=y|n wait on startup? ytransport=&lt;name&gt; transport spec noneaddress=&lt;listen/attach address&gt; transport spec ""server=y|n listen for debugger? nlaunch=&lt;command line&gt; run debugger on event noneonthrow=&lt;exception name&gt; debug on throw noneonuncaught=y|n debug on any uncaught? ntimeout=&lt;timeout value&gt; for listen/attach in milliseconds nmutf8=y|n output modified utf-8 nquiet=y|n control over terminal messages nObsolete Options----------------strict=y|nstdalloc=y|nExamples-------- - Using sockets connect to a debugger at a specific address: java -agentlib:jdwp=transport=dt_socket,address=localhost:8000 ... - Using sockets listen for a debugger to attach: java -agentlib:jdwp=transport=dt_socket,server=y,suspend=y ...Notes----- - A timeout value of 0 (the default) is no timeout.Warnings-------- - The older -Xrunjdwp interface can still be used, but will be removed in a future release, for example: java -Xdebug -Xrunjdwp:[help]|[&lt;option&gt;=&lt;value&gt;, ...]➜ ~]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux sort 命令详解]]></title>
    <url>%2F2015%2F12%2F09%2FLinux-sort-%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[sort 它是一个按行排序的命令行工具. -b 或者 –ignore-leading-blanks 忽略开头的空格 -d 或者 –dictionary-order 按字典排序 123456789101112131415161718192021➜ sort cat sort.txt 19 21 20 2112345➜ sort sort -d sort.txt1 192 20 21 21345➜ sort -f 或者 –ignore-case 忽略大小写 -g 或者 –general-numeric-sort 按通常的数字比较 -i 或者 –ignore-nonprinting 只考虑可打印字符 -M 或者 –month-sort 按月份比较 -h 或者 –human-numeric-sort 比较人性化的数字表示（比如1K 2G） -n 或者 –numeric-sort 将字符串的数字当用普通数值来比较 -R 或者 –random-sort 根据 keys 的随机 hash来排序 -r 或者 –reverse 降序 -V 或者 –version-sort 根据版本号排序 -t 或者 –field-separator=SEP 项分隔符 –parallel=N 并发处理 -u 或者 –unique 去重 -z 或者 –zero-terminated 以 0 byte 为行结尾，而不是换行符 -S 或者 –buffer-size=SIZE 内存缓存大小 -o 或者 –output=FILE 输出到指定文件 -k 或者 –key=KEYEF 根据指定key排序（即指定项排序） 123456789101112131415161718192021➜ sort cat sort.txt19 121 320 221 41 52 233 154 6515 23➜ sort sort -n -k2 sort.txt19 120 221 321 41 53 152 235 234 651➜ sort]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bash</tag>
        <tag>linux</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[/etc/hostname 和 /etc/hosts 详解]]></title>
    <url>%2F2015%2F12%2F09%2Fetc-hostname-%E5%92%8C-etc-hosts-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[/etc/hostname它表示的是在LAN（局域网）内的唯一主机名. 123➜ ~ cat /etc/hostnameyang➜ ~ 作用： 在局域网内，本机或者其他在同一局域网内的计算机，可以直接通过hostname.local可找到主机.比如: 1234567891011121314151617181920➜ ~ ping yang.localPING yang.local (10.0.0.105) 56(84) bytes of data.64 bytes from 10.0.0.105: icmp_seq=1 ttl=64 time=0.010 ms64 bytes from 10.0.0.105: icmp_seq=2 ttl=64 time=0.018 ms^C--- yang.local ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1001msrtt min/avg/max/mdev = 0.010/0.014/0.018/0.004 ms➜ ~➜ ~ ping yangPING yang (127.0.1.1) 56(84) bytes of data.64 bytes from yang (127.0.1.1): icmp_seq=1 ttl=64 time=0.017 ms64 bytes from yang (127.0.1.1): icmp_seq=2 ttl=64 time=0.019 ms^C--- yang ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 999msrtt min/avg/max/mdev = 0.017/0.018/0.019/0.001 ms➜ ~ 其他PC，可以通过ping yang.local来定位你的主机（同一局域网内），但ping yang则只能本机使用. 有些linux程序，它要求权限是认证过的hostname，如果随意改为了其他hostname，有些程序可能使用不了，而报类似以下错误: 1234unable to resolve host (none)No protocol specified 有些应用程序，会以hostname作为提示语.比如bash /ect/hosts这个是域名查找系统（DNS），只不过，它只是本地查找的，在本地建立一个ip &lt;-&gt; name的对应关系。 “DNS劫持”原理，就相当于修改这个文件，只是网络上的DNS范围比较大，而本地的这个/etc/hosts只是对本机生效，真正的DNS如果进行修改的话，就是对所有DNS服务器设置为该服务器的所有PC生效。 计算机的寻址：应用 -&gt; 应用缓存 -&gt; hosts -&gt; DNS -&gt; 目的PC 而修改hostname，只是对局域网寻址生效，而且hostname在一局域网里，应该是唯一的。hosts，只是类似一个本地的DNS映射数据库.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
        <tag>hostname</tag>
        <tag>hosts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 上设置Emacs字体]]></title>
    <url>%2F2015%2F12%2F06%2FMac-%E4%B8%8A%E8%AE%BE%E7%BD%AEEmacs%E5%AD%97%E4%BD%93%2F</url>
    <content type="text"><![CDATA[更新完Mac OS X EI Capitan后,emacs的字体变得惨不忍睹.还以为无救了, 然后试了下重装emacs, 删除~/.emacs.d/,最终都无效果.最后Google到有位同志的修改: 123456(set-frame-font "Monaco:pixelsize=15")(dolist (charset '(han kana symbol cjk-misc bopomofo)) (set-fontset-font (frame-parameter nil 'font) charset (font-spec :family "Hiragino Sans GB" :size 18))) 因为自己使用的是 prelude. 需要将这配置文件写到: 1234567➜ ~ cat ~/.emacs.d/personal/preload/yang.el(set-frame-font "Monaco:pixelsize=15")(dolist (charset '(han kana symbol cjk-misc bopomofo)) (set-fontset-font (frame-parameter nil 'font) charset (font-spec :family "Hiragino Sans GB" :size 15))) 他给出的字体太大,我自己改为了15, 我漂亮的emacs又回来了. 真的是大爱emacs. 用上了emacs后, 自己的网络ID等,都改为了emacsist. ~_~ 感谢这位仁兄: liuyix gist]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>linux</tag>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ中的基本概念]]></title>
    <url>%2F2015%2F12%2F06%2FRabbitMQ%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[RabbitMQ的工作流程12345----------------------- virtual host ------------------------------| -&gt; queue ||publisher -&gt; exchange -&gt; [binding] -&gt; queue -&gt; consumer || -&gt; queue |----------------------- virtual host ------------------------------ RabbitMQ是通过virtual host的概念来实行环境隔离的. 以下,来理解下各个概念 Virtual Host 为了在一个单独的代理上实现多个隔离的环境（用户、用户组、交换机、队列 等），AMQP提供了一个虚拟主机（virtual hosts - vhosts）的概念 默认的virtual host为/. 创建一个virtual host123456rabbitmqctl add_vhost test例如:➜ ~ rabbitmqctl add_vhost testCreating vhost "test" ...➜ ~ 删除一个virtual host1234567rabbitmqctl delete_vhost test例如:➜ ~ rabbitmqctl delete_vhost testDeleting vhost "test" ...➜ ~ 列出所有virtual host12345678910111213141516rabbitmqctl list_vhosts name tracing例如:➜ ~ rabbitmqctl list_vhostsListing vhosts .../test➜ ~➜ ~ rabbitmqctl list_vhosts name tracingListing vhosts .../ falsetest false➜ ~ exchange (交换机) 交换机是用来发送消息的AMQP实体。交换机拿到一个消息之后将它路由给一个或零个队列。它使用哪种路由算法是由交换机类型和被称作绑定（bindings）的规则所决定的 default exchange (默认交换机) 默认交换机（default exchange）实际上是一个由消息代理预先声明好的没有名字（名字为空字符串）的直连交换机（direct exchange）。它有一个特殊的属性使得它对于简单应用特别有用处：那就是每个新建队列（queue）都会自动绑定到默认交换机上，绑定的路由键（routing key）名称与队列名称相同。 Direct exchange（直连交换机） 直连型交换机（direct exchange）是根据消息携带的路由键（routing key）将消息投递给对应队列的。直连交换机用来处理消息的单播路由（unicast routing）（尽管它也可以处理多播路由） 注意,这个路由键必须完全匹配才能投递. funout exchange (扇形交换机) 扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的拷贝分别发送给这所有的N个队列。扇型用来交换机处理消息的广播路由（broadcast routing）。 topic exchanges (主题交换机) 主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。主题交换机经常用来实现各种分发/订阅模式及其变种。主题交换机通常用来实现消息的多播路由（multicast routing）。 headers exchange (头交换机) 头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则. 头交换机可以视为直连交换机的另一种表现形式。头交换机能够像直连交换机一样工作，不同之处在于头交换机的路由规则是建立在头属性值之上，而不是路由键。路由键必须是一个字符串，而头属性值则没有这个约束，它们甚至可以是整数或者哈希值（字典）等 交换机常用属性 Name: 交换机名 Durability: （消息代理重启后，交换机是否还存在） Auto-delete: （当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它） Arguments:（依赖代理本身) 常用命令列出所有交换机123456789101112131415161718rabbitmqadmin -V test list exchanges例如:➜ ~ rabbitmqadmin -V / list exchanges+--------------------+---------+| name | type |+--------------------+---------+| | direct || amq.direct | direct || amq.fanout | fanout || amq.headers | headers || amq.match | headers || amq.rabbitmq.log | topic || amq.rabbitmq.trace | topic || amq.topic | topic |+--------------------+---------+➜ ~ 声明一个交换机123rabbitmqadmin declare exchange name=my-new-exchange type=fanouttype可以参考上面的类型. queue (队列) 队列在声明（declare）后才能被使用。如果一个队列尚不存在，声明一个队列会创建它。如果声明的队列已经存在，并且属性完全相同，那么此次声明不会对原有队列产生任何影响。如果声明中的属性与已存在队列的属性有差异，那么一个错误代码为406的通道级异常就会被抛出 常用属性 Name: 队列名 Durable:（消息代理重启后，队列依旧存在） Exclusive:（只被一个连接（connection）使用，而且当连接关闭后队列即被删除） Auto-delete:（当最后一个消费者退订后即被删除） Arguments:（一些消息代理用他来完成类似与TTL的某些额外功能） 常用命令列出队列简要信息1234567891011rabbitmqadmin list queues vhost name node messages message_stats.publish_details.rate例如:➜ ~ rabbitmqadmin list queues vhost name node messages message_stats.publish_details.rate+-------+-------------+------------------+----------+------------------------------------+| vhost | name | node | messages | message_stats.publish_details.rate |+-------+-------------+------------------+----------+------------------------------------+| / | yangzhiyong | rabbit@localhost | 0 | |+-------+-------------+------------------+----------+------------------------------------+➜ ~ 列出队列尽可能详细信息1rabbitmqadmin -f long -d 3 list queues 声明一个队列1rabbitmqadmin declare queue name=my-new-queue durable=false 发布一条消息1rabbitmqadmin publish exchange=amq.default routing_key=test payload="hello, world" 取出一条消息1rabbitmqadmin get queue=test requeue=false Binding (绑定) 绑定（Binding）是交换机（exchange）将消息（message）路由给队列（queue）所需遵循的规则. 示例扇形交换机使用例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546声明一个扇形交换机:➜ ~ rabbitmqadmin declare exchange name=myexchange type=fanoutexchange declared声明两个队列➜ ~ rabbitmqadmin declare queue name=myqueue durable=truequeue declared➜ ~ rabbitmqadmin declare queue name=myqueue2 durable=truequeue declared➜ ~绑定队列到交换机➜ ~ rabbitmqadmin declare binding source=myexchange destination_type="queue" destination="myqueue" routing_key="ignore_routing_key"binding declared➜ ~➜ ~ rabbitmqadmin declare binding source=myexchange destination_type="queue" destination="myqueue2" routing_key="ignore_routing_key"binding declared➜ ~发布一条消息到交换myexchange➜ ~ rabbitmqadmin publish exchange=myexchange routing_key="ignore_routing_key" payload="hello, world, from publisher"Message published➜ ~从队列"myqueue"出队一条消息➜ ~ rabbitmqadmin get queue=myqueue requeue=true+--------------------+------------+---------------+------------------------------+---------------+------------------+------------+-------------+| routing_key | exchange | message_count | payload | payload_bytes | payload_encoding | properties | redelivered |+--------------------+------------+---------------+------------------------------+---------------+------------------+------------+-------------+| ignore_routing_key | myexchange | 0 | hello, world, from publisher | 28 | string | | False |+--------------------+------------+---------------+------------------------------+---------------+------------------+------------+-------------+➜从队列"myqueue2"出队一条消息➜ ~ rabbitmqadmin get queue=myqueue2 requeue=true+--------------------+------------+---------------+------------------------------+---------------+------------------+------------+-------------+| routing_key | exchange | message_count | payload | payload_bytes | payload_encoding | properties | redelivered |+--------------------+------------+---------------+------------------------------+---------------+------------------+------------+-------------+| ignore_routing_key | myexchange | 0 | hello, world, from publisher | 28 | string | | False |+--------------------+------------+---------------+------------------------------+---------------+------------------+------------+-------------+➜ 注意,扇形交换机会忽略routing_key的,只要队列绑定到了扇形交换机,那么扇形交换机就会将这些消息,都会发给每一个队列. 其他有兴趣的, 可以自行测试. 还有, 这里没有指明virtual host,那么就是默认的/.如果指定了virtual host,那么上面的每条命令的virtual host都要相同. 参考资料 Rabbitmq rabbitmqctl文档 Rabbitmq 中文文档 binding]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下设置brew国内源]]></title>
    <url>%2F2015%2F12%2F05%2FMac%E4%B8%8B%E8%AE%BE%E7%BD%AEbrew%E5%9B%BD%E5%86%85%E6%BA%90%2F</url>
    <content type="text"><![CDATA[清华大学镜像1234567891011121314cd /usr/localgit remote set-url origin git://mirrors.tuna.tsinghua.edu.cn/homebrew.gitbrew update如果速度还是很慢，可以尝试以下操作：cd ~/tmpgit clone git://mirrors.tuna.tsinghua.edu.cn/homebrew.gitrm -rf /usr/local/.gitrm -rf /usr/local/Librarycp -R homebrew/.git /usr/local/cp -R homebrew/Library /usr/local/brew update homebrew-science 或者 homebrew-python1234567cd /usr/local/Library/Taps/homebrew/homebrew-sciencegit remote set-url origin git://mirrors.tuna.tsinghua.edu.cn/homebrew-science.gitcd /usr/local/Library/Taps/homebrew/homebrew-pythongit remote set-url origin git://mirrors.tuna.tsinghua.edu.cn/homebrew-python.gitbrew update 中国科学技术大学开源镜像12cd /usr/localgit remote set-url origin git://mirrors.ustc.edu.cn/homebrew.git 资料 中国科学技术大学开源镜像 清华大学Homebrew开源镜像 清华大学开源镜像列表]]></content>
      <categories>
        <category>mac</category>
      </categories>
      <tags>
        <tag>macbook</tag>
        <tag>homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 在Mac上的安装与使用]]></title>
    <url>%2F2015%2F12%2F05%2FRabbitMQ-%E5%9C%A8Mac%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[安装12brew updatebrew install rabbitmq 这样子安装的话, RabbitMQ的脚本是安装到/usr/local/sbin这个目录里的.并且不会自动添加到你的PATH里,所以,要添加下先: 123456#根据你的shell类型选择open -e ~/.zshrc 或者 open -e ~/.bash_profile 或者 open -e ~/.profile然后添加以下语句:PATH=$PATH:/usr/local/sbin 这些脚本,可以不必使用sudo来运行. 启动服务1rabbitmq-server 默认情况下, 用户名为:guest,密码为guest.如果客户端没有配置任何的东西的话, 它就默认使用这个用户名和密码. 而且guest用户,默认情况下,只能通过localhost来连接到rabbitmq.如果想允许guest用户,进行远程连接,则应该将rabbitmq.config文件设置为如下: 1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;]. 生产环境下的配置调整最大打开文件数ulimit -n: 在大部分的操作系统里,这太小了(例如,在一些Linux发行版里, 它的默认值为1024). 强烈建议将用户rabbitmq设置为65536. 或者4096也应该可以满足大部分的开发者需求了. 操作系统内核允许最大打开文件数:1kern.maxfilesperproc 用户级别方法一1ulimit -n 用户级别的调整:在运行rabbitmq-server之前,设置一下:1ulimit -S -n 4096 方法二编辑rabbitmq-env.conf, 在启动服务之前调用ulimit 方法三配置 launchctl limit /etc/launchd.conf 注意修改这些限制,对于正在运行的进程来说,是无效的, 必须是启动之前设置. 查看rabbitmq当前限制1rabbitmqctl status 查看当前用户的限制1launchctl limit 配置文件的位置RabbitMQ 配置文件的位置 常用命令列出所有用户1rabbitmqctl list_users 添加一个用户1rabbitmqctl add_user Username Password 删除一个用户1rabbitmqctl delete_user Username 修改用户的密码1rabbitmqctl change_password Username Newpassword 可用用户角色administrator 可登陆管理控制台(启用management plugin的情况下)，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 monitoring 可登陆管理控制台(启用management plugin的情况下)，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) policymaker 可登陆管理控制台(启用management plugin的情况下), 同时可以对policy进行管理。但无法查看节点的相关信息. management 仅可登陆管理控制台(启用management plugin的情况下)，无法看到节点信息，也无法对策略进行管理 其他 就是普通的消费者和生产者 用户角色设置1rabbitmqctl set_user_tags User Tag [Tag2, Tag3 ...] User为用户名， Tag为角色名(对应于上面的administrator，monitoring，policymaker，management，或其他自定义名称) 使用 web 控制台1rabbitmq-plugins enable rabbitmq_management 访问:localhost:15672 就可以使用默认的guest用户来登录了. 要想使用远程登录,可以创建一个其他用户即可. RabbitMQ management 设置权限123456rabbitmqctl set_permissions -p vhostName yourName ".*" ".*" ".*"例如:➜ rabbitmq git:(master) rabbitmqctl set_permissions -p / yang ".*" ".*" ".*"Setting permissions for user "yang" in vhost "/" ...]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>mac</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash学习笔记]]></title>
    <url>%2F2015%2F12%2F04%2FBash%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[使脚本更具可移植12#!/usr/bin/env bash 布尔值0:表示true非0:表示false 12345678function getB()&#123; return 0&#125;while getB; do echo "fuck" sleep 1done 可以利用return 0表示true，return 1表示false. if123if TEST-COMMANDS; then CONSEQUENT-COMMANDSfi if-else12345if TEST_COMMANDS; then COMMANDSelse TEST_COMMANDS; then COMMANDSfi if-elif12345if TEST_COMMANDS; then COMMANDSelif TEST_COMMANDS; then COMMANDSfi if-elif-else1234567if TEST_COMMANDS; then COMMANDSelif TEST_COMMANDS; then COMMANDSelse COMMANDSfi demo123456789101112131415if [ -z $1 ];then usage exit 0fiif [ $1 = "stop" ]; then stopelif [ $1 = "start" ]; then startelif [ $1 = "restart" ]; then stop startelse usagefi while123while TEST_COMMANDS ; do COMMANDSdone demo1234while [ $1 -gt 0 ] ; do sleep 2 kill -0 $(getPID)done for123for i in `seq 1 10`; do echo $idone 123for i in $( ls ); do echo item: $idone function123function fname()&#123; COMMANDS&#125; 注意，在function里，并不能直接使用从命令行里传入的参数的，而要在调用函数时，显式再次传递如: 1fname $1 函数返回值12345function getPID()&#123; # replace the grep content with your tomcat path, start with [] local PID=`ps aux | grep "[a]pache-tomcat-7.0 (copy).63" | awk '&#123;print $2&#125;'` echo $PID&#125; 注意，bash里，return xxx可能并不是你想要的，它这样子并不是函数的返回值。要想使用函数的返回值，应该： 12345678function getPID()&#123; # replace the grep content with your tomcat path, start with [] local PID=`ps aux | grep "[a]pache-tomcat-7.0 (copy).63" | awk '&#123;print $2&#125;'` echo $PID&#125;local P_ID=$(getPID) 直接return，它表示的是函数执行完毕的状态结果。 例子获取命令行执行的结果12local PID=`ps aux | grep "[a]pache-tomcat-7.0 (copy).63" | awk '&#123;print $2&#125;'`echo $PID 即使用反单引号括住开头和结尾的命令行即可. 获取算术运算结果12H=$(( 3*4 ))echo $H 暂停N秒1sleep N 判断字符串是否为空1234if [ -z $1 ];then usage exit 0fi 数学表达式比较大于1[ ARG1 -gt ARG2 ] 大于等于1[ ARG1 -ge ARG2 ] 等于1[ ARG1 -eq ARG2 ] 不等于1[ ARG1 -ne ARG2 ] 小于1[ ARG1 -lt ARG2 ] 小于等于1[ ARG1 -le ARG2 ] 字符串比较等于1[ STR1 == STR2 ] 不等于1[ STR1 != STR2 ] 大于1[ STR1 &gt; STR2 ] 小于1[ STR1 &lt; STR2 ] 忽略大小写123shopt -s nocasematch[[ "foo" == "Foo" ]] &amp;&amp; echo "match" || echo "notmatch"shopt -u nocasematch 数字前补01for i in &#123;01..05&#125;; do echo "$i"; done 检测某程序是否存在stackoverflow 123$ command -v foo &gt;/dev/null 2&gt;&amp;1 || &#123; echo &gt;&amp;2 "I require foo but it's not installed. Aborting."; exit 1; &#125;$ type foo &gt;/dev/null 2&gt;&amp;1 || &#123; echo &gt;&amp;2 "I require foo but it's not installed. Aborting."; exit 1; &#125;$ hash foo 2&gt;/dev/null || &#123; echo &gt;&amp;2 "I require foo but it's not installed. Aborting."; exit 1; &#125;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bash</tag>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>script</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat控制脚本]]></title>
    <url>%2F2015%2F12%2F04%2FTomcat%E6%8E%A7%E5%88%B6%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[因为经常需要部署Tomcat服务器，所以才有了这个脚本. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#!/bin/bash#################################################################author: Zhiyong Yang#date: 2015-12-4#email: emacsist@qq.com################################################################TOMCAT_HOME_DIR='/home/yang/Java/apache-tomcat-7.0 (copy).63'function stop()&#123; if checkIsExist ; then "$&#123;TOMCAT_HOME_DIR&#125;"/bin/shutdown.sh sleep 1 while checkIsExist ; do sleep 2 kill -0 $(getPID) done fi&#125;function getPID()&#123; # replace the grep content with your tomcat path, start with [] local PID=`ps aux | grep "[a]pache-tomcat-7.0 (copy).63" | awk '&#123;print $2&#125;'` echo $PID&#125;function start()&#123; if ! checkIsExist ; then "$&#123;TOMCAT_HOME_DIR&#125;"/bin/startup.sh tail -f -n 100 "$&#123;TOMCAT_HOME_DIR&#125;"/logs/catalina.out fi&#125;function checkIsExist()&#123; local P_ID=$(getPID) if [ ! -z $&#123;P_ID&#125; ]; then echo "found running tomcat pid = $&#123;P_ID&#125;" return 0 else echo "not found running tomcat : $&#123;TOMCAT_HOME_DIR&#125;" return 1 fi&#125;function usage()&#123; echo "Usage:" echo "$0 start : for start tomcat, no repeat" echo "$0 stop : for stop tomcat" echo "$0 restart : for restart"&#125;if [ -z $1 ];then usage exit 0fiif [ $1 = "stop" ]; then stopelif [ $1 = "start" ]; then startelif [ $1 = "restart" ]; then stop startelse usagefi]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>server</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 中的 @Async 和 @Scheduled 理解]]></title>
    <url>%2F2015%2F12%2F04%2FSpring-%E4%B8%AD%E7%9A%84-Async-%E5%92%8C-Scheduled-%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[@Asyncspring-test.xml文件 12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:task="http://www.springframework.org/schema/task" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd"&gt; &lt;task:annotation-driven scheduler="myScheduler" executor="myExecutor"/&gt; &lt;task:executor id="myExecutor" pool-size="20"/&gt; &lt;task:scheduler id="myScheduler" pool-size="5"/&gt; &lt;bean id="hello" class="hello.world.task.TestTask" /&gt;&lt;/beans&gt; spring官网例子12345678910111213141516171819202122import java.util.concurrent.Future;import org.springframework.scheduling.annotation.Async;import org.springframework.scheduling.annotation.AsyncResult;import org.springframework.stereotype.Service;import org.springframework.web.client.RestTemplate;@Servicepublic class GitHubLookupService &#123; RestTemplate restTemplate = new RestTemplate(); @Async public Future&lt;User&gt; findUser(String user) throws InterruptedException &#123; System.out.println("Looking up " + user); User results = restTemplate.getForObject("https://api.github.com/users/" + user, User.class); // Artificial delay of 1s for demonstration purposes Thread.sleep(1000L); return new AsyncResult&lt;User&gt;(results); &#125;&#125; Async动作类 12345678910111213141516171819package hello.world.task;import org.springframework.scheduling.annotation.Async;import org.springframework.scheduling.annotation.AsyncResult;import java.util.concurrent.Future;/** * Created by yang on 15-12-3. */public class TestTask &#123; @Async public Future&lt;String&gt; run() throws InterruptedException &#123; System.out.println(Thread.currentThread().getName()); Thread.sleep(20 * 1000); return new AsyncResult&lt;String&gt;("hello"); &#125;&#125; java测试类 1234567891011121314151617181920212223242526272829303132package hello.world;import hello.world.task.TestTask;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import java.util.concurrent.ExecutionException;import java.util.concurrent.Future;/** * Created by yang on 15-11-9. */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:spring-test.xml")public class HelloTest &#123; @Autowired private TestTask testTask; @Test public void run() throws ExecutionException, InterruptedException &#123; Future&lt;String&gt; hello = testTask.run(); System.out.println("after 20 s?"); String h = hello.get(); System.out.println(h); &#125;&#125; 以上，它是以myexecutor的线程池来执行的. @Scheduled将@Async改为@Scheduled 1234567public class TestTask &#123; @Scheduled(cron = "*/2 * * * * *") public void run() throws InterruptedException &#123; System.out.println(Thread.currentThread().getName()); &#125;&#125; 看执行结果，它是以myscheduler的线程池来执行的，而且返回值只能是void. 同时使用 @Scheduled 和 @Async不过注意，如果这样子使用了，异步执行的返回结果Future就不要这样子使用了，这时返回值只能是void. 同时使用这两个注解的效果，相当于@Scheduled负责调度，而executor负责执行。 看打印的线程可知: 12345678910111213141516myExecutor-1myExecutor-2myExecutor-3myExecutor-4myExecutor-5myExecutor-6myExecutor-7myExecutor-8myExecutor-9myExecutor-10myExecutor-11myExecutor-12myExecutor-13myExecutor-14myExecutor-15myExecutor-16 它是非常有规律的：每一个任务，都是下一条线程。然后轮回。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>task</tag>
        <tag>executor</tag>
        <tag>scheduled</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA 和 Eclipse 调试多线程应用]]></title>
    <url>%2F2015%2F12%2F03%2FIDEA-%E5%92%8C-Eclipse-%E8%B0%83%E8%AF%95%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[起源从Eclipse切换到IDEA后，在进行多线程调试的时候，发现它阻塞了其他所有的线程，但是在同事的Eclipse上进行调试的时候，却发现并没有阻塞。 原因我使用的IDEA版本是14.1.4(Ubuntu 14.04 64 bit, JDK 1.8 64 bit)，经过查资料发现IDEA和Eclipse的调试策略默认情况下配置不同. IDEA默认是ALL级别 Eclipse默认是Thread级别 解决想要调整调试级别时，可以到相应的IDE下修改下即可. IDEA -&gt; run -&gt; View breakpoints，选择对应的断点，然后在右边的界面里选择Suspend，有两个选项ALL和Thread. 因为默认情况下是ALL，所以才会导致阻塞所有. Eclipse -&gt; Window -&gt; Preferences -&gt; Java -&gt; Debug ，右边的界面有Default suspend policy for new breakpoints，这个是全局默认修改配置.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>eclipse</tag>
        <tag>idea</tag>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL数组中统计例子]]></title>
    <url>%2F2015%2F12%2F02%2FPostgreSQL%E6%95%B0%E7%BB%84%E4%B8%AD%E7%BB%9F%E8%AE%A1%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[问题这个问题，是在一个PG群里有群友问到的。如下: 123456789101112131415请教个问题有个表 temp数据如下(ids为array类型)ids no&#123;1,2&#125; 10&#123;1,3&#125; 20&#123;2,3&#125; 30现在希望得到这样的结果id no1 302 403 50这个group by应该怎么写？ 建表1create table tep (ids int[], no int); 插入示例数据123insert into tep values (array[1,2], 10);insert into tep values (array[1,3], 20);insert into tep values (array[2,3], 30); SQL解决思路：因为他想要的是： 1231=10+202=10+303=20+30 所以，可以将数组中的元素，拆分成行，然后group by 一下id, sum(no)，就可以了，即： 12345678910111213141516171819202122yang=# with cte as (select unnest(ids) as id, no from tep) select id, sum(no) from cte group by id order by id asc; id | sum----+----- 1 | 30 2 | 40 3 | 50(3 rows)yang=#或yang=# select unnest(ids) as id, sum(no) from tep group by id order by id asc; id | sum----+----- 1 | 30 2 | 40 3 | 50(3 rows)yang=# 不知道为什么，总喜欢使用CTE来做.感觉这样子更清晰点，哈哈. 使用CTE，无索引的情况，与不使用CTE对比.123456789101112131415161718192021222324252627282930313233343536yang=# explain analyze verbose with cte as (select unnest(ids) as id, no from tep) select id, sum(no) from cte group by id order by id asc; QUERY PLAN-------------------------------------------------------------------------------------------------------------------------------- Sort (cost=306537.78..306538.28 rows=200 width=8) (actual time=8093.771..8093.771 rows=7 loops=1) Output: cte.id, (sum(cte.no)) Sort Key: cte.id Sort Method: quicksort Memory: 25kB CTE cte -&gt; Seq Scan on public.tep (cost=0.00..77148.14 rows=9175200 width=33) (actual time=0.076..3207.449 rows=7340032 loops=1) Output: unnest(tep.ids), tep.no -&gt; HashAggregate (cost=229380.00..229382.00 rows=200 width=8) (actual time=8093.757..8093.759 rows=7 loops=1) Output: cte.id, sum(cte.no) Group Key: cte.id -&gt; CTE Scan on cte (cost=0.00..183504.00 rows=9175200 width=8) (actual time=0.082..5851.946 rows=7340032 loops=1) Output: cte.id, cte.no Planning time: 0.175 ms Execution time: 8111.710 ms(14 rows)yang=# explain analyze verbose select unnest(ids) as id, sum(no) from tep group by id order by id asc; QUERY PLAN---------------------------------------------------------------------------------------------------------------------------------------- Sort (cost=3659321.29..3659323.04 rows=700 width=33) (actual time=5276.652..5276.653 rows=7 loops=1) Output: (unnest(ids)), (sum(no)) Sort Key: (unnest(tep.ids)) Sort Method: quicksort Memory: 25kB -&gt; HashAggregate (cost=3659284.66..3659288.21 rows=700 width=33) (actual time=5276.637..5276.639 rows=7 loops=1) Output: (unnest(ids)), sum(no) Group Key: unnest(tep.ids) -&gt; Seq Scan on public.tep (cost=0.00..1858440.66 rows=360168800 width=33) (actual time=0.052..3203.487 rows=7340032 loops=1) Output: unnest(ids), no Planning time: 0.212 ms Execution time: 5276.723 ms(11 rows)yang=# 这情况下，不使用CTE好点.]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Rabbit使用]]></title>
    <url>%2F2015%2F11%2F30%2FSpring-Rabbit%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Demo12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:task="http://www.springframework.org/schema/task" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:rabbit="http://www.springframework.org/schema/rabbit" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:p="http://www.springframework.org/schema/p" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit-1.1.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd"&gt; &lt;bean id="rabbitConnectionFactory" class="org.springframework.amqp.rabbit.connection.CachingConnectionFactory"&gt; &lt;constructor-arg value="10.0.0.11"/&gt; &lt;property name="username" value="guest"/&gt; &lt;property name="password" value="guest"/&gt; &lt;/bean&gt; &lt;bean id="converter" class="org.springframework.amqp.support.converter.JsonMessageConverter"&gt; &lt;property name="defaultCharset" value="UTF-8"/&gt; &lt;/bean&gt; &lt;rabbit:template id="rabbitTemplate" connection-factory="rabbitConnectionFactory" message-converter="converter" /&gt; &lt;rabbit:admin connection-factory="rabbitConnectionFactory"/&gt; &lt;rabbit:queue name="ttt.ttt.tt.tt"/&gt;&lt;/beans&gt; Java文件 12345678910111213141516171819202122232425262728293031323334package yourcompany;import com.yourcompany.pojo.ParamsPojo;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;/** * Created by yang on 15-11-9. */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:spring-test.xml")public class HelloTest &#123; @Autowired private RabbitTemplate template; @Test public void run() &#123; ParamsPojo pp = new ParamsPojo(); pp.setCuid(222222222); template.convertAndSend("ttt.ttt.tt.tt", pp); &#125; @Test public void run2() &#123; ParamsPojo pp = (ParamsPojo) template.receiveAndConvert("ttt.ttt.tt.tt"); System.out.println(pp.getCuid()); &#125;&#125; 关于序列化的选择问题&lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;rabbitConnectionFactory&quot; message-converter=&quot;converter&quot; /&gt; 这一行的配置，会创建一个org.springframework.amqp.rabbit.core.RabbitTemplate对象，默认情况下的MessageConverter，通过源码可知就是private volatile MessageConverter messageConverter = new SimpleMessageConverter(); 关于MessageConveter的类型： org.springframework.amqp.support.converter.SimpleMessageConverter这个是使用JDK默认的序列化来序列化Message的.（默认就是它） org.springframework.amqp.support.converter.JsonMessageConverter这个是使用Jacson工具来进行Message对象的JSON化的. org.springframework.amqp.support.converter.Jackson2JsonMessageConverter这个是使用Jacson 2 工具来进行message对象的json化的. org.springframework.amqp.support.converter.MarshallingMessageConverter这个是XML与对象互转的converter org.springframework.amqp.support.converter.SerializerMessageConverter这个是使用Spring框架内的序列化接口来做的. 序列化: org.springframework.core.serializer.DefaultSerializer，使用的是ObjectOutputStream来写入OutputStream反序列化：org.springframework.core.serializer.DefaultDeserializer，使用的是ObjectInputStream来读取InputStream. 使用默认的这两个Serializer时，本质上与JDK自带的序列化行为是相同的。通过源码可看到: 123456789public void serialize(Object object, OutputStream outputStream) throws IOException &#123; if (!(object instanceof Serializable)) &#123; throw new IllegalArgumentException(getClass().getSimpleName() + " requires a Serializable payload " + "but received an object of type [" + object.getClass().getName() + "]"); &#125; ObjectOutputStream objectOutputStream = new ObjectOutputStream(outputStream); objectOutputStream.writeObject(object); objectOutputStream.flush();&#125; 它必须要实现Serializable接口. 建议使用JSON的方式来进行序列化Message，这样子通过RabbitMQ管理后台，也可以了解队列的内容。如果用JDK自带的方式来序列化，这样子可查找问题的时候，难以定位数据.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下安装nodejs和hexo]]></title>
    <url>%2F2015%2F11%2F30%2FMac%E4%B8%8B%E5%AE%89%E8%A3%85nodejs%E5%92%8Chexo%2F</url>
    <content type="text"><![CDATA[安装xcode安装Install Xcode Command Line Tools. 在terminal，输入gcc，如果没有安装xcode，它会弹出一个窗口，让你安装Xcode Command Line Tools，安装即可. 安装 Homebrewruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装node123456789brew updatebrew install node升级brew updatebrew upgrade node删除brew uninstall node 使用Taobao的NPM镜像1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装成功后，就使用cnpm来代替npm使用即可. 安装hexo1234567891011cnpm install hexo-cli -gcnpm install hexo --no-optionalhexo init blogcd blogcnpm installhexo server 注意是有--no-optional的，不然有时会报以下这些错误（虽然不影响使用，但总会提示这些，不知道为什么） 123&#123; [Error: Cannot find module './build/Release/DTraceProviderBindings'] code: 'MODULE_NOT_FOUND' &#125;&#123; [Error: Cannot find module './build/default/DTraceProviderBindings'] code: 'MODULE_NOT_FOUND' &#125;&#123; [Error: Cannot find module './build/Debug/DTraceProviderBindings'] code: 'MODULE_NOT_FOUND' &#125;]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>hexo</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Task 中集群带来的问题]]></title>
    <url>%2F2015%2F11%2F27%2FSpring-Task-%E4%B8%AD%E9%9B%86%E7%BE%A4%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题当多台Tomcat同时进行调度时，如果没有处理好并发的问题，就会出现本应只是执行一次的Task，执行了两次（比如修改DB）。 DB解决办法在执行DB修改操作的方法上，添加上@Transactional（即添加事务处理）。如果想提高并发的话，减小事务锁的行数（这里是基于支持事务和行级锁的DB来说的，只支持全表锁的DB，可以忽略这行为），然后进行分批处理. 利用Redis的单线程处理机制利用redis的单线程处理机制，实现类似跨JVM锁的功能。合理控制好大范围并发，局部顺序执行（减小锁的范围）。 注：DB的话，最好还是由DB自身的MVCC特性来保证.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>task</tag>
        <tag>concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring里的Executor使用]]></title>
    <url>%2F2015%2F11%2F26%2FSpring%E9%87%8C%E7%9A%84Executor%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在生产环境中，发现我们Tomcat的应用导致超高的CPU（170%)及负载(90+)[Intel(R) Xeon(R) CPU E31230 @ 3.20GHz 四核心，8线程]. 原因经过排查发现，有些线程，占用超高的CPU： SimpleAsyncTaskExecutor-N，平均每个线程，上下文切换的次数都超过4W+，系统CPU占用率一直在60+。 查找原因途径查看上下文切换情况: pidstat -t -w -p PID 1 查看CPU情况: pidstat -t -u -p PID 1 查看内存情况: pidstat -t -r -p PID 1 查看IO情况: pidstat -t -d -p PID 1 找到对应的线程PID后，然后 jstatck -l Java主进程PID &gt; /tmp/Java主进程pid.log 导出线程栈情况，然后根据上面的pidstat工具查找对应占用资源情况的线程PID，与导出的Java线程情况的文件里/tmp/Java主进程pid.log查找与之对应的线程的详细情况.注意：pidstat得出的线程PID是十进制的，而jstatck导出的线程PID是十六进制的，这要转换成十六进制后，再在导出的文件/tmp/Java主进程pid.log里查找. 可以使用以下shell命令来进行转换1234567891011121314151617181920212223242526转换的方法:➜ Desktop cat hello.txt 03:25:21 HKT - 8765 2902.00 26.00 |__java03:25:21 HKT - 8767 3049.00 20.00 |__java03:25:21 HKT - 8852 2896.00 41.00 |__java03:25:21 HKT - 8853 3056.00 36.00 |__java03:25:21 HKT - 8854 2841.00 27.00 |__java03:25:21 HKT - 8855 2738.00 29.00 |__java03:25:21 HKT - 8871 2823.00 124.00 |__java03:25:21 HKT - 8872 2865.00 9.00 |__java03:25:21 HKT - 8875 2905.00 24.00 |__java03:25:21 HKT - 8876 3090.00 27.00 |__java➜ Desktop cat hello.txt | awk '&#123;print $4&#125;' | xargs -I &#123;&#125; printf "&#123;&#125;=%x\n" &#123;&#125; 8765=223d8767=223f8852=22948853=22958854=22968855=22978871=22a78872=22a88875=22ab8876=22ac➜ Desktop 这时，我发现，是由10多条以SimpleAsynctaskExecutor开头的线程占用了超高的CPU。 找出对应的线程后，再根据文件里/tmp/Java主进程pid.log对应线程的调用栈，类似如下内容: 12345678910111213141516"SimpleAsyncTaskExecutor-1" prio=10 tid=0x00007fe354e56000 nid=0x5440 runnable [0x00007fe359acd000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000007a1d79ed0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082) at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.nextMessage(BlockingQueueConsumer.java:188) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:466) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:455) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$300(SimpleMessageListenerContainer.java:58) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:548) at java.lang.Thread.run(Thread.java:722) Locked ownable synchronizers: - None 这时，我们查看类源码org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer，发现到一个问题： 1private volatile Executor taskExecutor = new SimpleAsyncTaskExecutor(); 这一行代码，暴露出了它使用了SimpleAsyncTaskExecutor来执行我们的任务. SimpleAsyncTaskExecutor 说明通过Spring官方文档SimpleAsynctaskExecutor可知： 每执行一个task，都会创建一个新的线程来执行任务 默认情况下，创建的线程数量是无限的（可以通过 concurrencyLimit 属性来限制） 这个实现，并不会重用任何线程的! 项目自身的原因由于我们使用了Spring Rabbit，配置如下: 12&lt;rabbit:listener-container connection-factory="rabbitConnectionFactory" error-handler="MessageErrorHandler"&gt;&lt;/rabbit:listener-container&gt; 这样子，默认的情况下，就是使用了private volatile Executor taskExecutor = new SimpleAsyncTaskExecutor(); 我们改为 12345 &lt;task:annotation-driven executor="myExecutor" scheduler="myScheduler"/&gt;&lt;task:executor id="myExecutor" pool-size="10-20" /&gt;&lt;task:scheduler id="myScheduler" pool-size="5" /&gt; &lt;rabbit:listener-container connection-factory="rabbitConnectionFactory" error-handler="MessageErrorHandler" concurrency="10" task-executor="myExecutor"&gt; &lt;/rabbit:listener-container&gt; 这样子定义&lt;task:executor&gt;后，就会Spring就会创建一个ThreadPoolTaskExecutor，包含有线程池了. Spring Task注意，使用Spring Task也要留意这个问题，都要记得指定executor，不然Spring又创建了SimpleAsyncTaskExecutor这种线程执行器。不过，SimpleAsyncTaskExecutor比较适合于那种临时性，执行时间非常短的任务。不过，还是线程池使用的比较安全点. 性能如果担心创建的线程池太多占用资源，可以使用pool-size=&quot;10-20&quot;这种范围式声明线程池的大小，有个动态范围. 技巧要多点看看Spring所在版本的 XSD 文件里的说明，那里有非常详细的说明文档，这样子在对应的版本里，就会有对应的executor行为了 参考资料 http://www.baeldung.com/spring-async http://stackoverflow.com/questions/13401558/spring-simpleasynctaskexecutor-and-threadpooltaskexecutor-with-async-annotation http://blog.csdn.net/yangjun2/article/details/8363750 http://www.7-sun.com/doc/spring2.5_doc_cn/org/springframework/scheduling/backportconcurrent/ThreadPoolTaskExecutor.html http://my.oschina.net/never/blog/140368?fromerr=PEzwhJbo]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>executor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux xargs 使用]]></title>
    <url>%2F2015%2F11%2F25%2Flinux-xargs-%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[使用xargs要特别注意，默认情况下，它是以整行作为[项]的. -a指定文件来代替标准输入(stdin). 12345➜ xargs cat hello.txta b c d➜ xargs xargs -a hello.txta b c d➜ xargs –null 或者 -0输入项，是以null字符结尾的，而不是以白空格（whitespace），引号，反斜杠等（这时，会将这些当作字面值处理）。 例子: 1234567➜ xargs echo "hello // world" | xargs -n 2hello //world➜ xargs echo "hello // world" | xargs -0 -n 2hello // world➜ xargs -d 或者 –delimiter=delim输入项以指定字符作为结束.（注意，不支持多字符），例如: 123456➜ xargs echo "hello//world" | xargs -d "/" -n 1helloworld➜ xargs -E eof-str 或者 –eof=eof-str 或者 -e[eof-str]设置文件结束字符串. 1234➜ xargs echo "hello//world hello//word2" | xargs -E "world" -n 1hello//worldhello//word2➜ xargs -I replace-str 或者 –replace=replace-str 或者 -i[replace-str]按行输入的内容替换到指定的replace-str中.例如: 123456➜ xargs cat hello.txt| xargs -I XYZ echo -e "line content: XYZ\nAgain: XYZ"line content: a b c dAgain: a b c dline content: aa bb cc ddAgain: aa bb cc dd➜ xargs 即-L 1 -L max-lines 或者 –max-lines=[max-lines] 或者 –l[max-lines]将最多max-lines行的输入当成一行。例如: 123456789➜ xargs cat hello.txta b c daa bb cc dd➜ xargs cat hello.txt | xargs -L 1 echoa b c daa bb cc dd➜ xargs cat hello.txt | xargs -L 2 echoa b c d aa bb cc dd➜ xargs –max-args=max-args 或者 -n max-args每个命令行最多使用max-args个参数。默认情况下，xargs会一次性传递所有数据，当作一个参数。使用这个参数，可以覆盖默认的行为。 12345➜ xargs cat hello.txt | xargs -L 2 -n 3 echoa b cd aa bbcc dd➜ xargs -t执行之前，打印一下要执行的命令 –show-limits显示命令行长度的限制.(字节） –exit 或者 -x退出，如果超出-s参数指定的值.（字节） –max-procs=max-procs 或者 -P max-procs一次运行max-procs个进程。默认为1,如果设置为0，则xargs会尽可能在同一时间同时运行多个进程。 示例删除redis某些指定的key1redis-cli -h 10.0.0.5 -n 2 -p 6579 -a yourpasswd keys *session* | xargs redis-cli -n 2 -h 10.0.0.5 -p 6579 -a yourpasswd del 根据文件里指定的key-value来设置redis1234567891011➜ xargs cat k-v.txtkey1 value1 key2 value2 key3 value3➜ xargs➜ xargs cat k-v.txtkey1 value1 key2 value2 key3 value3➜ xargs cat k-v.txt | xargs -P 0 -n 2 redis-cli -p 6379 setOKOKOK➜ xargs 删除由文件里指定的redis的key一个一个删除: 123456789➜ xargs cat redis.txtkey1 key2 key3 key4➜ xargs➜ xargs cat redis.txt | xargs -P 0 -n 1 redis-cli -p 6379 del(integer) 1(integer) 1(integer) 1➜ xargs 一次性删除: 1234567➜ xargs cat redis.txtkey1 key2 key3 key4➜ xargs➜ xargs cat redis.txt | xargs -P 0 redis-cli -p 6379 del(integer) 3➜ xargs]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bash</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 进程监控]]></title>
    <url>%2F2015%2F11%2F25%2FLinux-%E8%BF%9B%E7%A8%8B%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[进程监控pidstat [option] interval [count] 监控进程的内存使用情况12345678910$ pidstat -r -p 26092 1 5Linux 2.6.32-33-server (pro-srv4) Wednesday, November 25, 2015 _x86_64_ (8 CPU)11:16:38 HKT PID minflt/s majflt/s VSZ RSS %MEM Command11:16:39 HKT 26092 0.00 0.00 2983032 607484 3.69 java11:16:40 HKT 26092 0.00 0.00 2983032 607484 3.69 java11:16:41 HKT 26092 0.00 0.00 2983032 607484 3.69 java11:16:42 HKT 26092 0.00 0.00 2983032 607484 3.69 java11:16:43 HKT 26092 0.00 0.00 2983032 607484 3.69 javaAverage: 26092 0.00 0.00 2983032 607484 3.69 java 列说明: minflt/s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数majflt/s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生VSZ: 虚拟内存：整个进程使用的虚拟内存（KB）RSS: 常驻内存大小，占用的非交换分区的物理内存（KB）%MEM: 进程当前占用可用内存的百分比Command: 进程对应的命令 监控进程的IO使用情况1234567891011➜ ~ pidstat -d -p 2942 1 5Linux 3.16.0-50-generic (yang) 2015年11月25日 _x86_64_ (4 CPU)11时53分57秒 UID PID kB_rd/s kB_wr/s kB_ccwr/s Command11时53分58秒 1000 2942 0.00 0.00 0.00 java11时53分59秒 1000 2942 0.00 0.00 0.00 java11时54分00秒 1000 2942 0.00 0.00 0.00 java11时54分01秒 1000 2942 0.00 0.00 0.00 java11时54分02秒 1000 2942 0.00 0.00 0.00 javaAverage: 1000 2942 0.00 0.00 0.00 java➜ ~ 列说明: kb_rd/s：每秒读多少KBkb_rw/s：每秒写多少KBkb_ccwr/s：每秒多少KB正准备写到磁盘时被进程取消 监控进程的CPU使用情况12345678910➜ ~ pidstat -u -p 2942 1 5Linux 3.16.0-50-generic (yang) 2015年11月25日 _x86_64_ (4 CPU)11时59分19秒 UID PID %usr %system %guest %CPU CPU Command11时59分20秒 1000 2942 1.00 1.00 0.00 2.00 3 java11时59分21秒 1000 2942 1.00 0.00 0.00 1.00 3 java11时59分22秒 1000 2942 1.00 1.00 0.00 2.00 3 java11时59分23秒 1000 2942 1.00 0.00 0.00 1.00 3 java11时59分24秒 1000 2942 2.00 0.00 0.00 2.00 3 javaAverage: 1000 2942 1.20 0.40 0.00 1.60 - java 列说明： %usr：用户态CPU占用总CPU使用百分比%system：内核态CPU占总CPU使用百分比%guest： 进程运行在虚拟CPU上占用的百分比cpu: 进程运行在哪个CPU核上. 多处理器情况1pidstat -I 后面接的参数和上面的一样. 说明：这时，CPU的占用率是/CPU核心数后的数据的，没有 -I 的话，是看成单个CPU后的总占用率. 进程堆栈的情况1234567891011➜ ~ pidstat -s -p 2942 1 5Linux 3.16.0-50-generic (yang) 2015年11月25日 _x86_64_ (4 CPU)14时36分01秒 UID PID StkSize StkRef Command14时36分02秒 1000 2942 140 44 java14时36分03秒 1000 2942 140 44 java14时36分04秒 1000 2942 140 44 java14时36分05秒 1000 2942 140 44 java14时36分06秒 1000 2942 140 44 javaAverage: 1000 2942 140 44 java➜ ~ 列说明： StkSize：为进程预留的栈大小（KB）StkRef：进程使用的栈大小（KB） 进程上下文切换情况1234567891011➜ ~ pidstat -w -p 2942 1 5Linux 3.16.0-50-generic (yang) 2015年11月25日 _x86_64_ (4 CPU)14时38分55秒 UID PID cswch/s nvcswch/s Command14时38分56秒 1000 2942 0.00 0.00 java14时38分57秒 1000 2942 0.00 0.00 java14时38分58秒 1000 2942 0.00 0.00 java14时38分59秒 1000 2942 0.00 0.00 java14时39分00秒 1000 2942 0.00 0.00 javaAverage: 1000 2942 0.00 0.00 java➜ ~ 列说明: cswch/s：进程每秒自愿上下文切换次数，这当一个进程因为一个资源不可用而导致阻塞时就会出现这种自愿上下文切换. nvcswch/s: 进程非自愿上下文切换次数。当一个进程在CPU时间片内执行期间被强迫放弃CPU时就会出现这种非自愿上下文切换. 线程的级别1pidstat -t 其他参数和以上相同.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Redis 使用]]></title>
    <url>%2F2015%2F11%2F23%2FSpring-Redis-%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Pipelining共享一条connection，以减少因为网络连接导致的性能问题: 12345678910List&lt;Object&gt; results = stringRedisTemplate.executePipelined( new RedisCallback&lt;Object&gt;() &#123; public Object doInRedis(RedisConnection connection) throws DataAccessException &#123; StringRedisConnection stringRedisConn = (StringRedisConnection)connection; for(int i=0; i&lt; batchSize; i++) &#123; stringRedisConn.rPop("myqueue"); &#125; return null; &#125;&#125;); transactionredis中的事务 12345678910List&lt;Object&gt; txResults = redisTemplate.execute(new SessionCallback&lt;List&lt;Object&gt;&gt;() &#123; public List&lt;Object&gt; execute(RedisOperations operations) throws DataAccessException &#123; operations.multi(); operations.opsForSet().add("key", "value1"); // This will contain the results of all ops in the transaction return operations.exec(); &#125;&#125;);System.out.println("Number of items added to set: " + txResults.get(0)); demo12345678910111213141516171819202122232425262728293031323334353637383940414243@Testpublic void genrete() &#123; ValueOperations&lt;String, String&gt; valueOperations = redisTemplate.opsForValue(); for (int i = 0; i &lt; 2000; i++) &#123; valueOperations.set("hello" + i, String.valueOf(i)); &#125; System.out.println("gen ok");&#125;@Testpublic void forGet() &#123; ValueOperations&lt;String, String&gt; valueOperations = redisTemplate.opsForValue(); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 2000; i++) &#123; String hello = valueOperations.get("hello" + i); System.out.println(hello); &#125; System.out.println("cost for get " + (System.currentTimeMillis() - start)); // cost for get 2458 ms&#125;@Testpublic void forPipline() &#123; ValueOperations&lt;String, String&gt; valueOperations = redisTemplate.opsForValue(); long start = System.currentTimeMillis(); List&lt;Object&gt; list = redisTemplate.executePipelined(new RedisCallback&lt;Object&gt;() &#123; @Override public Object doInRedis(RedisConnection redisConnection) throws DataAccessException &#123; redisConnection.openPipeline(); for (int i = 0; i &lt; 2000; i++) &#123; redisConnection.get(("hello" + i).getBytes()); &#125; return null;//注意，这里一定要返回null &#125; &#125;, redisTemplate.getKeySerializer()); for (Object hello : list) &#123; System.out.println(hello); &#125; System.out.println("cost for piple " + (System.currentTimeMillis() - start)); // cost for piple 121 ms&#125; 使用问题ERR Protocol error: invalid multibulk length一下子执行的redis的命令大小太大，比如下面的： 1234final String keysPattern = CcRedisKeyUtils.Session.getCleanSessionObjectKeys(userId);//Set&lt;String&gt; ks = hashOps.getOperations().keys(keysPattern);final Set&lt;String&gt; ks = RedisKeysPatternUtils.getKeys(hashOps.getOperations(), keysPattern);hashOps.getOperations().delete(ks); 参考资料 参考资料 Spring-data-redis]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis升级]]></title>
    <url>%2F2015%2F11%2F23%2FRedis%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[创建一个新的实例123456wget http://download.redis.io/redis-stable.tar.gztar -xvf redis-stable.tar.gzcd redis-stablemakemake PREFIX=/some/other/directory install 启动slave实例 1/some/other/directory/bin/redis-server /path/to/redis/redis.conf 开启复制如果master要认证的话，要先认证下先,在slave的实例中的redis-cli启动后，输入以下命令 1config set masterauth &lt;password&gt; 然后开始复制: 1slaveof materIP masterPort 检查是否复制完成检查从slave的日志文件，如果出现如下的提示，表明复制成功: 12315293:S 23 Nov 16:21:37.560 * MASTER &lt;-&gt; SLAVE sync: Flushing old data15293:S 23 Nov 16:21:37.560 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory15293:S 23 Nov 16:21:50.799 * MASTER &lt;-&gt; SLAVE sync: Finished with success 查看主从的INFO信息在主从实例中，都执行INFO命令，查看键数等是否一致. 允许从实例进行写操作默认情况下,redis的从slave实例是只读的，要开启写的话，可以在slave上执行: 1config set slave-read-only no 配置你的应用（客户端使用新的slave的连接信息） 从切换为主在slave上执行以下命令（要在没有命令执行的情况下进行切换，可以在slave上执行MONITOR命令查看情况)，如果没有的话，就可以切换了: 1SLAVEOF NO ONE 即可关闭复制，成为主实例.]]></content>
      <categories>
        <category>nosql</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[找出Java最耗CPU或IO的线程]]></title>
    <url>%2F2015%2F11%2F23%2F%E6%89%BE%E5%87%BAJava%E6%9C%80%E8%80%97CPU%E7%9A%84%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[查看某进程及某线程占用CPU的例子 jps: 列出java进程,找到pid. pidstat -p pid -u 1 3 -u -t: 查看pid的进程所有线程的cpu使用情况. jstack -l pid &gt; /tmp/thread.txt: 导出指定Java应用的所有线程. 然后查看 nid=xxx(即第二步里线程号的线程),即可定位到某段代码. 查看某进程及某线程占用IO的例子 jps: 列出java进程,找到pid. pidstat -p pid -u 1 3 -d -t: 查看pid的进程所有线程的IO使用情况. jstack -l pid &gt; /tmp/thread.txt: 导出指定Java应用的所有线程. 然后查看 nid=xxx(即第二步里线程号的线程),即可定位到某段代码. 进制转换十进制转换十六进制1printf "%x\n" 十进制数字 十六进制转换十进制1echo $((0x十六进制数字)) 例子12345➜ ~ printf "%x\n" 202024eea➜ ~ echo $((0x4eea))20202➜ ~]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>cpu</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC 里加载两次Bean的解决办法]]></title>
    <url>%2F2015%2F11%2F23%2FSpring-MVC-%E9%87%8C%E5%8A%A0%E8%BD%BD%E4%B8%A4%E6%AC%A1Bean%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[SpringMVC 里上下文的概念web.xml 里的配置 1234567891011121314151617181920212223242526272829303132&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5"&gt; &lt;display-name&gt;uniweibov2&lt;/display-name&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 在SpringMVC里，有两种上下文。一种是：Application Context，还有一种是Web Application Context. application context (parent)12345678&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring.xml&lt;/param-value&gt;&lt;/context-param&gt; 这样的配置，就是在配置application context，也就是parent application context web application context (child)12345678910111213&lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; parent 是共享于 child的，也就是说，在parent中定义的东西，都可以在child中使用. Bean加载两次的原因：这是由于在这两个context里，配置的时候导致Spring扫描时，扫描并加载了两次Bean. 例如，在这两个spring.xml和spring-servlet.xml配置文件里，都配置了: 1&lt;context:component-scan base-package="xx.yy" /&gt; 这样子，就会导致Spring加载了两次上下文环境。 解决办法方法一只使用一个上下文环境。即Bean的定义，只放在一个配置文件里，让另一个配置文件为空,即如下: 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:task="http://www.springframework.org/schema/task" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:p="http://www.springframework.org/schema/p" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd"&gt;&lt;/beans&gt; 这两个，只要一个为空，另一个不为空即可. 方法二在这两个配置文件里，只是没有配置重复的内容即可.即如果在parent里定义了的Bean，就不要在child里定义了。这时，可以使用如下的方式来配置： 在spring.xml里配置: 1234&lt;context:annotation-config /&gt; &lt;context:component-scan base-package="xx.yy"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; 这样子，就表明扫描除了有@Controller之外的所有注解的Bean. 在spring-servlet.xml里配置: 12345&lt;mvc:annotation-driven /&gt;&lt;!-- Scans for annotated @Controllers in the classpath --&gt;&lt;context:component-scan base-package="xx.yy" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt;&lt;/context:component-scan 这样子，就表明只扫描@Controller注解的Bean.注意这里的user-default-filters=&quot;false&quot; 包扫描详解&lt;context:component-scan base-package=&quot;xx.yy&quot; use-default-filters=&quot;false&quot;&gt; base-package：要扫描的包use-default-filters：是否使用默认的过滤器，默认为true，即扫描@Component, @Repository, @Service, @Controller这些注解的Beancontext:include-filter：使用白名单过滤器context:exclude-filter：使用黑名单过滤器 Spring 的使用顺序是： 先 exclude-filter，再到include-filter。 在源码org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider的方法里: 123456789101112131415161718protected boolean isCandidateComponent(MetadataReader metadataReader) throws IOException &#123; for (TypeFilter tf : this.excludeFilters) &#123; if (tf.match(metadataReader, this.metadataReaderFactory)) &#123; return false; &#125; &#125; for (TypeFilter tf : this.includeFilters) &#123; if (tf.match(metadataReader, this.metadataReaderFactory)) &#123; AnnotationMetadata metadata = metadataReader.getAnnotationMetadata(); if (!metadata.isAnnotated(Profile.class.getName())) &#123; return true; &#125; AnnotationAttributes profile = MetadataUtils.attributesFor(metadata, Profile.class); return this.environment.acceptsProfiles(profile.getStringArray("value")); &#125; &#125; return false;&#125; type的类型还有: 12345type=`annotation`type=`assignable`type=`aspectj`type=`regex`type=`custom`]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring session 添加HttpSessionListener]]></title>
    <url>%2F2015%2F11%2F23%2FSpring-session-%E6%B7%BB%E5%8A%A0HttpSessionListener%2F</url>
    <content type="text"><![CDATA[这时介绍的版本，是基于以下版本: 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session&lt;/artifactId&gt; &lt;version&gt;1.1.0.M1&lt;/version&gt;&lt;/dependency&gt; 先上示例demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd"&gt; &lt;context:annotation-config /&gt; &lt;bean id="v2redisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory" p:host-name="$&#123;config.redis.host&#125;" p:port="$&#123;redis.port&#125;" p:use-pool="true" p:database="$&#123;redis.database&#125;" p:password="$&#123;config.redis.password&#125;" /&gt; &lt;bean id="stringRedisSerializer" class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;bean id="genericToStringSerializer" class="org.springframework.data.redis.serializer.GenericToStringSerializer"&gt; &lt;constructor-arg type="java.lang.Class" value="java.lang.Object"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id="object" class="java.lang.Object"/&gt; &lt;bean id="v2redisTemplate" class="org.springframework.data.redis.core.RedisTemplate" p:connection-factory-ref="v2redisConnectionFactory" p:keySerializer-ref="stringRedisSerializer" p:valueSerializer-ref="genericToStringSerializer" p:hashKeySerializer-ref="stringRedisSerializer" p:hashValueSerializer-ref="genericToStringSerializer"/&gt; &lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"/&gt; &lt;!-- 2017-2-13 更新： --&gt; &lt;!-- YourHttpSessionListener 加上 @Component 注解即可，不需要下面的配置了，因为上面 RedisHttpSessionConfiguration 会自动将实现了 HttpSessionListener 的 bean 注册 ，下面再注册的话，就会执行多次了 --&gt; &lt;!-- Http session Listener Start --&gt; &lt;!--&lt;bean id="l" class="org.springframework.session.web.http.SessionEventHttpSessionListenerAdapter"&gt;--&gt; &lt;!--&lt;constructor-arg&gt;--&gt; &lt;!--&lt;list&gt;--&gt; &lt;!--&lt;ref bean="webHttpSessionListener" /&gt;--&gt; &lt;!--&lt;/list&gt;--&gt; &lt;!--&lt;/constructor-arg&gt;--&gt; &lt;!--&lt;/bean&gt;--&gt; &lt;!--&lt;bean class="org.springframework.security.web.session.HttpSessionEventPublisher"/&gt;--&gt; &lt;!-- END --&gt;&lt;/beans&gt; 实现原理事件类型通过查看源码，可知在包org.springframework.session.events下，有4个session生命周期的类型，比默认的javax.servlet.http.HttpSessionListener还多了两个.分别是以下四种事件类型： SessionCreatedEvent; Session创建 SessionDeletedEvent; Session删除 SessionDestroyedEvent; Session销毁 SessionExpiredEvent; Session过期 事件的触发查看源码org.springframework.session.data.redis.RedisOperationsSessionRepository可知: 事件的触发，是由org.springframework.context.ApplicationEventPublisher来发布事件的，它利用了Spring自带的事件模型来进行session的生命周期的事件发布。 Spring自带的事件模型例子步骤: 创建一个自定义的事件，它要继承于org.springframework.context.ApplicationEvent，然后在这里定义事件的属性和方法 创建一个自定义事件的发布器（广播器）,实现org.springframework.context.ApplicationEventPublisherAware接口，或者@Autowire ApplicationEventPublisher applicationEventPublisher，然后通过它来发布自定义事件. 创建一个自定义事件的监听器，它要实现org.springframework.context.ApplicationListener即可。 同步事件模型默认情况下，就是同步的. 创建一个登录的事件： 123456789101112131415161718public class TestLoginEvent extends ApplicationEvent &#123; private int userId; public TestLoginEvent(int userId) &#123; super(userId); this.userId = userId; &#125; public int getUserId() &#123; return userId; &#125; public void setUserId(int userId) &#123; this.userId = userId; &#125;&#125; 创建一个登录的事件的发布者: 1234567891011121314@Servicepublic class TestLoginEventPubisher implements ApplicationEventPublisherAware &#123; private ApplicationEventPublisher applicationEventPublisher; @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher = applicationEventPublisher; &#125; public void login(int userId) &#123; applicationEventPublisher.publishEvent(new TestLoginEvent(userId)); &#125;&#125; 创建一个登录事件的监听器: 12345678@Servicepublic class TestLoginEventListener implements ApplicationListener&lt;TestLoginEvent&gt; &#123; @Override public void onApplicationEvent(TestLoginEvent event) &#123; int userId = event.getUserId(); System.out.println("user " + userId + " login"); &#125;&#125; 这样子就OK了。不过，这样子的模型，是同步的事件处理模型。 异步事件模型默认的情况下，是同步的事件处理模型，想改为异步，则进行如下修改即可： 在spring应用的配置文件里，添加以下配置： 1234567&lt;context:annotation-config /&gt;&lt;aop:aspectj-autoproxy /&gt;&lt;aop:aspectj-autoproxy proxy-target-class="true" /&gt;&lt;task:annotation-driven executor="myExecutor" scheduler="myScheduler"/&gt;&lt;task:executor id="myExecutor" pool-size="10" /&gt;&lt;task:scheduler id="myScheduler" pool-size="10" /&gt; 在发布者(publisher)或者监听器（listener)相应的方法上，添加注解 @Async 即可. 注意使用 Spring-session ，它会将 Session 的生命周期的事件，发布给所有集群中的 Tomcat 的，所以，如果你需要监听这些事件，而且事件的动作，只需要执行一次的话，那就要进行额外的处理了（比如，一个用户退出时，插入一条日志到数据库，如果不进行额外的处理的话，那你的集群里有多少个 Tomcat，就会插入多少条日志了，这可能并不是我们想要的）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git笔记]]></title>
    <url>%2F2015%2F11%2F13%2Fgit%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[命令补全123456789cp contrib/completion/git-completion.bash /etc/bash_completion.d/. /etc/bash_completion在/etc/profile和~/.bashrc 添加以下内容if [ -f /etc/bash_completion ]; then . /etc/bash_completionfi 中文乱码UTF-8 字符集时git config --global core.quotepath false GBK字符集时git config --global i18n.logOutputEncoding gbkgit config --global i18n.commitEncoding gbk 配置用户123git config --global user.name "your name"git config --global user.email "your email"git config --global color.ui true 建立别名1234git config --global alias.st statusgit config --global alias.ci commitgit config --global alias.co checkoutgit config --global alias.br branch 缓存http验证1234# 单位是秒git config --global credential.helper "cache --timeout=3600" 初始化git12cd /path/to/git/repgit init 或者git init dirName自动创建dirName目录并初始化git. 这个目录，就叫工作区 添加文件到版本管理12git add filegit commit -m "commit desc" 搜索git版本控制文件包含的内容1git grep "要搜索的内容" 定位.git目录位置假设你在git的某个比较深层的目录，但忘记了git工作区的根目录 1234567891011git rev-parse --git-dirgit rev-parse --show-toplevel显示相对于工作区根目录的目录git rev-parse --show-prefix显示从当前目录，进入到工作区的根的深度git rev-parse --show-cdup一次性回到工作区的根目录:cd `git rev-parse --show-cdup` 修改配置信息123git config -e : 将打开工作区的配置文件 /workding/.git/configgit config -e --global: 将打开用户home目录的git配置文件 ~/.gitconfiggit config -e --system: 将打开系统配置git的配置文件 /etc/gitconfig git loggit log --stat: 显示变更统计git log --pretty=oneline: 按一行一次显示提交日志 简要显示status1git status -s git diffgit diff : 工作区与暂存区的比较git diff HEAD : 工作区与版本仓库的比较（当前工作分支）git diff --cached : 暂存区与版本仓库的比较 git 命令对暂存区影响git reset HEAD : 暂存区的目录树会被master分支指向的目录树所替换，但工作区不受影响 git rm --cached &lt;file&gt;: 从暂存区删除文件，工作区不做出改变 git checkout . 或者 git checkout -- &lt;file&gt;: 用暂存区的文件，替换工作区的文件. git checkout HEAD 或者 git checkout HEAD &lt;file&gt; : 用HEAD所指向的分支中的文件替换暂存区和工作区中的文件. git reset --hard &lt;commitid&gt; : 替换引用的指向，替换暂存区，替换工作区 git reset --soft &lt;commit&gt; : 替换引用的指向，不改变暂存区，不改变工作区 git reset --mixed &lt;commit&gt;或git reset &lt;commit：替换引用的指向， 替换暂存区，但不改变工作区. 重置12345`git log --graph --oneline``git reset --hard HEAD^` : 这个命令会破坏工作区未提交的改动，慎用.`git reset --hard commitid` 恢复错误的重置要确认这个参数是开启的： git config core.logallrefupdates 查看所有操作日志git reflog show master | head -5 然后恢复: git reset --hard master@{2}：引用master之前第2次改变时的SHA1哈希值或者直接git reset --hard sha1id提交id git checkoutgit checkout branch：检出branch分支，更新HEAD引用，以及用branch的指向树，更新暂存区和工作区. git checkout : 汇总显示工作区，暂存区和HEAD的差异 git checkout HEAD： 汇总显示工作区，暂存区和head的差异 git checkout -- filename：用暂存区中的文件filename和覆盖工作区中的filename. git checkout branch -- filename：维持HEAD指向不变，用branch所指向的提交中的filename替换暂存区和工作区中的相应的文件。 git checkout -- . 或 git checkout .： 用暂存区的所有文件直接覆盖工作区的所有文件. git stashgit stash : 保存当前的工作进度，（暂存区和工作区） git stash list : 列出进度列表 git stash pop [--index] [&lt;stash&gt;]： 不使用参数的话，会恢复最新保存的工作进度，并从进度列表中删除。[stash]参数（来自 git stash list显示的列表，则从该stash恢复，恢复完后从进度列表中删除该stash.--index参数：除了恢复工作区的文件，还尝试恢复暂存区。 `git stash [save [–patch] [-k | –[no-]keep-index] [-q | –quiet] []：保存进度时添加说明： git stash save &#39;message&#39; git stash apply [--index] [&lt;stash&gt;]：除了不删除恢复的进度之外，和git stash pop一样 git stash drop [&lt;stash&gt;]：删除一个进度，默认删除最新. git stash clear：清空进度列表 git stash branch &lt;branchname&gt; &lt;stash&gt; : 基于进度创建分支. 文件追溯 git blamegit blame filename：逐行显示文件 只看某几行: git blame -L 6,+5 fileName 定位问题提交的commitid它是利用二分查找法来定位的。 步骤: git bisect start 坏提交的commitid 好提交的commitidgit bisect run ./test.sh：执行测试脚本.正常时返回0, 如果是125,则被跳过，1到127（除了125）就是bad.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[diff和patch使用]]></title>
    <url>%2F2015%2F11%2F13%2F%E7%9C%8B%E6%87%82diff%E7%BB%93%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[diff文件判断三个减号(---)：原始文件三个加号(+++)：目标文件 内容-号开始的行：只出现在原始文件中的行+号开始的行：只出现在目标文件中的行 以空格开始的行：同时出现在原始文件和目标文件中 差异注意：diff 是用于行比较的. 前后用两个@@标识来定位差异语句的开始。例如： @@ -1,4 +1,4 @@： -1,4：表示原始文件，从第一行开始的4行（注意，不是到第四行）+1,4：表示目标文件，从第一行开始的4行（注意，不是到第四行） patchf1, f2, diff.txt 假设 diff.txt 是由 diff -u f1 f2 的结果. 删除f2，想要还原12cp f1 f2patch f2 &lt; diff.txt 删除f1，想要还原12cp f2 f1patch -R f1 &lt; diff.txt 注意，有参数-R]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>git</tag>
        <tag>diff</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Task 使用]]></title>
    <url>%2F2015%2F11%2F10%2FSpring-Task-%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[使用12345678910 &lt;bean id="updateRsstask" class="xxxx.xxx.xx" /&gt;&lt;task:executor id="myexecutor" pool-size="10" /&gt;&lt;task:scheduler id="myscheduler" pool-size="10" /&gt;&lt;task:scheduled-tasks scheduler="myscheduler"&gt; &lt;!-- 每隔一个小时更新rss --&gt; &lt;task:scheduled ref="updateRssTask" method="execute" cron="0 0 * * * *" /&gt;&lt;/task:scheduled-tasks&gt; 注意事项&lt;task:schedule-tasks scheduler=&quot;myscheduler&quot;&gt; 这里的scheduler必须显式指定，否则它只会使用默认的值，默认为单线程的。 &lt;task:scheduler id=&quot;scheduler&quot; pool-size=&quot;10&quot;/&gt;如果在xml里这样子配置scheduler，则使用的是ThreadPoolTaskScheduler. &lt;task:executor id=&quot;executor&quot; pool-size=&quot;10&quot;/&gt;如果在xml里这样子配置executor，则使用的是ThreadPoolTaskExecutor excutor属性说明12345&lt;task:executor id="executorWithCallerRunsPolicy" pool-size="5-25" queue-capacity="100" rejection-policy="CALLER_RUNS"/&gt; pool-size：线程池大小，如果只是设置了一个值。则corePoolsize和maxPoolSize都是这个值。queue-capacity：队列大小rejection-policy: 队列满的时候，使用的拒绝策略。 拒绝策略有:ABORT（缺省）：抛出TaskRejectedException异常，然后不执行DISCARD：不执行，也不抛出异常DISCARD_OLDEST：丢弃queue中最旧的那个任务CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行 这些属性的默认值，可以到org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor类看.如下： 123456789private int corePoolSize = 1;private int maxPoolSize = Integer.MAX_VALUE;private int keepAliveSeconds = 60;private boolean allowCoreThreadTimeOut = false;private int queueCapacity = Integer.MAX_VALUE; task异常处理器使用1234567891011121314&lt;bean id="scheduler" class="org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler"&gt; &lt;property name="poolSize" value="5" /&gt; &lt;property name="errorHandler" ref="scheduledTaskErrorHandler" /&gt;&lt;/bean&gt;&lt;bean id="scheduledTaskErrorHandler" class="boo.ScheduledTaskErrorHandler" /&gt;public class ScheduledTaskErrorHandler implements ErrorHandler &#123;@Overridepublic void handleError(Throwable t) &#123; // do something, like shutdown the scheduler&#125;&#125; executor vs scheduler默认情况下，类似: 1234&lt;task:scheduled-tasks scheduler="myScheduler"&gt; &lt;task:scheduled ref="taskDemo" method="run" cron="*/5 * * * * *" /&gt; &lt;task:scheduled ref="taskDemo2" method="run" cron="*/5 * * * * *" /&gt;&lt;/task:scheduled-tasks&gt; 这些任务，既是 myScheduler 调度并执行 的。那么，我们的 myexecutor 定义了有什么用呢？如果我们只是想 myScheduler 只是调度，而让 executor 来执行我们的任务，则可以这样子配置: 在方法上加上注解 @Async 123456@Asyncpublic void run() throws InterruptedException &#123; log.info("this is a task"); Thread.sleep(8*1000); log.info("this is a task end");&#125; 然后要xml里配置时要加上: 1&lt;task:annotation-driven executor="myExecutor" scheduler="myScheduler" /&gt; 这样子，task 的方法，就会由 myExecutor 线程池来执行了。 如果 task 任务数比 myscheduler 多，并且没有 @Async 和 executor因为这些 task 都是要由 myScheduler 调度并执行的，如果 myScheduler 线程池数量不足够，则可能会导致有些任务，并没有在我们预期的时间点中执行！这个要特别注意。 比如，myScheduler 的线程池数是1，但有2个 task，要在同一时间点执行（模拟 myScheduler 数不足的情况），这时，虽然调度时，是调度了两个，但实际执行时，是一个一个地执行的。 假设每个方法执行都要3秒，而我们的定时任务是每5秒种执行一次（如果我们的 task 依赖于特点时间点的话），那第二个task真正的执行时间点是第8秒（5+3）才会执行的。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>task</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jetty学习笔记]]></title>
    <url>%2F2015%2F11%2F09%2FJetty%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[jetty.home 和 jetty.base可以看作：${jetty.home} 是jetty的安装目录${jetty.base} 是实例目录 Jetty常用命令查看帮助1java -jar $&#123;jetty.home&#125;/start.jar --help 指定jetty.home和jetty.base123java -jar /home/yang/Java/jetty-distribution-9.2.13.v20150730/start.jar \jetty.home=/home/yang/Java/jetty-distribution-9.2.13.v20150730 \jetty.base=/home/yang/Java/jetty-distribution-9.2.13.v20150730/demo-base 列出配置12cd $java -jar $&#123;jetty.home&#125;/start.jar --list-config 创建一个实例123456cd /path/to/jetty/base/empty/dirjava -jar $&#123;jetty.home&#125;/start.jar --add-to-startd=http,deploy添加https支持--add-to-startd=https Jetty配置说明在webapps下面，如果有一个xxx.war文件，并且有一个xxx.xml文件，则以xxx.xml为准来部署xxx.war应用的上下文.xxx.d目录，则是用于被xxx.xml使用，用来注入到xxx.war的额外配置. 参考资料Jetty中文翻译]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jetty</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下使用intellij]]></title>
    <url>%2F2015%2F11%2F02%2Fubuntu%E4%B8%8B%E4%BD%BF%E7%94%A8intellij%2F</url>
    <content type="text"><![CDATA[去掉Alt键触发快捷命令在右上角选择–&gt; System Settings &gt; Keyboard &gt; Shortcuts &gt; Launchers 找到选项Key to show the HUD，然后按下Backspace键清空即可. 设置IntelliJ的JVM参数在intellij的bin目录下，有两个以.vmoptions的文件。看你计算机的平台，修改对应的vm参数。idea.vmoptions是32位JDK的,idea64.vmoptions是64位JDK的。示例如下: 123-Xms128m-Xmx8192m-XX:MaxPermSize=1024m 设置源码源别File &gt; Project Structure &gt; Project Settings &gt; Modules &gt; Sources &gt; Language leve 选择即可。 常用插件插件的安装，在File &gt; Settings &gt; Plugins 然后选择browse repositories，索引要安装的插件即可。 mybatis]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>idea</tag>
        <tag>ide</tag>
        <tag>intellij</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常用命令及操作]]></title>
    <url>%2F2015%2F10%2F30%2FMySQL%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%8A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[查看当前活动线程1SELECT * FROM information_schema.processlist WHERE `INFO` LIKE 'SELECT %'; INFO字段就是当前正在执行的命令. 创建唯一索引，并删除有违反唯一索引的数据1ALTER IGNORE TABLE keyword_status ADD UNIQUE INDEX ks_kid_mid (keyword_id, mid);]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>bash</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单反学习]]></title>
    <url>%2F2015%2F10%2F27%2F%E5%8D%95%E5%8F%8D%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[单反单镜头反光镜, 简称”单反” 单反, 是光学取景的,取景相对快. 微单, 是电子取景的, 取景相对慢. 微单, 推荐: 索尼, 富士. 佳能低中高端单反高端单反EOS 1D X EOS 5D Mark III &lt;– EOS 5D Mark II &lt;– EOS 5D EOS 6D 中端单反EOS 7DEOS 70DEOS 60D &lt;– EOS 50D &lt;– EOS 40D &lt;– EOS 30D 低端单反EOS 700D EOS 600D &lt;– EOS 550D &lt;– EOS 500D &lt;– EOS 450D &lt;– EOS 400D EOS 100D EOS 1200D &lt;– EOS 1100D &lt;– EOS 1000D 除了高端的是全画幅, 其他中低的, 都是非全画幅单反. 全画幅与非全画幅全画幅传统胶片机时, 有效的成像范围是 (36mm * 24mm). 如果你的单反图像传感器的大小, 也是这个范围, 那就是全画幅. 非全画幅不是全画幅的, 就是非全画幅啦.即APS-C. 焦距透镜中心点到图像传感器的距离. 习惯于用焦距 + 光圈大小来命名镜头. 焦距与视角 即,焦距越长, 视角就越小. 超广角镜头焦距在6-8mm. 视角接近85或等于180度 广角镜头焦距16-35m. 视角大概60到90度 标准镜头焦距为’50mm`, 视角为60度. 长焦镜头135-300mm, 视角大概是18到5度. 超长焦镜头300mm以上. 牛头与狗头佳能: 有红色圈在镜头的, 就是牛头. 否则就是狗头. 尼康: 有金色的圈在镜头的, 就是牛头, 否则就是狗头. 镜头标识18-55mm: 可用的焦距范围. EF-S: 只能用于非全画幅的佳能EF卡口的单反. 1:3.5-5.6: 表示最小焦距时, 能使用的最大光圈为3.6. 最大焦距时, 能使用的最大光圈为5.6. 1:4: 表示无论焦距是什么范围, 都可以使用的最大光圈为4. IS: 佳能防抖镜头. $67mm: 表示镜头的口径. EF: 佳能的通用镜头. 可用于全画幅, 也可用于非全画幅. 光圈控制进光量的一个装置. F=镜头的焦距/镜头有效口径的直径 F值越小, 进光量越大(大光圈)F值越大, 进光量越小(小光圈) 作用: 控制进光量. 控制景深. 佳能的Av档,就是光圈优先模式. 镜头分类变焦镜头如果镜头上写着18-55mm这些有范围的焦距的, 就是变焦镜头 定焦镜头如果镜头上写着50mm这些只有一个数值的焦距的, 就是定焦镜头 恒定光圈恒定光圈通常是指变焦镜头在所有焦距段都能使用其标称的最大光圈.比如镜头标明28－70mm/2.8就是恒定光圈镜头。就指该镜头在28－70mm焦距段都可以使用最大F2.8的光圈值来拍摄。而如果镜头标识为28－70mm/3.5-4.5的，则是浮动光圈镜头，就是值在28mm焦距最大光圈能使用F3.5，而到70mm时则最大只能采用F4.5的光圈值。 背影虚化 增大光圈(F值越大,因为F是分数形式即 1/N, N的数值越小, 光圈就越大) 拉近摄距 增大焦距(EOS里,即调节镜头, 使其向最大方向转,比如:18-55m的,就将其转到55) 参考资料 使用定焦镜头,因为定焦镜头,光圈一般比较大.JD 50mm 1.8这个性价比最高.]]></content>
      <categories>
        <category>javax</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Findbugs 报 May expose internal representation by returning reference to mutable object]]></title>
    <url>%2F2015%2F10%2F27%2FFindbugs-%E6%8A%A5-May-expose-internal-representation-by-returning-reference-to-mutable-object%2F</url>
    <content type="text"><![CDATA[运行完一个Findbugs时，发现它报了一个警告： CccFans.getRowCreateTime() may expose internal representation by returning CcFans.rowCreateTime()以及CcFans.setRowCreateTime(Timestamp) may expose internal representation by storing an externally mutable object into CcFans.rowCreateTime 原因用例子来说明: 123456789101112131415161718192021222324252627282930313233343536373839404142package org.se;public class Main &#123; public static void main(String[] args) &#123; Person p = new Person(); p.setName("hello"); PersonHolder ph = new PersonHolder(); ph.setP(p); System.out.println(ph.getP().getName()); p.setName("new Hello"); System.out.println(ph.getP().getName()); &#125; public static class PersonHolder &#123; private Person p; public Person getP() &#123; return p; &#125; public void setP(Person p) &#123; this.p = p; &#125; &#125; public static class Person &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125;&#125;打印的结果:hellonew Hello 这里，已经在ph.setP()后，但p后面又修改了自己的数据（p.setName(“new Hello”)，这样子，下次ph使用时，就是新的数据了，而不是使用setP()时的p`的状态时的数据.这只是警告，存在可能的隐患。 建议凡是set一个对象的时候，都应该建议set对象的副本。比如，改进后这样子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package org.se;public class Main &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Person p = new Person(); p.setName("hello"); PersonHolder ph = new PersonHolder(); ph.setP(p); System.out.println(ph.getP().getName()); p.setName("new Hello"); System.out.println(ph.getP().getName()); &#125; public static class PersonHolder &#123; private Person p; public Person getP() &#123; return p; &#125; public void setP(Person p) throws CloneNotSupportedException &#123; this.p = (Person) p.clone(); &#125; &#125; public static class Person implements Cloneable &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; protected Object clone() throws CloneNotSupportedException &#123; Person p = new Person(); p.name = this.name; return p; &#125; &#125;&#125;打印的结果为:hellohello]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>findbugs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradle学习笔记]]></title>
    <url>%2F2015%2F10%2F23%2FGradle%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[gradle 设置代理123456systemProp.http.proxyHost=代理服务器地址systemProp.http.proxyPort=代理服务器端口systemProp.http.proxyUser=代理服务器登录用户名systemProp.http.proxyPassword=代理服务器登录密码systemProp.http.nonProxyHosts=*.nonproxyrepos.com|localhost|不需要代理的地址 以守护进程方式运行Gradle加速123456789在以下目录中/home/&lt;username&gt;/.gradle/ (Linux)/Users/&lt;username&gt;/.gradle/ (Mac)C:Users&lt;username&gt;.gradle (Windows)创建或修改文件名为 gradle.properties 的文件.添加以下一行:org.gradle.daemon=true Gradle 环境变量GRADLE_OPS对gradle进程,进行设置JVM参数.如 GRADLE_OPTS=&quot;-Xmx1024m GRADLE_HOMEGradle的安装目录位置.配置完,注意也要配置下PATH环境变量.如: PATH=$GRADLE_HOME/bin:$PATH Gradle 常用命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162### 将项目转换成Gradle`gradle init`### 执行某个指定任务`gradle [-q] 任务名`### 构建项目`gradle build`### 清除构建后的文件`gradle clean`### 显示的有任务`gradle tasks`### 构建项目但不执行测试任务`gradle assemble`### 只编译源码`gradle compileJava`### 编译和测试代码,但不打包`gradle check`### 查看所有属性`gradle properties`### 列出所有项目`gradle -q projects`### 搜索任务`gradle -q help --task 要搜索的任务名 `### 列出项目依赖`gradle -q dependencies`### 模拟执行过程`gradle -m clean`### 启动Gradle的GUI`gradle --gui`### 强制刷新依赖`gradle build --refresh-dependencies`### 命令行创建java 标准项目`gradle init --type java-library` task定义一个task123task helloWorld &lt;&lt; &#123; println "Hello World, Gradle!"&#125; 然后执行 gradle helloWorld 即可看到如下输出. 12345678➜ java gradle helloWorld:helloWorldHello World, Gradle!BUILD SUCCESSFULTotal time: 0.465 secs➜ java 扩展task属性12345678910111213141516class fuckTask extends DefaultTask &#123; @Input def inputProperty&#125;task fun(type:fuckTask) &#123; inputProperty = "hello world"&#125;引用task fuck &#123; println "I'm from --&gt; $fun.inputProperty"&#125; 输出如下： 1234567I'm from --&gt; hello world:fuck UP-TO-DATEBUILD SUCCESSFULTotal time: 0.479 secs 声明属性在 /.gradle/ 目录下 gradle.properties注意,只能在该目录下有一个属性文件. 在这里配置的,对所有项目都是可见的.在项目里引用: 1234567方法一:project.属性名方法二:task printP &lt;&lt; &#123; println "$属性名"&#125; 项目属性通过命令行 -P 来提供 gradle -Pkey=value 在gradle文件里引用,可直接使用: $key 系统属性通过命令行 -D 来提供 gradle -Dkey=value 在gradle里使用: `System.properties[‘key’] 环境属性所有以ORG_GRADLE_PROJECT_开头的,相当于-P例如:ORG_GRADLE_PROJECT_key=value 或者所有以org.gradle.project.开头的,也相当于-P 例如: 12345➜ gradle gradle -Penv=dev -q taskHello dev➜ gradle gradle -Dorg.gradle.project.env=dev -q taskHello dev➜ gradle 在项目下的 gradle.properties 声明属性key=value 默认 task12defaultTasks 'hello', 'helloTask2' 指定了默认任务, 这样子执行 gradle -q 时它就会执行指定默认的任务 hello, helloTask2. 排除执行某个task123456789task fu1 &lt;&lt; &#123; println "fu1"&#125;task fu2 &lt;&lt; &#123; println "fu2"&#125;fu2.dependsOn fu1 fu2依赖于fu1，但在执行时，可以排除他不执行fu1.默认情况下是： 123456789➜ java gradle fu2:fu1fu1:fu2fu2BUILD SUCCESSFULTotal time: 0.463 secs 排除执行的情况是: 1234567➜ java gradle fu2 -x fu1:fu2fu2BUILD SUCCESSFULTotal time: 0.459 secs 可执行Jar包1234567apply plugin: 'java'jar &#123; manifest &#123; attributes 'Main-Class': 'net.petrikainulainen.gradle.HelloWorld' &#125;&#125; 依赖管理配置仓库1234repositories&#123; mavenCentral()&#125; 配置依赖12345dependencies &#123; compile group:'commons-collections',name:'commons-collections',version:'3.2' testCompile group:'junit',name:'junit',version:'4.0+'&#125; 将项目转换成 eclipse 项目1apply plugin: 'eclipse' 然后执行 gradle eclipse 设置源码级别和编译输出级别12345源码级别sourceCompatibility = 1.7编译输出级别targetCompatibility = 1.7 Gradle对应Maven的坐标默认值1234groupId --&gt; project.groupartifactId --&gt; uploadTask.repositories.mavenDeployer.pom.artifactId (if set) or archiveTask.baseName.version --&gt; project.versionpackaging --&gt; archiveTask.extension 打包源码1234567ext.artifactBaseName="org-emacist"task sourcesJar(type: Jar) &#123; baseName artifactBaseName classifier 'sources' from sourceSets.main.allSource&#125; 不同环境打包12345678910111213if (!hasProperty("env")) &#123; project.ext.env = "default"&#125;sourceSets &#123; main &#123; resources &#123; srcDirs = ["src/main/resources/public","src/main/resources/$env"] &#125; &#125;&#125; 创建一个web项目123456789101112131415cd /path/to/project/root/dirgradle init --type java-library然后编辑`build.gradle`文件添加以下内容:apply plugin: 'idea'apply plugin: 'eclipse'apply plugin: 'war'// 这指定Web目录名字，默认为`src/main/webapp`webAppDirName = 'WebContent'然后再创建IDE的配置文件gradle idea然后导入即可 参考资料InfoQ]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 与 Spring 结合进行模块化开发实践]]></title>
    <url>%2F2015%2F10%2F16%2FMaven-%E4%B8%8E-Spring-%E7%BB%93%E5%90%88%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9D%97%E5%8C%96%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[模块化的解决方案OSGi是一种模块化标准。是真正意义的上模块化，Eclipse 就是基于OSGi进行开发的。热插拔，每个模块都有自己的classLoader，不同classLoader之间，通过服务来进行通信。 Maven使用maven的方式来进行模块化，主要是代码组织，以及代码重用度角度来进行模块化。 实践emacsist-project创建该项目，用于被继承，以及聚合各个模块。 它的pom.xml内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 总pom --&gt; &lt;groupId&gt;org.emacsist&lt;/groupId&gt; &lt;artifactId&gt;emacsist-project&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;emacsist-project&lt;/name&gt; &lt;url&gt;http://emacsist.github.io&lt;/url&gt; &lt;properties&gt; &lt;spring.version&gt;3.2.14.RELEASE&lt;/spring.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;modules&gt; &lt;!-- 工具类模块 --&gt; &lt;module&gt;../emacsist-kit&lt;/module&gt; &lt;module&gt;../emacsist-email&lt;/module&gt; &lt;module&gt;../emacsist-http&lt;/module&gt; &lt;module&gt;../emacsist-redis&lt;/module&gt; &lt;!-- weibosdk --&gt; &lt;module&gt;../weibosdk-base&lt;/module&gt; &lt;module&gt;../weibosdk-redis&lt;/module&gt; &lt;module&gt;../weibosdk-dao&lt;/module&gt; &lt;module&gt;../weibosdk-rabbitmq&lt;/module&gt; &lt;module&gt;../weibosdk-service&lt;/module&gt; &lt;module&gt;../common-pojo&lt;/module&gt; &lt;module&gt;../weibosdk-web&lt;/module&gt; &lt;module&gt;../weibosdk-interceptor&lt;/module&gt; &lt;/modules&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; ...为了本文的篇幅，以下依赖忽略 &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; dependencyManagement元素，主要是用于模块之间的版本一致管理。 emacsist-dao 模块pom.xml 内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 属于 emacsist-project 的子模块，继承父模块 --&gt; &lt;parent&gt; &lt;groupId&gt;org.emacsist&lt;/groupId&gt; &lt;artifactId&gt;emacsist-project&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;relativePath&gt;../emacsist-project/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;groupId&gt;org.emacsist.weibosdk&lt;/groupId&gt; &lt;artifactId&gt;weibosdk-dao&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;weibosdk-dao&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;default&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;!-- 开发环境的配置文件 --&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;properties&gt; &lt;!-- 生产环境的配置文件 --&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/java&lt;/sourceDirectory&gt; &lt;scriptSourceDirectory&gt;$&#123;runtime.env&#125;&lt;/scriptSourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;runtime.env&#125;&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.json&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 代码组织未例： src/main/env/dev: 开发环境的配置文件src/main/env/product: 生产环境的配置文件src/main/java/: 主源码src/test/java: 测试源码src/test/env/dev: 测试环境的配置文件 配置文件里，包含如下文件： mybatis-config.xml:mybatis配置文件，放在dao这个模块。即各自的模块，负责配置各自的配置文件 weibosdk-jdbc.properties：jdbc配置文件 weibosdk-module-dao.xml: dao模块的spring的配置文件，只需要配置属于dao的内容即可. 示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:task="http://www.springframework.org/schema/task" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:p="http://www.springframework.org/schema/p" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd"&gt; &lt;bean id="uniweibov2DataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClassName&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;property name="maxActive"&gt; &lt;value&gt;64&lt;/value&gt; &lt;/property&gt; &lt;property name="maxIdle"&gt; &lt;value&gt;64&lt;/value&gt; &lt;/property&gt; &lt;property name="maxWait"&gt; &lt;value&gt;0&lt;/value&gt; &lt;/property&gt; &lt;property name="validationQuery"&gt; &lt;value&gt;select 1&lt;/value&gt; &lt;/property&gt; &lt;property name="testWhileIdle"&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property name="minEvictableIdleTimeMillis"&gt; &lt;value&gt;20000000&lt;/value&gt; &lt;/property&gt; &lt;property name="timeBetweenEvictionRunsMillis"&gt; &lt;value&gt;3600000&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="TxManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="uniweibov2DataSource" /&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager="TxManager" proxy-target-class="true" /&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="uniweibov2DataSource" /&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml" /&gt; &lt;/bean&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="org.emacsist.weibosdk.dao.mapper" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory" /&gt; &lt;/bean&gt;&lt;/beans&gt; 其他模块其他模块，类似于上面的dao模块的 pom.xml web模块这个是主要的运行模块，依赖于其他子模块。主要解决的问题：聚合其他模块的配置文件以及bean这些东西。 集合其他模块的properties文件: 12345678910111213&lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath:weibo4j.properties&lt;/value&gt; &lt;value&gt;classpath:weibosdk-core.properties&lt;/value&gt; &lt;value&gt;classpath*:weibosdk-redis.properties&lt;/value&gt; &lt;value&gt;classpath*:weibosdk-rabbitmq.properties&lt;/value&gt; &lt;value&gt;classpath*:weibosdk-jdbc.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name="ignoreUnresolvablePlaceholders" value="true" /&gt;&lt;/bean&gt; 注意是classpath*:weibosdk-模块的.properties 集合其他模块的spring.xml 12345 &lt;import resource="classpath*:weibosdk-module-dao.xml" /&gt;&lt;import resource="classpath*:weibosdk-module-interceptor.xml" /&gt;&lt;import resource="classpath*:weibosdk-module-rabbitmq.xml" /&gt;&lt;import resource="classpath*:weibosdk-module-redis.xml" /&gt;&lt;import resource="classpath*:weibosdk-module-task.xml" /&gt; 注意，也是classpath*:weibosdk-module-模块的.xml 表示从jar包里查找这些配置文件。因为其他模块，都被打包成了jar包。 构建，测试，运行，打包12345678910111213这个在 emacsist-project下执行构建指定模块mvn clean install[test,package] -pl 模块1,模块2构建指定模块,以及这些模块所依赖的模块mvn clean install[test,package] -pl 模块1,模块2 -am构建依赖于指定模块以及该模块本身mvn clean install[test,package] -pl 模块 -amd指定从哪个模块开始构建mvn clean install[test,package] -rf 模块名 成功的话，输出类似： 123456789101112131415161718192021[INFO][INFO] emacsist-project ................................... SUCCESS [ 0.112 s][INFO] emacsist-kit ....................................... SUCCESS [ 1.186 s][INFO] emacsist-email ..................................... SUCCESS [ 0.177 s][INFO] emacsist-http ...................................... SUCCESS [ 0.093 s][INFO] emacsist-redis ..................................... SUCCESS [ 0.130 s][INFO] weibosdk-base ...................................... SUCCESS [ 0.337 s][INFO] common-pojo ........................................ SUCCESS [ 0.065 s][INFO] weibosdk-dao ....................................... SUCCESS [ 0.231 s][INFO] weibosdk-service ................................... SUCCESS [ 0.084 s][INFO] weibosdk-redis ..................................... SUCCESS [ 0.137 s][INFO] weibosdk-rabbitmq .................................. SUCCESS [ 0.200 s][INFO] weibosdk-web ....................................... SUCCESS [ 0.845 s][INFO] weibosdk-interceptor ............................... SUCCESS [ 0.148 s][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 4.010 s[INFO] Finished at: 2015-10-16T17:23:27+08:00[INFO] Final Memory: 33M/314M[INFO] ------------------------------------------------------------------------]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>modular</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven复习]]></title>
    <url>%2F2015%2F10%2F12%2FMaven%E5%A4%8D%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[快速升级利用软链接方式来进行升级 软链接目录：~/maven/current 代表当前要使用的版本具体某个版本的maven: ~/maven/maven3.0具体某个版本的maven: ~/maven/maven3.1 当要切换时，将软链接指向某个具体的版本的maven即可。如： 1ln -s ~/maven3.0 ~/maven/current 将环境变量，只需要指向~/maven/current即可，这样子，在切换版本时，就不用修改环境变量了. 配置maven将maven安装目录下的conf目录，复制一份settings.xml到~/.m2/settings.xml中。然后在这里配置maven的环境。在使用IDE时，记得修改maven的配置，指向系统中的maven，而不要使用IDE自带的maven（还有IDE里maven的配置的东西 ） 设置代理12345678910111213&lt;proxies&gt; &lt;proxy&gt; &lt;id&gt;my-proxy&lt;/id&gt; &lt;!-- 代理的ID --&gt; &lt;active&gt;true&lt;/active&gt;&lt;!-- 是否激活 --&gt; &lt;protocol&gt;http&lt;/protocol&gt;&lt;!-- 代理所使用的协议 --&gt; &lt;host&gt;ip&lt;/host&gt;&lt;!--这里填写代理服务器的IP地址--&gt; &lt;port&gt;port&lt;/port&gt;&lt;!-- 这里填写代理服务器的端口 --&gt; &lt;username&gt;usrename&lt;/username&gt;&lt;!-- 代理服务器认证的用户名 --&gt; &lt;password&gt;******&lt;/password&gt;&lt;!-- 代理服务器认证的用户密码 --&gt; &lt;nonProxyHosts&gt;localhost|127.0.0.1&lt;/nonProxyHosts&gt;&lt;!-- 不需要代理的地址，用|分隔，支持通配符* --&gt; &lt;/proxy&gt;&lt;/proxies&gt; 将eclipse运行在JDK上，而不是默认的JRE上eclipse.ini 文件 12345在 -vmargs 之前添加以下内容-vm/path/to/jdk/bin/javaw.exe(windows下)/path/to/jdk/bin/java(*nix下) Maven使用的环境变量MAVEN_OPTS这个是将JVM参数，传递给maven，因为maven本质上是Java命令。比如，将这个环境变量的参数值设置为: -Xms128m -Xmx512m M2_HOME这个环境变量，是指向maven的安装目录的。如~/maven/current Maven的约定代码位置主体代码放在 src/main/java中测试代码放在 src/test/java中 默认scope范围如果不指定依赖的范围，默认就是 comiple 编译输出目录target/classes/ 默认的打包方式jar 包输出目录为target/ 自定义源码目录在build元素下配置: &lt;sourceDirectory&gt;src/java&lt;/sourceDirectory&gt; 即可 超 pom.xml它在maven安装目录下的M2_HOME/lib/maven-x.x.x-uber.jar中的org/apache/maven/project/pom-4.0.0.xml目录下.(Maven2)M2_HOME/lib/maven-model-builder-x.x.x.jar中的org/apache/maven/model/pom-4.0.0.xml 源码编译级别123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; Maven常用命令123456789101112131415161718192021222324252627282930mvn help:systemmvn clean compilemvn clean testmvn clean packagemvn clean installmvn dependency:listmvn dependency:treemvn dependency:analyze查看插件的帮助mvn help:describe -Dplugin=org.apache.maven.plugins:maven-compiler-plugin:2.1用于多模块构建进入parent项目的根目录，执行以下命令构建指定模块mvn clean install -pl 模块1的路径(相对于parent的路径,注意是路径）,模块2的路径(相对于parent的路径,注意是路径）构建指定模块,以及这些模块所依赖的模块mvn clean install -pl 模块1的路径(相对于parent的路径,注意是路径）,模块2的路径(相对于parent的路径,注意是路径） -am构建依赖于指定模块以及该模块本身mvn clean install -pl 模块的路径(相对于parent的路径,注意是路径） -amd指定从哪个模块开始构建mvn clean install -rf 模块1的路径(相对于parent的路径,注意是路径）忽略测试步骤-Dmaven.test.skip=true 生成可执行的Jar包1234567891011121314151617181920&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation = "org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt; &lt;mainClass&gt;这里填写你的Main类&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 使用这个插件打包完时，会生成两个jar，一个是original开头的，这个jar包是不可以执行的，另一个就是可执行的jar包。 Maven的坐标groupId所属的实际项目 artifactId项目中的某个模块 version模块的版本 packaging模块的打包方式 classifier定义输出的一些附属构件。 项目构件的文件名的规则一般是：artifactId-version[-classifier].packaging Maven依赖范围compile编译范围。也是默认的依赖范围。对编译，测试，运行三种classpath都有效。 test测试依赖范围。只对测试classpath有效。在编译主代码，或者运行项目的使用时，无法使用此依赖。如: JUnit provided已提供依赖范围。对编译和测试classpath有效，但运行时无效。比如：servlet-api，它是tomcat等容器提供的。 runtime运行时依赖。对测试和运行有效，但编译主体代码时无效。如：JDBC驱动。 system系统范围依赖。它和 provided 一样。但使用system依赖，必须通过 systemPath元素，显式指定依赖文件的路径。这类依赖不是通过maven仓库，而是与本机系统绑定的，极可能是不可移植，应尽管避免使用。 import导入依赖范围。不会对三种（编译，测试，运行）classpath产生实际影响。 依赖传递调解原则：路径最近者优先、第一声明者优先 部署到远程仓库12345678910111213&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8080/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8080/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 如果远程仓库需要认证，则在~/.m2/settings.xml里配置 12345678910111213&lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; 镜像在~/.m2/settings.xml里配置 123456789&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-osc&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus osc&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; *表示镜像所有仓库。即对于远程仓库的请求，都会被该URL替代。 Maven 搜索mvnrepository OSChina clean生命周期 pre-clean clean post-clean default生命周期 validate initialize generate-sources process-sources generate-resources process-resources compile process-classes generate-test-sources process-test-sources generate-test-resources process-test-resources test-compile process-test-classes test prepare-package package pre-integration-test integration-test post-integration-test verify install deploy site生命周期 pre-site site post-site site-deploy 命令行与生命周期mvn clean: pre-clean, clean阶段 mvn test: default生命周期的形状到test的所有阶段。 mvn clean install: pre-clean, clean以及到default生命周期的开头到install阶段 mvn clean deploy site-deploy: pre-clean, clean以及default生命周期的所有阶段，site生命周期的所有阶段。 为源码打包12345678910111213 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 聚合项目创建一个新的空白的maven项目.在该pom.xml文件上, 配置如下的内容即可: 12345678910111213&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.emacsist&lt;/groupId&gt; &lt;artifactId&gt;Go&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;../mvn&lt;/module&gt; &lt;module&gt;../mvn2&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 注意, &lt;module&gt;../mvn&lt;/module&gt; 这是相对当前项目的其他模块的目录的路径. 继承在子模块的pom.xml里配置: 1234567&lt;parent&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;!--父pom的groupId--&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;!--父pom的artifactId--&gt; &lt;version&gt;1&lt;/version&gt; &lt;relativePath&gt;../parent/pom.xml&lt;/relativePath&gt;&lt;!--父pom.xml的位置--&gt;&lt;/parent&gt; 在集成时, 别忘记了, 将父模块,也放到聚合模块中. 可继承的元素 groupId:项目组ID version:项目版本 description:项目的描述信息 organization:项目的组织信息 inceptionYear:项目的创始年份 url:项目的URL地址 developers:项目的开发者信息 contributors:项目的贡献者信息 distributionManagement:项目的部署配置 issueManagement:项目的缺陷跟踪系统信息 ciManagement:项目的持续集成系统信息 scm:项目的版本控制系统信息 mailingLists:项目的邮件列表信息 properties:算定义的Maven属性 dependencies:项目的依赖配置 dependencyManagement:项目的依赖管理配置 repositoryies:项目的仓库配置 build:包括项目的源码目录配置，输出目录配置。插件配置，插件配置。插件管理配置等 reporting:包括项目的报告输出目录配置，报告插件配置竺。 dependencyManagement结合继承的作用dependencyManagement 结合继承, 主要是为了统一依赖的版本号.这时,在父pom.xml里使用dependencyManagement,而在子模块里,使用dependencies,但子模块里,并不指定版本号.这样子,它就会使用父的dependencyManagement中指定的依赖的版本了. Maven的Jetty插件使用官方文档 httpConnector 参数前缀都是：-Djetty.http.xxx=value 端口默认为 8080 端口port mvn -Djetty.http.port=9999 jetty:run 监听主机host 指定connector名name 最大空闲时间idleTimeout 关闭socket时的延时设置soLinger 使用123456789101112131415161718192021222324 &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.0.6.v20130930&lt;/version&gt; &lt;configuration&gt; &lt;!-- Jetty容器配置 --&gt; &lt;httpConnector&gt; &lt;!-- 监听的端口 --&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/httpConnector&gt; &lt;!-- 热部署，间隔多少秒重新扫描文件，默认为0,即不进行热部署 --&gt; &lt;scanIntervalSeconds&gt;1&lt;/scanIntervalSeconds&gt; &lt;!-- web应用配置 --&gt; &lt;webApp&gt; &lt;contextPath&gt;/&lt;/contextPath&gt; &lt;!-- web.xml路径 --&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/WebContent/WEB-INF/web.xml&lt;/descriptor&gt; &lt;allowDuplicateFragmentNames&gt;true&lt;/allowDuplicateFragmentNames&gt; &lt;/webApp&gt; &lt;!-- 生成classes的目录 --&gt; &lt;classesDirectory&gt;$&#123;project.basedir&#125;/target/classes&lt;/classesDirectory&gt; &lt;webAppSourceDirectory&gt;$&#123;project.basedir&#125;/WebContent/&lt;/webAppSourceDirectory&gt; &lt;/configuration&gt;&lt;/plugin&gt; Maven中的属性 property内置属性 ${basedir}，表示项目的根目录 ${version}，表示项目的版本 pom属性 ${project.build.sourceDirectory}: 表示项目的主源码目录。默认为src/main/java ${project.build.testSourceDirectory}: 项目的测试源码目录。默认为src/test/java ${project.build.directory}: 项目构建输出目录，默认为target/ ${project.outputDirector}: 项目主代码编译输出目录，默认为target/classes/ ${project.testOutputDirectory}: 项目测试代码编译输出目录，默认为target/test-classes/ ${project.groupId}: 项目的groupId ${project.artifactId}: 项目的artifactId ${project.version}: 项目的version，与${version}等价 ${project.build.finalName}: 项目打包输出文件名，默认为${project.artifactId}-${project.version}. 自定义属性12345&lt;properties&gt; &lt;property&gt; &lt;my.prop&gt;hello world&lt;/my.prop&gt; &lt;/property&gt;&lt;/properties&gt; settings 属性这个可以引用settings.xml文件元素值。如： ${settings.localRepository} Java系统属性可以通过mvn help:system查看所有该属性值.如: ${user.home} 环境变量属性都是以env.开头。如：${env.JAVA_HOME}.可以通过mvn help:system查看。 为不同环境使用不同配置12345678910111213141516171819202122&lt;profiles&gt; &lt;profile&gt; &lt;!-- 开发环境 --&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;!-- 是否是默认 --&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 测试环境 --&gt; &lt;id&gt;test&lt;/id&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 生产环境 --&gt; &lt;id&gt;production&lt;/id&gt; &lt;properties&gt; &lt;profile.active&gt;production&lt;/profile.active&gt; &lt;profile.scope&gt;provided&lt;/profile.scope&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 一般资源过滤还要注意，默认情况下，只有pom.xml时使用这些属性时，才会被解析。如果是在其他文件里，也要使用该属性时，默认情况下，是不是解析其他配置文件的占位符的变量的。 要开启maven解析其他资源文件来使用pom.xml里定义的属性，还需要配置如下： 1234567891011121314151617181920212223242526&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;!-- 资源目录 --&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;!-- 是否解析占位符$&#123;&#125; --&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;resource&gt; &lt;!-- 资源目录 --&gt; &lt;directory&gt;src/test/resources&lt;/directory&gt; &lt;!-- 是否解析占位符$&#123;&#125; --&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/testResources&gt;&lt;/build&gt; 然后在使用时，通过参数-P来激某个profile，如： 开发环境：mvn clean install -Pdev 生产环境：mvn clean install -Pproductino web 资源过滤要配置 maven-war-plugin 插件才行 12345678910111213141516171819&lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;warSourceDirectory&gt;WebContent&lt;/warSourceDirectory&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;webResources&gt; &lt;webResource&gt; &lt;directory&gt;WebContent&lt;/directory&gt; &lt;!-- 解析web资源 --&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.css&lt;/include&gt; &lt;include&gt;**/*.js&lt;/include&gt; &lt;/includes&gt; &lt;/webResource&gt; &lt;/webResources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 激活 profile命令行激活mvn clean install -PprofileId1,profileId2 settings.xml 文件显式激活123&lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt;&lt;/activeProfiles&gt; 系统属性激活12345678910&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;actProp&lt;/name&gt; &lt;value&gt;x&lt;/value&gt; &lt;/property&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 这表示，如果存在系统属性actProp，并且其值为x，则激活该profile。如果没有value，则表示只要存在actProp属性，就激活。系统属性，通过如下传递： mvn clean install -DactProp=x 操作系统激活123456789101112&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;os&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;family&gt;Windows&gt;&lt;/family&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 文件存在与否激活12345678910&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;file&gt; &lt;missing&gt;x.properties&lt;/missing&gt; &lt;exists&gt;y.properties&lt;/exists&gt; &lt;/file&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 默认激活12345678&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 经典的 pom.xml 配置例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 所属项目名 --&gt; &lt;groupId&gt;jetty-demo&lt;/groupId&gt; &lt;!-- 模块名 --&gt; &lt;artifactId&gt;jetty-demo&lt;/artifactId&gt; &lt;!-- 版本 --&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;!-- 打包方式 --&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!-- 项目的url --&gt; &lt;url&gt;http://emacsist.github.io&lt;/url&gt; &lt;!-- 开发者人员 --&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;emacsist&lt;/id&gt; &lt;name&gt;Zhiyong yang&lt;/name&gt; &lt;email&gt;emacsist@qq.com&lt;/email&gt; &lt;roles&gt; &lt;role&gt;admin&lt;/role&gt; &lt;/roles&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!-- SpringMVC 版本 --&gt; &lt;properties&gt; &lt;spring.version&gt;4.0.1.RELEASE&lt;/spring.version&gt; &lt;!— checkstyle配置文件 —&gt; &lt;!— config/sun_checks.xml - Sun Microsystems Definition (default). config/maven_checks.xml - Maven Development Definitions. config/turbine_checks.xml - Turbine Development Definitions. config/avalon_checks.xml - Avalon Development Definitions. —&gt; &lt;checkstyle.config.location&gt;config/maven_checks.xml&lt;/checkstyle.config.location&gt; &lt;/properties&gt; &lt;!-- 这里填写项目的git地址 --&gt; &lt;scm&gt; &lt;connection&gt;scm:git:git.coding.net/emacsist/Jetty_Maven.git&lt;/connection&gt; &lt;developerConnection&gt;scm:git:git.coding.net/emacsist/Jetty_Maven.git&lt;/developerConnection&gt; &lt;url&gt;git://git.coding.net/emacsist/Jetty_Maven.git&lt;/url&gt; &lt;/scm&gt; &lt;!-- 使用 mvn site 命令生成站点报告，生成后的文件在 target/site/ 目录下 --&gt; &lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;dependencyLocationsEnabled&gt;false&lt;/dependencyLocationsEnabled&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 报告里生成java doc --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;2.10.3&lt;/version&gt; &lt;configuration&gt; &lt;show&gt;public&lt;/show&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 报告里生成源码目录树 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jxr-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/plugin&gt; &lt;!— mvn checkstyle:checkstyle checkstyle —&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 注意，要先执行一下 mvn package 之后再执行 mvn findbugs:gui 检查bugs —&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;findbugs-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;configuration&gt; &lt;xmlOutput&gt;true&lt;/xmlOutput&gt; &lt;effort&gt;Max&lt;/effort&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 源码分析报告PMD --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-pmd-plugin&lt;/artifactId&gt; &lt;version&gt;3.5&lt;/version&gt; &lt;configuration&gt; &lt;!-- 默认情况下，如果没有什么问题的话，它会忽略PMD的报告，这里是无论如何都显示报告 --&gt; &lt;skipEmptyReport&gt;false&lt;/skipEmptyReport&gt; &lt;!-- 将所有模块的分析，集成到一起 --&gt; &lt;aggregate&gt;true&lt;/aggregate&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 更改记录，这个要配置上面的 scm 配置 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-changelog-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;build&gt; &lt;!-- 源码目录 --&gt; &lt;sourceDirectory&gt;src&lt;/sourceDirectory&gt; &lt;plugins&gt; &lt;!--mvn source:jar 打包源码的插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- mvn site 站点插件 --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- mvn javadoc:javadoc 用于生成java doc --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;2.10.3&lt;/version&gt; &lt;configuration&gt; &lt;show&gt;private&lt;/show&gt; &lt;nohelp&gt;true&lt;/nohelp&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- mvn pmd:pmd 源码分析插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-pmd-plugin&lt;/artifactId&gt; &lt;version&gt;3.5&lt;/version&gt; &lt;configuration&gt; &lt;!-- 默认情况下，如果没有什么问题的话，它会忽略PMD的报告，这里是无论如何都显示报告 --&gt; &lt;skipEmptyReport&gt;false&lt;/skipEmptyReport&gt; &lt;!-- 将所有模块的分析，集成到一起 --&gt; &lt;aggregate&gt;true&lt;/aggregate&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- mvn jetty:run Jetty 插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.0.6.v20130930&lt;/version&gt; &lt;configuration&gt; &lt;!-- Jetty容器配置 --&gt; &lt;httpConnector&gt; &lt;!-- 监听的端口 --&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/httpConnector&gt; &lt;!-- 热部署，间隔多少秒重新扫描文件，默认为0,即不进行热部署 --&gt; &lt;scanIntervalSeconds&gt;1&lt;/scanIntervalSeconds&gt; &lt;!-- web应用配置 --&gt; &lt;webApp&gt; &lt;contextPath&gt;/&lt;/contextPath&gt; &lt;!-- web.xml路径 --&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/WebContent/WEB-INF/web.xml&lt;/descriptor&gt; &lt;/webApp&gt; &lt;!-- 生成classes的目录 --&gt; &lt;classesDirectory&gt;$&#123;project.basedir&#125;/target/classes&lt;/classesDirectory&gt; &lt;webAppSourceDirectory&gt;$&#123;project.basedir&#125;/WebContent/&lt;/webAppSourceDirectory&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- mvn clean package 打包 war 的插件 --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;warSourceDirectory&gt;WebContent&lt;/warSourceDirectory&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;webResources&gt; &lt;webResource&gt; &lt;directory&gt;WebContent&lt;/directory&gt; &lt;!-- 解析web资源 --&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.css&lt;/include&gt; &lt;include&gt;**/*.js&lt;/include&gt; &lt;/includes&gt; &lt;/webResource&gt; &lt;/webResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 编译器插件 --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring dependencies start --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring dependencies end --&gt; &lt;/dependencies&gt;&lt;/project&gt; 编写Maven插件 创建一个maven-plugin项目：它本身也是一个maven项目，不过，packaging 必须是maven-plugin.可以使用maven-archetype-plugin快速创建一个Maven插件项目 为插件编写目标。每个插件都必须包含一个或多个目标，Maven称为Mojo（与POJO对应）。编写插件时，必须提供一个或者多个继承自AbstractMojo类。 为目标提供配置点。 编写代码，实现目标行为 错误处理及日志。 测试插件 一个简单的项目Jetty-demo]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记]]></title>
    <url>%2F2015%2F10%2F10%2FJava-RESTful-Web-Service-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[在 Java 世界 中， 与 大 Web Service 相 对应 的 规范 是 JAX- WS。 在 大 Web Service 已经 成为 明日黄花 之后， Java 世界 急需 一套 新的 规范 来 取代 JAX- WS。 这套 新的 规范 就是 JAX- RS： Java 世界 开发 RESTful Web Service（ 与 RESTful API 含义 相同， 可 混用） 的 规范。 虽然 起步 很晚， 毕竟 走上 了 正确 的 道路。 从 Java EE 6 开始， JAX- RS 在 Java EE 版图 中， 作为 最重要的 组成部分 之一， 逐步 取代 了 JAX- WS 的 地位。 概念REST 是 一种 跨 平台、 跨 语言 的 架构 风格， REST 式 的 Web 服务 是对 REST 在 Web 领域 的 实现； JAX- RS 标准 是在 Java 领域， 对 REST 式 的 Web 服务 制定 的 实现 标准， Jersey 是 JAX- RS 标准 的 参考 实现， 是 Java EE 参考 实现 项目 GlassFish 的 成员 项目。 REST 的六个特点 客户 端- 服务器 的 无 状态 的 可 缓存 的 统一 接口 分层 系统 按 需 编码 Application类Application 类 在 JAX- RS 2. 0（ JSR 339， 详见 参考资料） 标准 中 定义 为 javax. ws. rs. core. Application， 相当于 JAX- RS 2. 0 服务 的 入口。 作为 应用 的 入口， Application 需要 知道 具体 的 资源 文件， 这里 可以 通过 包 扫描 或 直接 指定 类 文件 的 方式 获得。 如果 REST 服务 没有 自定义 Application 的 子类， 容器 将 默认 生成 一个 javax. ws. rs. core. Application 类。 方法作用GET获取 POST创建 PUT更新 DELETE删除]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>restful</tag>
        <tag>web service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jersey 2.x 搭建Web service]]></title>
    <url>%2F2015%2F10%2F09%2FJersey-2-x-%E6%90%AD%E5%BB%BAWeb-service%2F</url>
    <content type="text"><![CDATA[假设创建的项目名为: hello Maven依赖123456789101112131415161718192021222324 &lt;repository&gt; &lt;id&gt;snapshot-repository.java.net&lt;/id&gt; &lt;name&gt;Java.net Snapshot Repository for Maven&lt;/name&gt; &lt;url&gt;https://maven.java.net/content/repositories/snapshots/&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt;&lt;/repository&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-server&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-common&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.containers&lt;/groupId&gt; &lt;artifactId&gt;jersey-container-servlet&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; web.xml配置1234567891011121314&lt;servlet&gt; &lt;servlet-name&gt;REST&lt;/servlet-name&gt; &lt;servlet-class&gt;org.glassfish.jersey.servlet.ServletContainer&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;javax.ws.rs.Application&lt;/param-name&gt; &lt;param-value&gt;org.emacsist.App&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;REST&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; org.emacsist.App 内容12345678910111213package org.emacsist;import javax.ws.rs.ApplicationPath;import org.glassfish.jersey.server.ResourceConfig;@ApplicationPath("/")public class App extends ResourceConfig &#123; public App() &#123; packages("org.emacsist"); &#125;&#125; org.emacsist.Helloworldresource 内容1234567891011121314151617package org.emacsist;import javax.ws.rs.GET;import javax.ws.rs.Path;import javax.ws.rs.Produces;import javax.ws.rs.core.MediaType;@Path("rest")public class HelloWorldResource &#123; @GET @Produces(MediaType.APPLICATION_JSON) public String hello() &#123; return "&#123;\"hello\":\"world\"&#125;"; &#125;&#125; 将项目部署到TomcatRun as –&gt; Run on server即可，然后访问 localhost:8080/hello/rest 参考资料jersey手册]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>restful</tag>
        <tag>web service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java是如何查找class的?]]></title>
    <url>%2F2015%2F09%2F14%2FJava%E6%98%AF%E5%A6%82%E4%BD%95%E6%9F%A5%E6%89%BEclass%E7%9A%84%2F</url>
    <content type="text"><![CDATA[Java中的三种类型class Bootstrap classes这些是核心class,即Java平台最基础的class. 它放在 rt.jar(runtime),以及其他一些非常重要的jar包里. 它是通过参数sun.boot.class.path来决定的.也有一个非标准的JVM参数来决定这些class:-Xbootclasspath.例子: java -Dsun.boot.class.path=/path/to/xx1.jar:/path/to/xx2.jar(注意,不同的操作系统,分隔符不同,*unix下是:,Windows下的是;) 使用-Xbootclasspath方式有以下三种: 替换java -Xbootclasspath:/path/to/xx1.jar:/path/to/xx2.jar 追加即在原java的bootstrap cless的基础上,追加以下这些jar包的class java -Xbootclasspath/a:/path/to/xx1.jar:/path/to/xx2.jar 前置即在原java的bootstrap class的基础上,前置(即优先)查找以下jar包的class java -Xbootclasspath/p:/path/to/xx1.jar:/path/to/xx2.jar 参考资料 Extension classes这些是扩展class,由用于Java扩展机制使用.这些是由一些在扩展目录的jar文件组成的.它们放在jre/lib/ext目录, 该目录下的所有jar文件是使用Java Extension Framework加载的. 可以使用-Djava.ext.dirs参数来修改这些目录的值.例如: java -Djava.ext.dirs=/path/to/your/dirs1:/path/to/your/dirs2(*unix是:分隔符,Windows是;分隔符) 参考资料 User classes这些值存放在java.class.path系统属性里. 这个是由开发者以及那些没有使用扩展机制的第三方定义的class. 它是通过-classpath 或者 -cp 的命令行选项或者CLASSPATH环境变量来定位class的.它的值有以下几种情况: .:意味着这些class在当前目录或者子目录(如果有package)吧.CLASSPATH: 如果有这个环境变量,它就会覆盖默认的值.-cp或者-classpath: 它会覆盖默认的值,以及CLASSPATH环境变量的值.通过-jar来启动的: 所有的class,都必须包含在jar文件里.(即它会忽略CLASSPATH以及-cp或-classpath的值). 在OSGi中使用注意可以参考这篇Apache-Felix-OSGi-使用非bundle-jar包共享到其他所有bundle]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>classloader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache Felix OSGi 使用非bundle jar包共享到其他所有bundle]]></title>
    <url>%2F2015%2F09%2F14%2FApache-Felix-OSGi-%E4%BD%BF%E7%94%A8%E9%9D%9Ebundle-jar%E5%8C%85%E5%85%B1%E4%BA%AB%E5%88%B0%E5%85%B6%E4%BB%96%E6%89%80%E6%9C%89bundle%2F</url>
    <content type="text"><![CDATA[使用 org.osgi.framework.system.packages 参数创建一个项目，假设使用了Google的Guava的bundle，但这个库并不是OSGi Bundle。但如果又想共享于其他bundle的话，可以按以下方式来处理。 在IDE里，添加buildpath，添加这个Guava类库（为了编译通过，亲）。然后记得在自己的Bundle里，修改MANIFEST.MF文件，Import-Package自己使用了哪些包，比如下面的例子: 12345678910Manifest-Version: 1.0Bundle-ManifestVersion: 2Bundle-Name: UseGuavaBundle-SymbolicName: UseGuavaBundle-Version: 1.0.0.qualifierBundle-Activator: useguava.ActivatorBundle-Vendor: yangzhiyongBundle-RequiredExecutionEnvironment: JavaSE-1.8Import-Package: org.osgi.framework;version="1.3.0", com.google.common.base 使用Guava的Bundle源码： 12345678910111213141516171819202122232425262728package useguava;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;import com.google.common.base.Strings;public class Activator implements BundleActivator &#123; private static BundleContext context; static BundleContext getContext() &#123; return context; &#125; public void start(BundleContext bundleContext) throws Exception &#123; Activator.context = bundleContext; System.out.println("start bundle"); System.out.println(Strings.repeat("fuck", 10)); &#125; public void stop(BundleContext bundleContext) throws Exception &#123; Activator.context = null; System.out.println("stop bundle"); &#125;&#125; 然后，在启动OSGi时，添加以下参数。这里以apache felix为例： 12345678➜ felix-framework-5.2.0 rm felix-cache -rf &amp;&amp; java -Dorg.osgi.framework.system.packages.extra=com.google.common.base -cp "bin/*" org.apache.felix.main.Main____________________________Welcome to Apache Felix Gogog! start file:'/tmp/plugins/UseGuava_1.0.0.201509141006.jar'start bundlefuckfuckfuckfuckfuckfuckfuckfuckfuckfuckg! 总结添加参数：-Dorg.osgi.framework.system.packages.extra，用逗号分开每个要导出（相当于Export-Packages），然后在各个Bundle，按需要使用Import-Packages即可。还要注意classpath的配置，要添加相应的classpath，让java启动时，找到这个jar包即可。 使用org.osgi.framework.bootdelegation 参数和以上的方式差不多。最重要的一点是：不要在Bundle里，添加 Import-Packages 来导入这在org.osgi.framework.bootdelegation参数里配置的包。千万记得不要Import-Packages。 还有，也要添加下org.osgi.framework.bundle.parent参数。完整启动参数如下： 我这里，只是将上面那个MF文件，去掉了相应的Import-Packages，内容如下： 123456789Manifest-Version: 1.0Bundle-ManifestVersion: 2Bundle-Name: UseGuavaBundle-SymbolicName: UseGuavaBundle-Version: 1.0.0.qualifierBundle-Activator: useguava.ActivatorBundle-Vendor: yangzhiyongBundle-RequiredExecutionEnvironment: JavaSE-1.8Import-Package: org.osgi.framework;version="1.3.0" 然后启动时如下： 12345678➜ felix-framework-5.2.0 rm felix-cache -rf &amp;&amp; java -Dorg.osgi.framework.bundle.parent=app -Dorg.osgi.framework.bootdelegation="com.google.common.base" -cp "bin/*" org.apache.felix.main.Main____________________________Welcome to Apache Felix Gogog! start file:'/tmp/plugins/UseGuava_1.0.0.201509141006.jar'start bundlefuckfuckfuckfuckfuckfuckfuckfuckfuckfuckg! 注意：org.osgi.framework.bundle.parent参数，默认值是boot，如果没有修改为app的话，启动会报错。如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253➜ felix-framework-5.2.0 rm felix-cache -rf &amp;&amp; java -Dorg.osgi.framework.bundle.parent=boot -Dorg.osgi.framework.bootdelegation="com.google.common.base" -cp "bin/*" org.apache.felix.main.Main____________________________Welcome to Apache Felix Gogog! start file:'/tmp/plugins/UseGuava_1.0.0.201509141006.jar'start bundleorg.osgi.framework.BundleException: Activator start error in bundle UseGuava [5]. at org.apache.felix.framework.Felix.activateBundle(Felix.java:2270) at org.apache.felix.framework.Felix.startBundle(Felix.java:2138) at org.apache.felix.framework.BundleImpl.start(BundleImpl.java:977) at org.apache.felix.gogo.command.Basic.start(Basic.java:729) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.felix.gogo.runtime.Reflective.invoke(Reflective.java:137) at org.apache.felix.gogo.runtime.CommandProxy.execute(CommandProxy.java:82) at org.apache.felix.gogo.runtime.Closure.executeCmd(Closure.java:480) at org.apache.felix.gogo.runtime.Closure.executeStatement(Closure.java:406) at org.apache.felix.gogo.runtime.Pipe.run(Pipe.java:108) at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:182) at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:119) at org.apache.felix.gogo.runtime.CommandSessionImpl.execute(CommandSessionImpl.java:94) at org.apache.felix.gogo.shell.Console.run(Console.java:62) at org.apache.felix.gogo.shell.Shell.console(Shell.java:203) at org.apache.felix.gogo.shell.Shell.gosh(Shell.java:128) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.felix.gogo.runtime.Reflective.invoke(Reflective.java:137) at org.apache.felix.gogo.runtime.CommandProxy.execute(CommandProxy.java:82) at org.apache.felix.gogo.runtime.Closure.executeCmd(Closure.java:480) at org.apache.felix.gogo.runtime.Closure.executeStatement(Closure.java:406) at org.apache.felix.gogo.runtime.Pipe.run(Pipe.java:108) at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:182) at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:119) at org.apache.felix.gogo.runtime.CommandSessionImpl.execute(CommandSessionImpl.java:94) at org.apache.felix.gogo.shell.Activator.run(Activator.java:75) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.NoClassDefFoundError: com/google/common/base/Strings at useguava.Activator.start(Activator.java:19) at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:697) at org.apache.felix.framework.Felix.activateBundle(Felix.java:2220) ... 32 moreCaused by: java.lang.ClassNotFoundException: com.google.common.base.Strings not found by UseGuava [5] at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1558) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:79) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1998) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 35 morejava.lang.NoClassDefFoundError: com/google/common/base/Stringsg! 虽然我们使用了-cp来添加我们的jar包，但由于这个参数是boot（默认就是它），所以，它只会加载-Dsun.boot.class.path参数的jar包，而忽略-cp的指定的jar包，所以导致ClassNotFoundException. 如果确定想使用-Dorg.osgi.framework.bundle.parent=boot的话（默认情况也是这样子），就要修改为以下： 12345678➜ felix-framework-5.2.0 rm felix-cache -rf &amp;&amp; java -Dsun.boot.class.path="/home/yang/Java/jdk1.8.0_51/jre/lib/resources.jar:/home/yang/Java/jdk1.8.0_51/jre/lib/rt.jar:/home/yang/Java/jdk1.8.0_51/jre/lib/sunrsasign.jar:/home/yang/Java/jdk1.8.0_51/jre/lib/jsse.jar:/home/yang/Java/jdk1.8.0_51/jre/lib/jce.jar:/home/yang/Java/jdk1.8.0_51/jre/lib/charsets.jar:/home/yang/Java/jdk1.8.0_51/jre/lib/jfr.jar:/home/yang/Java/jdk1.8.0_51/jre/classes:bin/guava-19.0-rc1.jar" -Dorg.osgi.framework.bundle.parent=boot -Dorg.osgi.framework.bootdelegation="com.google.common.base" -cp "bin/*" org.apache.felix.main.Main____________________________Welcome to Apache Felix Gogog! start file:'/tmp/plugins/UseGuava_1.0.0.201509141006.jar'start bundlefuckfuckfuckfuckfuckfuckfuckfuckfuckfuckg! -Dorg.osgi.framework.bundle.parent这个参数的数值可以有四个： boot: 就是上面那个例子，这个在-Dsun.boot.class.path修改（即加载java.及Java的核心类库），然后再添加上你自己的jar包的类库就可以了。（上面就是这样，在原来的，添加多了Guava的jar包）。默认情况下它主要加载的是rt.jar以及其他在jre/lib目录下的jar包。 ext: 这个主要加载jre/lib/ext目录下的jar包。这个虽然没有环境变量可以配置，但可以通过修改-Djava.ext.dirs参数来修改。比如，使用ext来加载时的启动例子如下：（注意，使用ext时，就不要配置-Dsun.boot.class.path了，而是配置-Djava.ext.dirs了. 12345678➜ felix-framework-5.2.0 rm felix-cache -rf &amp;&amp; java -Djava.ext.dirs="/home/yang/Java/jdk1.8.0_51/jre/lib/ext:/usr/java/packages/lib/ext:mylib" -Dorg.osgi.framework.bundle.parent=ext -Dorg.osgi.framework.bootdelegation="com.google.common.base" -cp "bin/*" org.apache.felix.main.Main____________________________Welcome to Apache Felix Gogog! start file:'/tmp/plugins/UseGuava_1.0.0.201509141006.jar'start bundlefuckfuckfuckfuckfuckfuckfuckfuckfuckfuckg! app: 这个主要加载的是CLASSPATH环境变量的类。注意，使用-cp指定时，它会覆盖系统里的CLASSPATH的值。使用app的启动例子如下： 12345678➜ felix-framework-5.2.0 rm felix-cache -rf &amp;&amp; java -Dorg.osgi.framework.bundle.parent=app -Dorg.osgi.framework.bootdelegation="com.google.common.base" -cp "bin/*:mylib/*" org.apache.felix.main.Main____________________________Welcome to Apache Felix Gogog! start file:'/tmp/plugins/UseGuava_1.0.0.201509141006.jar'start bundlefuckfuckfuckfuckfuckfuckfuckfuckfuckfuckg! framework: 这个是框架本身的加载地方。没有特别研究过。 关于java如何找class的官方文档]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将非OSGi jar转换成OSGi的Bundle]]></title>
    <url>%2F2015%2F09%2F13%2F%E5%B0%86%E9%9D%9EOSGi-jar%E8%BD%AC%E6%8D%A2%E6%88%90OSGi%E7%9A%84Bundle%2F</url>
    <content type="text"><![CDATA[建立转换的project测试环境: JDK 1.8, Eclipse 4.4.2 打开Eclipse, File-&gt; New -&gt; Project -&gt; Plug-in Development -&gt; Plug-in from Existing JAR Archives 然后选择你想要制作成bundle的jar包, 然后输入一些plugin的信息如作者等.记得不要勾选Unzip the JAR archive into the project,即不要解压Jar包. 然后导出并安装到OSGi运行环境即可. 导出成bundle右键项目 -&gt; Expor -&gt; Plug-in Development -&gt; Deployable plug-ins and fragment. 即可.这时bundle就制作成了.然后安装到相应的OSGi环境即可. 以apache felix为例.假设上面的导出的位置为/tmp/osgi/plugins/xxx.jar.然后在felix的OSGi运行环境里安装即可: start file:/tmp/osgi/plugins/xxx.jar]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发并打包一个OSGi的Bundle]]></title>
    <url>%2F2015%2F09%2F11%2F%E5%BC%80%E5%8F%91%E5%B9%B6%E6%89%93%E5%8C%85%E4%B8%80%E4%B8%AAOSGi%E7%9A%84Bundle%2F</url>
    <content type="text"><![CDATA[安装个Eclipse插件EclipsePlugin 功能：将某个目录下的jar包，添加到buildpath 打包一个Bundle这只是演示第三方jar包依赖的打包问题，Bundle之间的依赖，通过Import, Export来进行。 创建一个项目： File -&gt; New -&gt; Project -&gt; Plug-in Project，然后输入bundle名，target platform选择 an OSGi framework, standard. -&gt; Next -&gt; 最后一个Next，不要勾选模板即可 然后在项目的根目录，创建一个 lib 目录，将所依赖的jar，都放到这里（其实最好就做成bundle，运行成服务最好），然后右键项目 -&gt; Properties -&gt; Java Build Dath -&gt; Libraries -&gt; Add library -&gt; Directory Container -&gt; 选择刚创建的那个lib目录即可，这时该目录下的所有jar包，都放到build path里了。 Activator内容为： 12345678910111213141516171819202122232425package example;import org.apache.commons.lang.StringUtils;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;public class Activator implements BundleActivator &#123; private static BundleContext context; static BundleContext getContext() &#123; return context; &#125; public void start(BundleContext bundleContext) throws Exception &#123; Activator.context = bundleContext; System.out.println("Hello World."); System.out.println(StringUtils.upperCase("Hello OSGi")); &#125; public void stop(BundleContext bundleContext) throws Exception &#123; Activator.context = null; &#125;&#125; 注意 检查下右键项目 -&gt; Properties -&gt; Java Build Dath,看看source有没有其他的jar包文件，有的话，就删除掉，只保留源码目录。 这时，只是对eclipse编译通过了而已，还是还要在Bundle的描述文件里，配置Bundle-Classpath。 打开META-INF目录下的MANIFEST.MF文件，打开Runtime这个tab，然后在右边的classpath里，点击Add来添加所依赖的第三方jar包（注意，不能直接选择lib目录，而是要定位到具体的jar文件） 这样子，环境方面就做好了。接下来，就是导出这个Bundle。 右键项目 -&gt; Export -&gt; Plug-in Development -&gt; Deployable plug-ins and fragments -&gt; 勾选项目，以及选择导出到某个目录即可。 这样子就OK了。 运行直接放到 apache felix 安装目录的bundle目录，然后直接运行以下命令即可。 1234567➜ felix-framework-5.2.0 java -jar bin/felix.jarHello World.HELLO OSGI____________________________Welcome to Apache Felix Gogog!]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]为什么我的Bundle抛出ClassNotFoundException或者NoClassDefFoundError?]]></title>
    <url>%2F2015%2F09%2F10%2F%E7%BF%BB%E8%AF%91-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84Bundle%E6%8A%9B%E5%87%BAClassNotFoundException%E6%88%96%E8%80%85NoClassDefFoundError%2F</url>
    <content type="text"><![CDATA[原文 对于OSGi的新用户有一个非常普遍的如下问题 我的Bundle抛出一个 NoClassDefFoundError 在 org.example.FooBar, 尽管FooBar是在classpath里,这是啥情况?? 在OSGi,说有什么东西在classpath甚至是没有什么意义的,因为在OSGi中没有全局的classpath.相反,每一个bundle都有它自己独立的class loader.在每个bundle的class loader里只能加载也在budle里面的classes, 或者显式地从其他bundle导入的classes. 从其他bundle导入classes的更好方式是使用Import-Package. 你必须导入你bundle要使用的每一个包, 除了那些已经是你的bundle的一部分的以java.开头的包(例如java.net, java.util等等, 这些包是由JRE特别处理的. 听起来好像要做很多工作, 但不要担心. 许多开发者使用Bnd来构建他们的bundles, 或者基于类似Bndtools和Maven Bundle Plugin这些工具. 所有这些工具通过检查你的class文件的依赖来自动为你的bundle生成Import-Package元信息. 注意, 你的bundle导入的包, 必须是其他已经安装到OSGi框架的bundle并且使用Export-Package导出同样的包的元信息.在运行时, 框架会检测每一个import以及相应的export的指令是否正确.如果它不能找到一个匹配的export,那么你的bundle将解析(resolve)失败.这发生在一个bundle的生命周期的早期, 并且是在任何代码加载之前发生. 所以, 只要你正确地import了的话, 你不应该会遇到ClassNotFoundException或者NoClassDefFoundError.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSGi Bundle元数据描述说明]]></title>
    <url>%2F2015%2F09%2F10%2FOSGi-Bundle%E5%85%83%E6%95%B0%E6%8D%AE%E6%8F%8F%E8%BF%B0%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[Bundle 预定义标记描述元数据Bundle的元数据信息定义在/META-INF/MANIFEST.MF文件之中，OSGi规范中明确要求实现框架必须能够正确识别那些被预定义过的标记（在R5.0规范中预定义了28项标记），对于不可识别的标记以及不符合MANIFEST.MF标记格式的内容都要忽略且不能影响Bundle的正常解析。 预定义标记以下列出了MANIFEST.MF文件中常用的预定义标记，除非特别说明，所列举的标记项都是可选的。对于其中某些较重要的标记（如Import-Package和Export-Package等），我们将在后续章节着重分析讲解。 Bundle-ActivationPolicy标记Bundle-ActivationPolicy设置Bundle的加载策略，该参数目前只有一个值：lazy，设置该参数后，Bundle将延迟激活，延迟至有其他的Bundle请求加载该Bundle中的类或资源时它才会被激活，如果不设置这个参数，那么Bundle启动时就会被激活。 示例： Bundle-ActivationPolicy: lazy Bundle-Activator标记Bundle-Activator指明一个Activator 类，在Bundle启动和停止时会分别调用该类的start()和stop()方法，以便执行程序员所希望的动作，该类必须实现org.osgi.framework.BundleActivator接口。 Activator类通常用于在Bundle启动时注册和初始化服务，在Bundle卸载时注销这些服务。它很常用，但并不是必须的。 示例： Bundle-Activator: com.acme.fw.Activator Bundle-Category标记Bundle-Category指明该Bundle的功能类别，可使用逗号分隔多个类别名称。这个功能类别仅供人工分类和阅读，OSGi框架并不会使用它。 示例： Bundle-Category: osgi, test, nursery Bundle-Classpath标记Bundle-Classpath指明该Bundle所引用的类路径，该路径应为Bundle包内部的一个合法路径，如果有多个Classpath，使用逗号分隔。在介绍Bundle类加载过程时我们会详细介绍这个标记。 示例： Bundle-Classpath: /jar/http.jar,. Bundle-ContactAddress标记Bundle-ContactAddress描述Bundle发行者的联系信息，仅供人工阅读，OSGi框架并不会使用它。 示例： Bundle-ContactAddress: 2400 Oswego Road, Austin, TX 74563 Bundle-Copyright标记Bundle-Copyright描述Bundle的版权信息，仅供人工阅读，OSGi框架并不会使用它。示例： Bundle-Copyright: OSGi (c) 2002 Bundle-Description标记Bundle-Description给出关于该Bundle的简短描述信息，仅供人工阅读，OSGi框架并不会使用它。 示例： Bundle-Description: Network Firewall Bundle-DocURL标记Bundle-DocURL给出该Bundle文档的链接地址，仅供人工阅读，OSGi框架并不会使用它。 示例： Bundle-DocURL: http:/www.acme.com/Firewall/doc Bundle-Icon标记Bundle-Icon给出该Bundle的显示图标，图标应为一张正方形的图片，并通过参数size指出图标的宽度。OSGi规范要求实现框架至少要支持PNG图片格式。 示例： Bundle-Icon: /icons/acme-logo.png;size=64 Bundle-License标记Bundle-License给出该Bundle的授权协议信息。 示例： Bundle-License: http://www.opensource.org/licenses/jabberpl.php Bundle-Localization标记Bundle-Localization给出该Bundle在不同语言系统下的本地化信息，如果不设置此标记，它的默认值为OSGI-INF/l10n/bundle。 示例： Bundle-Localization: OSGI-INF/l10n/bundle Bundle-ManifestVersion标记Bundle-ManifestVersion指出该Bundle应遵循哪个版本的OSGi规范，默认值为1。对于OSGi R3规范，该值为1；对于OSGi R4/R5规范，该值为2。也可能在以后的OSGi规范中使用更高的数字,但现在仅允许将它设置为1或2。 示例： Bundle-ManifestVersion: 2 Bundle-Name标记Bundle-Name定义该Bundle的名称。注意该名称只供人工阅读，在Bundle-SymbolicName标记中定义的名称才会作为程序使用的Bundle的唯一标识来使用。根据一般开发习惯，Bundle-Name中所定义的名称会在打包发布时与Bundle-Version一起构成该Bundle的文件名，所以这个名称一般不含空格或其他不能在文件名中出现的字符。 示例： Bundle-Name: Firewall Bundle-NativeCode如果Bundle中需要使用JNI加载其他语言实现的本地代码，那么必须使用Bundle-NativeCode标记进行说明。这个标记有如下附加参数： osname：操作系统名称，如Windows等。 osversion：操作系统版本号，如3.1等。 processor：处理器指令集架构，如x86等。 language：遵循ISO编码的语言，如en，zh等。 seleciton-filter：选择过滤器，该值为一个过滤器表达式，指定被选中或未被选中的本地代码。 示例： Bundle-NativeCode: /lib/http.DLL; osname = QNX; osversion = 3.1 Bundle-RequiredExecutionEnvironment标记Bundle-RequiredExecutionEnvironment定义该Bundle所需的执行环境，支持多种执行环境的Bundle使用逗号分隔。OSGi在设计上就有非常广泛的应用范围，从嵌入式系统至大型服务器执行环境必然会有许多差异，因此在这个标记中需要指出该Bundle所适合的执行环境。在后续章节中我们还会继续介绍OSGi执行环境。 示例： Bundle-RequiredExecutionEnvironment: CDC-1.0/Foundation-1.0 Bundle-SymbolicName标记Bundle-SymbolicName给出该Bundle在OSGi容器中的全局唯一标识符。与其他可选标记不同，这个标记没有默认值，并且是Bundle元数据信息之中唯一一个必须设置的标记。程序将基于此标记和版本号在OSGi容器中定位到一个独一无二的Bundle。 当且仅当两个Bundle的Bundle-SymbolicName和Bundle-Version属性都相同的时候，它们才是完全相同的，不允许同时安装两个完全相同的Bundle到同一个OSGi容器之中。 Bundle-SymbolicName有以下两个附加参数。 singleton：表示Bundle是单例的。如果OSGi系统中同时存在两个Bundle-SymbolicName相同的（当然，要求Bundle-Version不相同，否则是不可能同时存在的）单例Bundle，那么仅有其中一个会被解析。如果其中一个没有声明为单例Bundle，则不会受到另外一个单例Bundle的影响，默认值为false。 fragment-attachment：定义Fragment Bundle是否能附加到该Bundle之上。允许值为always、never和resolve-time，含义为允许附加、禁止附加和只允许在解析过程中附加，默认值为always，即允许附加。 示例： Bundle-SymbolicName: com.acme.daffy Bundle-UpdateLocation标记Bundle-UpdateLocation给出Bundle的网络更新地址。如果Bundle需要更新版本，将使用这个地址。 示例： Bundle-UpdateLocation: http://www.acme.com/Firewall/bundle.jar Bundle-Vendor标记Bundle-Vendor给出该Bundle的发行者信息。 示例： Bundle-Vendor: OSGi Alliance Bundle-Version标记Bundle-Version给出该Bundle的版本信息，默认值为“0.0.0”。注意，这项信息并不是仅供人工阅读的，“版本”在OSGi中是一项受系统管理的信息。维护一个Bundle的不同版本也是运行OSGi框架的重要特征之一，当一个Bundle依赖另一个Bundle时，经常需要指明它依赖的是什么版本范围内的Bundle。 版本号是有序的，在Symbolic-Name相同的前提下，两个Bundle的版本可比较大小。完整的版本号会由“主版本号（Major）”+“副版本号（Minor）”+“微版本号（Micro）”+“限定字符串（Qualifier）”构成。 示例： Bundle-Version: 22.3.58.build-345678 根据一般的开发习惯，上述4项版本号约定俗成地表示如下含义。 主版本号：表示与之前版本不兼容的重大功能升级。 副版本号：表示与之前版本兼容，但可能提供新的特性或接口。 微版本号：表示API接口没有变化，只是内部实现改变，或者修正了错误。 限定字符串：通常用于表示编译时间戳或者编译次数。 在比较版本大小时，从前往后逐项（含限定字符串）进行比较，当且仅当4个比较项都对应相等，两个Bundle的版本才相等，否则以第一个出现差异的版本号的大小决定整个Bundle版本的大小。 示例： 1.2.3 &lt; 3.2.1 &lt; 4.0 有一点必须注意，对于限定字符串的处理，OSGi和Maven是恰恰相反的，在Maven里，版本“1.2.3.2012”&lt;=“1.2.3”，但在OSGi里则是版本“1.2.3.2012”&gt;=“1.2.3”。 DynamicImport-Package标记Dynamic Import-Package描述运行时动态导入的Package。Package的导入和导出构成了OSGi多模块之间的组织协作关系，这是一个相对复杂而又很重要的内容，我们将在后续章节中专门介绍。 示例： DynamicImport-Package: com.acme.plugin.* Export-Package标记Export-Package描述被导出的Package。导入导出Package是模块层的核心功能，该内容将在后续章节中具体介绍。 示例： Export-Package: org.osgi.util.tracker;version=1.3 Export-Service标记Export-Service描述被导出的服务，这个标记在OSGi规范中已经被声明为Deprecated了，不推荐继续使用此标记。 示例： Export-Service: org.osgi.service.log.LogService Fragment-Host当该Bundle是一个Fragment Bundle时，标记Fragment-Host指明它的宿主Bundle。 示例： Fragment-Host: org.eclipse.swt; bundle-version=”[3.0.0,4.0.0)” Import-Package标记Import-Package描述该Bundle需要导入的Package。导入导出Package是模块层的核心功能，该内容将在后续章节中具体介绍。 示例： Import-Package:org.osgi.service.io;version=1.4 Import-Service标记Import-Service描述导入的服务。这个标记在OSGi规范中已经被声明为Deprecated了，不推荐继续使用此标记。 示例： Import-Service: org.osgi.service.log.LogService Provided-Capability标记Provided-Capability描述该Bundle提供的服务特性（Capability）。服务特性是在OSGi R4.3规范中加入的新概念。在此之前，Bundle只能通过Bundle-RequiredExecution-Environment来声明所需的执行环境；但是在某些场景下一些执行环境特性是由其他Bundle提供的，这样依赖运行环境来描述所需特性就受到限制了。因此在R4.3规范中加入了Provided-Capability和Require-Capability来声明Bundle所需要和能够提供的特性。 示例： Provided-Capability: com.acme.dict; from=nl; to=de; version:Version=1.2 Require-Capability标记Require-Capability描述该Bundle所需要的服务特性。 示例： Require-Capability: osgi.ee; filter:=”(&amp;(osgi.ee=AcmeMin)(version=1.1))” Require-Bundle标记Require-Bundle描述该Bundle所依赖的其他Bundle，一旦声明了依赖某个Bundle，就意味着可以直接使用所有从这个Bundle中导出的Package。 示例： Require-Bundle: com.acme.chess 来源]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSGi注意事项]]></title>
    <url>%2F2015%2F09%2F10%2FOSGi%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[关于导入的版本处理问题1Import-Package: org.osgi.framework;version="1.8.0" 这个表示，只要是org.osgi.framework包的版本，&gt;=1.8.0的都可以。 1Import-Package: org.osgi.framework;version="[1.8.0,1.8.9)" 这个表示，只要是org.osgi.framework包的版本只能是 1.8.0 &lt;= version &lt; 1.8.9的都可以。其他的则不能. 例如，我将项目的依赖的org.osgi.framework改为了[1.1.0,1.1.9)后，然后启动这个bundle，就会报如下类似的错误。这是因为找不到相应的版本的依赖bundle导致的。 123g! start file:/home/yang/Downloads/felix-framework-5.2.0/bundle/Example1_1.0.0.jarorg.osgi.framework.BundleException: Unable to resolve Example1 [5](R 5.0): missing requirement [Example1 [5](R 5.0)] osgi.wiring.package; (&amp;(osgi.wiring.package=org.osgi.framework)(version&gt;=1.1.0)(!(version&gt;=1.1.9))) Unresolved requirements: [[Example1 [5](R 5.0)] osgi.wiring.package; (&amp;(osgi.wiring.package=org.osgi.framework)(version&gt;=1.1.0)(!(version&gt;=1.1.9)))]g! 在Bundle中，导入第三方非Bundle的jar包在项目的根目录下，创建一个目录lib，然后将所有的jar包，放到这里，然后修改MANIFEST.MF文件，添加以下配置: 1Bundle-ClassPath: lib/commons-lang-2.6.jar,. 每一个jar以逗号分隔隔离开，注意，要定位到jar，而不能只写目录。我也不知道为什么。我使用的是Apache Felix的OSGi实现，版本为:felix-framework-5.2.0。 测试过了下，如果不定位到jar包，改为目录级，如： 1Bundle-ClassPath: lib/,. 会报以下的类似错误： 12345678910111213141516171819ERROR: Bundle Example2 [1] Error starting file:/home/yang/Downloads/felix-framework-5.2.0/bundle/Example2_1.0.0.jar (org.osgi.framework.BundleException: Activator start error in bundle Example2 [1].)java.lang.NoClassDefFoundError: org/apache/commons/lang/StringUtils at example2.Activator.start(Activator.java:25) at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:697) at org.apache.felix.framework.Felix.activateBundle(Felix.java:2220) at org.apache.felix.framework.Felix.startBundle(Felix.java:2138) at org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1365) at org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.ClassNotFoundException: org.apache.commons.lang.StringUtils not found by Example2 [1] at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1558) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:79) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1998) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 7 more____________________________Welcome to Apache Felix Gogog! 还要注意 这样子写了Jar包之后，千万不要再使用Import-Package来导入这些第三方包了。不然也会报以上的类似错误。 关于包的可见性问题总之一句话, 除了java.开头的包对于任何的OSGi框架运行时都是可见的, 其他的都应该假设它是不可见的.包括javax.开头的包!!]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Apache Felix OSGi运行环境及Bundle的生命周期例子]]></title>
    <url>%2F2015%2F09%2F10%2F%E6%90%AD%E5%BB%BAApache-Felix-OSGi%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E5%8F%8ABundle%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[运行环境配置好Java这些基础环境就忽略了。 下载Felix 假设下载到~/Downloads目录，然后解压 123cd ~/Downloadstar -xvf org.apache.felix.main.distribution-5.2.0.tar.gzcd felix-framework-5.2.0 启动OSGi运行环境: 12345678910111213➜ felix-framework-5.2.0 java -jar bin/felix.jar____________________________Welcome to Apache Felix Gogog! lbSTART LEVEL 1 ID|State |Level|Name 0|Active | 0|System Bundle (5.2.0) 1|Active | 1|Apache Felix Bundle Repository (2.0.4) 2|Active | 1|Apache Felix Gogo Command (0.14.0) 3|Active | 1|Apache Felix Gogo Runtime (0.16.2) 4|Active | 1|Apache Felix Gogo Shell (0.10.0)g! 服务的生命周期监听器例子example1 打开eclipse，File–&gt; New –&gt; Project –&gt; Plug-in Project –&gt; 填写项目名 –&gt; Target Platform 里选择 an OSGi framework --&gt;standard`.最后一步创建模板时，选择空，即不选择任何模板。 创建成功后，修改MANIFEST.MF文件相应内容，比如Version等，然后创建一个类，内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940package example1;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;import org.osgi.framework.ServiceEvent;import org.osgi.framework.ServiceListener;public class Activator implements BundleActivator, ServiceListener &#123; private static BundleContext context; static BundleContext getContext() &#123; return context; &#125; public void start(BundleContext bundleContext) throws Exception &#123; Activator.context = bundleContext; Activator.context.addServiceListener(this); System.out.println("启动Bundle"); &#125; public void stop(BundleContext bundleContext) throws Exception &#123; Activator.context.removeServiceListener(this); Activator.context = null; System.out.println("停止Bundle"); &#125; @Override public void serviceChanged(ServiceEvent event) &#123; String[] objectClass = (String[]) event.getServiceReference().getProperty("objectClass"); if (event.getType() == ServiceEvent.REGISTERED) &#123; System.out.println("服务类型为: " + objectClass[0] + " 已经注册."); &#125; else if (event.getType() == ServiceEvent.UNREGISTERING) &#123; System.out.println("服务类型为: " + objectClass[0] + " 已经取消注册."); &#125; else if (event.getType() == ServiceEvent.MODIFIED) &#123; System.out.println("服务类型为: " + objectClass[0] + " 已经修改."); &#125; &#125;&#125; 然后File –&gt; Export –&gt; Plug-in Development –&gt; Deployable plug-ins and fragments –&gt; Directory 选择到Felix的bundle目录里。可以看到目录内容如下： 1234567➜ bundle lsExample1_1.0.0.jarorg.apache.felix.bundlerepository-2.0.4.jarorg.apache.felix.gogo.command-0.14.0.jarorg.apache.felix.gogo.runtime-0.16.2.jarorg.apache.felix.gogo.shell-0.10.0.jar➜ bundle 我们的Bundle, Example1_1.0.0.jar 已经准备好了。接下来就是安装这个Bundle 安装bundle123456789101112131415➜ felix-framework-5.2.0 java -jar bin/felix.jar____________________________Welcome to Apache Felix Gogog! lbSTART LEVEL 1 ID|State |Level|Name 0|Active | 0|System Bundle (5.2.0) 1|Active | 1|Apache Felix Bundle Repository (2.0.4) 2|Active | 1|Apache Felix Gogo Command (0.14.0) 3|Active | 1|Apache Felix Gogo Runtime (0.16.2) 4|Active | 1|Apache Felix Gogo Shell (0.10.0)g! start file:/home/yang/Downloads/felix-framework-5.2.0/bundle/Example1_1.0.0.jar启动Bundleg! 可以看到，打印出了启动Bundle的输出。 停止Bundle1234567891011121314151617181920212223242526➜ felix-framework-5.2.0 java -jar bin/felix.jar____________________________Welcome to Apache Felix Gogog! lbSTART LEVEL 1 ID|State |Level|Name 0|Active | 0|System Bundle (5.2.0) 1|Active | 1|Apache Felix Bundle Repository (2.0.4) 2|Active | 1|Apache Felix Gogo Command (0.14.0) 3|Active | 1|Apache Felix Gogo Runtime (0.16.2) 4|Active | 1|Apache Felix Gogo Shell (0.10.0)g! start file:/home/yang/Downloads/felix-framework-5.2.0/bundle/Example1_1.0.0.jar启动Bundleg! lbSTART LEVEL 1 ID|State |Level|Name 0|Active | 0|System Bundle (5.2.0) 1|Active | 1|Apache Felix Bundle Repository (2.0.4) 2|Active | 1|Apache Felix Gogo Command (0.14.0) 3|Active | 1|Apache Felix Gogo Runtime (0.16.2) 4|Active | 1|Apache Felix Gogo Shell (0.10.0) 5|Active | 1|Example1 (1.0.0)g! stop 5停止Bundleg! 这个只是服务的监听器类，下面创建一个新的服务项目，用来注册某种服务。 Example2服务接口如下： 12345package example2.service;public interface SayHelloService &#123; public String say(String name);&#125; 服务实现接口如下： 1234567891011121314151617181920212223242526272829303132333435363738package example2;import java.util.Hashtable;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;import example2.service.SayHelloService;public class Activator implements BundleActivator &#123; private static BundleContext context; static BundleContext getContext() &#123; return context; &#125; public void start(BundleContext bundleContext) throws Exception &#123; Activator.context = bundleContext; Hashtable&lt;String, String&gt; props = new Hashtable&lt;String, String&gt;(); props.put("Language", "English"); context.registerService(SayHelloService.class.getName(), new SayHelloImpl(), props); &#125; public void stop(BundleContext bundleContext) throws Exception &#123; Activator.context = null; &#125; private static class SayHelloImpl implements SayHelloService &#123; @Override public String say(String name) &#123; return "from say hello impl: " + name; &#125; &#125;&#125; 然后以同样的方式，导出到Felix的bundle目录。然后启动: 1234567891011121314151617181920212223242526g! lbSTART LEVEL 1 ID|State |Level|Name 0|Active | 0|System Bundle (5.2.0) 1|Active | 1|Apache Felix Bundle Repository (2.0.4) 2|Active | 1|Apache Felix Gogo Command (0.14.0) 3|Active | 1|Apache Felix Gogo Runtime (0.16.2) 4|Active | 1|Apache Felix Gogo Shell (0.10.0) 6|Resolved | 1|Example1 (1.0.0) 7|Active | 1|Example2 (1.0.0)g! stop 7g! start 6启动Bundleg! lbSTART LEVEL 1 ID|State |Level|Name 0|Active | 0|System Bundle (5.2.0) 1|Active | 1|Apache Felix Bundle Repository (2.0.4) 2|Active | 1|Apache Felix Gogo Command (0.14.0) 3|Active | 1|Apache Felix Gogo Runtime (0.16.2) 4|Active | 1|Apache Felix Gogo Shell (0.10.0) 6|Active | 1|Example1 (1.0.0) 7|Resolved | 1|Example2 (1.0.0)g! start 7服务类型为: example2.service.SayHelloService 已经注册.g! 这样，就完成了服务注册及其监听器的小例子了。开启OSGi之路吧！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSGi之Web HelloWorld]]></title>
    <url>%2F2015%2F09%2F08%2FOSGi%E4%B9%8BWeb-HelloWorld%2F</url>
    <content type="text"><![CDATA[本文的测试环境使用的是: Mac + Eclipse 4.4.2 搭建基础环境打开Eclipse,然后 Run -&gt; Run Configurations -&gt; OSGi Framework,添加一个新的项目.Name就自己喜欢全名了. 然后在Bundles里,只勾选以下的bundles: 1234567891011121314151617181920javax.servletorg.apache.felix.gogo.commandorg.apache.felix.gogo.runtimeorg.apache.felix.gogo.shellorg.eclipse.equinox.consoleorg.eclipse.equinox.http.jettyorg.eclipse.equinox.http.servletorg.eclipse.jetty.continuationorg.eclipse.jetty.httporg.eclipse.jetty.ioorg.eclipse.jetty.securityorg.eclipse.jetty.serverorg.eclipse.jetty.servletorg.eclipse.jetty.utilorg.eclipse.osgiorg.eclipse.osgi.services 然后在 Arguments 里的 VM arguments里添加多一个以下的参数,用来个修改HTTP服务的端口(默认情况下是80端口) -Dorg.osgi.service.http.port=8000 然后apply -&gt; run 就可以了. 这个时候,可以打开 http://localhost:8000 可以看到报404,而不是找不到网络了.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>OSGi</tag>
        <tag>eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven打包时带有旧版本的jar包问题]]></title>
    <url>%2F2015%2F09%2F08%2FMaven%E6%89%93%E5%8C%85%E6%97%B6%E5%B8%A6%E6%9C%89%E6%97%A7%E7%89%88%E6%9C%AC%E7%9A%84jar%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近发现在修改pom.xl的jar包版本依赖时，每次进行package时，都会发现以前的版本的jar包遗留下来。 原因这是因为我们公司有部分同事，喜欢在Eclipse里配置Tomcat的部署目录直接为项目的目录，而且在pom.xml配置了如下的task 1234567891011121314151617181920212223242526&lt;plugin&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-lib-src-webapps&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;configuration&gt; &lt;tasks&gt; &lt;copy todir="webroot/WEB-INF/lib"&gt; &lt;fileset dir="target/ROOT/WEB-INF/lib"&gt; &lt;include name="*" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;copy todir="webroot/WEB-INF/classes"&gt; &lt;fileset dir="target/ROOT/WEB-INF/classes"&gt; &lt;include name="*" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/tasks&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 关键就是上面的tasks部分，它是直接将target/ROOT/WEB-INF/lib目录，复制到项目工程的webroot/WEB-INF/lib目录下。而target/ROOT/WEB-INF/lib又是在部署时，将webroot/WEB-INF/lib目录复制到该目录的。这样子，就造成了旧版本的JAR包，一直会叠加了。还有classes目录也同理，虽然同名的会覆盖，但删除的java文件，还会保留下来，作为一名处女座，应该不能忍受这种事情。所以，进行了以下改造： 解决修改上面那段代码为以下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;version&gt;1.8&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;delete-lib&lt;/id&gt; &lt;phase&gt;clean&lt;/phase&gt; &lt;configuration&gt; &lt;target&gt; &lt;mkdir dir="webroot/WEB-INF/lib/"/&gt; &lt;delete includeemptydirs="true"&gt; &lt;fileset dir="webroot/WEB-INF/lib/" includes="**/*"/&gt; &lt;/delete&gt; &lt;mkdir dir="webroot/WEB-INF/classes"/&gt; &lt;delete includeemptydirs="true"&gt; &lt;fileset dir="webroot/WEB-INF/classes/" includes="**/*"/&gt; &lt;/delete&gt; &lt;mkdir dir="webroot/WEB-INF/classes"/&gt; &lt;/target&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;copy-lib-src-webapps&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;configuration&gt; &lt;target&gt; &lt;copy todir="webroot/WEB-INF/lib"&gt; &lt;fileset dir="target/ROOT/WEB-INF/lib"&gt; &lt;include name="*" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;copy todir="webroot/WEB-INF/classes"&gt; &lt;fileset dir="target/ROOT/WEB-INF/classes"&gt; &lt;include name="*" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/target&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 这样子就解决了。思路也非常简单：就是先删除，再copy。 这样子，执行命令时，就不会有遗留旧的jar包版本了。 1mvn clean package -Dmaven.test.skip=true]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络和租房防范知识]]></title>
    <url>%2F2015%2F09%2F07%2F%E7%BD%91%E7%BB%9C%E5%92%8C%E7%A7%9F%E6%88%BF%E9%98%B2%E8%8C%83%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[租房安全关于逃生窗租好房好，一定要看看有没有租房有没有防盗网，逃生窗这些东西，特别要注意的是逃生窗，它是一个空间比较小，但是可以打开的窗（我在广州Xiao Jiao这边，昨晚就是因为这个而被盗了），一定要买把锁锁住。 关于门永远不要嫌麻烦，有门的地方，都要买把锁锁着。虽然不一定确保没有问题，但至少增加小偷工作的成本，拖长时间，拖得拖久越好。 而且出门在外时，一定要将所有能关的地方，都关掉，比如窗(特别是逃生窗）、门，而且记得要上锁。 关于贵重物品说真的，出门在外，能避免买些贵重的东西，就避免了吧。如果有的，能带在身的，都要放在身边。比如笔记本，平板这些移动型的数码产品，一句话：你既然买得了，就要背得了。而数码产品，也是小偷的最爱。还有些什么金戒指之类的小型但贵重的东西。 终极解决办法就是尽量什么贵重物品都不要放在租房里。出门在外，尽可能轻装上阵，否则能带的都带在身边。你说，被抢了什么办？我觉得，小偷都是有计划的，平时多点留意下身边的生活情况，养成时时刻刻都要警戒的状态，不要想着，这种事，应该不会发生在我身上吧。这次就当交个学费了。在城市打工的孩子，真心不容易。在租房怕被盗，在外怕被抢。辛苦几个月的工资，几分钟就被这些人渣偷走了，还能说些什么呢？就像农民伯伯，干了一个季节的活，种了几亩大白菜，原以为可以小小享受下收成的，结果被猪去拱了。我也是醉了。 被偷一次，当买个教训；被偷二次，也当是个重要教训；被偷三次，你TM就是个SB。 网络安全既然被偷了，一般都是不见电脑，平板，手机这些的东西的。这样子就涉及了网络安全的问题. 数码产品被盗后将所有的网络重要的账户，都进行更改密码。尤其是支付宝（电子理财，支付之类的产品），微信，QQ，邮箱，网购电商账号等。 平时网络安全尽可能使用chrome的隐身模式，永远不要记住重要的密码，永远对重要的账号进行人工手动输入密码（比如网络银行，网页版支付宝，重要的邮箱等）]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>租房</tag>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 备份方案]]></title>
    <url>%2F2015%2F08%2F31%2FMySQL-%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[Percona XtraBackup介绍官方文档 它是一个MySQL的开源的热备工具，备份时不会锁数据库。当前最新版本为2.2，它可以备份MySQL 5.1, 5.5和5.6的InnoDB, XtraDB和MyISAM类型的表。 相比MySQL自带的mysqldump，它有以下特点： 非常快速和可靠 备份期间，不会中断处理事务处理 节约磁盘空间和网络带宽（传输时，会进行流压缩） 自动备份验证 由于恢复非常快，所以可用时间高 可以增量备份 可在线中进行MySQL服务器之间的表迁移 非常容易地创建一个MySQL从复制 备份时，不会添加额外的服务器负载 它的详细介绍，请看官方手册介绍：Intro 安装下载地址Download Ubuntu 使用 apt 方式官方文档 好像由于要翻墙，我搬了下来： 123456789apt-key adv --keyserver keys.gnupg.net --recv-keys 1C4CBDCDCD2EFD2A# 添加到 /etc/apt/sources.list# 注意，这里的 VERSION 请替换为自己的ubuntu版本deb http://repo.percona.com/apt VERSION maindeb-src http://repo.percona.com/apt VERSION mainsudo apt-get updatesudo apt-get install percona-xtrabackup 源码方式，请参看源码目录的安装说明，在此不多说了。 工具说明innobackupex: 它是一个包装的Perl脚本，可以备份整个表类型为MyISAM, InnoDB和XtraDB的MySQL实例。 xtrabackup: 一个用C写的二进制工具，仅用于复制InnoDB和XtraDB数据 xbcrypt： 用于加/解密备份的文件的工具 xbstream: 用于sbstream格式文件。 注意：虽然可以单独使用xtrabackup工具，但是，还是建议使用innobackupex这个包装的脚本来执行，让它来为你调用xtrabackup。 使用方式全量备份备份 123$ innobackupex --user=DBUSER --password=SECRET /path/to/backup/dir/$ innobackupex --user=LUKE --password=US3TH3F0RC3 --stream=tar ./ | bzip2 -$ xtrabackup --user=DVADER --password=14MY0URF4TH3R --backup --target-dir=/data/bkps/ 如果不指定--user，它会假定数据库的用户和你当前执行这些命令的用户名一样。 指定my.cnf文件： 1$ innobackupex --defaults-file=/tmp/other-my.cnf --user=DBUSER --password=SECRET /path/to/backup/dir/ 注意，这个必须是第一个参数. 连接数据库的其他选项： -port: MySQL端口-socket: MySQL的Socket文件-host: MySQL主机 这些选项是传递给mysql的，你可以参考其他mysql --help允许的选项。 权限 你需要在文件系统级别对服务器的datadir（即数据目录）拥有READ, WRITE和EXECUTE权限 在创建MySQL用户时，最小权限的例子： 123mysql&gt; CREATE USER 'bkpuser'@'localhost' IDENTIFIED BY 's3cret';mysql&gt; GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO 'bkpuser'@'localhost';mysql&gt; FLUSH PRIVILEGES; 准备$ innobackupex --user=DBUSER --password=SECRET /path/to/backup/dir/这步只是备份而已，但没有恢复数据，还要执行以下操作 $ innobackupex --apply-log --use-memory=4G /path/to/backup/dir如果不指定--use-memory，默认是100M 恢复 innobackupex --copy-back /path/to/BACKUP-DIR 增量备份阶段 首先使用以下命令，创建一个基础的增量序列 innobackupex /data/backups 然后创建第一个增量备份: innobackupex --incremental /data/backups --incremental-basedir=BASEDIR 然后再创建另一个增量备份： innobackupex --incremental /data/backups --incremental-basedir=INCREMENTAL-DIR-1这时，要特别注意，以后每一次的增量备份，都要修改 --incremental-basedir=参数为上一次的值 准备阶段 innobackupex --apply-log --redo-only BASE-DIR 然后依次恢复（从旧到新）增量备份的数据 innobackupex --apply-log --redo-only BASE-DIR --incremental-dir=INCREMENTAL-DIR-1innobackupex --apply-log --incremental-dir=INCREMENTAL-DIR-2… 注意，第二条没有--redo-only参数。这个参数应该用于当合并所有增量，但除了最近一次的。 一旦完成了所有增量恢复，就可以执行以下命令了： innobackupex --apply-log BASE-DIR 恢复阶段 innobackupex --copy-back BASE-DIR 参考资料[1] xtrabackup原理 xtrabackup 实战全量备份及恢复备份注意：这里的--user以及--password是上连接该DB的用户名和密码，而且必须要拥有相应的权限，请参考上面的[权限]说明。/home/mysql/3306/backup：这里是保存备份的位置 123456789101112131415mysql@yang:/usr/local/mysql-5.6$ innobackupex --user=bkpuser --password=s3cret --socket=/usr/local/mysql-data/3306/3306.socket --defaults-file=/usr/local/mysql-data/3306/my.cnf /home/mysql/3306/backupInnoDB Backup Utility v1.5.1-xtrabackup; Copyright 2003, 2009 Innobase Oyand Percona LLC and/or its affiliates 2009-2013. All Rights Reserved.This software is published underthe GNU GENERAL PUBLIC LICENSE Version 2, June 1991.Get the latest version of Percona XtraBackup, documentation, and help resources:http://www.percona.com/xb/p...中间省略输出....一定要看到有以下一句才算是成功!innobackupex: Backup created in directory '/home/mysql/3306/backup/2015-09-01_11-17-17'150901 11:17:22 innobackupex: Connection to database server closed150901 11:17:22 innobackupex: completed OK! 还原这里模拟数据损坏（直接删除mysql数据目录的相应的数据部分数据文件） 12345678910111213141516cd /usr/local/mysql-data/3306/test#删除aa表的所有数据rm -rf aa.*#这时看表时，可以发现没有了aa表，而且启动时也有警告提示:2015-09-01 11:56:34 28638 [ERROR] InnoDB: Table test/aa in the InnoDB data dictionary has tablespace id 6, but tablespace with that id or name does not exist. Have you deleted or moved .ibd files? This may also be a table created with CREATE TEMPORARY TABLE whose .ibd and .frm files MySQL automatically removed, but the table still exists in the InnoDB internal data dictionary.mysql&gt; mysql&gt; show tables;+----------------+| Tables_in_test |+----------------+| mvcc |+----------------+1 row in set (0.00 sec) 这表示物理删除了数据文件，但是MySQL的数据字典里，还存在有表aa的信息，MySQL在启动的时候忽略了这个错误，继续启动。 现在，准备还原数据看看： 准备阶段 12innobackupex --defaults-file=/usr/local/mysql-data/3306/my.cnf --apply-log --use-memory=4G /home/mysql/3306/backup 执行完后，发现报错： 123456789101112131415161718192021222324mysql@yang:~$ innobackupex --defaults-file=/usr/local/mysql-data/3306/my.cnf --apply-log --use-memory=4G /home/mysql/3306/backupInnoDB Backup Utility v1.5.1-xtrabackup; Copyright 2003, 2009 Innobase Oyand Percona LLC and/or its affiliates 2009-2013. All Rights Reserved.This software is published underthe GNU GENERAL PUBLIC LICENSE Version 2, June 1991.Get the latest version of Percona XtraBackup, documentation, and help resources:http://www.percona.com/xb/p150901 12:06:36 innobackupex: Starting the apply-log operationIMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints "completed OK!".Could not open required defaults file: /home/mysql/3306/backup/backup-my.cnfFatal error in defaults handling. Program abortedinnobackupex: got a fatal error with the following stacktrace: at /usr/bin/innobackupex line 4545. main::get_option('innodb_data_file_path') called at /usr/bin/innobackupex line 2631 main::apply_log() called at /usr/bin/innobackupex line 1578innobackupex: Error: no 'innodb_data_file_path' option in group 'mysqld' in server configuration file '/usr/local/mysql-data/3306/my.cnf' at /usr/bin/innobackupex line 4545.mysql@yang:~$ 这时，打开MySQL终端，输入以下命令： 12345678910mysql&gt; show variables like 'innodb_data_file_path' -&gt; ;+-----------------------+------------------------+| Variable_name | Value |+-----------------------+------------------------+| innodb_data_file_path | ibdata1:12M:autoextend |+-----------------------+------------------------+1 row in set (0.00 sec)mysql&gt; 然后，在配置文件 /home/mysql/3306/backup/backup-my.cnf的[mysqld]组中，添加以下参数: 1innodb_data_file_path=ibdata1:12M:autoextend 注意，这个是备份目录下的文件。 然后，又发现报错： 12345678910111213141516xtrabackup version 2.2.12 based on MySQL server 5.6.24 Linux (x86_64) (revision id: 8726828)xtrabackup: cd to /home/mysql/3306/backupxtrabackup: Error: cannot open ./xtrabackup_checkpointsxtrabackup: error: xtrabackup_read_metadata()xtrabackup: This target seems not to have correct metadata...2015-09-01 12:20:19 7f3854c9c780 InnoDB: Operating system error number 2 in a file operation.InnoDB: The error means the system cannot find the path specified.xtrabackup: Warning: cannot open ./xtrabackup_logfile. will try to find.2015-09-01 12:20:19 7f3854c9c780 InnoDB: Operating system error number 2 in a file operation.InnoDB: The error means the system cannot find the path specified. xtrabackup: Fatal error: cannot find ./xtrabackup_logfile.xtrabackup: Error: xtrabackup_init_temp_log() failed.innobackupex: got a fatal error with the following stacktrace: at /usr/bin/innobackupex line 2649. main::apply_log() called at /usr/bin/innobackupex line 1578innobackupex: Error:innobackupex: ibbackup failed at /usr/bin/innobackupex line 2649. 解决办法：因为在备份时，默认情况下生成的路径为/home/mysql/3306/backup/2015-09-01_11-17-17，所以，应该将最后的目录参数改为/home/mysql/3306/backup/2015-09-01_11-17-17，再试一次： 12345678910111213141516171819202122232425mysql@yang:~$ innobackupex --defaults-file=/usr/local/mysql-data/3306/my.cnf --apply-log --use-memory=4G /home/mysql/3306/backup/2015-09-01_11-17-17/InnoDB Backup Utility v1.5.1-xtrabackup; Copyright 2003, 2009 Innobase Oyand Percona LLC and/or its affiliates 2009-2013. All Rights Reserved.This software is published underthe GNU GENERAL PUBLIC LICENSE Version 2, June 1991.Get the latest version of Percona XtraBackup, documentation, and help resources:http://www.percona.com/xb/p150901 12:33:35 innobackupex: Starting the apply-log operationIMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints "completed OK!".150901 12:33:35 innobackupex: Starting ibbackup with command: xtrabackup --defaults-file="/home/mysql/3306/backup/2015-09-01_11-17-17/backup-my.cnf" --defaults-group="mysqld" --prepare --target-dir=/home/mysql/3306/backup/2015-09-01_11-17-17 --use-memory=4G...输出省略...xtrabackup: starting shutdown with innodb_fast_shutdown = 1InnoDB: FTS optimize thread exiting.InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 232371734150901 12:33:39 innobackupex: completed OK! 这次终于成功了，判断的标志是最后是否打印innobackupex: completed OK! 正式还原 1innobackupex --copy-back --defaults-file=/usr/local/mysql-data/3306/my.cnf /home/mysql/3306/backup/2015-09-01_11-17-17 很悲剧地又发现报以下错误： 123456789101112131415161718192021mysql@yang:~$ innobackupex --copy-back --defaults-file=/usr/local/mysql-data/3306/my.cnf /home/mysql/3306/backup/2015-09-01_11-17-17InnoDB Backup Utility v1.5.1-xtrabackup; Copyright 2003, 2009 Innobase Oyand Percona LLC and/or its affiliates 2009-2013. All Rights Reserved.This software is published underthe GNU GENERAL PUBLIC LICENSE Version 2, June 1991.Get the latest version of Percona XtraBackup, documentation, and help resources:http://www.percona.com/xb/p150901 12:39:40 innobackupex: Starting the copy-back operationIMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints "completed OK!".innobackupex: got a fatal error with the following stacktrace: at /usr/bin/innobackupex line 2201. main::if_directory_exists_and_empty('/usr/local/mysql-data/3306', 'Original data') called at /usr/bin/innobackupex line 2474 main::copy_back(0) called at /usr/bin/innobackupex line 1578innobackupex: Error: Original data directory '/usr/local/mysql-data/3306' is not empty! at /usr/bin/innobackupex line 2201. 原来，还要令/usr/local/mysql-data/3306 这个目录为空才行.所以，为了安全见，再备份下： 123mv /usr/local/mysql-data/3306 /usr/local/mysql-data/3306.oldmkdir /usr/local/mysql-data/3306sudo chown mysql:mysql /usr/local/mysql-data/ -R 然后再试一次： 这里要注意，这使用了3306.old/my.cnf 1234mysql@yang:/usr/local/mysql-data$ innobackupex --copy-back --defaults-file=/usr/local/mysql-data/3306.old/my.cnf /home/mysql/3306/backup/2015-09-01_11-17-17....输出省略...150901 12:51:07 innobackupex: completed OK!mysql@yang:/usr/local/mysql-data$ 重启重启后，再检查数据： 123456789101112131415mysql&gt; use test;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+----------------+| Tables_in_test |+----------------+| aa || mvcc |+----------------+2 rows in set (0.00 sec)mysql&gt; 增量备份与还原备份进行基础备份 12345678910111213mysql@yang:~/3306$ innobackupex --user=bkpuser --password=s3cret --socket=/usr/local/mysql-data/3306/3306.socket --defaults-file=/usr/local/mysql-data/3306/my.cnf /home/mysql/3306/baseInnoDB Backup Utility v1.5.1-xtrabackup; Copyright 2003, 2009 Innobase Oyand Percona LLC and/or its affiliates 2009-2013. All Rights Reserved.This software is published underthe GNU GENERAL PUBLIC LICENSE Version 2, June 1991.Get the latest version of Percona XtraBackup, documentation, and help resources:http://www.percona.com/xb/p...中间省略输出....一定要看到有以下一句才算是成功!150901 13:02:13 innobackupex: completed OK! 进行第一次增量备份 1mysql@yang:~/3306$ innobackupex --user=bkpuser --password=s3cret --socket=/usr/local/mysql-data/3306/3306.socket --defaults-file=/usr/local/mysql-data/3306/my.cnf --incremental-basedir=/home/mysql/3306/base/2015-09-01_13-02-10 --incremental /home/mysql/3306/incremental/one 结果如下： 1234mysql@yang:~/3306$ innobackupex --user=bkpuser --password=s3cret --socket=/usr/local/mysql-data/3306/3306.socket --defaults-file=/usr/local/mysql-data/3306/my.cnf --incremental-basedir=/home/mysql/3306/base/2015-09-01_13-02-10 --incremental /home/mysql/3306/incremental/one...中间省略输出....一定要看到有以下一句才算是成功!150901 13:07:32 innobackupex: completed OK! 这中间做一些其他的数据库操作，比如插入几条新数据，然后再进行第二次境量备份注意 incremental-basedir和-incremental参数的变化 1mysql@yang:~/3306$ innobackupex --user=bkpuser --password=s3cret --defaults-file=/usr/local/mysql-data/3306/my.cnf --incremental-basedir=/home/mysql/3306/incremental/one/2015-09-01_13-07-29 --incremental /home/mysql/3306/incremental/two 特别注意 因为默认情况下，备份的目录会自动生成时间截，所以，参数要定位到时间截的目录。 还原准备阶段 1mysql@yang:~$ innobackupex --defaults-file=/usr/local/mysql-data/3306/my.cnf --apply-log --redo-only --use-memory=4G /home/mysql/3306/base/2015-09-01_13-02-10 模拟数据损坏 1234567891011121314151617181920212223242526272829删除某几条数据mysql&gt; select * from aa;+----+--------+| id | name |+----+--------+| 1 | yang || 2 | yang2 || 3 | yang-s || 4 | y || 5 | yy |+----+--------+5 rows in set (0.00 sec)mysql&gt; insert into aa (name) values ('yy');mysql&gt;mysql&gt; delete from aa where id &lt; 3;Query OK, 2 rows affected (0.00 sec)mysql&gt; select * from aa;+----+--------+| id | name |+----+--------+| 3 | yang-s || 4 | y || 5 | yy |+----+--------+3 rows in set (0.00 sec)mysql&gt; 还原123456mv /usr/local/mysql-data/3306 /usr/local/mysql-data/3306.old2mysql@yang:~$ innobackupex --defaults-file=/usr/local/mysql-data/3306.old2/my.cnf --copy-back /home/mysql/3306/base/2015-09-01_13-02-10##复制回配置文件及启动脚本`copy /usr/local/mysql-data/3306.old2/my.cnf /usr/local/mysql-data/3306.old2/startup.sh /usr/local/mysql-data/3306/` 启动mysql，这时看到数据： 1234567891011mysql&gt; select * from aa;+----+--------+| id | name |+----+--------+| 1 | yang || 2 | yang2 || 3 | yang-s |+----+--------+3 rows in set (0.00 sec)mysql&gt; 关闭掉mysql，还原第一，二次的增量备份数据: 123innobackupex --defaults-file=/usr/local/mysql-data/3306/my.cnf --apply-log --redo-only --use-memory=4G /home/mysql/3306/base/2015-09-01_13-02-10 --incremental-dir=/home/mysql/3306/incremental/one/2015-09-01_14-22-53innobackupex --defaults-file=/usr/local/mysql-data/3306/my.cnf --apply-log --redo-only --use-memory=4G /home/mysql/3306/base/2015-09-01_14-21-12/ --incremental-dir=/home/mysql/3306/incremental/two/2015-09-01_14-24-06/ 注意，这里你按需准备好想要恢复的增量的数据即可。（比如，我只想要恢复base + one的数据） 然后，正式还原： 1mysql@yang:/usr/local/mysql-data$ innobackupex --defaults-file=/usr/local/mysql-data/3306.old/my.cnf --copy-back /home/mysql/3306/base/2015-09-01_14-21-12/ 还原时，只需要指定基础备份的目录即可 参考资料 drupal001 zhengdazhi offical mysqldump备份1mysqldump -S /usr/local/mysql-data/3306/3306.socket --single-transaction --skip-opt -q --routines --triggers --create-options --no-autocommit -B test | gzip &gt; /tmp/test.sql.gz 还原12345先删除test数据库，再还原：mysql&gt;drop database test;shell:gunzip &lt; /tmp/test.sql.gz | mysql -S /usr/local/mysql-data/3306/3306.socket -h localhost -u root -p 参考资料mysqldump 主从复制(master/slave)主配置1234567891011121314151617181920212223242526[mysqld]port = 3306socket = /usr/local/mysql-data/3306/3306.socketdatadir = /usr/local/mysql-data/3306pid-file = /usr/local/mysql-data/3306/3306.pidlog-error = /usr/local/mysql-data/3306/3306.errslow_query_log = 1long_query_time = 0.3slow_query_log_file = /usr/local/mysql-data/3306/query-slow.loggeneral_log = /usr/local/mysql-data/3306/general-log.loglanguage = /usr/local/mysql-5.6/share/englishsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES# replicationlog-bin = mysql-binserver-id = 1enforce-gtid-consistencygtid-mode=ON#replication the dbreplicate-do-db=test#mustlog-slave-updates 然后重启master服务器 然后创建一个用于复制的用户 123CREATE USER 'repl-user'@'%' IDENTIFIED BY 'slavepass';GRANT REPLICATION SLAVE ON *.* TO 'repl-user'@'%';flush privileges; 从配置123456789101112131415161718192021[mysqld]port = 3307socket = /usr/local/mysql-data/3307/3307.socketdatadir = /usr/local/mysql-data/3307pid-file = /usr/local/mysql-data/3307/3307.pidlog-error = /usr/local/mysql-data/3307/3307.errslow_query_log = 1long_query_time = 0.3slow_query_log_file = /usr/local/mysql-data/3307/query-slow.loggeneral_log = /usr/local/mysql-data/3307/general-log.loglanguage = /usr/local/mysql-5.6/share/englishsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESlog-bin = mysql-binserver-id = 2relay-log = relay-log-slaveread-only = ONgtid-mode =ONenforce-gtid-consistencylog-slave-updates 然后重启slave服务器 然后在slave里执行以下命令： 123456789CHANGE MASTER TO \MASTER_HOST = '10.0.0.81', \MASTER_PORT = 3306, \MASTER_USER = 'repl-user', \MASTER_PASSWORD = 'slavepass', \MASTER_AUTO_POSITION = 1;然后正式开始：mysql&gt;START SLAVE; 检查复制状态1SHOW SLAVE STATUS; Slave_SQL_Running 为No12345678910111213141516171819202122232425262728到slave执行以下命令：mysql&gt; stop slave;到master执行以下命令：mysql&gt; show master status \G*************************** 1. row *************************** File: mysql-bin.000001 Position: 1790 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set: 3bf331ce-5074-11e5-9a27-7824af3fdd83:1-71 row in set (0.00 sec)到slave执行以下命令：mysql&gt;CHANGE MASTER TO \MASTER_HOST = '10.0.0.81', \MASTER_PORT = 3306, \MASTER_USER = 'repl-user', \MASTER_PASSWORD = 'slavepass', \MASTER_LOG_FILE = 'mysql-bin.000001', \MASTER_AUTO_POSITION = 0, \MASTER_LOG_POS = 1790;到slave执行以下命令启动slavemysql&gt; start slave; 从库延后的解决不知道为什么，做好复制好，发现从库没有更上主库，如下： 主库： 123456789101112mysql&gt; select * from test_slave;+----+---------+| id | name |+----+---------+| 1 | aa || 2 | aa || 3 | aa || 4 | a32323a |+----+---------+4 rows in set (0.00 sec)mysql&gt; 从库: 12345678910mysql&gt; select * from test_slave;+----+---------+| id | name |+----+---------+| 3 | aa || 4 | a32323a |+----+---------+2 rows in set (0.00 sec)mysql&gt; 解决： 在master上执行以下命令 12345678RESET MASTER;FLUSH TABLES WITH READ LOCK;SHOW MASTER STATUS;mysqldump -uroot -p -S /usr/local/mysql-data/3306/3306.socket --master-data=2 --all-databases &gt; /tmp/3306.all.sqlUNLOCK TABLES; 在slave上执行以下命令 1234567891011121314151617STOP SLAVE;RESET MASTER;mysql -S /usr/local/mysql-data/3307/3307.socket -u root -p -h localhost -P 3307 &lt; /tmp/3306.all.sqlRESET SLAVE;CHANGE MASTER TO \MASTER_HOST = '10.0.0.81', \MASTER_PORT = 3306, \MASTER_USER = 'repl-user', \MASTER_PASSWORD = 'slavepass', \MASTER_LOG_FILE = 'mysql-bin.000001', \MASTER_AUTO_POSITION = 0, \MASTER_LOG_POS = 151;START SLAVE; 执行完，记得再次检查slave状态： 1show slave status; 看看两个线程是不是都是Yes: 12Slave_IO_Running: YesSlave_SQL_Running: Yes 参考资料CSNDStackoverflow 文件同步方式（冷备）这个方式最好就是停掉服务器，然后进行文件同步. rsync -avh --delete /usr/local/mysql-data/3306 /home/mysql/3306/backup rsync是个神器！它可以增量同步文件。这个没有什么特别的了。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>dba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署代码到远程Tomcat]]></title>
    <url>%2F2015%2F08%2F31%2F%E9%83%A8%E7%BD%B2%E4%BB%A3%E7%A0%81%E5%88%B0%E8%BF%9C%E7%A8%8BTomcat%2F</url>
    <content type="text"><![CDATA[直接上码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141将这个脚本，放到项目的根目录即可.#!/bin/bash# 使用方式：# 部署生产环境# 完全部署: ./server.sh p# 只部署静态文件: ./server.sh p static# 只部署后端文件: ./server.sh p class# 部署beta环境# 完全部署 ./server.sh pre# 只部署后端文件: ./server.sh pre classYYYYYY_REMOTE_IP="xxx.xxx.xx.xx"BETA_REMOTE_IP="yyy.yyy.yyy.yyy"V2_ROOT=$( cd "$( dirname "$&#123;BASH_SOURCE[0]&#125;" )" &amp;&amp; pwd )SCP_PORT=1850YYYYYY_PRODUCT_APPJS="var current_lang = 'zh-cn';\nvar GOLBAL_CONFIG = &#123;\n\t// 'wbapi': 'http://localhost',\n\t'wbapi': 'http://wbapi.xxxxxxx.com',\n\t'wxapi': 'http://wxapi.xxxxxxx.com',\n\t'luceneapi': 'http://lucenesdk.xxxxxxx.com',\n\t'wbappid': 'u.xxxxxxx.com'\n&#125;;\n"BETA_PRODUCT_APPJS="var current_lang = 'zh-cn';\nvar GOLBAL_CONFIG = &#123;\n\t// 'wbapi': 'http://localhost',\n\t'wbapi': 'http://wbapi.yyyyyy.com',\n\t'wxapi': 'http://wxapi.yyyyyy.com',\n\t'luceneapi': 'http://lucenesdk.yyyyyy.com',\n\t'wbappid': 'beta.yyyyyy.com'\n&#125;;\n"NOW="$(date +'%Y_%m_%d_%H_%M_%S')"echo "第一个参数为：-&gt;$1&lt;-"echo "第二个参数为：-&gt;$2&lt;-"if [ "$1" == "p" ]; then echo "部署生产环境" ENV="product" REMOTE_IP=$&#123;YYYYYY_REMOTE_IP&#125; PRODUCT_APPJS=$&#123;YYYYYY_PRODUCT_APPJS&#125;else echo "部署beta环境" ENV="pre-release" REMOTE_IP=$&#123;BETA_REMOTE_IP&#125; PRODUCT_APPJS=$&#123;BETA_PRODUCT_APPJS&#125; fi# 这个比较好，增量更新function deployV2UseRsync()&#123; echo "部署的环境是" $&#123;ENV&#125; "IP为" $&#123;REMOTE_IP&#125; mvn clean package -P$&#123;ENV&#125; -Dmaven.test.skip=true &gt; /dev/null &amp;&amp; bundleRes $1 $2 &amp;&amp; echo "执行前端脚本成功" &amp;&amp; cd $&#123;V2_ROOT&#125;/target/ROOT/ &amp;&amp; echo "In v2 ROOT" #完全同步 ROOT下面的目录，但除了 res/upload 和 res/lottery 目录，因为要保留服务器上传的文件，这个功能要谨慎处理 ssh -p $&#123;SCP_PORT&#125; yourusername@$&#123;REMOTE_IP&#125; "tar -czf /home/yourusername/tomcat/apache-tomcat-7.0.27/webapps/ROOT-$&#123;NOW&#125;.tar.gz /home/yourusername/tomcat/apache-tomcat-7.0.27/webapps/ROOT" echo "备份v2资源成功" if [ "$2" == "static" ]; then echo "部署静态文件" deployStaticFile elif [ "$2" == "class" ]; then echo "部署Java文件" deployJavaClassFile $1 $2 else echo "部署Java文件和静态文件" deployJavaClassFile $1 $2 deployStaticFile $1 $2 fi if [ "$1" != "p" ] &amp;&amp; [ "$2" != "static" ]; then echo "要重启beta服务器" ssh -p $&#123;SCP_PORT&#125; yourusername@$&#123;REMOTE_IP&#125; "/home/yourusername/yzy/restartV2.sh" echo "重启beta服务器成功" fi &#125;# 进行前端处理function bundleRes()&#123; echo "处理前端公共处理" gulp srcToDist gulp release if [ "$1" == "p" ]; then echo "前端处理生产环境的部署" gulp mainrev configrev --production else echo "前端处理beta环境的部署" gulp mainrev configrev fi &#125;# 同步静态资源文件function deployStaticFile()&#123; cd $&#123;V2_ROOT&#125;/target/ROOT/res/ rsync -azh --delete --exclude="upload/" --exclude="lottery/" --exclude="$&#123;V2_ROOT&#125;/target/ROOT/res/upload/" --exclude="$&#123;V2_ROOT&#125;/target/ROOT/res/lottery/" "-e ssh -p $&#123;SCP_PORT&#125;" $&#123;V2_ROOT&#125;/target/ROOT/res/ yourusername@$&#123;REMOTE_IP&#125;:/home/yourusername/tomcat/apache-tomcat-7.0.27/webapps/ROOT/res/ rsync -azh --delete "-e ssh -p $&#123;SCP_PORT&#125;" $&#123;V2_ROOT&#125;/target/ROOT/index.html yourusername@$&#123;REMOTE_IP&#125;:/home/yourusername/tomcat/apache-tomcat-7.0.27/webapps/ROOT/index.html rsync -azh --delete "-e ssh -p $&#123;SCP_PORT&#125;" $&#123;V2_ROOT&#125;/target/ROOT/WEB-INF/velocity/ yourusername@$&#123;REMOTE_IP&#125;:/home/yourusername/tomcat/apache-tomcat-7.0.27/webapps/ROOT/WEB-INF/velocity/ echo "同步静态资源文件成功"&#125;# 同步与后端java程序相关文件function deployJavaClassFile()&#123; deleteUnusedJar rsync -azh --delete "-e ssh -p $&#123;SCP_PORT&#125;" $&#123;V2_ROOT&#125;/target/ROOT/WEB-INF/ yourusername@$&#123;REMOTE_IP&#125;:/home/yourusername/tomcat/apache-tomcat-7.0.27/webapps/ROOT/WEB-INF/ echo "同步后端资源WEB-INF目录文件成功"&#125;# 删除无用的jar包function deleteUnusedJar()&#123; rm $&#123;V2_ROOT&#125;/target/ROOT/WEB-INF/lib/javax.servlet-api-3.0.1.jar echo "删除无用的jar包成功"&#125;#旧的前端处理应该是要废弃了 ~~function oldBundleRes()&#123; MAIN_JS=`cat res/dist/rev-manifest.json | jq '.["main.js"]' | head -c -2 | tail -c +2` echo "前端打包后的main js为 " $&#123;MAIN_JS&#125; sed '1,9d' res/dist/$&#123;MAIN_JS&#125; &gt; res/dist/$&#123;MAIN_JS&#125;.tmp.js &amp;&amp; mv res/dist/$&#123;MAIN_JS&#125;.tmp.js res/dist/$&#123;MAIN_JS&#125; echo -e $&#123;PRODUCT_APPJS&#125; | cat - res/dist/$&#123;MAIN_JS&#125; &gt; res/dist/$&#123;MAIN_JS&#125;.js.temp &amp;&amp; mv res/dist/$&#123;MAIN_JS&#125;.js.temp res/dist/$&#123;MAIN_JS&#125; sed '1,9d' res/js/newform/config.js &gt; res/js/newform/config.tmp.js &amp;&amp; mv res/js/newform/config.tmp.js res/js/newform/config.js echo -e $&#123;PRODUCT_APPJS&#125; | cat - res/js/newform/config.js &gt; res/js/newform/config.js.temp &amp;&amp; mv res/js/newform/config.js.temp res/js/newform/config.js&#125;deployV2UseRsync $1 $2 restartV2.sh 文件内容123456789#!/bin/bash## kill ps aux | grep tomcat名 | grep "/home" | awk '&#123; print $2&#125;' | xargs kill -9## start /home/yourusername/tomcat/apache-tomcat-7.0.27/bin/startup.sh &amp;&amp; tail -f -n 200 /home/yourusername/tomcat/apache-tomcat-7.0.27/logs/catalina.out]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>server</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux同步文件工具rsync]]></title>
    <url>%2F2015%2F08%2F31%2FLinux%E5%90%8C%E6%AD%A5%E6%96%87%E4%BB%B6%E5%B7%A5%E5%85%B7rsync%2F</url>
    <content type="text"><![CDATA[rsync rsync是类unix系统下的数据镜像备份工具——remote sync。一款快速增量备份工具 Remote Sync，远程同步 支持本地复制，或者与其他SSH、rsync主机同步 用法rsync src dest 这是最简单的用法，表示同步src,dest文件。（即，执行之后，dest的文件与src的相同，以src的为准) 常用选项-a: 等价于-rlptgoD,归档式 -r: 递归 -l: 复制软件链接 -p: 保留权限信息 -t: 将src的修改时间，同步到dest -g: 同步组信息(group) -o: 同步拥有者信息(own) -D: 保持字符与块设备文件 -z: 启用压缩传输 -–delete：如果src没有此文件，那么dest也不能有，即在dest删除src里没有的文件。（如果你使用这个选项，就必须搭配-r选项一起） 例子同步当前目录到远程的 /tmp/test/目录:rsync -avzh --delete &#39;-e ssh -p 1850&#39; . yang@xxx.xxx.xxx.xxx:/tmp/test/ 如果远程的ssh服务端口不是默认的，就可以按以上的方式来指定端口.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat报java.lang.ClassNotFoundException: 1catalina.org.apache.juli.FileHandler]]></title>
    <url>%2F2015%2F08%2F28%2FTomcat%E6%8A%A5java-lang-ClassNotFoundException-1catalina-org-apache-juli-FileHandler%2F</url>
    <content type="text"><![CDATA[最近在生产环境部署Tomcat的时候，在启动的时候，在控制台报“java.lang.ClassNotFoundException: 1catalina.org.apache.juli.FileHandler”这样子类似的错误。 原因这个极有可能是因为你修改了catalina.sh文件（比如，你想修改下JVM的参数等）。 这个错误，会导致在Tomcat的logs目录下的localhost.yyyy-MM-dd这类的日志文件不会进行记录的了。 解决办法正确的处理方式为： 在Tomcat的安装目录下的bin目录下，创建一个 setenv.sh的文件，然后写入你想要修改的参数，比如我的如下： 123#!/bin/shCATALINA_OPTS="-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n" 说明： -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager:这个参数就是解决上面报的问题的-Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n: 这个参数是使用远程调试的 还有一点要特别注意的是：它是使用CATALINA_OPTS参数，而不是JAVA_OPTS。不知道为什么，我在JAVA_OPTS里修改，一直没有生效。*_* 这个问题困惑了我好久，今天终于认真看看Tomcat官方文档，才得以解决。 更新2016-7-5经过学习,CATALINA_OPTS参数是针对Tomcat本身的, 而JAVA_OPTS则是控制我们的应用的.所以JAVA_OPTS里修改这参数,并没有传递到CATALINA_OPTS里.]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码学习之导入源码工程到Eclipse]]></title>
    <url>%2F2015%2F08%2F25%2FTomcat%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%AF%BC%E5%85%A5%E6%BA%90%E7%A0%81%E5%B7%A5%E7%A8%8B%E5%88%B0Eclipse%2F</url>
    <content type="text"><![CDATA[测试环境为：Ubuntu 14.04 LTS + Tomcat 7.0.63 下载Tomcat源码1234cd ~/Downloadswget -c http://mirror.bit.edu.cn/apache/tomcat/tomcat-7/v7.0.63/src/apache-tomcat-7.0.63-src.tar.gztar -xvf apache-tomcat-7.0.63-src.tar.gzcd apache-tomcat-7.0.63-src 转换成Maven工程12cd ~/Downloads/apache-tomcat-7.0.63-srctouch pom.xml pom.xml 文件内容如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;Tomcat7.0&lt;/artifactId&gt; &lt;name&gt;Tomcat7.0&lt;/name&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;build&gt; &lt;finalName&gt;Tomcat7.0&lt;/finalName&gt; &lt;sourceDirectory&gt;java&lt;/sourceDirectory&gt; &lt;testSourceDirectory&gt;test&lt;/testSourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;java&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;test&lt;/directory&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ant&lt;/groupId&gt; &lt;artifactId&gt;ant&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;wsdl4j&lt;/groupId&gt; &lt;artifactId&gt;wsdl4j&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml&lt;/groupId&gt; &lt;artifactId&gt;jaxrpc&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jdt.core.compiler&lt;/groupId&gt; &lt;artifactId&gt;ecj&lt;/artifactId&gt; &lt;version&gt;4.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 注意点：当你使用不同版本的Tomcat时，修改一下dependencies里相应的依赖版本即可，版本请参考Tomcat源码目录的build.properties.default文件里相应依赖的版本作修改即可。 导入到EclipseFile -&gt; import -&gt; Maven -&gt; Existing Maven Projects 然后定位到 ~/Downloads/apache-tomcat-7.0.63-src目录即可 启动Tomcat打开org.apache.catalina.startup.Bootstrap这个启动类，然后右键选择Run As -&gt; Run Configurations -&gt; Arguments -&gt; VM arguments 输入以下参数（相应的目录，请自己作修改） 1234-Dcatalina.home=/home/yang/Downloads/apache-tomcat-7.0.63-src -Dcatalina.base=/home/yang/Downloads/apache-tomcat-7.0.63-src-Djava.endorsed.dirs=/home/yang/Downloads/apache-tomcat-7.0.63-src/endorsed -Djava.io.tmpdir=/home/yang/Downloads/apache-tomcat-7.0.63-src/temp-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager-Djava.util.logging.config.file=/home/yang/Downloads/apache-tomcat-7.0.63-src/conf/logging.properties OK一切都没有问题时，启动的结果，类似如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.ClassLoaderFactory validateFileWARNING: Problem with directory [/home/yang/Downloads/apache-tomcat-7.0.63-src/lib], exists: [false], isDirectory: [false], canRead: [false]Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.ClassLoaderFactory validateFileWARNING: Problem with directory [/home/yang/Downloads/apache-tomcat-7.0.63-src/lib], exists: [false], isDirectory: [false], canRead: [false]Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.ClassLoaderFactory validateFileWARNING: Problem with directory [/home/yang/Downloads/apache-tomcat-7.0.63-src/lib], exists: [false], isDirectory: [false], canRead: [false]Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.ClassLoaderFactory validateFileWARNING: Problem with directory [/home/yang/Downloads/apache-tomcat-7.0.63-src/lib], exists: [false], isDirectory: [false], canRead: [false]Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.Catalina initDirsSEVERE: Cannot find specified temporary folder at /home/yang/Downloads/apache-tomcat-7.0.63-src/tempAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Server version: Apache Tomcat/@VERSION@Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Server built: @VERSION_BUILT@Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Server number: @VERSION_NUMBER@Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: OS Name: LinuxAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: OS Version: 3.16.0-30-genericAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Architecture: amd64Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Java Home: /home/yang/Java/jdk1.8.0_51/jreAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: JVM Version: 1.8.0_51-b16Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: JVM Vendor: Oracle CorporationAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: CATALINA_BASE: /home/yang/Downloads/apache-tomcat-7.0.63-srcAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: CATALINA_HOME: /home/yang/Downloads/apache-tomcat-7.0.63-srcAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Command line argument: -Dcatalina.home=/home/yang/Downloads/apache-tomcat-7.0.63-srcAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Command line argument: -Dcatalina.base=/home/yang/Downloads/apache-tomcat-7.0.63-srcAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Command line argument: -Djava.endorsed.dirs=/home/yang/Downloads/apache-tomcat-7.0.63-src/endorsedAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Command line argument: -Djava.io.tmpdir=/home/yang/Downloads/apache-tomcat-7.0.63-src/tempAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManagerAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Command line argument: -Djava.util.logging.config.file=/home/yang/Downloads/apache-tomcat-7.0.63-src/conf/logging.propertiesAug 25, 2015 2:32:09 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Command line argument: -Dfile.encoding=UTF-8Aug 25, 2015 2:32:09 PM org.apache.catalina.core.AprLifecycleListener lifecycleEventINFO: The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/libAug 25, 2015 2:32:09 PM org.apache.coyote.AbstractProtocol initINFO: Initializing ProtocolHandler ["http-bio-8090"]Aug 25, 2015 2:32:09 PM org.apache.coyote.AbstractProtocol initINFO: Initializing ProtocolHandler ["ajp-bio-8019"]Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.Catalina loadINFO: Initialization processed in 355 msAug 25, 2015 2:32:09 PM org.apache.catalina.core.StandardService startInternalINFO: Starting service CatalinaAug 25, 2015 2:32:09 PM org.apache.catalina.core.StandardEngine startInternalINFO: Starting Servlet Engine: Apache Tomcat/@VERSION@Aug 25, 2015 2:32:09 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deploying web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/managerAug 25, 2015 2:32:10 PM org.apache.catalina.startup.TldConfig executeINFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.Aug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deployment of web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/manager has finished in 159 msAug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deploying web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/examplesAug 25, 2015 2:32:10 PM org.apache.catalina.startup.TldConfig executeINFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.Aug 25, 2015 2:32:10 PM org.apache.catalina.core.StandardContext startInternalSEVERE: One or more listeners failed to start. Full details will be found in the appropriate container log fileAug 25, 2015 2:32:10 PM org.apache.catalina.core.StandardContext startInternalSEVERE: Context [/examples] startup failed due to previous errorsAug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deployment of web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/examples has finished in 99 msAug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deploying web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/docsAug 25, 2015 2:32:10 PM org.apache.catalina.startup.TldConfig executeINFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.Aug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deployment of web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/docs has finished in 20 msAug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deploying web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/ROOTAug 25, 2015 2:32:10 PM org.apache.catalina.startup.TldConfig executeINFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.Aug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deployment of web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/ROOT has finished in 24 msAug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deploying web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/host-managerAug 25, 2015 2:32:10 PM org.apache.catalina.startup.TldConfig executeINFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.Aug 25, 2015 2:32:10 PM org.apache.catalina.startup.HostConfig deployDirectoryINFO: Deployment of web application directory /home/yang/Downloads/apache-tomcat-7.0.63-src/webapps/host-manager has finished in 19 msAug 25, 2015 2:32:10 PM org.apache.coyote.AbstractProtocol startINFO: Starting ProtocolHandler ["http-bio-8090"]Aug 25, 2015 2:32:10 PM org.apache.coyote.AbstractProtocol startINFO: Starting ProtocolHandler ["ajp-bio-8019"]Aug 25, 2015 2:32:10 PM org.apache.catalina.startup.Catalina startINFO: Server startup in 370 ms]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux技巧收集]]></title>
    <url>%2F2015%2F08%2F25%2FLinux%E6%8A%80%E5%B7%A7%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[获取外网IP12345PUBLIC_IP=`wget http://ipecho.net/plain -O - -q ; echo`echo $PUBLIC_IP直接显示:wget http://ipecho.net/plain -O - -q ; echo 查找历史命令1Ctrl+R 搜索从当前目录，递归搜索”10.0.0.40”这个词 1grep -rnw . -e "10.0.0.40" 毫秒转换成日期：1date -d @$( echo "(1445930011000 + 500) / 1000" | bc) 十六进制转十进制123echo $((0xa))10 十进制转十六进制1234printf "%x\n" 10a➜ ~ 运行进程与session不挂勾1nohup idea.sh &gt; /dev/null 2&gt;&amp;1 &amp; 查看某进程监听的端口123sudo ss -l -p -n | grep PIDsudo lsof -Pan -p PID -i 统计代码行数1234find . -name "*.java" | xargs -P 0 wc -l | sort -k1 -n不包括空行find . -name "*.java" | xargs -P 0 sed '/^\s*$/d' | wc -l 统计列的总和1awk '&#123; sum+=$1&#125; END &#123;print sum&#125;' 清除日志的脚本123456789#!/bin/bashset -xcd /tmp/test/FILE_N="delete.file.list"find . -type f \( -iname \*.log -o -iname \*.txt \) &gt; $&#123;FILE_N&#125;cat $&#123;FILE_N&#125; | xargs -t -n 1 -I &#123;&#125; -P 0 bash -c "split -d --bytes=100M --filter='gzip &gt; \$FILE.gz' &#123;&#125; &#123;&#125; &amp;&amp; rm -rf &#123;&#125;" 除了指定的文件名不处理! -iname access.log 123456789#!/bin/bashset -xcd /tmp/test/FILE_N="delete.file.list"find . -type f \( ! -iname access.log -iname \*.log -o -iname \*.txt \) &gt; $&#123;FILE_N&#125;cat $&#123;FILE_N&#125; | xargs -t -n 1 -I &#123;&#125; -P 0 bash -c "split -d --bytes=100M --filter='gzip &gt; \$FILE.gz' &#123;&#125; &#123;&#125; &amp;&amp; rm -rf &#123;&#125;" find 1天以前修改的文件1find -mtime +1 find 1天之内修改的文件1find -mtime -1 mv 命令在脚本里的使用1cat $&#123;MOVE_FILE_NAME&#125; | xargs -t -n 1 -I &#123;&#125; -P 0 dirname &#123;&#125; | sort -u | xargs -t -n 1 -I &#123;&#125; -P 0 bash -c "mv &#123;&#125;/*.sync.gz \"$&#123;SAVE_DIR&#125;&#123;&#125;/\"" 删除匹配的字符串之间的行12345#直接修改文件sed -i '/no task start/,/no task end/d' $&#123;ROOT&#125;/target/ROOT/WEB-INF/classes/spring.xml#不修改文件，只是将修改后的结果输出到stdout中sed '/no task start/,/no task end/d' $&#123;ROOT&#125;/target/ROOT/WEB-INF/classes/spring.xml 查看进程启动时间1ps -p 25517 -o lstart grep包含\的使用1234567有段数据，内容如下：sdfsdf2e\x22bidfloor\x22:800,sldkfjsldkfslflsdf然后想 grep 出 bidfloor\x22:800 这个内容，可以这样子:cat test.file | grep -o "bidfloor\\\\\x22:[0-9]*"注意，是5个\，即4个\加上\x22内容本身 显示每个进程的SWAP使用量1for file in /proc/*/status ; do awk '/VmSwap|Name|^Pid:/&#123;printf $1 " " $2 " " $3 " " $4 " " $5 " " $6&#125;END&#123; print ""&#125;' $file; done | sort -k 6 -n -r | less Bash 00-23 遍历123for i in &#123;00..23&#125;; do echo $&#123;i&#125;done tar 忽略某文件或目录1tar -cvjf /path/to/xxx.tar.bz2 /path/to/backup --exclude=/path/to/dir --exclude=/path/to/file 注意，忽略目录时，目录的结尾不能有/结尾. 删除子字符串12345从字符串string开头匹配pattern，并将匹配的删除$&#123;string#pattern&#125;从字符串string结尾开始匹配pattern，并将匹配的删除$&#123;string%pattern&#125; 将秒数批量显示为日期1cat dd | grep -o "^[0-9]*" | xargs -n 1 -I&#123;&#125; echo &#123;&#125; | xargs -n 1 -P 1 -t -I&#123;&#125; date -d @&#123;&#125; 文件dd的内容如下:12314657126401465638231... 在指定正则表达式的文件里搜索内容1time grep -rnw console_2016-06-14.1[0-9][0-9]*.log -e "清除" 批量重命名123456789101112╭─sky@sky-linux /tmp/testbash ╰─➤ lshello1.txt hello2.txt hello3.txt hello4.txt hello5.txt hello6.txt hello7.txt将hello改为hello-new╭─sky@sky-linux /tmp/testbash ╰─➤ rename 's/hello/hello-new/' *.txt╭─sky@sky-linux /tmp/testbash ╰─➤ lshello-new1.txt hello-new2.txt hello-new3.txt hello-new4.txt hello-new5.txt hello-new6.txt hello-new7.txt 同步文件,然后再删除源文件比如,我们想将日志文件迁移到某台服务器后,再删除源文件,以减轻磁盘占用空间. 123456789101112131415161718192021#!/usr/bin/env bashDEST_PORT=1850DEST_DIR="/tmp/logs"DEST_IP="1.2.3.4"DEST_USER="sky"SOURCE_DIR="/home/sky/share/unknown"SOURCE_SUFFIX="*"find $&#123;SOURCE_DIR&#125; -mtime +1 -name "*.$&#123;SOURCE_SUFFIX&#125;" | xargs -n 1 -I&#123;&#125; -P 2 rsync -R --remove-source-files -avzh "-e ssh -p $&#123;DEST_PORT&#125;" &#123;&#125; $&#123;DEST_USER&#125;@$&#123;DEST_IP&#125;:$&#123;DEST_DIR&#125;如果有多个后缀的话,那要写成如下的形式find . -mtime +1 -name "*.log" -o -mtime +1 -name "*.zip"再如:find /home/sky/tomcat/ -path "*logs*" -mtime +1 -name "*.log" -o -path "*logs*" -mtime +1 -name "*.txt" -o -path "*logs*" -mtime +1 -name "*.tmp" | xargs -n 1 -P2 -I&#123;&#125; tar --remove-files -cvjf &#123;&#125;.tar.bz2 &#123;&#125; &gt;&gt; /tmp/compress.log iptable 禁止外网访问某端口eth1:就是外网所在的网卡号,请用 ifconfig 来查看. 12sudo iptables -t filter -i eth1 -A INPUT -p tcp --dport 6606 -j REJECTsudo iptables -t filter -i eth1 -A INPUT -p udp --dport 6606 -j REJECT 开机自动使iptables生效1sudo apt-get install iptables-persistent 如果修改了iptables的话, 要做如下修改: 12sudo su -c 'iptables-save &gt; /etc/iptables/rules.v4'sudo su -c 'ip6tables-save &gt; /etc/iptables/rules.v6' 归档日志, 并删除源文件1nohup bash -c " ls console_2016-06-30.*.log | xargs -n 1 -P2 -I&#123;&#125; tar --remove-files -cvjf &#123;&#125;.tar.bz2 &#123;&#125; " &gt; ~/compress-log.log &amp; rsync同步文件后并删除源文件12345678nohup bash -c " find /home/yourname/tomcat/logs/ -name \"*_[0-9][0-9][0-9][0-9]-*.log\" | xargs -n 1 -P2 -I&#123;&#125; tar --remove-files -cvjf &#123;&#125;.tar.bz2 &#123;&#125; " &gt;&gt; /tmp/compress.log &amp;nohup bash -c " find /home/yourname/tomcat/logs/ -name \"*.bz2\" | xargs -n 1 -P2 -I&#123;&#125; rsync -e \"ssh -p 你的ssh端口\" -avzh -R --remove-source-files &#123;&#125; yourname@yourIP:/remote/server/path " &gt;&gt; /tmp/rsync.log &amp;-R参数:表示相对在 /remote/server/path 目录下,再创建与源目录的相对路径.比如, 上同这样子,就会在远程服务器上创建如下类似的结构:/remote/server/path/home/yourname/tomcat/logs 在文件的开头添加内容12345678910╭─sky@sky-linux /tmp ╰─➤ echo "hsdlf" &gt; hello.txt╭─sky@sky-linux /tmp ╰─➤ sed -i "1iWorld" hello.txt ╭─sky@sky-linux /tmp ╰─➤ cat hello.txt Worldhsdlf╭─sky@sky-linux /tmp ╰─➤ 替换字符串123将所有'0000-00-00 00:00:00替换为 1998-07-01 00:00:00'sed -i "s/0000-00-00 00:00:00/1998-07-01 00:00:00/g" wb_status.data 查找文件的创建时间12345678# 查找文件的inode号码ls -i file# 根据inode来查看文件的crtime╭─sky@sky-linux /ihome/db/postgresql/current/data/base/16384 ╰─➤ sudo debugfs -R 'stat &lt;3022225&gt;' /dev/sda1 [sudo] password for sky: debugfs 1.42.9 (4-Feb-2014) 同步Tomcat12 按自然排序1cat /tmp/xxx.log| sort -k4n 搜索文件然后对它进行处理1find . -name "*.js" -o -name "*.html" -o -name "*.map" -print0 -type f | xargs -0 sed -i 's/hello/world/g' 并，差，交集并集1sort a.txt b.txt | uniq 交集1sort a.txt b.txt | uniq -d -d表示显示有重复的 差集1sort a.txt b.txt b.txt | uniq -u -u表示只显示没有重复的. 查看gcc搜索头文件的路径 xxx.h1gcc -v -E - 解压zip到指定文件名1unzip -p xxx.zip &gt; hello.file Enter passphrase for key1234$ eval `ssh-agent -s`$ ssh-add ~/.ssh/id_rsa_key$ ssh-add -l$ ssh your-server 也可以将这些放到bashrc文件中. 将当前目录下的所有 git 仓库 pull 当前分支的最新代码1ls | xargs -I&#123;&#125; -n 1 bash -c "cd &#123;&#125;;git pull origin \"$(git branch | grep -E '^\* ' | sed 's/^\* //g')\";git fetch --all" 列出所有正在监听的端口12sudo lsof -iTCP -sTCP:LISTEN grep 某进程，然后kill掉12ps -ef | grep PROCESS | grep -v grep | awk '&#123;print $2&#125;' | xargs kill -9 检查磁盘是否是SSD12345678910cat /sys/block/sda/queue/rotational0：是SSD，1是HDD或sudo smartctl -a /dev/sdb如果看到Rotation Rate: Solid State Device就表明是SSD 查看网速1sar -n DEV 1 100 1：间隔1秒100：共100次 logrotate 使用logrotate logrotate linux.die.net 一个小例子: 123456789101112/home/emacsist/nginx/nginx-1.9.3/logs/*.log &#123; daily compress nodelaycompress rotate 100 missingok nocreate sharedscripts postrotate test ! -f /home/emacsist/nginx/nginx-1.9.3/logs/nginx.pid || kill -USR1 `cat /home/emacsist/nginx/nginx-1.9.3/logs/nginx.pid` endscript&#125;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL源码编译及使用单机多实例管理]]></title>
    <url>%2F2015%2F08%2F24%2FMySQL%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%AE%9E%E4%BE%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[本文的测试环境为 Ubuntu 14.04.2 LTS 64 bit + MySQL 5.6 下载源码并安装及初始化数据库123456789101112131415161718192021222324252627282930313233343536cd ~/Downloadswget -c http://cdn.mysql.com/Downloads/MySQL-5.6/mysql-5.6.26.tar.gztar -xvf mysql-5.6.26.tar.gzcd mysql-5.6.26sudo groupadd mysqlsudo useradd -r -g mysql mysqlsudo apt-get install cmakecmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql-5.6 -DMYSQL_USER=mysqlsudo mkdir /usr/local/mysql-5.6sudo make installsudo chown mysql:mysql -R /usr/local/mysql-5.6sudo mkdir /usr/local/mysql-data/3306 -psudo mkdir /usr/local/mysql-data/3307 -psudo chown mysql:mysql /usr/local/mysql-data/3306 -Rsudo chown mysql:mysql /usr/local/mysql-data/3307 -Rsudo susu mysqlcd /usr/local/mysql-5.6scripts/mysql_install_db --datadir=/usr/local/mysql-data/3306 --basedir=/usr/local/mysql-5.6 --user=mysqlscripts/mysql_install_db --datadir=/usr/local/mysql-data/3307 --basedir=/usr/local/mysql-5.6 --user=mysql 配置my.conf文件位置： /usr/local/mysql-5.6/my.cnf 内容 12345678910111213141516171819202122232425262728293031323334# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html[mysqld_multi]mysqld = /usr/local/mysql-5.6/bin/mysqld_safemysqladmin = /usr/local/mysql-5.6/bin/mysqladminlog = /usr/local/mysql-5.6/log.erruser = rootpassword = yang# The MySQL server[mysqld1]port = 3306socket = /usr/local/mysql-data/3306/3306.socketdatadir = /usr/local/mysql-data/3306pid-file = /usr/local/mysql-data/3306/3306.pidlog-error = /usr/local/mysql-data/3306/3306.errslow_query_log = 1long_query_time = 0.3slow_query_log_file = /usr/local/mysql-data/3306/query-slow.loggeneral_log = /usr/local/mysql-data/3306/general-log.logsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES[mysqld2]port = 3307socket = /usr/local/mysql-data/3307/3307.socketdatadir = /usr/local/mysql-data/3307pid-file = /usr/local/mysql-data/3307/3307.pidlog-error = /usr/local/mysql-data/3307/3307.errslow_query_log = 1long_query_time = 0.3slow_query_log_file = /usr/local/mysql-data/3307/query-slow.loggeneral_log = /usr/local/mysql-data/3307/general-log.logsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 启动各个实例export PATH=/usr/local/mysql-5.6/bin:$PATH 查看各个实例状态mysqld_multi --defaults-file=/usr/local/mysql-5.6/my.cnf report 启动某个实例mysqld_multi --defaults-file=/usr/local/mysql-5.6/my.cnf start 1 这表示启动my.conf文件里[mysqld1]配置的实例 一次性启动多个实例mysqld_multi --defaults-file=/usr/local/mysql-5.6/my.cnf start 1-2 这表示启动my.conf文件里的[mysqld1]和[mysqld2] 停止某个实例mysqld_multi --defaults-file=/usr/local/mysql-5.6/my.cnf stop 1 一次性停止多个实例mysqld_multi --defaults-file=/usr/local/mysql-5.6/my.cnf stop 1-2 修改默认密码12/usr/local/mysql-5.6/bin/mysqladmin -S /usr/local/mysql-data/3306/3306.socket -u root password 'yang'/usr/local/mysql-5.6/bin/mysqladmin -S /usr/local/mysql-data/3307/3307.socket -u root password 'yang']]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Explain 详解]]></title>
    <url>%2F2015%2F08%2F20%2FMySQL-Explain-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[用法explain select xxx id 列从ID列可以判断SQL的执行顺序：从大到小，如果ID相同，就从上到下执行。如果行引用联合结果的其他行，那么它的值可能为NULL，这种情况下，table列的值会显示为&lt;unionM,N&gt;来指明行引用的是联合行中的带有指定M,N值的ID。 select_type 列SIMPLE简单的SELECT语句（没有使用 union 或者 子查询） PRIMARY最外层的SELECT语句 UNION在一个UNION语句中第二或之后的SELECT语句 DEPENENT_UNION在一个UNION语句中第二或之后的SELECT语句，取决于外层的查询 UNION_RESULTUNION的结果集 SUBQUERY子查询中的第一个SELECT DEPENENT_SUBQUERY子查询中的第一个SELECT,取决于外层的查询 DERIVEDSELECT的驱动表（FROM子查询） MATERIALIZED物化子查询 UNCACHEABLE SUBQUERY不能将结果缓存的子查询，必须重新计算外部查询的每一行 UNCACHEABLE UNION在一个UNION中第二或之后的SELECT查询属于UNCACHEABLE SUBQUERY（请看UNCACHEABLE SUBQUERY) 特别说明DEPENDENT：典型代表就是使用了相关子查询。（相关子查询：子查询里包含了一个同时在子查询里，又在外部查询的表的查询） DEPENDENT SUBQUERY: 它不同于UNCACHEABLE SUBQUERY的求值。对于DEPENDENT SUBQUERY，子查询对于外部上下文里每一个集合中不同的变星值仅仅重新计算一次。 而对于UNCACHEABLE SUBQUERY，子查询对于外部上下文里的每一行都会重新计算一次. table 列SQL中使用到的表.它的值也可为下面的其中之一： &lt;unionM,N&gt;: 行引用了带有值为M,N的查询ID的联合行 &lt;derivedN&gt;: 行引用了值为N的ID的驱动表结果。例如，它是从FROM子查询中的结果形成的驱动表的结果集 &lt;subqueryN&gt;: 行引用了一个值为N的ID的materialized subquery（物化子查询）的结果。 partitions 列查询中所匹配的记录所在的分区。这列只有在使用了PARTITIONS关键字时才会显示。对于没有使用分区表的，该值为NULL type 列连接类型 system表只有一行（=system table）.这个const连接类型的一个特例。 const该表最多只有一条匹配的行，这是读取查询的开始。因为这里只有一行，该行这列的值可以被优化器的剩余部分认为是常量。const表是非常快的，因为它们只会读取一次。 const用于当你与主键或唯一索引的所有部分比较的是常量值时。在以下的查询中，tal_name 可以被用作const表： 123select * from tbl_name where primary_key = 1;select * from tbl_name where primary_key_part1 = 1 and primary_key_part2 = 2 eq_ref从该表中读取一行与前一张表的所有行的每一种组合。除了system和const类型，这可能是最好的连接类型了。它通常于用在连接时使用了索引的所有部分，并且索引是一个主键索引或者唯一非空索引. eq_ref可用于索引列使用=比较操作符的情况。比较的值可能是一个常量或者是 从读这表之前的表中使用的一个列表达式。比如下面的例子，MySQL能够使用eq_ref连接去处理ref_table表： 123select * from ref_table, other_table where ref_table.key_column = other_table.column;select * from ref_table, other_table where ref_table.key_column_part1 = other_table.column and ref_table.key_column_part2 = 1 ref所有索引匹配的行的值与前一张表的所有行的每一种组合。ref用于连接仅使用最左前缀索引或者索引不是主键索引，唯一索引（换句话说，连接不能基于该索引值选择一行 ）。如果索引用于匹配少数行，这是一个好的连接类型。 ref能够用于使用=或者&lt;=&gt;操作符的索引列中。比如下面的例子，MySQL能够使用ref连接去处理ref_table表： 12345select * from ref_table where key_column = expr;select * from ref_table , other_table where ref_table.key_column = other_table.column;select * from ref_table, other_table where ref_table.key_column_part1 = other_table.column and ref_table.key_column_part2 = 1; fulltext这个连接使用fulltext索引执行 ref_or_null这个连接类型是类似ref，但有些额外的不同：MySQL要做一些额外操作去搜索包含NULL值的行。这个连接类型通常用于优化执行子查询。在以下的例子里，MySQL 可以使用ref_or_null连接去处理ref_table. 1select * from ref_table where key_column = expr or key_column is null; index_merge这个连接类型说明使用了索引合并优化。在这种情况下，在输出行的key列包含了一个使用索引的列表，并且key_len包含了使用了索引最长的那部分列表。 unique_subquery这个类型在以下格式的一些IN子查询是替代ref类型的。 value IN (select primary_key from single_table where some_expr) unique_subquery 完全只是为了更高效地替代子查询的一个索引查找函数。 index_subquery这个连接类型是类似unique_subquery。它代替IN子查询，但用于以下格式的子查询中的非唯一索引。 value in (select key_column from single_table where some_expr) range仅在给定的范围使用索引检索行。在输出的行中的key列说明使用了哪个索引。key_len列包含了使用了索引的最长部分。对于这类型下，ref列的值为NULL。 range可以用于当索引列使用以下任一个操作符与常量比较时使用：=, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN 或者 IN() 1234567select * from tbl_name where key_column = 10;select * from tbl_name where key_colum between 10 and 20;select * from tbl_name where key_column in (10, 20, 30);select * from tbl_name where key_part1 = 10 and key_part2 in (10,20,30); indexindex索引连接类型与all相同，除了它是扫描索引树外（即全索引扫描）。这在两种情况下发生： 如果索引对于查询来说是覆盖索引并且可用于满足要求表的数据要求，这时只有索引树会被扫描。在这种情况下，Extra列会显示为Using index。一个只读索引扫描通常比ALL更快，因为索引的大小通常是比表的大小更小。 全表扫描的执行是从索引读取的顺序去查找数据行。这时Extra列不会出现Uses index。 MySQL 当查询仅使用单独索引的一部分列时才会使用这个连接类型。 ALL从前表中每一个行组合进行全表扫描。如果表是第一个表并没有标识为const的话，这通常是不好的，并且在其他的情况下是非常糟糕的。通过，你可以通过添加索引来避免ALL连接类型，这使得行检索基于常量值或者从更早的表中的列值。 possible_keys 列该列指出MySQL可以从该表中使用哪个索引去查找行。注意，该列完全独立于explain输出结果显示的表的顺序的。这意味着，一些在possible_keys里的键，在实际上可能无法在产生表的顺序时使用。 如果没有相关的索引，该列就为NULL。在这种情况下，你可以通过测试WHERE子句检查它使用的列有没有适当的索引来提高查询的性能。如果的确如此的话，创建一个合适的索引并使用Explain来再次检查你的查询有没有用上了索引。 查看表有哪些索引，可以使用show index from tbl_name key 列该列指出MySQL实际决定使用的key(索引）。如果MySQL决定使用possible_keys中之一的索引去查找行，那么那个索引的值就是该key列的值 不过，有可能key列的索引名没有出现在possible_keys列中。这可能发生在，如果possible_keys索引中没有一个是适合查找行的索引，但查询所选择的列都是其他索引中包含的列的情况。这意味着，命名的索引覆盖了所选择的列，所以尽管它不用于决定哪些行要检索，但一个索引扫描比数据行扫描更高效。 对于InnoDB,二级索引可能覆盖了所选择的列，尽管查询也选择了主键，因为InnoDB保存每一个二级索引里保存了主键的值。如果key列为NULL，MySQL会发现没有索引可用于执行更高效的查询。 强制MySQL去使用或者忽略在possible_keys列的某个索引，可以在查询中使用FORCE INDEX, USE INDEX 或者 IGNORE INDEX。 对于MyISAM和NDB表，执行ANALYZE TABLE可以帮助优化器选择更好的索引。对于NDB表，这也会提高分布式下推连接的性能。对于MyISAM表，myisamchk --analyze 与 analyze table的作用相同。 key_len 列该列指出MySQL决定使用的索引(key)的长度。如果key列为NULL，那么该列也为NULL。注意，key_len的值能够让你确定MySQL实际上使用了一个组合索引中的多少部分。 ref 列该列显示了哪些列或常量是用于与在key列的命名的索引列来进行比较来从表中选择行的。 如果值为func，该值就会用于一些函数的结果集。为了查找出哪些函数，执行SHOW WARNINGS之后，使用EXPLAIN EXTENDED来查看。函数可能实际上是一个操作符，像算术操作那样。 rows 列该列指出MySQL认为它必须检验执行查询的行数。 对于InnoDB表，这个数值是个估计值，并不总是准确的。 filtered 列该列指出，表行中的百分比将会被表的条件过滤。即，rows列显示了测试的行数，而(rows * filtered / 100) 显示了将与之前的表进行连接的行数。该列将会在你使用explain extended`时显示出来。 extra 列 及常见的值该列包含了额外的关于MySQL执行查询的信息。 const row not found对于像select ... from tbl_name这样的查询，该表是空的。 Deleting all rows对于DELETE，一些存储引擎(例如MyISAM)支持的一个处理方法简单并且快速地删除所有表行。如果引擎使用了这个优化，则Extra表的值就会显示为这个。 DistinctMySQL 正查找不同复的值，所以，它会停止搜索当前行之后已经第一次匹配的行。 FirstMatch(tbl_name)它是用于表tbl_name的 semi-join FirstMatch策略的缩写 Full scan on NULL key这出现在当优化器不能使用索引来优化子查询时的一个备用策略。 Impossible HAVINGHAVING子句总是为false并且不能检索到任何行。 Impossible WHEREWHERE子句总是为false并且不能检索到任何行。 Impossible WHERE noticed after reading const tablesMySQL 已经读取了所有const(和system)表，并且注意到WHERE子句总是为false. LooseScan(m…n)semi-join LooseScan策略被使用。m和n是索引部分的数字。 Materialize, Scan在MySQL 5.6.7 之前，这表明使用了一个独立的物化临时表。如果Scan出现，表示临时表索引没有用于读取表。否则，表示使用了索引来查找。同样也看Start materialize 在 MySQL 5.6.7 中，物化说明行的select_type列值为MATERIALIZED，并且行的table表是一个值为&lt;subqueryN&gt; No matching min/max row对于类似select min(...) from ... where condition这样的查询没有满足条件的行。 no matching row in const table对于一个连接查询，有一个空表或者一个没有满足唯一索引条件的行的表。 No matching rows after partition pruning对于DELETE或者UPDATE，优化器发现进行分区调整时发现没有数据可以删除或者更新。这类似于select语句的Impossible WHERE No tables used查询没有from子句，或者有一个from dual子句。 对于INSERT或者REPLACE语句，当没有select部分时explain就会显示这个值。例如， 它会出现在explain insert into t values(10)，因为它等效于explain insert into t select 10 from dual. Not existsMySQL能够在进行left join查询优化，在它发现匹配LEFT JOIN 标准一行数之后不会对于之前的行组合中在该表上检查更多的行。这有一个使用该优化的查询例子： select * from t1 left join t2 on t1.id = t2.id where t2.id is null 假设t2.id是定义为NOT NULL的。在这种情况下，MySQL扫描t1并使用t1.id的值查找t2的行。如果MySQL发现在t2中有匹配的行，它知道t2.id能够永不为NULL，并且不会扫描t2中具有相同id值的剩余的行。换句话说，对于每一个t1的行，MySQL只需要在t2中进行一次查找，而不管在t2中实际有多少匹配的行。 Using filesortMySQL 必须做一些额外的工作去决定如何检索的行进行排序。排序是通过根据连接类型所筛选的所有行然后保存要排序的键和这些所有经过WHERE子句筛选的所有行的指针来完成的。 这些排序键将被保存然后按排序的顺序来检索行数据。 Using index从表中检索的列信息只需从索引信息中获取，而不用经过额外的访问实际的表数据来寻找。这个策略]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>explain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记二]]></title>
    <url>%2F2015%2F08%2F14%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BC%98%E5%8C%96-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[索引片及匹配列访问路径(即执行计划)的成本很大程序上取决于索引片的厚度, 即谓词表达式确定的值域范围.索引片越厚,需要顺序扫描的索引页就越多,需要处理的索引页记录也越多, 而最大开销还是来自于增加对表的同步读操作.相反, 如果索引片比较窄, 就会显著减少索引访问的那部分开销,但主要的成本节省还是在更少的对表的同步读上. 另一种广泛的描述索引片的方法是:定义索引匹配列的数量. 索引过滤及过滤列有时候,列可能既存在于 WHERE 子句中,也存在于索引中,但这个列却不能参与索引片的定义. 不过, 这些列仍然能减少对表进行同步读的次数, 也以这些列仍然扮演着很重要的角色, 我们称这些列为过滤列. 假如有复合索引: A,B,C,D 从头到尾依次检索索引列: 在WHERE子句,该列是否至少拥有一个足够简单的谓词与之对应?如果有,那么这个列就是匹配列.如果没有,那么这个列及其后的索引列,都是非匹配列. 如果该谓词是一个范围谓词,那么剩余的索引列都是非匹配列. 对于最的一个匹配列之后的索引列,如果拥有一个足够简单的谓词与其对应,那么该列为过滤列. 如: where A = :A and B &gt; :B and C = :CA,B是匹配列,而C是索引过滤列. 访问路径术语也即是执行计划. 表查找: SQL Server用来描述使用索引并且需要读取表行的访问路径. 消除表访问的最显而易见的方式,就是将缺失的列添加到索引上.许多SQL Server的书将这种能避免某个SELECT调用的表访问的索引称为覆盖索引.使用覆盖索引的SELECT语句,有时被称为覆盖SELECT. 帮助优化器(统计信息)优化器进行成本估算是基于统计的信息的.如果信息不完整,优化器可能会执行错误的决定. 在应用程序开发的过程中,基于成本的优化器进行访问路径选择的处理成本不容忽视. 每次执行时进行路径访问选择,这方式可能会为优化器提供一个更好的访问路径的机会. 过滤因子它描述了谓词的选择性, 即表中满足表的谓词条件的记录行所占的比例. 在评估一个索引是否合适时,最差情况下的过滤因子比平均过滤因子更重要. 组合谓词过滤因子如果谓词A与谓词B没有相关性,那么它们的组合谓词的过滤因子(WHERE A AND B)为 1/A列中不同值的个数 * 1/B列中不同值的个数. 在设计索引结构的时候, 需要将组合谓词看作一个整体来评估过滤因子, 而不能仅仅基于零相关性进行评估.]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记一]]></title>
    <url>%2F2015%2F08%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BC%98%E5%8C%96-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[误区和误解误区1: 索引层级不要超过5层这个通常基于的假设就是:只有根页是留在内存中的.对于现代的硬件来说,对索引的层数做强制限制是没有什么意义的. 现今,我们完全可以假设B树索引的所有非叶子页通常都会留在内存或读缓存中. 误区2: 单表的索引数不要超过6个保证所有的SQL语句都能够流畅运行是设计的底线.我们总能找到一种方法来达到这一点.如果为了达到这一点需要在表上创建10个索引,那么你就应该在表上建10个索引. 误区3: 不应该索引不稳定的列这人与误区1相似,也是基于:只有根页是留在内存中的.对于现代的硬件来说,更新一个不稳定的列,只会对该更新操作增加10ms的响应时间. 只有在更新频率多于10次/秒的情况下,不稳定列才可能成为问题,但是这样的列并不常见. 系统化的索引设计步骤1找到由于索引不合适而导致运行太慢的查询语句(最差输入,导致执行时间最长的变量值) 步骤2设计索引,使所有查询语句都运行得足够快(表的维护,插入,更新,删除等也必须足够快) 表和索引结构索引页和表页表和索引行,都被存储在页中.页的大小,一般为4KB,这是一个可以满足大多数需求的大小,不过,也可以使用其他大小. 页的大小,仅决定了一个页可以存储多少个索引行,表行,以及一共需要多少个页来存储表或者索引. 当表和索引被加载或者重组时,每个页都会预留出一定比例的空闲空间,以满足向其添加新的表行或索引行的需求. 缓冲池和I/O都是基于页的.这意味着,一次I/O会读入多条记录到缓冲池,而不仅是一条.我们还可以看到,一次I/O可以读入多个页到缓冲池. 索引行一个索引行,等同于叶子页中的一个索引条目.字段的值从表中复制到索引上,并加上一个指向表中记录的指针.通常,表页的编号是这个指针的组成部分,我们需要牢记这一点. 索引结构非叶子页通常包含着一个(可能被截断的)键值,以及一个指向下一层级页的指针,该键值是下一层级页中的最大值.多个索引层级按照这一方式逐层建立,直到只剩下一个页,我们把这个页叫作根页. 它位于索引结构的最上层,这种组织方式的索引被称为B树索引.因为通过这种索引来查找任何一条索引记录都需要访问相同数量的非叶子页. 表行每一个索引行都指向表中相对应的一行记录,指针通常标识了记录所存放的页及它在页中的位置.表中的每一行,除了存储行的字段之外,还包含了一些控制信息用于定义行并帮助DBMS处理插入或删除操作. 当加载表或者向表中插入记录的时候,表中记录的顺序可以被定义成和它的某一个索引记录相同的顺序.在这种情况下,当索引行被按顺序处理时,对应的表行也将依照相同的顺序被逐个处理.索引和表都按相同的顺序被访问,这是一个效率很高的处理过程. 显然,表中记录的顺序只能按表上某一个索引的顺序来组织,如果通过表上其他的索引来访问这张表,那么表中相应的记录将不会按照与索引条目相同的顺序存储.如此一来,虽然索引的处理仍然是顺序且高效的,但表的处理却是随机且低效的. 缓冲池和磁盘I/O关系型数据库管理系统最重要的一个目标是确保表或者索引中的数据是随时可用的.为了尽可能实现这个目标,我们使用内存中的缓冲池来最小化磁盘活动.索引或者表页在不在缓冲池中,访问的成本是不同的. 从磁盘驱动器进行的随机 I/O我们必须记住,一个页包含了多条记录,我们可能需要该页上所有的行,或者其中的一部分行,又或者是其中的一行,但所花的成本都是相同的,约10ms. 从磁盘服务器缓存进行的读取如果DBMS所需要的页,不在数据库缓冲区中,会继续向磁盘服务器发起请求,磁盘服务器会判断该页是否在服务器缓冲区中,只有当它发现不在缓冲区中时才从磁盘驱动器上读取该页,如果该页在磁盘服务器的读缓冲区中,那么所花费的时间将从10ms降低到1ms.即 数据库缓冲池 ==&gt; 磁盘服务器的读缓冲区 ==&gt; 磁盘I/O. 从磁盘驱动器进行顺序读取 全表扫描 全索引扫描 索引片扫描 通过聚簇索引扫描表行 顺序地读取页的优势 : (1) 同时读取多个页意味着平均读取每个页的时间将减少.在当前的磁盘服务器条件下,对于4KB大小的页而言,这一值可能会低至0.1ms(40MS/s) (2) 由于DBMS事先知道需要读取哪些页,所以,可以在页被真正请求之前就提前将其读取进来,我们称为预读. 自动跳跃式顺序读从定义上看,如果一系列不连续的行被按照同一个方向扫描,那么访问模式将会是跳跃顺序的.于是,每行的平均I/O时间自然比随机访问时间短,跳跃的距离越短则节省的距离越多. 当表行是通过一个聚簇索引读取时,访问模式即为跳跃式顺序的. 跳跃式顺序读的好处能在两种情况下被放大: 磁盘服务器可能注意到对某一驱动器的访问是顺序的(或者几乎是顺序的),于是服务器开始向前提前读取多个页. DBMS可能注意到SELECT语句正以顺序的或几乎顺序的方式访问索引或表页,于是DBMS便开始向前提前读取多个页. 列表预计DB2 for z/OS 能够在表和索引行顺序不一致的情况下主动创造跳跃式顺序访问.为了做到这一点,它需要访问所有满足条件的索引行,然后按表页的顺序对其进行排序后再访问表行. 数据块预读当表行和索引行的访问顺序不一致时,Oracle会使用数据块预读这一特性. DBMS特性页表页的大小限定了表行的最大长度.通常,一个表行必须能够存入一个表页中, 一个索引行也必须能够存入一个叶子页中. 如果一张表的平均行长大于表页大小的三分之一,那么空间利用率将很糟. Oracle使用术语:块(BLOCK_SIZE)来代表术语页. 表聚簇通常情况下,一个表页中只包含一张表中的数据.但Oracle提供了一个选项以支持在一个表页中存储多个相关表的数据.(如一个张表的主键,其他表引用这个主键为外键).当把所有与这个表相关的数据交错存储在一张表中,这些数据可能都能够保存在同一页中.(注意:这与聚簇索引是完全不同的东西) 索引行通常,索引键由所有被复制到索引上的列组成,它决定了索引条目的顺序.在唯一索引中,索引条目等同于索引行.在非唯一索引中,对于每一个唯一的索引键值,都存在一个索引条目,以及指向每一个满足该索引键的表行的指针.在这种方式下, DBMS先从索引片上收集指针,然后再进行多重随机I/O来并行地读取表行. 表行使用聚簇索引的目的是为了使得表行的存储顺序尽可能地与索引行的顺序保持一致.如果表上没有聚簇索引,那么新插入的表行将会被放置在表的最后一个页上,或者被放置在任何一个有足够空闲空间的表页上. 无论何种DBMS,都可以通过频繁地重组表来使得表行按照所需要的顺序存储–通过重载前经由某个特定的索引读取表行来实现,或者通过在重载前对数据进行排序来实现. 索引组织表如果一个表的行不是特别长,那么可以考虑将表上所有的列复制到索引上,以加快SELECT的执行速度.如此一来,表就变得冗余了. 包含表行的索引被称为主键索引. 其余的索引(Oracle称为次级索引,SQL Server中称为非聚集索引)都指向包含表行的那个索引. 好处: 索引组织表的最明显的好处就是节省磁盘空间. 另外,INSERT, UPDATE 和 DELETE 操作的速度也更快,因为减少了一个需要更新的页. 然而, 这给其余的索引带来了不利.任何对于主键索引键的更新操作,由于需要移动索引行,都会导致DBMS去更新那些指向这一索引行的其他索引行.(即导致大量磁盘I/O)所以,为了降低指针维护成本, 通常会选择一个键值不会被更新的索引作为聚集索引. 磁盘前读当DBMS请求一个页时,磁盘系统可能也会将接下来的一组页加载至磁盘缓冲区中(它预测这些页也可能很快被请求到).这种机制称为磁盘前读. 页邻接物理相邻的三个级别: 读取一个页, 得到许多行.(这是自动的,如果4KB大小的页包含10行,那么I/O时间=1ms每行) 读取一个磁轨, 得到许多页.(这是DBMS或磁盘系统支持的,可能将顺序I/O时间降到0.1ms每行) 磁盘服务器提前从驱动器上将数据读取至读缓冲区中(这是磁盘服务器支持的,可能将顺序I/O时间降到0.01ms每行) B树索引的替代品位图索引位图索引由针对各个不同列值的位图(位向量)组成.在每一个位图中,表中的每一行对应一个位.若该行满足位图条件,则该位被置为1. 对于复杂且不可预测的组合谓词的大表查询,适合用位图索引.因为用位图索引进行与,和,或计算的速度非常快.即便表行数量达亿级也是如此.而若使用B树索引进行同样的操作则需要收集大量指针并进行排序. 另一方面,一个包含合适列的B树索引能够避免表访问.这一点很重要,因为对一张大表进行随机I/O是非常慢的.而若使用位图索引,那么必须访问表行,除非SELECT列只包含COUNT.因此,使用位图索引可能比使用一个合适的(宽)B树索引的总执行时间长得多. 位图索引应当在满足以下条件的情况下使用: 可能的谓词组合数量太多了.以至于设计足够的B树索引是不可行的. 单个谓词具有很高的过滤因子, 但组合起来后具有很低的过滤因子, 或者select列表中只包含COUNT 更新操作是批量进行的.(不存在锁争用) 散列散列,或者说是随机化, 是在已知主键值的情况下,读取一个表行的最快方式. 聚簇的许多含义聚簇索引: 定义了新插入的表行所在表页的索引.如果索引行的顺序和表行的顺序之间具有强关联性,那么就可以说该索引是聚集的.一张表上只能有一个聚簇索引. 索引的聚簇比例,是指索引行和表行顺序之间关联度的一个量度.优化器会使用这一测量值来估算I/O时间. SQL Server中存储表行的索引被称为是聚集的.只有当需要一张索引组织表时才定义一个聚集索引.其余的索引都指向这一聚集索引. Oracle中,聚簇一词被用于代表将多个表的行交错存储(聚簇的表).这个词与限定表行顺序的聚簇索引毫不相干.]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse遇到Unable to load the mojo错误]]></title>
    <url>%2F2015%2F08%2F06%2FEclipse%E9%81%87%E5%88%B0Unable-to-load-the-mojo%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[Eclipse在进行 Maven更新时出现错误Unable to load the mojo 在 stackoverflow 上有人回答，也帮我解决了问题。 12When I had this problem, it seemed to be a problem with my Maven install.Uninstalling the M2Eclipse plugin and deleting the .m2 folder on my drive, then reinstalling M2Eclipse seemed to fix it. 还有种解决方法 1I just deleted the org\apache\maven folder and the problem got solved Stackoverflow]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>eclipse</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 开发环境配置]]></title>
    <url>%2F2015%2F08%2F04%2Fubuntu-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装必要的编译环境sudo apt-get update &amp;&amp; sudo apt-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev build-essential 安装从这里打开终端sudo apt-get install nautilus-open-terminal 安装Chromewget -c https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb 源码安装Emacs1234567891011sudo apt-get build-dep emacs24wget -c http://mirror.rise.ph/gnu/emacs/emacs-24.5.tar.gztar -xvf emacs-24.5.tar.gzmkdir /usr/local/emacs-24.5/sudo chown -R yang:yang /usr/local/emacs-24.5./configure --prefix=/usr/local/emacs-24.5/make -j 8make installsudo chown -R yang:yang /usr/local/emacs-24.5sudo ln -s /usr/local/emacs-24.5/ /usr/local/emacssudo chown -R yang:yang /usr/local/emacs 添加到环境变量 1234567export PATH=/usr/local/emacs/bin:$PATH# for emacsalias e='emacsclient -t'alias ec='nohup emacsclient -c &lt;/dev/null &amp;&gt;/dev/null &amp;'alias vim='emacsclient -t'alias vi='emacsclient -t' 开机自动启动守护进程 1234567ec /etc/init.d/rc.local在最后添加emacs --deamon即可 配置系统的locale123456789101112131415LANG=en_US.UTF-8LANGUAGE=en_US.UTF-8LC_CTYPE=zh_CN.UTF-8LC_NUMERIC=zh_CN.UTF-8LC_TIME=zh_CN.UTF-8LC_COLLATE=zh_CN.UTF-8LC_MONETARY=zh_CN.UTF-8LC_MESSAGES=zh_CN.UTF-8LC_PAPER=zh_CN.UTF-8LC_NAME=zh_CN.UTF-8LC_ADDRESS=zh_CN.UTF-8LC_TELEPHONE=zh_CN.UTF-8LC_MEASUREMENT=zh_CN.UTF-8LC_IDENTIFICATION=zh_CN.UTF-8LC_ALL= 源码安装git12345678910111213141516171819202122232425sudo apt-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-devsudo apt-get install asciidoc xmlto docbook2xwget -c https://codeload.github.com/git/git/zip/v2.5.0unzip v2.5.0cd git-2.5.0make configuremkdir /usr/local/git-2.5sudo chown yang:yang /usr/local/git-2.5./configure --prefix=/usr/local/git-2.5make all doc infosudo make install install-doc install-html install-infosudo chown -R yang:yang /usr/local/git-2.5sudo ln -s /usr/local/git-2.5 /usr/local/gitsudo chown -R yang:yang /usr/local/git 添加到环境变量 12# for gitexport PATH=/usr/local/git/bin:$PATH 配置 1234567891011git config --global user.name "Zhiyong Yang"git config --global user.email dreamers.yzy@gmail.comecho "export LESSCHARSET=utf-8" &gt; $HOME/.profilegit config --global gui.encoding utf-8git config --global i18n.commitencoding utf-8git config --global i18n.logoutputencoding utf-8# 全局编辑器，提交时将COMMIT_EDITMSG编码转换成UTF-8可避免乱码git config --global core.editor e apt安装最新git123sudo add-apt-repository ppa:git-core/ppasudo apt-get updatesudo apt-get install git 安装Java及Eclipse及MavenJDKEclipseMaven 1234#这里也使用了软链接，将current指向某个具体版本的JDK目录即可export JAVA_HOME=/home/yang/Java/currentexport PATH=$JAVA_HOME/bin:$PATHexport PATH=/home/yang/Java/apache-maven-3.3.3/bin:$PAT 安装五笔输入法1sudo apt-get install fcitx-table-wubi 安装完成后，进入System Settings –&gt; Language Support –&gt; Keyboard input method system 中选择 fcitx 还有，在桌面的右上角，离网络图标左边的那个图标（即配置输入法），点击选择Configure Current Input Method –&gt; 点击左下角的+号，添加Wubi –&gt; 点击OK 即可。 安装zsh + oh my zsh123sudo apt-get install zshwget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | zshchsh -s `which zsh` 去掉Alt键触发快捷命令在右上角选择–&gt; System Settings &gt; Keyboard &gt; Shortcuts &gt; Launchers 找到选项Key to show the HUD，然后按下Backspace键清空即可. 去掉alt+f触发菜单打开terminal -&gt; edit -&gt; Keyboard Shortcuts and check Disable all menu access keys (such as Alt+f to open File Menu) 最后注销下系统，重新登录桌面环境即可。]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>emacs</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下SSD优化]]></title>
    <url>%2F2015%2F08%2F03%2FUbuntu%E4%B8%8BSSD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[检查4K对齐12345678910111213141516171819✗ sudo fdisk -luDisk /dev/sda: 500.1 GB, 500107862016 bytes255 heads, 63 sectors/track, 60801 cylinders, total 976773168 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x1abd1abc Device Boot Start End Blocks Id System/dev/sda1 * 2048 782335 390144 83 Linux/dev/sda2 784382 976768064 487991841+ f W95 Ext'd (LBA)/dev/sda5 159385672 432015439 136314884 7 HPFS/NTFS/exFAT/dev/sda6 432015504 704645271 136314884 7 HPFS/NTFS/exFAT/dev/sda7 704645336 976768064 136061364+ 7 HPFS/NTFS/exFAT/dev/sda8 784384 16406527 7811072 82 Linux swap / Solaris/dev/sda9 16408576 159381503 71486464 83 LinuxPartition table entries are not in disk order Units 是512字节，4K = 8 × 512 byte。所以只要看分区的Start地址能否整除8,可以的话这个分区就是4K对齐的。 一般来说，Linux下默认分区时，就自动进行4K对齐了 开启 AHCI开机进入 BIOS 设置好 AHCI 经常检查SSD固件减少写操作保留一定的剩余空间（7%），不要写满使用 EXT4 文件系统禁用noatime修改 /etc/fstab ，添加 noatime 挂载参数。大概如下： UUID=9de8a5a7-d693-4ce9-8dc6-80b18897c56d / ext4 noatime,discard,errors=remount-ro 0 1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>ssd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Java应用启动时报 could not find the document 错误的问题及解决]]></title>
    <url>%2F2015%2F07%2F30%2F%E5%85%B3%E4%BA%8EJava%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8A%A5-could-not-find-the-document-%E9%94%99%E8%AF%AF%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[这两天发现到一个很奇怪的问题，就是应用有时候在启动的时候，会报 1234567o.s.b.f.x.XmlBeanDefinitionReader.warning[2015-07-30 14:19:05] : Ignored XML validation warningorg.xml.sax.SAXParseException: schema_reference.4: Failed to read schema document 'http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd', because 1) could not find the document; 2) the document could not be read; 3) the root element of the document is not &lt;xsd:schema&gt;. at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:203) at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.warning(ErrorHandlerWrapper.java:99) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:433) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:347) at com.sun.org.apache.xerces.internal.impl.xs.traversers.XSDHandler.reportSchemaErr(XSDHandler.java:4166) at com.sun.org.apache.xerces.internal.impl.xs.traversers.XSDHandler.reportSchemaWarnin 这类错误，但有时候却不会报。当时自己在内网启动时及部署到生产环境的时候，没有报错，所以当时也就没有注意到这个问题。昨晚更新到外网时和今天，自己启动应用的时候，偶尔会报这个错，才意识到是真的有问题。 原因这是因为 XSD 文件在访问的时候，由于网络原因导致访问不了。比如上面的http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd，时好时坏。 在与同事讨论的时候，才发现最终的原因。是由于他将 http://www.springframework.org/schema/rabbit/spring-rabbit-1.1.xsd 升级为了 http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd，而且相对应的pom.xml的spring-rabbit的依赖没有同步升级，导致应用每次启动的时候，都会使用网络的方式去访问这个地址的文件来加载解析。如果有网络问题的话， 上面的错误就会发生了。而且还有一点不好的地方，就是XSD的文件与jar包的版本没有一致的问题。这样子有可能会有潜在的Bug，只是还没有遇到而已。 解决办法一般情况下，第三方的Jar包里，已经自带了XSD文件，并且已经放在了Jar文件里的，所以每次启动时，就可以避免每次都访问网络来加载解析XSD文件了。这次出现的问题，是由于同事升级了XSD文件的版本号，而Jar包的版本并没有同步过来，所以才会导致在Jar包找不到，而不得不去访问网络了。 所以切记， 必须要将Jar包的版本与XSD文件的版本号要一致。 当时同时说，可以下载XSD文件到本地，然后修改下XSD文件的访问URL为本地。但是极不推荐这种方式。一是不够优雅，让人困惑。二是修改起来比较麻烦。除非没有其他选择，不然都不要使用这种方式。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven为不同环境打包war]]></title>
    <url>%2F2015%2F07%2F30%2FMaven%E4%B8%BA%E4%B8%8D%E5%90%8C%E7%8E%AF%E5%A2%83%E6%89%93%E5%8C%85war%2F</url>
    <content type="text"><![CDATA[Maven为生产环境，测试环境（或者更多）的不同而使用不同的配置文件首先，为项目准备好不同的环境存放的配置文件的目录比如 存放测试环境的配置文件src/main/env/dev 存放生产环境的配置文件src/main/env/product 详细情况如下: 123456789101112131415project/`-- src |-- main | |-- java | |-- env | | |-- dev | | | |-- core.properties | | | |-- jdbc.properties | | | `-- spring.xml | | |-- product | | | |-- core.properties | | | |-- jdbc.properties | | | `-- spring.xml | `-- webroot `-- test 配置pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.test.maven.package&lt;/groupId&gt; &lt;artifactId&gt;package&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;spring.version&gt;3.2.6.RELEASE&lt;/spring.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;default&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;!-- dev env --&gt; &lt;runtime.env&gt;src/main/env/dev&lt;/runtime.env&gt; &lt;!-- 这里添加放根据开发环境需要配置的其他的 property 数据 --&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;!-- product env --&gt; &lt;runtime.env&gt;src/main/env/product&lt;/runtime.env&gt; &lt;!-- 这里添加放根据生产环境需要配置的其他的 property 数据 --&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;dependencies&gt; &lt;!-- 这里放项目依赖的jar包 --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;ROOT&lt;/finalName&gt; &lt;sourceDirectory&gt;src/main/java&lt;/sourceDirectory&gt; &lt;scriptSourceDirectory&gt;$&#123;runtime.env&#125;&lt;/scriptSourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;!-- 如果上面的directory有除了java文件以外的文件，也要在这里配置，需要copy到编译后的classes目录里 --&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;runtime.env&#125;&lt;/directory&gt; &lt;includes&gt; &lt;!-- 这里是按需copy所要的文件 --&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.json&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;!-- 这里是否开启过虑，即上面的文件是否有占位符 $&#123;变量&#125; 之类的，如果有就要设置为true，否则就是false --&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;outputDirectory&gt;webroot/WEB-INF/classes&lt;/outputDirectory&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;configuration&gt; &lt;webXml&gt;webroot/WEB-INF/web.xml&lt;/webXml&gt; &lt;warSourceDirectory&gt;webroot&lt;/warSourceDirectory&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;runtime.env&#125;&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-lib-src-webapps&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;configuration&gt; &lt;tasks&gt; &lt;!-- 这里的作用是将target下编译好的数据，复制回到webroot下的，对应的目录，因为有些人喜欢直接将tomcat的部署目录指向项目路径，而不是tomcat默认的部署目录里 --&gt; &lt;copy todir="webroot/WEB-INF/lib"&gt; &lt;fileset dir="target/ROOT/WEB-INF/lib"&gt; &lt;include name="*" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;copy todir="webroot/WEB-INF/classes"&gt; &lt;fileset dir="target/ROOT/WEB-INF/classes"&gt; &lt;include name="*" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/tasks&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 打包开发环境123#如果打包时需要调用测试代码，就去掉最后的参数，这里为了加快编译，直接去掉了测试代码。#因为默认情况下就是开发环境，所以不需要特别添加参数mvn clean package -Dmaven.test.skip=true 生产环境123#如果打包时需要调用测试代码，就去掉最后的参数，这里为了加快编译，直接去掉了测试代码。#用 `-P` 指定环境参数mvn clean package -Pproduct -Dmaven.test.skip=true]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx + Tomcat + Session 共享解决方案]]></title>
    <url>%2F2015%2F07%2F29%2FNginx-Tomcat-Session-%E5%85%B1%E4%BA%AB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[注意， 这里使用的是 Linux + Tomcat 7.x + JDK 7 + Nginx + Spring Session 的方式 安装RedisRedis.io 配置Tomcat这里为了简单，直接复制两份Tomcat，分别将目录命名为spring_session_master, spring_session_slave。然后还要修改各个Tomcat下的conf/server.xml配置文件，修改下其中的相关端口。 我这里，将master的改为了9090端口，将slave的改为了9096端口.并且一起启动它. 配置Nginx1234upstream springsession &#123; server localhost:9090; server localhost:9096;&#125; 1234567server &#123; listen 80 default_server; server_name localhost; location / &#123; proxy_pass http://springsession; &#125;&#125; 然后重启下Nginx： sudo nginx -s reload Spring Session 的使用Spring中的spring.xml配置文件 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:task="http://www.springframework.org/schema/task" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:p="http://www.springframework.org/schema/p" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd"&gt; &lt;!-- scan package --&gt; &lt;context:component-scan base-package="test.yang.test" /&gt; &lt;context:annotation-config /&gt; &lt;mvc:annotation-driven /&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath:core.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name="ignoreUnresolvablePlaceholders" value="true" /&gt; &lt;/bean&gt; &lt;import resource="session.xml" /&gt;&lt;/beans&gt; Spring中的关于session的配置文件session.xml的内容 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:task="http://www.springframework.org/schema/task" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd"&gt; &lt;context:annotation-config /&gt; &lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration" /&gt; &lt;bean class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory" p:port="$&#123;redis.port&#125;" p:hostName="$&#123;redis.host&#125;" p:database="$&#123;redis.database&#125;"/&gt;&lt;/beans&gt; SpringMVC中的spring-servlet.xml文件内容 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd"&gt; &lt;context:property-placeholder location="classpath:core.properties" ignore-unresolvable="true" order="2" /&gt; &lt;mvc:resources location="/res/" mapping="/res/**" /&gt; &lt;mvc:annotation-driven /&gt; &lt;context:component-scan base-package="test.yang.test" /&gt; &lt;bean id="velocityConfig" class="org.springframework.web.servlet.view.velocity.VelocityConfigurer"&gt; &lt;property name="resourceLoaderPath" value="/WEB-INF/velocity" /&gt; &lt;property name="velocityProperties"&gt; &lt;props&gt; &lt;prop key="input.encoding"&gt;utf-8&lt;/prop&gt; &lt;prop key="output.encoding"&gt;utf-8&lt;/prop&gt; &lt;prop key="file.resource.loader.cache"&gt;false&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.velocity.VelocityViewResolver"&gt; &lt;property name="cache" value="true" /&gt; &lt;property name="prefix" value="" /&gt; &lt;property name="suffix" value=".vm" /&gt; &lt;property name="contentType" value="text/html; charset=utf-8" /&gt; &lt;property name="exposeRequestAttributes" value="true" /&gt; &lt;property name="exposeSessionAttributes" value="true" /&gt; &lt;property name="exposeSpringMacroHelpers" value="true" /&gt; &lt;/bean&gt;&lt;/beans&gt; 应用的 web.xml 文件内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5"&gt; &lt;display-name&gt;uniweibov2&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;session-config&gt; &lt;session-timeout&gt;45&lt;/session-timeout&gt; &lt;/session-config&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/error&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/error&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;504&lt;/error-code&gt; &lt;location&gt;/error&lt;/location&gt; &lt;/error-page&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; /WEB-INF/conf/spring.xml &lt;/param-value&gt; &lt;/context-param&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/conf/spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 项目的pom.xml文件内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130 &lt;properties&gt; &lt;spring.version&gt;3.2.6.RELEASE&lt;/spring.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;version&gt;1.0.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-amqp&lt;/artifactId&gt; &lt;version&gt;1.1.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;1.1.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt; &lt;version&gt;1.9.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt;这 &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-tools&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; core.properties文件内容 1234#redis serverredis.host = 10.0.0.40redis.port = 6379redis.database = 8 Controller示例代码Hello.java 1234567891011121314151617181920212223package test.yang.test;import javax.servlet.http.HttpSession;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controller@RequestMapping("/hello")public class Hello &#123; @RequestMapping("/index") public void name(HttpSession session) &#123; session.setAttribute("hello", "world"); System.out.println(session.getId()); &#125; @RequestMapping("/get") public void get(HttpSession session) &#123; String world = (String) session.getAttribute("hello"); System.out.println(session.getId()); System.out.println("结果为:" + world); &#125;&#125; Spring Session 原理为什么按上面这样子直接配置就可以直接实现Session共享了呢？让我们一步一步来解释。 首先是session.xml文件： 123&lt;context:annotation-config /&gt; &lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration" /&gt; 这段代码，就实现了Spring Session中使用redis作为存储session的配置文件。进入源码，可以发现，它使用了RedisTemplate以及import org.springframework.session.web.http.SessionRepositoryFilter。 SpringSession实现了HttpSession的接口来处理Session相关的业务操作，它提供了两种解决方案，一种是默认的使用Map来保存Session，还有一种，是为了在集群中解决Session共享的方案的使用Redis来处理Session数据。 它们分别是接口org.springframework.session.SessionRepository（即处理Session的接口）的两个实现：org.springframework.session.MapSessionRepository 和 org.springframework.session.RedisOperationsSessionRepository。 然后，它们在SessionRepositoryFilter,被注入进来处理对应的Session实现的策略方式。注意，这个是Filter，为了在Spring中生效，所以在web.xml中添加了 12345678&lt;filter&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 它是一个代理过滤器，它会在Spring Context里，查看实现了Filter的Bean，然后调用doFilter方法来进代理。因为SessionRepositoryFilter需要一些Spring Context的处理。所以才要在web.xml里配置这段过滤器的代理过滤器。整个流程就是这样子了。再详细的， 可以根据此思想，深入每一个相关的类的源码。或者直接进行单步调试。 测试全部启动完毕后， 每将访问http://localhost/hello/index，就可以看到tomcat的控制台里，打印sessionID的内容了，因为默认情况下是轮询的方式，所以master和slave会循环显示。即第一次请求在一个tomcat的控制台显示，下一次请求就会在另一个Tomcat里显示，如此循环。 然后可以关闭一个Tomcat（模拟进程死掉，或重新部署项目时，先让一个运行着，升级另一个Tomcat的应用，完成后再切换），可以看到sessionId没有变。当再次启动这个Tomcat时， 发现负载均衡又正常工作了，而且SessionID没有变。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tomcat</tag>
        <tag>集群</tag>
        <tag>session共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 负载均衡配置]]></title>
    <url>%2F2015%2F07%2F28%2FNginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Ningx 配置负载均衡 注意，默认情况下，它使用的是轮询的方式来进行负载均衡的。 示例配置代码 123456789101112131415http &#123; upstream myapp1 &#123; server srv1.example.com; server srv2.example.com; server srv3.example.com; &#125; server &#123; listen 80; location / &#123; proxy_pass http://myapp1; &#125; &#125;&#125; 均衡策略round-robin，轮询(默认策略，Default)这也是默认情况下的策略。 即第一个请求发给 srv1, 第二个请求发给srv2，第三个请求给srv3，第四个请求又给srv1，如此循环下去。 Session persistence， 会话持久化的方式即, ip_hash 示例代码: 123456upstream myapp1 &#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; 最近连接优先处理，Least connected load balancing示例代码 123456upstream myapp1 &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; 按权重的方式，Weighted load balancing示例代码 1234567upstream myapp1 &#123; server srv1.example.com weight=3; server srv2.example.com; server srv3.example.com;&#125;默认情况下，权重为1. 负载均衡的健康检查max_fails指令，是指在fail_timeout时间内，最大的失败尝试次数。 默认情况下，max_fails 为1, 如果设置为0,则表示禁用健康检查。默认情况下，fail_timeout为10. 参考资料 nginx.org load-balancing]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>load balancer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的Comparator使用]]></title>
    <url>%2F2015%2F07%2F27%2FJava%E4%B8%AD%E7%9A%84Comparator%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Comparator 与 Comparable 比较器，一般用于排序的时候。即如果某个没有实现Comparable接口， 这时可以通过Comparator来实现类的外在排序器。它与 Comparable 不同， 它一般是用于类自身，即类的内在排序。 Comparator 比较灵活点，可以通过需求，按指定的排序要求来进行排序。而实现Comparable则是Collections.sort(list)时，默认的排序。这里可以通过一个简单的例子来说明。 比如，Person类，默认情况下，自身是可以按年龄来排序的。如: Comparable1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import java.util.ArrayList;import java.util.Collections;import java.util.List;import java.util.Random;public class T3 &#123; public static void main(String[] args) &#123; List&lt;Person&gt; persons = new ArrayList&lt;Person&gt;(); Random r = new Random(); Person p = null; for (int i = 0; i &lt; 5; i++) &#123; p = new Person(); p.setAge(r.nextInt(100)); p.setName("name" + i); persons.add(p); &#125; System.out.println("排序之前："); printInfo(persons); System.out.println("排序之后"); Collections.sort(persons); printInfo(persons); &#125; public static void printInfo(List&lt;Person&gt; list) &#123; for (Person person : list) &#123; System.out.println(" name = " + person.getName() + ", age = " + person.getAge()); &#125; &#125;&#125;class Person implements Comparable&lt;Person&gt; &#123; private int age; private String name; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public int compareTo(Person o) &#123; return this.age - o.age; &#125;&#125;结果为：排序之前： name = name0, age = 71 name = name1, age = 64 name = name2, age = 9 name = name3, age = 52 name = name4, age = 22排序之后 name = name2, age = 9 name = name4, age = 22 name = name3, age = 52 name = name1, age = 64 name = name0, age = 71 使用Comparator改为Comparator，则可以动态按需排序。只需要构造相应 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import java.util.ArrayList;import java.util.Collections;import java.util.Comparator;import java.util.List;import java.util.Random;public class T3 &#123; public static void main(String[] args) &#123; List&lt;Person&gt; persons = new ArrayList&lt;Person&gt;(); Random r = new Random(); Person p = null; for (int i = 0; i &lt; 5; i++) &#123; p = new Person(); p.setAge(r.nextInt(100)); p.setName("name" + i); persons.add(p); &#125; System.out.println("排序之前："); printInfo(persons); System.out.println("排序之后"); Collections.sort(persons, new PersonComparator()); printInfo(persons); &#125; public static void printInfo(List&lt;Person&gt; list) &#123; for (Person person : list) &#123; System.out.println(" name = " + person.getName() + ", age = " + person.getAge()); &#125; &#125;&#125;class PersonComparator implements Comparator&lt;Person&gt; &#123; @Override public int compare(Person o1, Person o2) &#123; return o1.getAge() - o2.getAge(); &#125;&#125;class Person &#123; private int age; private String name; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;结果：排序之前： name = name0, age = 80 name = name1, age = 16 name = name2, age = 12 name = name3, age = 22 name = name4, age = 22排序之后 name = name2, age = 12 name = name1, age = 16 name = name3, age = 22 name = name4, age = 22 name = name0, age = 80 升序，降序Comparator升序 1234@Overridepublic int compare(Person o1, Person o2) &#123; return o1.getAge() - o2.getAge();&#125; 降序 1234@Overridepublic int compare(Person o1, Person o2) &#123; return o2.getAge() - o1.getAge();&#125; Comparable升序 1234@Overridepublic int compareTo(Person o) &#123; return this.age - o.age;&#125; 降序 1234@Overridepublic int compareTo(Person o) &#123; return o.age - this.age;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>comparator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门指南--读书笔记]]></title>
    <url>%2F2015%2F07%2F26%2FRedis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97--%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[版本规则x.y.z X: 大版本号Y: 如果是偶数, 则是稳定版; 否则为不稳定版Z: 修补号 安装(Linux)最新稳定版: 1wget http://download.redis.io/redis-stable.tar.gz 编译及安装到指定目录(默认情况下,它会安装到 /usr/local/bin 目录下). 12makemake PREFIX=/some/other/directory install 启动和停止RedisRedis中的可用命令行工具及说明 名称 说明 redis-server Redis服务器 redis-cli Redis命令行客户端 redis-benchmark Redis 性能测试工具 redis-check-aof AOF 文件修复工具 redis-check-dump RDB 文件检测工具 redis-sentinel Sentinel 服务器 (2.8之后) 开发环境中启动直接运行 redis-server, 默认情况下会以6379的端口来启动. 也可以通过--port N来指定端口. 123451) redis-server --port 6379指定某个配置文件来指定redis-server /path/to/config.file Redis 源码目录里, 有一个名为redis.conf的文件, 它是配置文件的模板. 通过脚本来初始化在Redis源码的utils文件夹下, 有一个名为 redis_init_script的初始化脚本文件. 然后按需修改相应的文件配置. 123456参数名 值 说明daemonize yes 以守护进程模式运行pidfile /var/run/redis_端口号.pid PID文件位置port 端口号dir /var/redis/端口号 设置持久化文件存放位置databases 数字 支持的数据数量(0~N-1) 停止redis1redis-cli SHUTDOWN Redis 命令行客户端1redis-clie -h 127.0.0.1 -p 6379 多数据库这不是像真正的多个实例的数据库, 而是类似不同的命名空间的数据库.而且只能以数字来进行选择(0~N-1) Redis 的 glob pattern 风格 字符 说明 ? 匹配一个字符 * 匹配任意个(包括0个)字符 [] 匹配括号间的任一个字符.可以用-表示区间. \x 匹配字符x,如:要匹配?,就需要用 \? KEYS pattern注意, KEYS 命令需要遍历Redis中的所有键, 当键的数量较多时会影响性能. 所以不建议在生产环境中使用. Redis不区分命令的大小写. Redis 常见命令KEYS pattern获取符合规则的键名列表 EXISTS key判断是否存在某个键. 返回1则存在, 0则不存在. DEL key [key2…]删除一个或多个键 删除多个符合规则的键12345redis-clie -h 127.0.0.1 -p 6379 -n 0 KEYS "user:*" | xargs redis-cli -h 127.0.0.1 -p 6379 -n 0 DEL或者redis-cli -h 127.0.0.1 -p 6379 -n 0 DEL `redis-cli -h 127.0.0.1 -p 6379 -n 0 KYES "user:*"` TYPE key获取键值的类型.返回值可能是: string, hash, list, set, zset. Redis 数据类型字符串, String它可以存储任何形式的字符串, 包括二进制数据. 你可以用其存储用户的邮箱, JSON化的对象,甚至是一张图片. 一个字符串类型键,允许存储的数据的最大容量是 512MB 字符串类型,是其他数据类型的基础.从某种角度来说, 它们只是组织字符串的形式不同. 12345设置值SET key value获取值GET key 递增数字. 如果存储的字符串是整数形式时, Redis提供了一个实用的命令 INCR. 自增ID 可以通过 INCR 命令建立的键初始化为1.(设置起始值为0,然后获取其自增ID时, 它会自动加1.这样子就可以实现自增ID了) 列表, List1234567891011121314# 如果index为负数, 则从右边开始,最右边的为-1.但最左边是从0开始的.LINDEX key indexLSET key index value# 只保留指定片段.结合 LPUSH,可以限制列表的大小.每次调用LPUSH后, 再调用下面的命令即可.LTRIM key start end# 从左到右查找值为 pivot 的元素,然后根据第二个参数 BEFORE 还是 AFTER 来决定将value放到pivot的前面还是后面.LINSERT key BEFORE | AFTER pivot value# 将元素从一个列表转到另一个列表RPOPLPUSH source destination 集合, Set12345678910111213141516171819202122232425262728SADD key member [member ...]SREM key member [member ...]# 获取集合中的所有元素SMEMBERS key# 获取集合中元素个数SCARD key# 判断元素是否存在集合中SISMEMBER key member# 集合间的运行SDIFF key [key ...]SINTER key [key ...]SUNION key [key ...]# 进行集合运算,并将结果存储SDIFFSTORE destination key [key ...]SINTERSTORE destination key [key ...]SUNIONSTORE destination key [key ...]# 随机获取集合中的元素SRANDMEMBER key [count]count&gt;0, 则取出cont个不重复的元素count&lt;0, 则取出|count|个元素,但有可能重复 有序集合, Zset123456789ZADD key score member [score member ...]ZSCORE key member# 按score, 从小到大返回ZRANGE key start stop [WITHSCORES]# 按score, 从大到小返回ZREVRANGE key start stop [WITHSCORES] Redis中的事务在 redis-cli 中执行 123456multicmd1cmd2exec 过期时间12345678EXPIRE key secondsPEXPIRE key millis#查看还有多久过期,当键不存在时返回-2.(如果没有设置过期时间,则永不过期, 这时返回的是 -1).TTL key#取消过期时间,让它成为永久的PERSIST key 用Redis实现队列伪代码 123loop$task = BRPOP queue, 0execute($task[1]) BRPOP命令接受两个参数, 第一个是键名, 第二个是超时时间,单位是秒.如果为0,则不限制等待时间.即如果没有元素,会一直阻塞下去. 它返回两个值.第一个是键名, 第二个是元素值. 用Redis实现优先级队列 因为 BRPOP 命令可以同时接受多个键, 其完整的命令格式为: BRPOP key [key...] timout 如果所有键都没有元素,则阻塞.如果其中一个键有元素,则会从该键中弹出.如果多个键都有元素,则按照从左到右的顺序取第一个键中的一个元素. 用Redis实现”发布/订阅”模式发布者它使用PUBLISH命令, PUBLISH channel message, 发布一条消息.注意,发出去的消息,不会被持久化. 所以,后续的订阅者只能接收后续发布的消息,之前的是接收不到的. 订阅者它使用SUBSCRIBE命令,可以同时订阅多个频道,用法是:SUBSCRIBE channel1 [channel2 ...] 按规则订阅PSUBSCRIBE ,它支持glob风格通配符格式. 这与上面的两个是独立的. 即可能会重复匹配消息(如果执行这条,之前又执行了上面的,并且这条的匹配规则也匹配了上面的订阅的channel,不过这时返回的消息类型是不同的,不过消息是一样的) 复制12345master:redis-serverslave:redis-server ---port 6380 --slaveof 127.0.0.1 6379 这样, 6380(slave)端口的redis,就会同步6379(master)的redis了.默认情况下slave是只读的. redis中转义默认情况下，redis会将中文进行转义然后再输出，例如： 12127.0.0.1:6379&gt; get fffffffhello-by-test"\xe6\x88\x91\xe4\xba\x86\xe4\xb8\xaa\xe5\x8e\xbb" 想让它输出原始数据，可以如下: 1234uniweibo@uniweibo40:~$ ~/redis/redis-2.8.17/src/redis-cli -p 6379 --raw127.0.0.1:6379&gt; get fffffffhello-by-test我了个去127.0.0.1:6379&gt;]]></content>
      <categories>
        <category>nosql</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 日志实践]]></title>
    <url>%2F2015%2F07%2F23%2FJava-%E6%97%A5%E5%BF%97%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[每个类一个Logger1private static final Logger LOG = LoggerFactory.getLogger(Your.class); 日志级别trace最详细的日志级别信息 debug调试级别的日志级别信息 info一般的日志级别信息 warn警告级别信息 error错误级别信息 fatal导致终止程序的级别信息 在应用中按需开启不同的级别示例日志配置 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration &gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;Pattern&gt;%-70(%c&#123;15&#125;.%M[%date&#123;yyyy-MM-dd HH:mm:ss&#125;]) : %m%ex%n&lt;/Pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;root&gt; &lt;!-- 假设是生产环境，可以默认将所有日志级别设置为error级别 --&gt; &lt;level value="error" /&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/root&gt; &lt;!-- 这里可以将在你程序里，想要将不同的类设置为不同的级别打印消息 --&gt; &lt;logger name="com.your.packge[.YourClassName]" level="debug"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/logger&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Web 项目包建议设计]]></title>
    <url>%2F2015%2F07%2F21%2FJava-Web-%E9%A1%B9%E7%9B%AE%E5%8C%85%E5%BB%BA%E8%AE%AE%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[以下这些都只是从工作中，思考出来的，只是在下自己的拙见。一个好的包设计， 可以让项目更加清晰具体。 com.company.dao.pojo这里存放的是与数据库对应的表的POJO com.company.dao这里存放最原子的数据库操作的代码，每一个类的操作，都有一张与之对应的表。它只向 com.company.dao.service 层提供服务。 com.company.dao.service这里存放的是对 com.company.dao 的管理服层，因为有些关系不是只是操作一张表的， 可能要对两张或以上的表进行事务操作。这时， 就应该把这些操作放在这里。 com.company.controller这里存放的是所有 controller 的类，即Restful API层。前端可以直接访问的方法就放在这里。 com.company.task这里存放的是所有与task相关的类。比如用了spring task的服务的类都放在这里。（如果有的话） com.company.rabbitmq.queue这里存放的是所有与消息队列进队相关的类。 com.company.rabbitmq.listener这里存放的是所有与消息队列出队相关的监听器的类 com.company.utils这里存放的是所有与工具类相关的类 com.company.pojo这里存放的是除了DB的映射关系的POJO以外的POJO com.company.constants这里存放的是与常量有关的类 com.company.redis这里存放的是所有与redis操作相关的类 com.company.filter这里存放所有filter类 com.company.inteceptor这里存放所有interceptor类 com.company.service为其他类提供的服务类，因为有些时候，使用Utils静态工具类，无法注入Spring的依赖，这时可以使用@service来注解某个服务类，为其他类提供服务，又可以使用Spring的DI优点。因为Spring默认下是对象是单例的。所以不必担心对象实例化过多的问题。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java web</tag>
        <tag>java ee</tag>
        <tag>spring</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中的事务回滚]]></title>
    <url>%2F2015%2F07%2F16%2FSpring%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%9B%9E%E6%BB%9A%2F</url>
    <content type="text"><![CDATA[开启声明式事务spring.xml里配置 12345678910111213141516171819202122232425262728293031323334&lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClassName&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;property name="maxActive"&gt; &lt;value&gt;64&lt;/value&gt; &lt;/property&gt; &lt;property name="maxIdle"&gt; &lt;value&gt;64&lt;/value&gt; &lt;/property&gt; &lt;property name="maxWait"&gt; &lt;value&gt;0&lt;/value&gt; &lt;/property&gt; &lt;property name="validationQuery"&gt; &lt;value&gt;select 1&lt;/value&gt; &lt;/property&gt; &lt;property name="testWhileIdle"&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property name="minEvictableIdleTimeMillis"&gt; &lt;value&gt;20000000&lt;/value&gt; &lt;/property&gt; &lt;property name="timeBetweenEvictionRunsMillis"&gt; &lt;value&gt;3600000&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="TxManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager="TxManager" proxy-target-class="true" /&gt; 默认情况下Spring对事务回滚策略的处理 在 Spring 的文档里, 可以看到这一句话: Any RuntimeException triggers rollback, and any checked Exception does not. spring-framework-reference/html/transaction.html 可以看到, 对于检查型异常, 默认情况下是不会对事务进行回滚的 让事务进行按自己的策略进行回滚检查型异常如果有检查型异常, 而又要进行事务回滚, 这时可以在检查型异常里的 catch 块里, 再次抛出 RuntimeException 即可. RuntimeException如果有运行时异常, Spring会自动进行事务回滚. 按自己想要的异常类型来进行选择性回滚在要进行事务的方法里, 添加以下方法级别的注解: 1@Transactional(rollbackFor=Exception.class) 这时, Spring就会按指定的异常及其子类异常类型来进行事务回滚了. 如果配置了Exception.class, 那么任何Exception及其子类抛出的异常, 都会进行事务回滚. 注意, 是要抛出异常. 如果你捕获了异常的而且又没有抛出新的异常的话, 就不会进行事务回滚了. 参考资料 Spring Doc ITEye]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring单元测试]]></title>
    <url>%2F2015%2F07%2F14%2FSpring%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[资源文件 将所有的资源文件, 放到测试包及测试资源下(如果没有的话).以免麻烦, 统一放到 classpath 下. 12345# 这放测试代码文件src/test/java# 这放测试资源文件src/test/resource 进行单元测试在要测试的类, 加上以下注解(类级别的) 12@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:spring.xml") 其中 spring.xml 为核心spring文件, 即容器统一管理的文件(不是Spring MVC的那个在web.xml里配置指向的文件,当然也可以是同一个,如果没有分开的话). 示例代码 123456789101112131415161718192021222324252627282930313233343536373839@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:spring.xml")public class TestSpring &#123; @Autowired private CCSessionMsgListener listener; @Autowired private RabbitTemplate rabbitTemplate; @Test public void test() &#123; System.out.println("11111111111111111"); &#125; @Test public void listTest() &#123; CcSessionMsg ccSessionMsg = inqueue("yyy", "xxx", "test", System.currentTimeMillis(), new Date()); rabbitTemplate.convertAndSend("queue", ccSessionMsg); &#125; @Test public void outQueue()&#123; CcSessionMsg msg = (CcSessionMsg)rabbitTemplate.receiveAndConvert("queue"); listener.getSessionMsg(msg); &#125; public CcSessionMsg inqueue(String fromOpenid, String toOpenid, String content, long mid, Date createAt) &#123; CcSessionMsg sessionMsg = new CcSessionMsg(); sessionMsg.setContent(content); sessionMsg.setMid(mid); sessionMsg.setCreateAt(new Timestamp(createAt.getTime())); sessionMsg.setType(301); sessionMsg.setFromOpenid(fromOpenid); sessionMsg.setToOpenid(toOpenid); return sessionMsg; &#125;&#125; 注意: 在每个要测试的方法里, 不要忘记了添加上 @Test 注解哈.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我使用的Emacs插件]]></title>
    <url>%2F2015%2F07%2F11%2F%E6%88%91%E4%BD%BF%E7%94%A8%E7%9A%84Emacs%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[使用相对行号relative-line-numbers ace-jump 快速跳转ace-jump-mode 主题Emacs theme Emacs 资源Emacs Sexy]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的Emacs]]></title>
    <url>%2F2015%2F07%2F10%2F%E6%88%91%E7%9A%84%20Emacs%20%2F</url>
    <content type="text"><![CDATA[Emacs PreludeGithub 配置说明~/.emacs.d/personal 目录: 用于存放自己的个性化配置, 最好不要动其他的目录的文件. 比如自己通过 package-install 安装完成后,可以将该插件的一些配置自定义放在这里 ~/.emacs.d/personal/preload/ 目录: 用于最先预加载自己的配置文件, 在加载 Prelude 之前会加载这个目录下的所有配置文件. 比如主题配置, 可以放在这里 Prelude 源码里有注释说明: &quot;This directory is for your personal configuration, that you want loaded before Prelude.&quot; 我使用的插件 ace-jump-mode relative-line-number]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
        <tag>prelude</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]Emacs的prelude READMD文档]]></title>
    <url>%2F2015%2F07%2F09%2F%E7%BF%BB%E8%AF%91-Emacs%E7%9A%84prelude-READMD%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[原文 Emacs PreludePrelude 是一个Emacs发行版, 旨在加强默认Emacs的体验.Prelude更改了许多默认的配置, 组合捆绑了大量的额外的插件,并添加了它自己的核心库.最终的产品提供了一个对于新手易于使用, 对于高级用户提供了许多额外的能力的Emacs配置. Prelude 只对 GNU Emacs 24.x 版本兼容.一般地, 我们总是建议你以最新版本的Emacs来运行Prelude - 当前最新版本为 24.4. 目录快速使用我们假设你正运行 Unix-like 系统(*BSD, GNU/Linux, OS X, Solaris, 等等), 并且你已经安装了Emacs 24, 也安装好了git以及curl,你可以忽略整个手册, 只需要在你喜欢的shell里输入以下命令: 1curl -L https://git.io/epre | sh 你可以启动你的Emacs,坐下来并享受prelude了,忘记这份手册的剩余部分. 这时有两人个环境变量你可以用于控制源码仓库以及安装目录.为了改变安装目录, 你可以: 1export PRELUDE_INSTALL_DIR="$HOME/.emacs.d" &amp;&amp; curl -L https://github.com/bbatsov/prelude/raw/master/utils/installer.sh | sh 为了改变源码仓库为, 你可以: 1export PRELUDE_URL="https://github.com/yourname/prelude.git" &amp;&amp; curl -L https://github.com/bbatsov/prelude/raw/master/utils/installer.sh | sh 注意,安装包会备份任何在 .emacs 文件或 .emacs.d 目录,然后它会解压Prelude的代码到.emacs.d 目录里.如果你打算手动安装, 请确保你没有.emacs文件或者手动备份你已经存在的.emacs.d 目录. 一旦你安装完成后,不要忘记去调整你的prelude-modules.el文件.默认情况下, 许多prelude自带的模块并没有加载. 安装 Emacs 24好明显, 你使用 Emacs Prelude 之前, 你首先得安装 Emacs 24 . 请看 WikEmacs articles on installing Emacs 安装(Prelude)自动化安装你可以通过命令行使用curl 或者wget来安装Emacs Prelude.自然地,git也是要安装好的. 通过 curl 安装如果你打算用curl, 请在shell里输入以下命令: 1curl -L https://github.com/bbatsov/prelude/raw/master/utils/installer.sh | sh 通过 Wget 安装如果你打算使用 wget, 请在shell里输入以下命令: 1wget --no-check-certificate https://github.com/bbatsov/prelude/raw/master/utils/installer.sh -O - | sh 手动安装123git clone git://github.com/bbatsov/prelude.git path/to/local/repoln -s path/to/local/repo ~/.emacs.dcd ~/.emacs.d 更新 Prelude手动更新更新过程非常简单直接,由3个步骤组成: 更新所有插件包只需要运行 M-x package-list-packages RET U x 更新Prelude的代码12cd path/to/prelude/installationgit pull 路径path/to/prelude/installation通常是 ~/.emacs.d (在最新的Unix系统下) 重启 Prelude在你更新完之后,重启一下Emacs通常是一个好的主意.在下次Prelude启动时, 它会安装好新的依赖(如果需要的话). 自动更新简单地执行M-x prelude,然后重启下Emacs就可以了. 开启额外的模块.默认情况下,大多数Prelude自带的模块并没有加载.更多关于这些模块提供的功能, 请查这个文档 docs 12345678910111213141516171819202122232425;;; Uncomment the modules you'd like to use and restart Prelude afterwards(require 'prelude-c);; (require 'prelude-clojure);; (require 'prelude-coffee);; (require 'prelude-common-lisp);; (require 'prelude-css)(require 'prelude-emacs-lisp)(require 'prelude-erc);; (require 'prelude-erlang);; (require 'prelude-elixir);; (require 'prelude-haskell)(require 'prelude-js);; (require 'prelude-latex)(require 'prelude-lisp);; (require 'prelude-mediawiki)(require 'prelude-org)(require 'prelude-perl);; (require 'prelude-python);; (require 'prelude-ruby);; (require 'prelude-scala)(require 'prelude-scheme);; (require 'prelude-scss);; (require 'prelude-web)(require 'prelude-xml) 一旦你安装完成后,你可修改你的prelude-modules.el文件.如果你打算手动安装,这时你需要复制 prelude-modules.el 文件(译注: 放到~/.emacs.d/目录下),这个文件在根目录 path/to/prelude/installation 下的 sample 目录里. 你在注释掉一些模块后, 你也应该重启Emacs或者通过C-x C-e来evaluate模块require表达式.(这个不好翻译…) 运行这没有什么特别的. 像平常一样启动Emacs就可以了.我个人将Emacs运行在一个守护模式: 1emacs --daemon 然后,我通过终端或者一个图形客户端连接到服务, 就像这样: 12emacsclient -temacsclient -c 你可能在你的.zshrc或者.bashrc也设置一些别名: 1234alias e='emacsclient -t'alias ec='emacsclient -c'alias vim='emacsclient -t'alias vi='emacsclient -t' 如果你通常在命令行使用vi(m)编辑文件, 最后两个别名将非常有用. 你也可以打开一个文件并跳到指定行: 1emacsclient somefile:1234 这会打开一个somefile文件,并且将光标定位到第1234行. 开始了解 Prelude当然,了解Prelude是如何加强默认的Emacs检验的最好的方式就是去精读Prelude的源码.(好明显,是用Emacs Lisp来写的).理解代码不是必修课.Prelude包含了一个prelude-mode次模式, 它是prelude提供的额外的功能的集合.它也提供了些额外的键位映射绑定扩展. 键位映射情况全局范围的 绑定的键位 描述 C-x \ 根据正则对齐区域 C-+ 放大字体(text-scale-increase) C– 缩小字体(text-scale-decrease) C-x 0 返回之前的窗口(反转 other-window (C-x o)) C-^ 将两行合并成一行(prelude-top-join-line)(译注:将当前行与下一行合并到当前行) C-x p 启动 proced (Emacs进程管理器, 仅在Linux下工作) C-x m 启动 eshell C-x M-m 启动你的默认shell C-x C-m M-x的别名 M-X 类似 M-x ,但命令只限于当前活动的主模式. C-h A 运行 apropos (搜索所有Emacs符号) C-h C-m 显示当前主模式的键位绑定以及描述所有绑定的键位说明 M-/ 运行 hippie-expand (一个替代默认的dabbrev-expand) C-x C-b 打开 ibuffer (一个代替默认的buffer-list的东东) F11 全屏 F12 开启/关闭 Emacs 菜单栏 C-x g 开启 magit 的状态缓冲区 C-x M-g 打开 magit 的弹出窗 M-Z 显示与字符相关的操作的快捷键 C-= 执行 expand-region(增量文本选择) (译注:对于写代码这个功能非常有用) C-a 执行 prelude-move-beginning-of-line. 详情请这里 Prelude 模式下的 绑定的键位 描述 C-c o 用外部程序打开当前访问的文件 C-c i 搜索符号, 仅在包含代码的缓冲里搜索 C-c g 用Google搜索光标下的东西(或者一个交互式查询) C-c G 用Github搜索光标下的东西(或者一个交互式查询) C-c y 用Youtube搜索光标下的东西(或者一个交互式查询) C-c U 用Duckduckgo搜索光标下的东西(或者一个交互式查询) C-s RET 或者 Super-o 在当前行向上一行插入一个空行并适当进行缩进 S-RET 或者 M-o 插入一个空行并适当缩进 C-S-up 或者 M-S-up 将当前行或区域向上移(注意S是大写) C-S-down 或者 M-S-down 将当前行或区域向下移(注意S是大写 C-c n 修正缩进及去掉空白 C-c f 打开最近访问的文件 C-M-\ 缩进区块(如果有选择的话)或者整个缓冲区 C-c u 根据URL,打开一个新的缓冲区来打开该URL C-c e 计算 Emacs Lisp 代码表达式,并用结果来替换 C-c s 切换两个活动窗口 C-c D 删除当前文件及缓冲区 C-c d 复制当前行(或区块)到下一行 C-c M-d 复制当前行(或区块)到下一行并注释掉 C-c r 重命名当前的缓冲区以及它正在访问的文件 C-c t 打开一个终端模拟器(ansi-term) C-c k 关闭所有缓冲区除了你当前正在使用的 C-c TAB 缩进并复制区块到粘贴板 C-c I 打开用户的 init 文件(即 prelude/personal/preload 目录) C-c S 打开 shell 的 init 文件 即 ~/.bashrc 或 ~/.zshrc C-c . + 将当前数字加1 C-c . - 将当前数字减1 C-c . * 将当前数字*2 C-c . / 将当前数字/2 C-c . \ 将当前数字取模, %2 C-c . ^ 将当前数字进行平方 ^2 C-c . &lt; 将当前数字左移 1 个单位, 即*2 C-c . &gt; 将当前数字右移 1 个单位,即/2 C-c . # 将当前数字转换为指定基数的数字. 默认为10 C-c . % 将当前数字用另一个数字来替换 C-c . ‘ 将当前数字用数学操作符来操作 Super-g 开启或关闭 God 模式 Super-r 最近的文件 Super-j 合并行 Super-k 删除整行 Super-m m magit 状态 Super-m l magit 日志 Super-m f magit 文件日志 Super-m b magit blame 模式 注意: 对于各种算术运算符, 前缀操作符 C-c . , 仅需要同时按一次. 剩下部分的操作符, 适当按下就可以了. OS X 修改键位Prelude 默认情况下不弄乱标准的键位映射 Command (就是 Super), Option 就是Meta. 如果你想互换它们, 请添加以下配置到你的个人配置文件里: 12(setq mac-command-modifier 'meta)(setq mac-option-modifier 'super) Projectile这些是 Projectile 提供的功能 绑定的键位 描述 C-c p f 显示项目里文件列表.带有前缀参数, 将会首先清空缓存 (这个命令非常好用) C-c p d 显示项目里目录列表.带有前缀参数, 将会首先清空缓存 C-c p T 显示项目里所有测试文件列表 C-c p s g 对项目进行执行 grep (相当于全文搜索) M– C-c p s g 在项目里执行 projectile-grep-default-files C-c p b 显示当前项目里所有已经打开到缓冲区的文件列表 C-c p o 对所有项目打开的缓冲区执行 multi-occur C-c p r 对项目里所有的项目文件执行 query-replace C-c p i 使用项目的缓存失效(如果存在的话) C-c p R 对项目重新生成 TAGS 文件 C-c p k 删除所有项目的缓冲区 C-c p D 在 dired 模式打开项目的根目录 C-c p e 显示所有最近打开过的项目的文件 C-c p s a 对项目执行 ack.需要有 ack-and-a-half C-c p s s 对项目执行 ag. 需要有 ag.el C-c p a 对项目执行 ack. 需要有 ack-and-a-half C-c p c 对项目执行标准的编译命令 C-c p P 对项目执行标准的测试命令 C-c p z 添加当前访问的文件到缓存 C-c p p 显示所有你可以切换的项目 Prelude 提供了一个额外的键位前缀 S-p (S 代表 Super), 所以, 你也可以使用 S-p 来代替 C-c p 如果你有时忘记了任何项目的键位绑定情况, 只需要输入: C-c p C-h HelmHelm 的设置是根据这个指引的 A Package in a league of its own: Helm.. 你可以根据以下的指导来学习Helm的用法和按键绑定情况. C-c h 是 Prelude 对 Helm 默认的按键前缀. 如果你不记得任何的按键, 在 C-c h 之后再加上 C-h 就可以列所所有关于 Helm 的所有绑定的按键的情况. 如果你喜欢 Helm 并且想全局上使用 Helm 通过 helm-find-files, helm-buffer-lists… 来加强, 这时你加上(require &#39;prelude-helm-everywhere). 当 prelude-helm-everywhere激活了, Helm 就会开启以下这些全局按键: 绑定的键位 描述 M-x 执行 helm-M-x,一个 M-x 的交互版. M-y 执行 helm-show-kill-ring. 显示 kill-ring的内容 C-x b 执行 helm-mini, 一个 C-x b 的交互版. C-x C-f 执行 helm-find-files , 一个 find-file 的交互版 C-h f 执行 helm-apropos, 一个 apropos-command 的交互版 C-h r 执行 helm-info-emacs, 一个 info-emacs-manual 的交互版 C-h C-l 执行 helm-locate-library, 可以搜索所有加载到 emacs 的文件位置 以下的按键是在 shell-mode 情况下激活: 绑定的键位 描述 C-c C-l 执行 helm-comint-input-ring, 使用helm接口来显示 shell 历史命令 以下的按键是在 eshell-mode 情况下激活:|绑定的键位 | 描述 ||–: | –: || C-c C-l | 执行 helm-eshell-history, 使用helm接口来显示 eshell 历史命令 | 如果你更喜欢在所有地方使用 Ido, 你就不应该添加 prelude-helm-everywhere, 这样你就可以同时使用 Helm和 Ido, 以及 Prelude 的默认按键了. 你总是可以通过 (prelude-global-helm-global-mode-on) 来重新激活 Helm. 注意: 在 helm-M-x, 你必须传递前缀参数在你执行helm-M-x 之后, 因为你的前缀参数将会在helm-M-x显示的模式线上. helm-M-x之前,是没有效果的. Key-chordsKey-chords 仅当 prelude-key-chord 模块开启时才可用. 绑定的键位 描述 jj 跳到一个单词的开始位置 (avy-goto-word-1) jk 跳到一个字符(avy-goto-char) jl 跳到一行的开始(avy-goto-line) JJ 跳到前一个缓冲区 (prelude-switch-to-previous-buffer) uu 编辑视图作为树 (undo-tree-visualize) xx 执行一个外部命令 ( execute-extended-command ) yy 浏览 kill-ring 内容 ( browser-kill-ring) 禁用 Key-chords在一些情况下, 你可能不想要prelude已经定义好的 key-chord 的按键, 这时, 你可以在personal.el文件里通过设置它的命令为nil来禁用这些按键. 例如, 为了禁用jj key-chord, 可以添加以下行到配置文件里: 1(key-chord-define-global "jj" nil) 如果你是一个 evil-mode 用户, 你可能也想同时禁用 key-chord-mode: 1(key-chord-mode -1) vim 模拟器如果你想在emacs里使用vim, 可以启用prelude-evil模块, 它提供了对evil-mode的支持. 自动化包安装默认情况下, Prelude 安装好后只带最小限度的功能.它也可以在后台自动安装各种编程语言及框架的附加插件.例如: 你试图打开一个.clj文件 clojure-mode, cider以及Prelude的加强版Lisp配置将会自动为你安装. 当然, 你也可以手动安装任何东西. 颜色主题Emacs 24 自带了一个新的主题服务, 这显式有效地渲染一些老的颜色主题包. Emacs 24 提供了一打内建的主题, 你可以开箱即用, 通过调用 M-x load-theme 命令. Zenburn是Prelude的默认颜色主题, 但你可以自行修改. 为什么用Zenburn?我(并且世界上许多黑客)发现它相当简洁.个人发现默认的主题容易对眼睛产生厌倦, 这是为什么我决定把有争议的地方替换它. 当然, 你也可以返回默认(或者选择其他颜色主题). 为了禁用 Zenburn 主题, 你可以将以下行放到你个人的配置文件里: 1(disable-theme 'zenburn) 或者你可以使用其他主题颜色, 通过添加以下内容到 personal/preload, 像这样: 1(setq prelude-theme 'solarized-dark) 注意: Solarized 默认情况下是不可用的. 你可以从MELPA安装它(`M-x package-install RET solarized-theme). 最后, 如果你不想用任何主题, 你可以添加以下内容到你的 personal/preload: 1(setq prelude-theme nil) 个性化fork官方的 Prelude 仓库并添加一些你自己的东西. 你应该避免去修改你个人文件夹之外的东西, 以免在日后升级时带来的冲突问题. 如果你想添加一些自动安装的包到你的个人配置文件, 可以使用以下代码: 1(prelude-require-packages '(some-package some-other-package)) 如果你只需要单一的包, 你也可以这样子: 1(prelude-require-packages 'some-package) 预加载你自己的配置文件有时, 你想要在 Perlude 加载之前, 加载你自己的配置文件. Prelude 会自动预加载所有在 personal/preload 文件夹下的 Emacs Lisp 文件. 注意, 这意味着你不能使用任何与Prelude相关的东西, 除了几个变量之外, 比如prelude-dir等等. 禁用 whitespace-mode尽管 whitespace-mode 模式人令人眼前一亮, 但有些人觉得它太过有入侵性.你可以在你的个人配置文件里通过以下代码禁用它: 1(setq prelude-whitespace nil) 如果你喜欢 whitespace-mode 但更愿意它不要在你保存文件时自动清除空格, 你可以在你的配置文件里通过设置 prelude-clean-whitespace-on-save 为nil 来禁用这些行为. 1(setq prelude-clean-whitespace-on-save nil) 禁用 flyspell-mode如果你不喜欢, 可以这样子禁用它 1(setq prelude-flyspell nil) 注意事项更新捆绑的包在执行更新 Prelude 之前, 最好更新一下你已经安装好的包, 因为最新的Prelude通常依赖于捆绑好的包的更新版本. 如果你打算手动更新Prelude, 你总是应该首先执行包更新操作. 1M-x package-list-packages RET U x 如果你打算使用 M-x prelude-update, 上步的步骤就不是必须的, 因为它会自动先执行更新包操作. flyspell-mode 的问题Prelude 会大量使用 flyspell-mode 来对各种设置进行拼写检查. 这些操作会依赖于你的操作系统中的 aspell 程序以及一个英文字典. 在Mac OS X下, 你可以通过 homebrew 来安装 aspell, 像这样: 1brew install aspell --with-lang=en 在Linux发行版, 只需使用你的包管理器来安装即可. Emacs 的终端版颜色太丑的问题如果你的Emacs在终端上看上去太丑陋(相对于图形界面版), 可以试下添加以下配置到你的 ~/.bashrc 或者 ~/.zshrc. 1export TERM=xterm-256color 然后重新加载下 ~/.bashrc 或 ~/.zshrc 文件, 然后再次启动emacs. 在初始化启动时报 MELPA 错误如果你发现有一些 HTTP 连接到MELPA错误相关的信息, 只要手动执行 M-x package-refresh-contents , 然后直接重启Emacs即可. 在编辑器缓冲区发现箭头导航的警告这不是个bug, 而是一个特色. 我坚信唯一使用Emacs的方法是按它的方式来使用(至少相对于导航而言是这样子) 如果你相信这会使你更进一步, 你可以完全禁用箭头导航, 可以在你的配置文件里添加: 1(setq guru-warn-only nil) 完全禁用, 可以在你的配置文件里添加以下片段: 1(setq prelude-guru nil) 自定义 C-a 的行为Prelude 覆盖了 C-a 的行为, 描述在这里. 如果你不喜欢, 你可以简单地添加以下代码到你的配置文件里: 12(global-set-key [remap move-beginning-of-line] 'move-beginning-of-line) ido 在大的数据处理里遇到性能问题Prelude 将ido-fix 与默认的 ido 互换了. flx的排序算法更复杂, 但有着更好的结果. 在一些比较慢的机器下, 它可能需要降低 flx-ido-threshold 的值来确保有比较好的体验. 1(setq flx-ido-threshold 1000) 你也可以完全禁止这些排序算法, 像这样: 1(flx-ido-mode -1) Windows 兼容性理论上 Prelude 应该在 Windows 也可以很好地工作, 我只在 Linux 与 OS X上测试过, 所以Windows时而会有相关的问题. 这种情况可能随着时间的推移而解决 . 已知的问题checkout 项目的未解决的问题列表. 顺便说下, 随意修复好它,然后发给我一个 pull 请求就好. :-) 技术支持通过 Prelude的 Google Group 可以得到些技术支持 emacs-prelude@googlegroups.com.. 贡献这有份清单, 列出了所有为 Emacs Prelude 做出过贡献的人 bugs 以及 修正我们总是欢迎任何提交bugs以及改进的建议. 如果能有 Github 的pull request 就更好了. :-) 我也接受一些赞助, 可以通过 gittip来捐赠.]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
        <tag>prelude</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Java监控工具出现 Can't attach to the process]]></title>
    <url>%2F2015%2F07%2F07%2F%E4%BD%BF%E7%94%A8Java%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E5%87%BA%E7%8E%B0-Can-t-attach-to-the-process%2F</url>
    <content type="text"><![CDATA[问题重现12345678910111213141516171819202122232425➜ jinfo -flags 3032Attaching to process ID 3032, please wait...Error attaching to process: sun.jvm.hotspot.debugger.DebuggerException: Can't attach to the processsun.jvm.hotspot.debugger.DebuggerException: sun.jvm.hotspot.debugger.DebuggerException: Can't attach to the process at sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$LinuxDebuggerLocalWorkerThread.execute(LinuxDebuggerLocal.java:163) at sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal.attach(LinuxDebuggerLocal.java:278) at sun.jvm.hotspot.HotSpotAgent.attachDebugger(HotSpotAgent.java:671) at sun.jvm.hotspot.HotSpotAgent.setupDebuggerLinux(HotSpotAgent.java:611) at sun.jvm.hotspot.HotSpotAgent.setupDebugger(HotSpotAgent.java:337) at sun.jvm.hotspot.HotSpotAgent.go(HotSpotAgent.java:304) at sun.jvm.hotspot.HotSpotAgent.attach(HotSpotAgent.java:140) at sun.jvm.hotspot.tools.Tool.start(Tool.java:185) at sun.jvm.hotspot.tools.Tool.execute(Tool.java:118) at sun.jvm.hotspot.tools.JInfo.main(JInfo.java:138) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at sun.tools.jinfo.JInfo.runTool(JInfo.java:108) at sun.tools.jinfo.JInfo.main(JInfo.java:76)Caused by: sun.jvm.hotspot.debugger.DebuggerException: Can't attach to the process at sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal.attach0(Native Method) at sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal.access$100(LinuxDebuggerLocal.java:62) at sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$1AttachTask.doit(LinuxDebuggerLocal.java:269) at sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$LinuxDebuggerLocalWorkerThread.run(LinuxDebuggerLocal.java:138) 解决办法1echo 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope 再次执行时就可以得到结果了1234567➜ jinfo -flags 3032Attaching to process ID 3032, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.5-b02Non-default VM flags: -XX:InitialHeapSize=41943040 -XX:MaxHeapSize=536870912 -XX:MaxNewSize=178782208 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=1572864 -XX:OldSize=40370176 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGCCommand line: -Dosgi.requiredJavaVersion=1.6 -XX:MaxPermSize=256m -Xms40m -Xmx512m 原因这是因为新版的Linux系统加入了 ptrace-scope 机制. 这种机制为了防止用户访问当前正在运行的进程的内存和状态, 而一些调试软件本身就是利用 ptrace 来进行获取某进程的内存状态的(包括GDB),所以在新版本的Linux系统, 默认情况下不允许再访问了. 可以临时开启. 如: 1echo 0 &gt; /proc/sys/kernel/yama/ptrace_scope 永久写到文件来持久化: 1234emacs /etc/sysctl.d/10-ptrace.conf添加或修改为以下这一句:(0:允许, 1:不允许)kernel.yama.ptrace_scope = 0 参考资料 http://my.huhoo.net/ Askubuntu 一根稻草]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis与Java使用经验]]></title>
    <url>%2F2015%2F07%2F06%2FRedis%E4%B8%8EJava%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[Redis 中的数据类型 String——字符串 Hash——字典 List——列表 Set——集合 Sorted Set——有序集合 String (简单的 K-V 类型) 适合场景: 简单的 K-V 键值对. Hash 结构 适合存储Java对象.Key就是对象有唯一标识, HashKey就是对象的属性标识, value就是属性的值.Object -&gt; HashMap -&gt; RedisRedis -&gt; HashMap -&gt; Object 可以使用 apache common 包来进行 HashMap和Object的相互转换 123456#HashMap to ObjectBeanUtils.populate(bean, properties)#Object to HashMapMap&lt;String, Object&gt; objectAsMap = BeanUtils.describe(bean); 为什么要这样子呢, 因为如果使用 String 数据类型, 只是修改一个字段的话, 每次都要加载所有Redis中的数据(如果对象比较大的话, 就更严重了).然后修改完, 最后再序列化到Redis.但如果使用Hash就不会这样子了, 只是修改一个字段的话, 可以直接去修改该字段即可. List 结构 就是链表. 可以想像链表的数据结构使用场景.(队列等) Set 集合 Set 就是一个集合，集合的概念就是一堆不重复值的组合. Sorted Set 排序集合 在公司里, 唯一用过一次的场景就是.会话的排序.每个会话(不重复性)根据最新的消息的时间来排序.这时就可以使用这个数据结构了. 特别提一下, 它是根据 score 来排序. 如果需要根据多个字段来进行排序的话, 可以在score里,逻辑上分配个多字段值. 在这里, 以我在公司里的两个字段排序来举个例子.上面说到,一个排序是根据消息最新时间来排序, 还有一个是置顶. 置顶永远是最前面的.然后才是最新消息的排序. 这里, 我使用了 x.y 的 score 方式来排序. 置顶时 x=1, 否则就是 x=0, 然后 y 就是最新消息的时间戳.这样子就可以实现两人个字段来排序的逻辑了. 编码注意多用 pipline业务允许的话，尽可能将命令合并到一个 pipline 减小操作的粒度比如大 zset ，可以分批，小量小量地删除（删除操作，可以凌晨或业务空闲的时候处理） 删除大 key在业务繁忙时，不要删除一个大 key ，可以临时 rename 这个 key，然后定时在凌晨相对空闲时才正式删除。 scan 注意scan 的耗时与 count 的大小有非常重要的关系, count 的参数越大，耗时越多。]]></content>
      <categories>
        <category>nosql</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 14.04 LTS 下安装Emacs 24.5]]></title>
    <url>%2F2015%2F07%2F03%2FUbuntu%2014.04%20LTS%20%E4%B8%8B%E5%AE%89%E8%A3%85Emacs-24-5%2F</url>
    <content type="text"><![CDATA[先删除以前的 emacs 版本可以进入 Ubuntu Software Center 里进行删除. 如果熟悉命令行, 也可以使用 sudo apt-get remove emacs 来进行删除. 安装核心依赖123sudo apt-get install build-essentialsudo apt-get build-dep emacs24 下载 Emacs 24.5 源码 GNU Emacs 24.5 1cd ~/Downloads &amp;&amp; wget -c http://ftp.gnu.org/gnu/emacs/emacs-24.5.tar.gz 解压并进入该目录1cd ~/Downloads &amp;&amp; tar -xf emacs-24.5.tar.* &amp;&amp; cd emacs-24.5 检测并安装1234567./configure如果 configure 这一步出错, 一般是缺少其他相对应的依赖的, 这时, 可以使用 `aptitude` 这个工具来解决依赖的问题.make -j 4sudo make install 添加为 Unity 启动图标123456789101112[Desktop Entry]Version=1.0Name=Emacs-24.5Exec=env UBUNTU_MENUPROXY=0 /usr/local/bin/emacsTerminal=falseIcon=emacsType=ApplicationCategories=IDEX-Ayatana-Desktop-Shortcuts=NewWindow[NewWindow Shortcut Group]Name=New WindowTargetEnvironment=Unity 参考资料 Askubuntu Ubuntuhandbook wikemacs]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Emacs配置文件之prelude]]></title>
    <url>%2F2015%2F07%2F03%2FEmacs%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B9%8Bprelude%2F</url>
    <content type="text"><![CDATA[Prelude 它是一个高度可配置的开箱即用的Emacs配置文件集合. Github Prelude 开启里面的modules 默认情况下, 安装好 prelude 是没有开启它的模块功能的,要开启自己想要的模块, 可以按以下做: 123cd ~/.eamcs.d/cp sample/prelude-modules.el .emacs prelude-modules.el 然后按里面的模块, 根据自己的需要, 去开启或者关闭. 自定义自己的额外配置 将自己的配置文件放到 ~/.emacs.d/personal/preload/ 目录下即可. 例如, 我有一个配置文件 ~/.emacs.d/personal/preload/yang.el , 这样子 prelude 就会自动加载这个配置文件了. 我刚开始做 prelude , 我只是暂时添加了自己喜欢的主题, yang.el 的内容就只有以下一行: 1(setq prelude-theme 'solarized-dark) 注意, 默认情况下, prelude 并没有安装这个主题, 所以先要安装下这个主题先: 1M-x package-install RET solarized-theme 注意为了升级方便, 其他地方的文件自己不要随便添加或者修改, 最好按 prelude 的约定来做: ~/.emacs.d/prelude-modules.el : 这里开启或关闭自己需要的模块. ~/.emacs.d/personal/preload/ : 这个目录,存放自定义的配置文件.]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Emacs技巧之反转指定区域的内容]]></title>
    <url>%2F2015%2F07%2F01%2FEmacs%E6%8A%80%E5%B7%A7%E4%B9%8B%E5%8F%8D%E8%BD%AC%E6%8C%87%E5%AE%9A%E5%8C%BA%E5%9F%9F%E7%9A%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[原内容12345678一二三四五六七八 操作之后的内容12345678八七六五四三二一 操作步骤 先标记所要反转的区域的内容(C-@ 为开始标记, 然后移动渔村到指定区域) 然后输入以下命令: M-x reverse-region RET 即可. 某两行之间进行反转 C-x C-t : 反转当前行和上一行,并且将光标移动这两行的下面. 或者 M-x transpose-lines 两个字符间的反转 C-t : 反转当前光标所在的字符与后一个(左)字符.并且将光标向前移动一个字符. 或者 M-x transpose-chars 两个单词之间的反转 M-t: 反转当前光标所在的单词与后一个(左)单词,并且将光标移动到反转后单词的结尾.(要注意光标的位置, 在一个单词开始处, 与结束处的行为是不同的) 或者 M-x transpose-words zhi yang yong 根据某规则来排序原内容12345678八 a 二且全七 c 了顶起六 e 是是在五 d 是是是四 b 我我我三 f 是是是是二 h 我是不是一 g 你妹 根据第二个Filed来排序之后的内容为12345678八 a 二且全四 b 我我我七 c 了顶起五 d 是是是六 e 是是在三 f 是是是是一 g 你妹二 h 我是不是 命令1C-u 2 M-x sort-fields 2 表示根据第2项来排序. 更多资料可以参考 GNU Emacs 官网 Sorting Text]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 备份脚本]]></title>
    <url>%2F2015%2F07%2F01%2FMySQL-%E5%A4%87%E4%BB%BD%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[MySQL 备份 InnoDB每天备份策略1234567cd /etc/cron.daily/touch /etc/cron.daily/dbbackup-daily.shchmod 755 /etc/cron.daily/dbbackup-daily.shvi /etc/cron.daily/dbbackup-daily.sh 然后写入以下内容 123456789101112131415161718192021222324252627#!/bin/bashdbs=( "db1" "db2" "db3" )for db in "$&#123;dbs[@]&#125;"do now="$(date +'%Y_%m_%d_%H_%M_%S')" filename="$&#123;db&#125;_backup_$now".gz backupfolder="/home/yang/dbbackup" fullpathbackupfile="$backupfolder/$filename" logfile="$backupfolder/"backup_log_"$(date +'%Y_%m')".txt echo "mysqldump $&#123;db&#125; started at $(date +'%Y_%m_%d %H:%M:%S')" &gt;&gt; "$logfile" /home/uniweibo/mysql/mysql-5.6.17/bin/mysqldump -h127.0.0.1 --single-transaction -uroot -P6606 -pxxxxx $&#123;db&#125; | gzip &gt; "$fullpathbackupfile" echo "mysqldump $&#123;db&#125; finished at $(date +'%Y_%m_%d %H:%M:%S')" &gt;&gt; "$logfile" #chown myuser "$fullpathbackupfile" #chown myuser "$logfile" #echo "file permission changed" &gt;&gt; "$logfile" find "$backupfolder" -name $&#123;db&#125;_backup_* -mtime +8 -exec rm &#123;&#125; \; echo "old files deleted" &gt;&gt; "$logfile" echo "operation finished at $(date +'%Y_%m_%d %H:%M:%S')" &gt;&gt; "$logfile" echo "*****************" &gt;&gt; "$logfile"done 参考资料: 资料来源:stackoverflow 我在此基础之上, 小作了下修改.]]></content>
      <categories>
        <category>mysql</category>
        <category>backup</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>backup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Emacs技巧收集]]></title>
    <url>%2F2015%2F06%2F30%2FEmacs%E6%8A%80%E5%B7%A7%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Emacs中的按键说明 C-: 意思是按住 Ctrol 键 `M-‘: 意指 Meta 键 (在大多数键盘上指 Alt 键) `DEL’: 意指退格键 (不是 删除(Delete) key) `RET’: 意指回车键 `SPC’: 意指空格键 `ESC’: 意指Escape键 `TAB’: 意指Tab键 获取帮助按下 C-h 后, 接着按以下 k : 查看某键位的说明 f : 查看某函数的功能 m : 查看当前模式的键盘设置. w : 查看某个函数设定到哪个键上 a : 查看包含某个字符串的所有函数 Undo 和 Redo undo 1`C-/` 或者 `C-_` 或者 `C-x u` redo 1`C-g C-/` 或者 `C-g C-_` 或者 `C-g C-x u` redo 的思维就是 “undo undo”. 在光标处插入指定命令的输出结果1`C-u M-! 命令 RET` 打开 emacs 指南 C-h t 或者 F1 t 或者 M-x help-with-tutorial 如果你想看非英文的指南, 可以使用: M-x help-with-tutorial-spec-language RET 然后选择你想看要看语种的指南.(有中文的哦) 替换替换所有完全匹配(非包含), 大小写敏感 M-x replace-string RET 要替换的字符串 RET 新的字符串 RET 包含匹配, 大小写不敏感 M-x replace-regexp RET 要替换的字符串 RET 新的字符串 RET 查询并替换完全匹配, 大小写敏感 M-x query-replace RET 要替换的字符串 RET 新的字符串 RET, 然后按 y 或者 n, 决定是否替换. q 或者 RET 为退出. 包含匹配, 大小写不敏感 M-x query-replace-regexp RET 要替换的字符串 RET 新的字符串 RET, 然后按 y 或者 n, 决定是否替换. q 或者 RET 为退出. 搜索向后搜索 C-r 或者 M-x isearch-backward 搜索的字符串 RET 向前搜索 C-s 或者 M-x isearch-forward RET 搜索的字符串 RET 统计行数 C-x l 插入一个 tab 有时候, 想输入一个tab字符, 但是tab已经有它自己的作用, 特别是在org-mode, 或者是markdown-mode下, tab表示缩略标题及它的内容.这时如果想插入一个原始的tab字符,一般情况下就不适用了.这时可以按以下的做 C-q TAB C-q 表示下一个要输入的是原始(RAW)字符. 从当前光标开始删除到下一个指定的字符为止(包括这个字符)1zap-to-char(M-z) 也是vim里的ct命令. 删除两个单词之间的空格12M-x cycle-spacing或者 Alt+Space Ubuntu下要禁用Alt+Space快捷捷才行. 删除空白行, 只保留一行空白行:1C-x C-o Emacs中的undo-treespacemacs:1M-m a u 命令叫undo-tree-visualize 使用: b:左分支f:右分支p:上一节点n:下一节点q:退出 删除行尾的空格1M-x delete-trailing-whitespace]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Emacs技巧之宏编辑]]></title>
    <url>%2F2015%2F06%2F29%2FEmacs%E6%8A%80%E5%B7%A7%E4%B9%8B%E5%AE%8F%E7%BC%96%E8%BE%91%2F</url>
    <content type="text"><![CDATA[宏编辑 定义: 所谓宏，就是一些命令组织在一起，作为一个单独命令完成一个特定任务. 宏操作 C-x ( 或者 F3 : 开始定义一个键盘操作宏. C-x ) 或者 F4 : 结束定义一个键盘操作宏. C-x e 或者 F4 : 执行键盘宏 C-u 37 C-x e : 重复执行37次该宏 给宏起一个名字 C-x C-k n 或者 M-x kmacro-name-last-macro RET 宏名字 插入指定名字的宏 M-x insert-kbd-macro RET 宏名字 RET 然后按 C-x e 或者 F4 或者 C-u 232 C-x e 或者 C-u 232 F4 来执行宏. 编辑最近一次的录制好的宏 C-x C-k C-e 或者 kmacro-edit-macro 编辑指定名字的宏 C-x C-k e 宏名字 RET 或者 edit-kbd-macro]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Emacs技巧之矩阵编辑]]></title>
    <url>%2F2015%2F06%2F29%2FEmacs%E6%8A%80%E5%B7%A7%E4%B9%8B%E7%9F%A9%E9%98%B5%E7%BC%96%E8%BE%91%2F</url>
    <content type="text"><![CDATA[Emacs中的矩阵编辑 在开始进行矩阵编辑之前, 首先要标记所要编辑的矩阵.矩阵的选择, 是指两个对角的点所在的范围里. 在矩阵编辑中, 所有的指令, 都是以 C-x r 开头的. 矩阵的选择 标记对角的起点. [C-@] 标记对角的终点. [移动光标到对角的另一点的位置即可] 剪切矩阵的内容 C-x r k 或者 M-x kill-rectangle 以某字符串替代矩阵里的每一行的内容 注意,首先要选择好所要编辑的矩阵内容 C-x r t string RET 或者 M-x string-rectangle 粘贴已经复制好或剪切好的矩阵内容 C-x r y 或者 M-x yank-rectangle 为矩阵内的每一行,添加行数数字. 行数, 是以所选择的内容为起始数字, 第一行为1. C-x r N 或者 M-x rectangle-number-lines 更多内容, 请参考 Emacs Rectangles Emacs Rocks!关于矩阵操作的视频]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的Emacs]]></title>
    <url>%2F2015%2F06%2F27%2F%E6%88%91%E7%9A%84Emacs%2F</url>
    <content type="text"><![CDATA[安装Mac Emacs For Mac OS X Ubuntu123sudo add-apt-repository ppa:cassou/emacssudo apt-get updatesudo apt-get install emacs24 安装完Emacs后还要配置好相应的中文输入法问题，经过折腾，总结如下：（ubuntu14.04，fxcti-table-wubi fxcti-table-wubi-large） 下载Unity Tweat Tool这个配置工具 下载Yahei Consolas Hybrid这个字体，并进行安装 利用1）的工具，Fonts这个tab的配置将所有字体都设置为2)的字体并应用 locale 设置123456789101112131415export LANG="en_US.UTF-8"export LANGUAGE="en_US.UTF-8"export LC_CTYPE="zh_CN.UTF-8"export LC_NUMERIC="zh_CN.UTF-8"export LC_TIME="zh_CN.UTF-8"export LC_COLLATE="zh_CN.UTF-8"export LC_MONETARY="zh_CN.UTF-8"export LC_MESSAGES="zh_CN.UTF-8"export LC_PAPER="zh_CN.UTF-8"export LC_NAME="zh_CN.UTF-8"export LC_ADDRESS="zh_CN.UTF-8"export LC_TELEPHONE="zh_CN.UTF-8"export LC_MEASUREMENT="zh_CN.UTF-8"export LC_IDENTIFICATION="zh_CN.UTF-8"export LC_ALL="zh_CN.UTF-8" 安装 markdown-mode markdown-mode 执行以下命令 1git clone git://jblevins.org/git/markdown-mode.git ~/.emacs.d/iemacs/ 添加以下配置到init.el文件中 12345678910;; add markdown start(add-to-list 'load-path "~/.emacs.d/iemacs/markdown-mode/")(autoload 'markdown-mode "markdown-mode" "Major mode for editing Markdown files" t)(add-to-list 'auto-mode-alist '("\\.text\\'" . markdown-mode))(add-to-list 'auto-mode-alist '("\\.markdown\\'" . markdown-mode))(add-to-list 'auto-mode-alist '("\\.md\\'" . markdown-mode));; add markdown end 查看当前模式绑定的以 C-c 开头的按键1C-c C-h]]></content>
      <categories>
        <category>emacs</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记之分析堆]]></title>
    <url>%2F2015%2F06%2F27%2F%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%88%86%E6%9E%90%E5%A0%86%2F</url>
    <content type="text"><![CDATA[常量池的位置 Java 6 及之前, 常量池放在永久区 Java 7 及以后, 字符串常量池放到了堆进行管理.(也就是说可以被垃圾收集器回收) Java 7 及以后, 可以通过虚拟机参数-XX:StringTableSize来指定常量池的大小. 参考资料 string-intern-in-java-6-7-8/ 你真的了解java.lang.String吗?]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记之性能监控工具]]></title>
    <url>%2F2015%2F06%2F26%2F%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[topvmstatiostatpidstat查看某进程及某线程占用CPU的例子 jps: 列出java进程,找到pid. pidstat -p pid -u 1 3 -u -t: 查看pid的进程所有线程的cpu使用情况. jstack -l pid &gt; /tmp/thread.txt: 导出指定Java应用的所有线程. 然后查看 nid=xxx(即第二步里线程号的线程),即可定位到某段代码. 查看某进程及某线程占用IO的例子 jps: 列出java进程,找到pid. pidstat -p pid -u 1 3 -d -t: 查看pid的进程所有线程的IO使用情况. jstack -l pid &gt; /tmp/thread.txt: 导出指定Java应用的所有线程. 然后查看 nid=xxx(即第二步里线程号的线程),即可定位到某段代码. 内存监控 pidstat -r -p pid 1 5:查看某pid进程的内存. jps 查看Java进程1jps -mlv jstat 查看堆运行时信息 格式:jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid JVM进程ID&gt; [&lt;interval 每次统计间隔时间&gt; [&lt;count 统计次数&gt;] ] option 列表 class (类加载器) compiler (JIT) gc (GC堆状态) gccapacity (各区大小) gccause (最近一次GC统计和原因) gcnew (新区统计) gcnewcapacity (新区大小) gcold (老区统计) gcoldcapacity (老区大小) gcpermcapacity (永久区大小) gcutil (GC统计汇总) printcompilation (HotSpot编译统计) jinfo 查看虚拟机参数查看或者修改正在运行的虚拟机参数. 格式:jinfo option 列表 -flag &lt;name&gt; : 查看名为name的虚拟机参数 例如: jinfo -flag MaxThenuringThreshold 111 -flag +|-name:设置指定虚拟机参数的布尔值 -flag &lt;name&gt;=&lt;value&gt;:设置指定虚拟机参数的值 jmap 导出堆到文件统计对象信息1jmap -histo pid &gt; /tmp/heap.txt 导出当前堆快照1jmap -dump:format=b,file=/tmp/heap.hprof pid 查看 ClassLoader 信息1jmap -permstat pid 查看 finalizer 队列中的对象1jmap -finalizerinfo pid 查看内存各区的大小信息1jmap -heap pid jhat 自带的堆分析工具1jhat /tmp/heap.hprof 然后打开浏览器访问 localhost:7000 jstack 查看线程堆栈1jstack [-l] &lt;pid&gt; &gt; /tmp.stack.txt jcmd 多功能命令行[JDK 7自带]12345678#相当于 jpsjcmd -l#查看启动时间jcm pid VM.uptime...更多请使用 jcmd &lt;pid&gt; help 看所支持的命令. hprof 性能统计工具123查看帮助:java -agentlib:hprof=help 查看函数执行时间 123执行Java程序时,添加上以下参数-agentlib:hprof=cpu=times,interval=10 图形化监控工具 jConsole1234567远程配置:-Djava.rmi.server.hostname=127.0.0.1-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.port=8888-Dcom.sun.management.jmxremote.authenticate=false-Dcom.sun.management.jmxremote.ssl=false 多合一工具 Visual VM1234567远程配置:-Djava.rmi.server.hostname=127.0.0.1-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.port=8888-Dcom.sun.management.jmxremote.authenticate=false-Dcom.sun.management.jmxremote.ssl=false Mission Control 该工具在 JDK Update 40 之后. 在bin目录下的 jmc.exe.]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记之垃圾收集器参数]]></title>
    <url>%2F2015%2F06%2F25%2F%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[串行回收器参数 -XX:+UseSerialGC: 在新生代和年老代使用串行收集器 -XX:SurvivorRatio: 设置eden和survivor区大小的比例 -XX:PretenureSizeThreshold: 设置大对象直接进入老年代的阈值.当对象的大小,超过这个值时,直接在年老代分配. -XX:MaxTenuringThreshold: 设置对象进入老年代的年龄最大值.每一次Minor GC后,对象年龄就会加1, 任何大于该值的对象, 就一定会进入老年代. 并行GC相关参数 -XX:+UseParNewGC: 在新生代使用并行收集器 -XX:+UseParallelOldGC: 老年代使用并行收集器 -XX:ParallelGCThreads: 垃圾回收的线程数.一般情况下和CPU数量相等. -XX:MaxGCPauseMillis: 最大垃圾收集停顿时间. 它的值是一个大于0的整数. -XX:GCTimeRatio: 设置吞吐量大小. 它的值是一个0到100之间的整数.假设为N,则系统将花费不超过1/(1+N)的时间用于垃圾收集. -XX:+UseAdaptiveSizePolicy:打开自适应GC策略.它会自动调整新生代大小,eden, survivor的比例,晋升年老对象年龄等来达到平衡点. 与CMS回收器相关参数 -XX:+UseConcMarkSweepGC:新生代使用并行收集器,老年代使用CMS+串行收集器. -XX:ParallelCMSThreads:设置CMS线程数量 -XX:CMSInitiatingOccupancyFraction:设置CMS在老年代空间被使用多少后触发.默认为68%. -XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否进行一次内存碎片整理. -XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后, 进行一次内存压缩. -XX:+CMSClassUnloadingEnabled:允许对类元数据区进行回收 -XX:CMSInitiatingPermOccupancyFraction:当永久区占用率达到这一百分比时,启动CMS回收.(前提是-XX:+CMSClassUnloadingEnabled启用了) -XX:UseCMSInitiatingOccupancyOnly:表示只在到达阈值的时候才进行CMS回收. -XX:+CMSIncrementalMode:使用增量模式.比较适合单CPU. 在JDK 8中标记为废弃, 并且将在JDK 9中彻底移除. 与G1回收器相关参数 -XX:+UseG1GC:启用G1回收器 -XX:MaxGCPauseMillis: 最大垃圾收集停顿时间 -XX:GCPauseIntervalMillis: 设置停顿间隔时间 TLAB 相关 -XX:+UseTLAB:开启TLAB分配 -XX:+PrintTLAB: 打印TLAB相关分配信息 -XX:TLABSize: 设置TLAB大小 -XX:+ResizeTLAB: 自动调整TLAB大小 其他参数 -XX:+DisableExplicitGC:禁用显式调用GC -XX:+ExplicitGCInvokesConcurrent:使用并发方式处理显式GC]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jackson JSON 库使用例子]]></title>
    <url>%2F2015%2F06%2F25%2FJackson-JSON-%E5%BA%93%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[ObjectMapper123它是线程安全的，所以建议使用它时，作为单例使用：private static final ObjectMapper mapper = new ObjectMapper(); Quick Parsing1234String jsonString = &quot;&#123;\&quot;k1\&quot;:\&quot;v1\&quot;,\&quot;k2\&quot;:\&quot;v2\&quot;&#125;&quot;;ObjectMapper mapper = new ObjectMapper();JsonNode actualObj = mapper.readTree(jsonString);assertNotNull(actualObj); Convert JSON to Java Map123456JsonFactory factory = new JsonFactory();ObjectMapper mapper = new ObjectMapper(factory);File from = new File(&quot;albumnList.txt&quot;);TypeReference&lt;HashMap&lt;String,Object&gt;&gt; typeRef = new TypeReference&lt;HashMap&lt;String,Object&gt;&gt;() &#123;&#125;;HashMap&lt;String,Object&gt; o = mapper.readValue(from, typeRef);System.out.println(&quot;Got &quot; + o); Convert JSON to Java List123String value = &quot;&#123;json string&#125;&quot;ObjectMapper om = new ObjectMapper();List&lt;Integer&gt; agentList = om.readValue(value, om.getTypeFactory().constructCollectionType(List.class, Integer.class)); Convert JSON to Java object12ObjectMapper mapper = new ObjectMapper();User user = mapper.readValue(new File(&quot;c:\\user.json&quot;), User.class); Convert JavaObject to JSON String123mapper.writeValue(new File(&quot;c:\\user.json&quot;), user); // display to console System.out.println(mapper.writeValueAsString(user)); Low Level Parsing1234567String jsonString = &quot;&#123;\&quot;k1\&quot;:\&quot;v1\&quot;,\&quot;k2\&quot;:\&quot;v2\&quot;&#125;&quot;; ObjectMapper mapper = new ObjectMapper();JsonFactory factory = mapper.getFactory();JsonParser parser = factory.createParser(jsonString);JsonNode actualObj = mapper.readTree(parser); assertNotNull(actualObj); Use jsonNode1234567String jsonString = &quot;&#123;\&quot;k1\&quot;:\&quot;v1\&quot;,\&quot;k2\&quot;:\&quot;v2\&quot;&#125;&quot;;ObjectMapper mapper = new ObjectMapper(); JsonNode actualObj = mapper.readTree(jsonString); // When JsonNode jsonNode1 = actualObj.get(&quot;k1&quot;); assertThat(jsonNode1.textValue(), equalTo(&quot;v1&quot;)); timestamp解析, string –&gt; timestampstackoverflow 1234567891011class UnixTimestampDeserializer extends JsonDeserializer&lt;DateTime&gt; class TimestampThing &#123; @JsonDeserialize(using = UnixTimestampDeserializer.class) DateTime timestamp @JsonCreator public TimestampThing(@JsonProperty(&apos;timestamp&apos;) DateTime timestamp) &#123; this.timestamp = timestamp &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>json</tag>
        <tag>jackson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记之回收算法]]></title>
    <url>%2F2015%2F06%2F24%2F%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引用计数法 问题1: 无法处理循环引用的情况 问题2: 都要伴随着加减引用计数操作,对性能有一定的影响 名词解释可达对象 通过根对象进行引用搜索, 最终可以达到的对象 不可达对象 通过根对象进行引用搜索,最终没有被引用到的对象 新生代 存放年轻对象的堆空间.年轻对象指刚刚创建的, 或者经历垃圾回收次数不多的对象. 老年代 存放老年对象的堆空间.老年对象指经历多次垃圾回收依然存活的对象. 标记清除(Mark-Sweep) 第一阶段: 首先通过根节点, 标记所有从根节点开始的可达对象.因此未被标记的对象就是未被引用的垃圾对象. 第二阶段: 清除所有未被标记的对象. 最大的问题: 空间碎片. 复制算法 将原有的内存空间分成两块, 每次只使用其中一块, 在垃圾回收时, 将正在使用的内存中的存活对象复制到未使用的内存块中,之后清除正在使用的内存块中的所有对象, 交换两个内存的角色, 完成垃圾回收. 最大问题: 可用内存减半. 在Java新生代串行垃圾回收器中,使用了复制算法的思想.如其中的 from 和 to 空间. 标记压缩算法(Mark-Compact)老年代的一种垃圾回收算法. 第一阶段: 标记 第二阶段: 压缩 第三阶段: 清理 最终效果等同于标记清除算法执行完成后, 再进行一次内存碎片整理. 分代算法 新生代: 复制算法 老年代: 标记压缩算法 或 标记清除算法 分区算法引用类型强引用 强引用可以直接访问目标对象 强引用所指向的对象在任何时候都不会被系统回收,虚拟机宁愿抛出OOM异常,也不会回收强引用所指向对象 强引用可能导致内存泄漏 例如: Object o = new Ojbect(), o 就是强引用. 软引用 一个对象只持有软引用, 那么当堆空间不足时, 就会被回收. 软引用使用java.lang.ref.SoftReference类实现. 弱引用 GC时,只要发现弱引用,就会回收.使用java.lang.ref.WeakFeference 软引用 和 弱引用 都非常适合来保存那些可有可无的缓存数据. 虚引用 和没有引用几乎一样.试图get()时,总是会失败. 并且必须要和队列一起使用, 它的作用在于跟踪垃圾回收过程.]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实战Java虚拟机》学习笔记之常用Java虚拟机参数]]></title>
    <url>%2F2015%2F06%2F23%2F%E3%80%8A%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%B8%B8%E7%94%A8Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[跟踪垃圾回收-XX:+PrintGC例子日志样本： 1[GC 4793K-&gt;377K(15872K), 0.0006926 secs] 表示当前使用了4793K,GC后，使用量变为377K，最大可用为15872K -XX:+PrintGCDetails 格式： [名称:当前某区大小-&gt;GC后某区大小（一共可用某区大小） GC时间跟踪 -XX:+PrintGCTimeStamps 例子: 0.185: [GC 66048K-&gt;53077K(251392K), 0.0977580 secs] -XX:+PrintGCDateStamps 例子: 2014-01-03T12:08:38.102-0100: [GC 66048K-&gt;53077K(251392K), 0.0959470 secs] 指定GC日志到某路径 -Xloggc 默认情况下，GC日志是打印到控制台的，添加这个参数，可以将GC日志重定向到某文件. 例子： -Xloggc:/home/gc.log 查看GC时详细堆信息 -XX:+PrintHeapAtGC 查看应用程序执行时间和停顿时间 -XX:+PrintGCApplicationConcurrentTime 打印应用程序的执行时间 -XX:+PrintGCApplicationStoppedTime 打印应用程序由于GC而产生的停顿时间 查看虚拟机引用信息 -XX:+PrintReferenceGC 类的加载和卸载跟踪 -XX:+TraceClassLoading -XX:+TraceClassUnloading -verbose:class: 这一个参数，相当于上两个一起。 查看虚拟机参数 -XX:+PrintVMOptions: 查看显式传递的参数 -XX:+PrintCommandLineFlags：查看显式和隐式参数 -XX:+PrintFlagsFinal：查看所有包括系统默认的参数 堆的配置 整个堆的大小，公式为： 总堆可用大小（-Xmx) = 老年代 + 新生代 = 老年代 + eden + from + to 新生代总大小，公式为： 新生代（-Xmn）= Eden + from + to 新生代可用大小，公式为： 新生代可用大小 = Eden + from = Eden + to 整个虚拟机最大大小，公式为： 总可用大小 = 持久代 + 年老代 + 新生代 最大堆和初始堆设置 -Xms：初始堆大小 例如：-Xms10m -Xmx：最大堆设置 例如：-Xmx100m 新生代大小 -Xmn：一般设置为整个堆的 1/3到1/4 例如 -Xmn10m -XX:SurvivorRatio：设置新生代中eden和from/to空间的比例关系 例如 -XX:SurvivorRatio=2 -XX:SurvivorRatio = eden/from = eden/to 注意：新生代总可用的空间，只有 eden + from 或者 eden + to。即 新生代总可用空间 = eden + from = eden + to -XX:NewRatio：设置新生代和老年代的比例 例如：-XX:NewRatio=2 -XX:NewRatio=老年代/新生代 堆溢出处理 -XX:+HeapDumpOnOutOfMemoryError：可堆溢出时，导出整个堆信息 -XX:HeapDumpPath：导出到指定的路径 例如 -XX:HeapDumpPath=/home/to/path -XX:OnOutOfMemoryError=&quot;&lt;cmd args&gt;;&lt;cmd args&gt;&quot;：在发现溢出时，执行指定命令 例如: -Xmx20 -XX:+HeapDumpOnOutOfMemoryError “-XX:OnOutOfMemoryError=/path/to/commnd.sh %p” 注意：写法是双引号包括整个参数。%p 表示进程号 非堆区方法区（永久代）[JDK 1.8前] -XX:PermSize：初始永久区大小 例如：-XX:PermSize=64M -XX:MaxPermSize：最大永久区大小 例如：-XX:MaxPermSize=128M 元数据区[JDK 1.8 及之后]默认的情况下，该区只受系统可用内存的限制。但也可以使用参数 -XX:MetaspaceSize：指定初始时的元数据区大小 例如：-XX:MetaspaceSize=128M -XX:MaxMetaspaceSize：指定元数据区的最大可用值。 例如： -XX:MaxMetaspaceSize=256M 直接堆内存配置 -XX:MaxDirectMemorySize: 最大可用直接内存。如果不设置，默认值为最大堆空间，即-Xmx的值。]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实战Java虚拟机》学习笔记之函数调用]]></title>
    <url>%2F2015%2F06%2F22%2F%E3%80%8A%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[出入Java栈Java栈是一块线程私有的内存空间。它是一块先进后出的数据结构。Java栈中保存的主要内容为栈帧。每一次函数调用，都会有一个对应的栈帧被压入栈，每一个函数调用结束，都会有一个栈帧被弹出Java栈。当前正在执行的函数所对应的帧就是当前的帧（位于栈顶），它保存着当前函数的局部变量、中间运算结果等数据。 Java方法有两种返回函数的方式，一种是正常的函数返回，使用return指令；另一种是抛出异常。不管使用哪种方式，都会导致栈帧被弹出。 在一个栈帧中，至少要包含局部变量表，操作数栈，帧数据区几个部分。 Java栈的大小，是通过虚拟机参数-Xss来控制大小的。 函数嵌套调用的层次，在很大程度上由栈的大小决定。栈越大，函数可以支持的嵌套调用次数越多。 局部变量表它用于保存函数的参数及局部变量。局部变量表中的变量只在当前函数调用中有效，当函数调用结束后，随着函数栈帧的销毁，局部变量表也会随之销毁。 由于局部变量表在栈帧之中，因此，如果函数的参数和局部变量较多，会使得局部变量表膨胀，从而每一次函数调用就会占用更多的栈空间，最终导致函数的嵌套调用次数减少。 查看局部变量表的工具： jclasslib 操作数栈操作数栈也是栈帧中重要内容之一，它主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。 帧数据区它保存着访问常量池的指针，方便程序访问常量池。 异常处理表，也是帧数据区中重要的一部分。]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实战Java虚拟机》学习笔记之浮点数表示方式]]></title>
    <url>%2F2015%2F06%2F22%2F%E3%80%8A%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%B5%AE%E7%82%B9%E6%95%B0%E8%A1%A8%E7%A4%BA%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[IEEE 754 标准 Java虚拟机处理浮点数的标准是参考 IEEE 754 规范的。 参考文档 : IEEE 754 标示格式1234567符号位 | 阶码 | 尾数##32位1 位 | 8 位 | 23位##64位1 位 | 11 位 | 52位 阶码（指数位） 指数部分即使用所谓的偏正值形式表示，实际值为表示值与一个固定值(32位的情况是127)的和 单精度的指数部分是-126～+127加上127 ，指数值的大小从1～254（0和255是特殊值）]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实战Java虚拟机》学习笔记之数值表示]]></title>
    <url>%2F2015%2F06%2F21%2F%E3%80%8A%E5%AE%9E%E6%88%98Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%95%B0%E5%80%BC%E8%A1%A8%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[原码 在数值前直接加一符号位的表示法。 123[+7]原= 0 0000111 B[-7]原= 1 0000111 B -127～+127 反码 负数的反码，符号位为“1”，数值部分按位取反。 123[+7]反= 0 0000111 B[-7]反= 1 1111000 B -127～+127 补码 正数的补码和原码相同 负数的补码则是符号位为“1”。并且，这个“1”既是符号位，也是数值位。数值部分按位取反后再在末位（最低位）加1。也就是“反码+1” 123[+7]补= 0 0000111 B[-7]补= 1 1111001 B -128～+127 参考资料 百度百科 补码 百度百科 原码 百度百科 反码]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的Git学习笔记]]></title>
    <url>%2F2015%2F06%2F21%2F%E6%88%91%E7%9A%84Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[常用配置123456789#配置用户名git config --global user.name "Zhiyong yang"#配置邮箱git config --global user.email "dreamers.yzy@gmail.com"#配置编辑器, 这个要先启动emacs: `emacs --daemon`git config --global core.editor "emacsclient -t" 克隆远程代码库1git clone https://github.com/emacsist/emacsist.github.io 初始化本地git仓库12cd projectgit init 将本地仓库映射到远程仓库1git remote add origin https://dreamer_yzy@bitbucket.org/dreamer_yzy/blog.git 拉取远程最新的代码1git pull 推送分支到远程仓库1git push origin master 格式为: git push origin 本地分支名[:远程分支名], 如果远程分支名不写, 就与本地的相同. 添加文件到git跟踪1git add file1 file2 ... git add . 将当前所有除 .gitignore 里除开的忽略文件以外的文件添加到git跟踪. git add dictory 将整个目录及子目录下的文件,添加到git跟踪. 查看git的状态1git status 提交到git暂存区12345添加完整的代码提交说明git commit以简要的方式提交代码说明git commit -m "提交说明" 查看当前文件与上一次提交的差异1git diff 文件路径 回退版本回退到上一个版本1git reset --hard HEAD^ 回退到指定的版本1git reset --hard commitId 查看git的命令历史1git reflog 如果使用 git reset --hard commitId 后,再想恢复回指定的commitID,可以在这里查看对应的commitID. 撤消修改1git checkout -- file 这个修改的意思是最近一次的 git commit或 git add 删除git暂存文件1git rm file git的分支创建分支12创建并切换到新的分支git checkout -b 新的分支名 [远程分支,如 origin/develop] 如果没有指定远程分支, 就会以当前的分支为基础, 创建一个”新的分支名”的分支. 查看所有分支1git branch -v 切换分支1git checkout 分支名 合并分支1git merge --no-ff 分支名 注意, 这条命令的意思是将某个分支,合并到当前分支. 删除分支1git branch -d 分支名 删除远程分支 1git push origin :the_remote_branch 推送到远程仓库1git push origin 分支名[:远程分支名] 拉取远程指定分支1git pull origin 分支名[:远程分支名] git中的标签在当前的提交打上标签1git tag v1.0 指定标签名和说明 1git tag -a v1.0 -m "1.0 version" [commitID] 在指定的提交ID里添加标签1git tag v1.0 commitID 查看所有标签1git tag 查看标签信息1git show 标签名 删除标签1git tag -d v1.0 删除远程标签1git push origin :refs/tags/&lt;tagname&gt; 先删除本地标签,后再删除远程标签 推送标签到远程1234git push origin &lt;tagname&gt;例如git push origin v1.0 推送所有标签到远程1git push origin --tags Git中的子模块使用添加子模块1git submodule add 仓库地址 路径 更新子模块1git submodule update 注意, 默认情况下, clone 主项目时, 子模块不会clone数据, 这时要使用以下命令来将子模块也update下来. 1git submodule update --init --recursive 查看子模块1git submodule 如果可以看到图中子模块前面有一个-，说明子模块文件还未检入（空文件夹）, 这时就要调用更新子模块命令来拉取数据. 删除子模块 从文件 .gitmodules 删除相关的子模块部分 暂存 .gitmodules: git add .gitmodules 从文件 .git/config 删除相关的子模块部分 执行命令: rm --cached path_to_submodule 执行命令: rm -rf .git/modules/path_to_submodule 提交修改: git commit -m &quot;remove submodule xxxsubmodule&quot; 删除未跟踪的文件: rm -rf path_to_submodule .gitignore文件说明忽略所有.a文件, * 为正则匹配,任意字符1*.a 但是 lib.a将被包括进git版本控制, !为非1!lib.a 或略build文件夹及其包含的所有文件1build/ 忽略doc文件夹下所有以及包含的 .txt文件,不包括类似doc/test/tell.txt 这样的文件1doc/*.txt 忽略doc文件夹中所有 .txt文件1doc/**/*.txt gitignore 文件不生效解决办法首先，提交所有你当前所做的修改(git add xxx; git commit -m “xxx”) 然后 123git rm -r --cached .git add .git commit -m "fixed untracked files" pull 或者 push 一直指向当前分支123git pull origin "$(git branch | grep -E '^\* ' | sed 's/^\* //g')"git push origin "$(git branch | grep -E '^\* ' | sed 's/^\* //g')" 回到git的根目录1cd `git rev-parse --show-toplevel` 用master指向游离的版本 使用了 git checkout c681960 后, git的提示变成了这样子: 12345╭─yangzhiyong@yangzhiyongdeMacBook-Pro.local ~/Documents/git/emacsist ‹c681960›╰─➤ git branch -a* (detached from 387a11a) master remotes/origin/master 恢复指示: 步骤1首先, 找到最新的那个分支的commitID 1git reflog 然后记下这个ID,比如,就是现在的c681960 然后进行如下操作: 步骤212345678910111213141516╭─yangzhiyong@yangzhiyongdeMacBook-Pro.local ~/Documents/git/emacsist ‹c681960›╰─➤ git checkout masterWarning: you are leaving 1 commit behind, not connected toany of your branches: c681960 add headIf you want to keep them by creating a new branch, this may be a good timeto do so with: git branch new_branch_name c681960Switched to branch 'master'Your branch is up-to-date with 'origin/master'.╭─yangzhiyong@yangzhiyongdeMacBook-Pro.local ~/Documents/git/emacsist ‹master›╰─➤ 步骤3123456789╭─yangzhiyong@yangzhiyongdeMacBook-Pro.local ~/Documents/git/emacsist ‹master›╰─➤ git merge c6819605b8201ea983261cd6d84d7fc5d91c6c62Updating 387a11a..c681960Fast-forward .gitignore | 1 + db.json | 1 - source/_posts/我的Git学习笔记.md | 88 ++++++++++++++++++++++++++++++++++++++++++++-------------------------------------------- 3 files changed, 45 insertions(+), 45 deletions(-) delete mode 100644 db.json 步骤4恭喜你! 经过上面3个步骤, 你的master又是最新的指向了. 删除敏感数据1234567891011步骤1, 其中 path-to-your-remove-file 就是你要删除的文件路径git filter-branch --force --index-filter 'git rm --cached --ignore-unmatch path-to-your-remove-file' --prune-empty --tag-name-filter cat -- --all推送到远程git push origin master --forcegit push origin --force --tagsGC清理git for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdingit reflog expire --expire=now --allgit gc --prune=now 冲突时，以本地或远程分支的为准12345以远程的为准git checkout --theirs path_to_file以本地的为准git checkout --ours path_to_file Git迁移到另一个远程服务器123456789101112#!/usr/bin/env bashremote=origin for brname in `git branch -r | grep $remote | grep -v master | grep -v HEAD | awk '&#123;gsub(/^[^\/]+\//,"",$1); print $1&#125;'`; do #git branch --set-upstream-to $remote/$brname $brname; git checkout $brname git pull $remote $brnamedonegit remote remove $remotegit remote add $remote https://github.com/emacist/xxx/xx.gitgit push --all 参考文档 廖雪峰 git教程 豆瓣 寻找git最佳实践之#Gitignore详解 阮一锋 Git分支]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github Pages搭建个人Blog]]></title>
    <url>%2F2015%2F06%2F20%2FHexo-Github-Pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BABlog%2F</url>
    <content type="text"><![CDATA[因为 Hexo 版本问题,可能每次的安装及配置不同, 所以,最好还是参照官方的文档来做.这里只是添加一些文档链接,方便日后查询. 安装及配置 Hexo官方网站: Hexo 详细安装方法,参考官方文档 我使用的主题官方网站: Hexo-theme-next 部署到 Github Pages参考: hexo-deploy-git 注意,在执行以下命令时, 可能要等上好一会儿, 当时自己一直以为是卡住了, 或者是出问题,所以常常按 Ctrl+C 来中断. 其实它还在执行中的. 1npm install hexo-deployer-git --save 所以,最好添加上详细输出的参数,看来整个执行的过程: 1npm install hexo-deployer-git --save --verbose]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
        <tag>hexo</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]手把手教你配置流复制]]></title>
    <url>%2F2015%2F01%2F24%2F%E7%BF%BB%E8%AF%91-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E9%85%8D%E7%BD%AE%E6%B5%81%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[[翻译]手把手教你配置流复制原文 尽管许多人知道流复制，这篇博客是为初学者准备的，我将从必要条件和一些关于流复制的介绍开始。:-) 必要条件： 在各自的服务器上安装相同版本的PostgreSQL数据库。 配置”postgres”用户的无密码ssh认证（译注：如使用ssh的公私密匙） 生产环境的服务器必须在postgresql.conf文件配置通过设置archive_mode和archive_command参数来开启WAL归档模式。 生产环境的服务器和备份服务器之间应该一直拥有连接以让归档的WAL文件从生产环境的服务器传输到备份服务器. 明确地配置好你的备份机的环境和目录结构要与生产服务器的一样。 介绍它是一个异步机制；所以备机是延迟于主服务器。但不同于其他复制方法，这个延迟是非常短的，可能是一个单事务的延迟，这取决于网速，数据库负载以及流复制配置。此外，在主机上对每个备机的负载是最小的，允许一个主服务器支持多个备机。 这个特性包含在PostgreSQL 9.0中，伴随的第二个数据库实例（译注：指stand-by是依赖于主服务器的二进制日志，在这期间会标记备机服务器只能接受只读请求） 这是实践步骤所需命令： 1.到主服务器，然后创建一个带有复制权限的replication用户。例如： 1234567$ psql Password for user postgres: psql.bin (9.2.1) Type &quot;help&quot; for help. postgres=# create user replication with replication password &apos;&lt;password&gt;&apos;; 2.我们需要在主服务器的/opt/PostgreSQL92/data/（译注：就是postgresql的数据目录）目录修改postgresql.conf参数以及pg_hba.conf的验证参数。设置好连接及验证，以让备机服务器可以成功地连接到主服务器的replication这个假的数据库。 12345678$ $EDITOR postgresql.conf listen_addresses = &apos;*&apos; $ $EDITOR pg_hba.conf #备机服务器必须有超级用户身份的访问权限host replication replication 10.176.0.0/16 md5 3.在主服务器上设置流复制相关的参数。 123456789101112131415 $EDITOR postgresql.conf #为了在备机服务器上开始“只读”查询，wal_level必须设置成“hot_standby”. 但是，如果你一直不会在stand-by模式下连接到备机，你可以选择“archive” wal_level = hot_standby #设置允许备机的最大并发连接数 max_wal_senders = 5 #为了防止主服务器在循环利用WAL段文件前移动备机服务器所要求的WAL段文件，设置保留在 pg_xlog 目录里最小的段文件数。 wal_keep_segments = 32 #在主服务器上开启WAL归档到一个归档目录以让备服务器获取。如果&quot;wal_keep_segments&quot;值足够大以保留备机所要求的WAL段文件数，这可能就不必要开启。 archive_mode = on archive_command = &apos;cp %p &lt;archive location&gt;%f &amp;&amp; scp %p postgres@10.176.112.189:&lt;archive location&gt;/%f&apos; 注意：在 postgresql文件里修改以上参数时，要重启服务器。 4.在主服务器上重启postgres并检查参数是否生效。 123456789101112131415161718192021222324252627282930postgres=# show archive_command ; archive_command ----------------- cp %p /var/PG92_Archives/%f (1 row) postgres=# show archive_mode ; archive_mode ------------- on (1 row) postgres=# show wal_level ; wal_level ------------ hot_standby (1 row) postgres=# show max_wal_senders ; max_wal_senders ---------------- 5 (1 row) postgres=# show wal_keep_segments ; wal_keep_segments ------------------ 32 5.对主服务器的数据目录做一个基础备份。 1234567891011$ psql ­c &quot;SELECT pg_start_backup(&apos;label&apos;, true)&quot; $ cp /opt/PostgreSQL92/data/* backup/ $psql ­c &quot;SELECT pg_stop_backup()&quot; -- 打包备份目录并传输到备机的数据目录下 $tar ­cvzf backup.tar backup/ $scp backup.tar postgres@10.176.112.189:/opt/PostgreSQL92/ 6.移动备机的数据内容到其他的位置，解压备份的文件并复制解压后的数据到备机的数据目录。 7.在备服务器上像主服务器那样设置复制相关的参数，连接以及验证，以便让备服务器在主服务器宕机之后可以切换成主服务器。 8.在备服务器上开启只读查询。但如果在主服务器上的wal_level参数值是archive，那hot_standby就不需要更改（即是：off） 12$ $EDITOR postgresql.conf hot_standby = on 9.在备机服务器上创建一个恢复命令文件，以下参数对于流复制是必需的。、1234567891011121314$ $EDITOR recovery.conf # 指明是否开启服务器作为一个备机。在流复制里，这个参数必须要开启。standby_mode = &apos;on&apos; # 指明用于备服务器连接到主服务器的连接字符串。 primary_conninfo = &apos;host=10.176.112.188 port=5432 user=replication password=&lt;password&gt; application=&lt;app_name&gt;&apos; # 指定一个触发文件让备服务器感觉到它的时候就会停止流复制（即：故障转移） trigger_file = &apos;&lt;any path=&quot;&quot;&gt;&apos; ===&gt; 不要创建这个文件。当你想主从切换的时候才需要创建它。# 指定一个命令从WAL归档中加载归档段文件。如果“wal_keep_segments”是一个足够大的数值以保留WAL段文件满足备机的要求，这可能不是必要的。但一个高负载情况下可能会导致段文件在备服务器完全同步之前就已经循环利用的，这时就要求你重新开始一个新的基础备份。 restore_command = &apos;cp &lt;archive_location&gt;%f &quot;%p&quot;&apos; &lt;/archive_location&gt;&lt;/any&gt; 10.在备服务器上启动postgres。它就会开始流复制并且你会看到像以下的信息： 1234LOG: entering standby mode LOG: consistent recovery state reached at 0/1D000078 LOG: record with zero length at 0/1D000078 LOG: streaming replication successfully connected to primary 11.你可以通过比较主服务器上的当前的WAL写位置与备服务器上的最新“接收/重做”的WAL位置来计算复制的延迟。它们各自可以通过在主服务器端使用pg_current_xlog_location函数来获取，在备服务器上通过pg_last_xlog_receive_location或者pg_last_xlog_replay_location来获取。12345678910111213141516171819$ psql ­c &quot;SELECT pg_current_xlog_location()&quot; ­h192.168.0.10 (primary host) pg_current_xlog_location 0/2000000 (1 row) $ psql ­c &quot;select pg_last_xlog_receive_location()&quot; ­h192.168.0.20 (standby host) pg_last_xlog_receive_location 0/2000000 (1 row) $ psql ­c &quot;select pg_last_xlog_replay_location()&quot; ­h192.168.0.20 (standby host) pg_last_xlog_replay_location 0/2000000 (1 row) 12.其他检查流复制的方法有：最简单的方法是在备服务器上执行“select now()-pg_last_xact_replay_timestamp();”。pg_last_xact_replay_timestamp()函数给出在恢复期间最近的事务重做的时间戳，这些是在主服务器产生事务产生的提交或中止WAL记录的时间。如果在恢复期间没有事务重做，这个函数就会返回NULL。否则，如果恢复仍然在进行的话，它会一直递增。如果恢复已经完成，这时的值会保留在恢复期间中最近事务重做的值而不会变。当服务器已经正常启动并没有恢复，这个函数就返回NULL.你可以尝试在主服务器上做一些操作，然后检查这个函数的输出。如果你想手工检查主备之间的延迟，那可以做以下步骤： 1234567891011步骤1：在主服务器上使用以下命令来创建表。create table stream_delay (tstamp timestamp without time zone ); insert into stream_delay select now(); 步骤2: 在主服务器上使用调度工具cronjob每分钟执行以下命令。 update stream_delay set tstamp=&apos;now()&apos;; 步骤3: 通过在备服务器上检索&quot;stream_delay&quot;表来证实延迟。它应该显示在主服务器上最近更新的时间。这个时间戳和备服务器的当前时间戳之差就是主服务器和备服务器之间的延迟。 你也可以通过使用ps命令来检查流复制的进展。显示的”LSNs”位置指明了备服务器已经写到了xlog的字节位置。 1234567[primary] $ ps ­ef | grep sender postgres 6879 6831 0 10:31 ? 00:00:00 postgres: wal sender process postgres 127.0.0.1(44663) streaming 0/2000000 [standby] $ ps ­ef | grep receiver postgres 6878 6872 1 10:31 ? receiver process streaming 0/2000000 谢谢大家，请让我知道我是否遗漏了什么。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]PostgreSQL 9.0 内存 & 进程]]></title>
    <url>%2F2015%2F01%2F09%2F-%E7%BF%BB%E8%AF%91-PostgreSQL-9-0-%E5%86%85%E5%AD%98-%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原文作者：Raghav 在PostgreSQL构架基础上进一步了解，在这里，通过信息链接我将会讨论关于实用进程和内存。许多提交者已经好好地记录了关于进程和内存，在这里有提供链接。在我这里有适当关于PostgreSQL实用进程的描述。 每个PostgreSQL实例启动，会有一组实用进程（包括强制性和可选性进程）和内存。两个强制性进程（bgwriter后台写进程和walwriter预写式日志写进程）。你可以通过命令ps -ef | grep postgres检测一下，结果如图10.1. 图10.1 进程和内存概要图10.2 关于图10.2，它表明了进程附加到PostgreSQL共享内存。 BGWriter/Writer Process后台写进程或者叫写进程:后台写进程或者叫写进程是一种强制性进程: 所有PostgreSQL服务器进程从磁盘读取数据然后将它们移到共享缓冲池（Shared Buffer Pool）里。 共享缓冲池使用ARC算法或者LRU（最近最少使用）机制来淘汰页数据。BGWRITER后台写进程很多时候都是在休眠，但每次唤醒，它通过搜索共享缓冲池（Shared Buffer Pool）来寻找被修改的页。每次搜索完之后，BGWRITER后台写进程就会选择那些被修改的页，将它们写到磁盘，然后将它们从共享缓冲池里淘汰出来。后台写进程通过三个参数BGWRITER_DELAY、BGWRITER_LRU_PERCENT以及BGWRITER_LRU_MAXPAGES来控制。 http://www.enterprisedb.com/docs/en/9.0/pg/kernel-resources.htmlhttp://www.enterprisedb.com/docs/en/8.4/pg/runtime-config-resource.html WAL Writer Process预写式日志写进程:预写式日志写进程是一个强制性进程。 预写式日志写进程在适当间隔时会写入并进行文件同步。为了保证事务安全，预写式日志缓冲区在事务日志里持有数据库的更改操作。预写式日志缓冲区在每次事务提交时写到磁盘，预写式日志写进程负责写到磁盘。WAL_WRITER_DELAY参数是用于调用预写式日志写进程的，然而，还有其他参数同样会使预写式日志写进程比较繁忙。下面有一些链接。 http://www.enterprisedb.com/docs/en/8.4/pg/wal-configuration.html Stats Collector Process状态收集进程:状态收集进程是可选进程，默认是开启的。 状态收集进程会收集一些关于服务器运作的信息。它会计算访问表和索引二者磁盘块的数量和个别的行项数（我注：一个block有可能多个row item，可以通过 select ctid from tbname来查看，第一个数字就是block数，第二个就是row item数)。它同样会跟踪每一个表的总行数，每一个表关于VACUUM（清理）和ANALYZE（分析）动作的信息。收集这些统计数据会对查询执行有额外的开销，自己决定收不收集这些信息。以下的链接有更多关于状态收集进程以及相关参数的说明。 http://www.enterprisedb.com/docs/en/9.0/pg/monitoring-stats.html Autovacuum Launcher Process自动清理启动器进程:自动清理进程是一个可选进程，默认是开启的。 为了自动执行VACUUM和ANALYZE命令，自动清理启动器进程是由许多被称为autovacuum workers(自动清理工作者)组成的后台进程。自动清理启动器进程负责启动autovacuum workers(自动清理工作者)进程来处理所有数据库。启动器会按交叉时间地分发工作，在每个时间间隔里会试图在每一个数据库里启动一个工作者（我注：指autovacuum workers），通过参数autovacuum_naptime来设置间隔时间。每个数据库都会启动一个工作者，通过参数autovacuum_max_workers来设置最大数。每一个工作者进程都会在它所在的数据库里检查每一张表，然后在有需要的时候执行VACUUM或者ANALYZE命令。以下的链接有更多关于AUTOVACUUM自动清理启动器进程的相关参数的说明。 http://www.enterprisedb.com/docs/en/8.4/pg/runtime-config-autovacuum.html Syslogger Process / Logger Process系统日志进程或者叫日志进程 :图10.3 日志是一个可选进程，默认是关闭的。 依据图10.3， 可以清楚地理解所有 实用进程+用户后台进程 + Postmaster守护进程都附加到系统日志进程来记录这它们的活动信息。每一个进程信息都会被记录在PGDATA/pg_log 目录下的.log文件里。注意：如果数据目录是通过INITDB命令创建的，pg_log目录不会在数据目录里自动创建。需要显式地创建该目录。 调试更多的进程信息会导致服务器的一些额外开销。总是建议日志是最低级别的，如果有要求的话再提高调试级别。以下的链接有更多关于日志参数的说明。 http://www.enterprisedb.com/docs/en/8.4/pg/runtime-config-logging.html Archiver Process归档进程:图10.4 归档进程是可选进程，默认是关闭的。 上面图10.4 是从我观察PostgreSQL的归档进程而制作的。设置数据库为归档模式，意味着捕捉预写式日志（WAL）数据填充到每个段文件。在段文件重新回收利用之前，会将数据保存到某些地方。 图中每个数字标签的解释。 1.在数据库的归档模式，一旦预写式日志（WAL）数据填充满了预写式日志（WAL）段文件，填充满的段文件会被预写式日志写进程（WAL Writer）在目录$PGDATA/pg_xlog/archive_status下创建一个后缀为”.ready”的文件。文件名将会是“段文件名.ready”。 2.归档进程就会触发去查找那些被预写式日志写进程创建的“.ready”状态的文件。归档进程选择那些后缀是”.ready”的”段_文件号”文件，然后从$PGDATA/pg_xlog复制这些文件到archive_command参数（在postgresql.conf）指定的目的地里。 3.成功地从源目录复制到目的目录，归档进程会重命名”段-文件名.ready”为段-文件名.done。这就完成了归档的过程。 不用说，如果在$PGDATA/pg_xlog/archive_status目录里有任何名为”段-文件名.ready”的文件都是正等待着被复制到归档目的地里（我注：通过参数archive_command来指定）。 更多关于参数和归档的信息，请看以下链接。 http://www.enterprisedb.com/docs/en/9.0/pg/continuous-archiving.html 请把你的意见/建议提交在这篇文章中,将不胜感激。 献上我真诚的问候Raghav]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]PostgreSQL 9.0 构架]]></title>
    <url>%2F2015%2F01%2F08%2F-%E7%BF%BB%E8%AF%91-PostgreSQL-9-0-%E6%9E%84%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[原文 作者：Raghavendra很高兴在这里发布我的第一篇博客，是关于 PostgreSQL 构架的。 在很长一段时间里，我在工作、学习上都广泛地接触PostgreSQL。作为一个初学者，想到尝试给出一张关于 PostgreSQL 的架构图。PostgreSQL构架包括几部分：内存、进程和文件存储系统，这难以在一张图里展示所有东西。我尽我所能地给出一个关于PostgreSQL构架的概要。 大部分的设计都是在我们的PostgreSQL提交者（Heikki,Robert Haas,Bruce）的帮助下完成的， 我从他们身上学习到了很多关于PostgreSQL内部的东西。 非常感谢他们的协作让我了解到关于PostgreSQL的一切。我不是黑客，也不是构架师，仅仅是为PostgreSQL新手写了一篇文章。请留下你的评论、建议或者发现到我写文章的任何错误也可留言。 PostgreSQL 9.0 构架概述PostgreSQL实例由一系列进程和内存组成。PostgreSQL 使用一个简单的 “每个用户一个进程” 的 客户/服务器 模型。PostgreSQL 有许多种类型进程。 postmaster进程，是后台监听进程，postmaster附加到共享内存段（我注：其实就是通过共享内存来进行进程间的通信），但是尽量避免访问它（我注：避免我们自定义去访问该共享内存，而是由PG内部各进程进行协调）。 实用进程（bgwriter后台写进程，walwriter预写式日志写进程，syslogger系统日志进程，archiver归档进程，statscollector状态收集器进程 以及 autovacuum自动清理进程）以及 用户后台进程（postgres进程自身，服务器进程） 当有一个客户端请求连接到数据库时，首先，请求被postmaster后台进程执行身份认证，受权之后会复制一个服务器后台进程（postgres进程）来处理该请求。从那时起，客户端进程和服务器端进程进程通信，而不再需要postmaster介入。因此，postmaster进程是一直在运行的，一直等待连接请求，然而客户端和服务器端进程会继续进行通信。libpq库允许一个单客户端连接到多个服务器进程。 然而，每个后台进程都是单线程的，一次仅仅只能执行一条查询；所以，任何的一个前端-后台连接都是单线程的。postmaster进程和postgres进程都是以PostgreSQL的”超级用户”身份的用户ID来运行的。每个打开数据库的会话里都会存在一个postgres进程。一旦经过身份验证的用户连接,它就会与共享内存直接连接（与谁，目的是做什么）。 内存 Shared Buffers，共享缓冲区 WAL Buffers，预写式日志缓冲区 clog Buffers，是一种 SLRU 类型的缓冲区(Commit log，提交日志缓冲区） Other Buffers，其他缓冲区 PostgreSQL共享内存是非常大的并且所有缓冲区都没有同步的，这意味着都是独立的。一些专家/提交者已经将他们的大量关于PostgreSQL的经验信息放在网站上。结合PostgreSQL文档和这个构架图就会对PostgreSQL构架的有个基础的了解。以下链接有更多概述. http://www.postgresql.org/docs/9.0/interactive/runtime-config-resource.htmlhttp://www.enterprisedb.com/docs/en/8.4/pg/runtime-config-resource.htmlhttp://www.postgresql.org/files/documentation/books/aw_pgsql/hw_performance/0.html 实用进程:强制性进程：这些进程是没有选项来 开启/关闭 的 BGWriter WAL Writer 可选进程：这些进程是有选项来 开启/关闭 的 Stats-collector，状态收集进程 Autovacuum launcher，自动清理进程 Archiver，归档进程 Syslogger，系统日志进程 WAL Sender，预写式日志发送进程 WAL Receiver，预写式日志接收进程 不久，我将会提交一张关于实用性进程和用户后台进程的概要图 献上我真诚的问候Raghav]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《啊哈！算法》学习笔记之栈]]></title>
    <url>%2F2015%2F01%2F08%2F%E3%80%8A%E5%95%8A%E5%93%88%EF%BC%81%E7%AE%97%E6%B3%95%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%A0%88%2F</url>
    <content type="text"><![CDATA[栈实现也很简单，只需要一个一维数组和一个指向栈顶的变量 top 就可以了。我们通过 top 来对栈进行插入和删除操作。 ##特点：后进先出 利用栈判断是否回文（java实现）1234567891011121314151617181920212223242526public static void main(String[] args) &#123; char[] character = &#123; &apos;a&apos;, &apos;a&apos;, &apos;h&apos;, &apos;a&apos;, &apos;a&apos; &#125;; char[] stack = new char[10]; int top = -1; int mid = character.length % 2 == 0 ? character.length / 2 - 1 : character.length / 2; for (int i = 0; i &lt;= mid; i++) &#123; top++; stack[top] = character[i]; &#125; if (character.length % 2 == 0) &#123; mid++; &#125; for (int i = mid; i &lt; character.length; i++) &#123; if (top &gt;= 0) &#123; if (stack[top] != character[i]) &#123; break; &#125; &#125; top--; &#125; if (top == -1) &#123; System.out.println(&quot;YES&quot;); &#125; else &#123; System.out.println(&quot;NO&quot;); &#125;&#125;]]></content>
      <categories>
        <category>编程</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>啊哈！算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《啊哈！算法》学习笔记之队列]]></title>
    <url>%2F2015%2F01%2F08%2F%E3%80%8A%E5%95%8A%E5%93%88%EF%BC%81%E7%AE%97%E6%B3%95%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[列队的主要特点：先进先出文中题目规则是这样的：首先将第 1个数删除，紧接着将第 2 个数放到这串数的末尾，再将第 3 个数删除并将第 4 个数放到这串数的末尾，再将第 5 个数删除……直到剩下最后一个数，将最后一个数也删除。按照刚才删除的顺序，把这些删除的数连在一起就是小哈的 QQ啦. Java实现例如：加密过的一串数是 “6 3 1 7 5 8 9 2 4”，输出应该是“6 1 5 9 4 7 2 8 3”1234567891011121314151617public static void main(String[] args) &#123; int[] array = &#123; 6, 3, 1, 7, 5, 8, 9, 2, 4 &#125;; int[] queue = new int[100]; int head = 0; int tail = 0; for (int i = 0; i &lt; array.length; i++) &#123; queue[i] = array[i]; tail++; &#125; while (head &lt; tail) &#123; System.out.println(queue[head]); head++; queue[tail] = queue[head]; tail++; head++; &#125;&#125;]]></content>
      <categories>
        <category>编程</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>啊哈！算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《啊哈！算法》学习笔记之快速排序]]></title>
    <url>%2F2015%2F01%2F08%2F%E3%80%8A%E5%95%8A%E5%93%88%EF%BC%81%E7%AE%97%E6%B3%95%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的一边，将大于等于基准点的数全部放到基准点的另一边. 时间复杂度因此快速排序的最差时间复杂度和冒泡排序是一样的，都是 O(N^2 )，它的平均时间复杂度为 O(NlogN)。 Java实现（从大到小）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static void main(String[] args) &#123; int length = 20; int maxValue = 20; int[] array = new int[length]; Random r = new Random(); for (int i = 0; i &lt; array.length; i++) &#123; array[i] = r.nextInt(maxValue); &#125; System.out.println(Arrays.toString(array)); quickSort(array, 0, length-1); System.out.println(Arrays.toString(array));&#125; // 假设以左边的为基数，那就要从右边开始移动。左为大于基数，右为小于基数public static void quickSort(int[] array, int leftPoint, int rightPoint) &#123; if (leftPoint &gt; rightPoint) &#123; return; &#125; int swapTmp = 0; int baseNumber = array[leftPoint];// 以左边为基准 int i = leftPoint; int j = rightPoint; while (leftPoint != rightPoint) &#123; // 从右边开始向左移动，到找第一个大于基数时停止 while (array[rightPoint] &lt;= baseNumber &amp;&amp; leftPoint &lt; rightPoint) &#123; rightPoint--; &#125; // 从左边开始向右移动，到找第一个小于基数时停止 while (array[leftPoint] &gt;= baseNumber &amp;&amp; leftPoint &lt; rightPoint) &#123; leftPoint++; &#125; // 没有相遇时，就交换 if (leftPoint &lt; rightPoint) &#123; swapTmp = array[leftPoint]; array[leftPoint] = array[rightPoint]; array[rightPoint] = swapTmp; &#125; &#125; //恢复新一轮的基准，将旧的基准归位，然后又重新定一个新的左边基准位。即将基准数与中间数互换 array[i] = array[leftPoint]; array[leftPoint] = baseNumber; //递归左，右两边 quickSort(array, i, leftPoint-1); quickSort(array, leftPoint+1, j);&#125;]]></content>
      <categories>
        <category>编程</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>啊哈！算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《啊哈！算法》学习笔记之冒泡排序]]></title>
    <url>%2F2015%2F01%2F08%2F%E3%80%8A%E5%95%8A%E5%93%88%EF%BC%81%E7%AE%97%E6%B3%95%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想冒泡排序的基本思想是：每次比较两个相邻的元素，如果它们的顺序错误就把它们交换过来。 以从大到小为例。 每次都是比较相邻的两个数，如果后面的数比前面的数大，则交换这两个数的位置。一直比较下去直到最后两个数比较完毕后，最小的数就在最后一个了。就如同是一个气泡，一步一步往后“翻滚” ，直到最后一位。所以这个排序的方法有一个很好听的名字“冒泡排序” 。 每将一个数归位我们将其称为“一趟” 。每一趟，都是将小的归位（先是最小，后次小，次后第三小…）。 如果有 n 个数进行排序，只需将 n-1 个数归位，也就是说要进行n-1 趟操作。而“每一趟”都需要从第 1 位开始进行相邻两个数的比较，将较小的一个数放在后面，比较完毕后向后挪一位继续比较下面两个相邻数的大小，重复此步骤，直到最后一个尚未归位的数， 已经归位的数则无需再进行比较 （已经归位的数你还比较个啥， 浪费表情） 。 核心思想冒泡排序的核心部分是双重嵌套循环。 ##时间复杂度：O（N^2） ##Java实现 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) &#123; int length = 10; int maxValue = 20; int[] array = new int[length]; Random r = new Random(); for (int i = 0; i &lt; array.length; i++) &#123; array[i] = r.nextInt(maxValue); &#125; System.out.println(&quot;before&quot;); print(array); bubbleSort(array); System.out.println(&quot;after&quot;); print(array);&#125; public static void bubbleSort(int[] array) &#123; int tmp = 0; for (int i = 0; i &lt; array.length; i++) &#123; for (int j = 0; j &lt; array.length-1; j++) &#123; if (array[j] &lt; array[j+1]) &#123;//如果前一个比后一个小，则进行交换。这样子就可以是从大到小。 tmp = array[j]; array[j] = array[j+1]; array[j+1] = tmp; &#125; &#125; &#125;&#125; public static void print(int[] array) &#123; System.out.println(Arrays.toString(array));&#125; 总结冒泡比较耗时]]></content>
      <categories>
        <category>编程</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>啊哈！算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《啊哈！算法》学习笔记之桶排序]]></title>
    <url>%2F2015%2F01%2F06%2F%E3%80%8A%E5%95%8A%E5%93%88%EF%BC%81%E7%AE%97%E6%B3%95%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%A1%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[时间复杂度：O(M+N)M:桶的个数（也是该数值的最大数）N:待排序个数 Java实现随便输入N个不大于M的数字，然后从小到大输出：（从大到小，作一下小修改即可）1234567891011121314151617public static void main(String[] args) &#123; int M= 100; int N = 5; int[] array = new int[M+ 1]; Scanner scan = new Scanner(System.in); int in = 0; for (int i = 0; i &lt; N; i++) &#123; in = scan.nextInt(); array[in] = array[in] + 1; &#125; for (int i = 0; i &lt; array.length; i++) &#123; for (int j = 0; j &lt; array[i]; j++) &#123; System.out.println(i); &#125; &#125;&#125; 个人总结这种算法适合于范围比较小的排序，并且是需要知道输入的最大值。不然就不适用了。]]></content>
      <categories>
        <category>编程</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>啊哈！算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用PostgreSQL无限递归 SELECT 评论系统]]></title>
    <url>%2F2015%2F01%2F05%2F%E4%BD%BF%E7%94%A8PostgreSQL%E6%97%A0%E9%99%90%E9%80%92%E5%BD%92-SELECT-%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[假设有个评论系统，要求支持无限层级的回复，就像一棵树那样 12345 文章 / \ / \评论1 评论2.... 注意可以有任意个子树以及做任意个叶子 大意的表结构12345678create table comments ( comment_id serial primary key, parent_id bigint, bug_id bigint not null, author varchar(20) not null, comment text not null, foreign key (parent_id) references comments(comment_id)); 1234567891011test=# select * from comments; comment_id | parent_id | bug_id | author | comment ------------+-----------+--------+--------+--------------------- 1 | | 1 | Fran | 这个bug的成因是什么 2 | 1 | 1 | Ollie | 我觉得是一个空指针 3 | 2 | 1 | Fran | 不，我查过了 4 | 1 | 1 | Kukla | 我们需要查无效输入 5 | 4 | 1 | Ollie | 是的，那是个问题 6 | 4 | 1 | Fran | 好，查一下吧 7 | 6 | 1 | Kukla | 解决了(7 rows) SQL语句利用递归查询，可以查某篇文章评论组成的树结构。其中 depth是树的深度，显示的时候，按已经排序好的层次及相应的父结点显示出来就可以了。 1234567891011121314test=# with RECURSIVE commenttree (comment_id, bug_id, parent_id, author, comment, depth) as (select comment_id, bug_id, parent_id, author, comment , 0 as depth from comments where parent_id is null union all select c.comment_id, c.bug_id, c.parent_id, c.author, c.comment, ct.depth+1 as depth from commenttree as ct join comments as c on (ct.comment_id = c.parent_id)) select * from commenttree where bug_id = 1;; comment_id | bug_id | parent_id | author | comment | depth------------+--------+-----------+--------+---------------------+------- 1 | 1 | | Fran | 这个bug的成因是什么 | 0 2 | 1 | 1 | Ollie | 我觉得是一个空指针 | 1 4 | 1 | 1 | Kukla | 我们需要查无效输入 | 1 3 | 1 | 2 | Fran | 不，我查过了 | 2 5 | 1 | 4 | Ollie | 是的，那是个问题 | 2 6 | 1 | 4 | Fran | 好，查一下吧 | 2 7 | 1 | 6 | Kukla | 解决了 | 3(7 rows) test=# 注意PostgreSQL里，必须加 RECURSIVE 才能支持递归。 内容来源资料：[1]《SQL反模式》]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL使用 postgres_fdw 进行跨库操作]]></title>
    <url>%2F2015%2F01%2F05%2FPostgreSQL%E4%BD%BF%E7%94%A8-postgres-fdw-%E8%BF%9B%E8%A1%8C%E8%B7%A8%E5%BA%93%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[说明该 postgres_fdw 模块提供了 远程-数据 包装器 postgres_fdw，它能够用于访问一些保存在外部 PostgreSQL 服务器的数据。 该模块提供的功能很大程度上与以前的dblink模块重叠。但是postgres_fdw 提供了更加透明和符合标准的语法来访问远程表，并且能够在某些情况下有更好的性能。 安装extensioncd contrib/postgres_fdwmake install 安装到数据库123test=# CREATE EXTENSION postgres_fdw;CREATE EXTENSIONtest=# 检查是否安装成功12345678test=# \dx postgres_fdw; List of installed extensions Name | Version | Schema | Description --------------+---------+--------+---------------------------------------------------- postgres_fdw | 1.0 | public | foreign-data wrapper for remote PostgreSQL servers(1 row) test=# 创建并查看一个远程服务器1234567891011121314151617test=# \dx postgres_fdw; List of installed extensions Name | Version | Schema | Description --------------+---------+--------+---------------------------------------------------- postgres_fdw | 1.0 | public | foreign-data wrapper for remote PostgreSQL servers(1 row) test=# CREATE SERVER postgres_server FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host &apos;10.0.0.10&apos;, port &apos;5432&apos;, dbname &apos;test&apos;);CREATE SERVERtest=# \des; List of foreign servers Name | Owner | Foreign-data wrapper-----------------+----------+----------------------postgres_server | postgres | postgres_fdw(1 row) test=# 创建一个远程映射用户1CREATE USER MAPPING FOR PUBLIC SERVER postgres_server OPTIONS (user &apos;postgres&apos;, password &apos;yang&apos;); user,password 是远程数据库上的用户名和密码 创建一个远程映射表123test=# CREATE FOREIGN TABLE tcost_foreign (path integer, cost numeric) SERVER postgres_server OPTIONS (schema_name &apos;public&apos;, table_name &apos;tcost&apos;);CREATE FOREIGN TABLEtest=# 操作像它在本地表一样操作就可以了。 资料：[1] 官网]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转载]你知道数据库索引的工作原理吗？]]></title>
    <url>%2F2015%2F01%2F05%2F-%E8%BD%AC%E8%BD%BD-%E4%BD%A0%E7%9F%A5%E9%81%93%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[转载自：http://www.ituring.com.cn/article/986作者：李松峰 发表于 2012-02-04 11:43 译者按：今天在翻译时无意中搜索到StackOverflow中的这篇文章（问答），觉得有必要翻译出来。不仅因为文章本身写得精彩，更重要的是它昭示了一个写文章（特别是技术文章）的重要法则——5W1H。 原文在此 How does database indexing work?（作者：Xenph Yan） 问：随着数据库的增大，既然索引的作用那么重要，有谁能抛开具体的数据库来解释一下索引的工作原理？ 答：（我自己来回答这个问题，:o-)） 为什么需要索引数据在磁盘上是以块的形式存储的。为确保对磁盘操作的原子性，访问数据的时候会一并访问所有数据块。磁盘上的这些数据块与链表类似，即它们都包含一个数据段和一个指针，指针指向下一个节点（数据块）的内存地址，而且它们都不需要连续存储（即逻辑上相邻的数据块在物理上可以相隔很远）。 鉴于很多记录只能做到按一个字段排序，所以要查询某个未经排序的字段，就需要使用线性查找，即要访问N/2个数据块，其中N指的是一个表所涵盖的所有数据块。如果该字段是非键字段（也就是说，不包含唯一值），那么就要搜索整个表空间，即要访问全部N个数据块。 然而，对于经过排序的字段，可以使用二分查找，因此只要访问log2 N个数据块。同样，对于已经排过序的非键字段，只要找到更大的值，也就不用再搜索表中的其他数据块了。这样一来，性能就会有实质性的提升。 什么是索引索引是对记录按照多个字段进行排序的一种方式。对表中的某个字段建立索引会创建另一种数据结构，其中保存着字段的值，每个值又指向与它相关的记录。这种索引的数据结构是经过排序的，因而可以对其执行二分查找。 索引的缺点是占用额外的磁盘空间。因为索引保存在MyISAM数据库中，所以如果为同一个表中的很多字段都建立索引，那这个文件可能会很快膨胀到文件系统规定的上限。 索引的原理首先，来看一个示例数据库表的模式： 12345字段名 数据类型 在磁盘上的大小id (Primary key) Unsigned INT 4 字节firstName Char(50) 50 字节lastName Char(50) 50 字节emailAddress Char(100) 100 字节 注意：这里用char而不用varchar是为了精确地描述数据占用磁盘的大小。这个示例数据库中包含500万行记录，而且没有建立索引。接下来我们就分析针对这个表的两个查询：一个查询使用id（经过排序的键字段），另一个查询使用firstName（未经排序的非键字段）。 示例分析一对于这个拥有r = 5 000 000条记录的示例数据库，在磁盘上要为每条记录分配 R = 204字节的固定存储空间。这个表保存在MyISAM数据库中，而这个数据库默认的数据库块大小为 B = 1024字节。于是，我们可计算出这个表的分块因数为 bfr = (B/R) = 1024/204 = 5，即磁盘上每个数据块保存5条记录。那么，保存整个表所需的数据块数就是 N = (r/bfr) = 5000000/5 = 1 000 000。 使用线性查找搜索id字段——这个字段是键字段（每个字段的值唯一），需要访问 N/2 ＝ 500 000个数据块才能找到目标值。不过，因为这个字段是经过排序的，所以可以使用二分查找法，而这样平均只需要访问log2 1000000 = 19.93 = 20 个块。显然，这会给性能带来极大的提升。 再来看看firstName字段，这个字段是未经排序的，因此不可能使用二分查找，况且这个字段的值也不是唯一的，所以要从表的开头查找末尾，即要访问 N = 1 000 000个数据块。这种情况通过建立索引就能得到改善。 如果一条索引记录只包含索引字段和一个指向原始记录的指针，那么这条记录肯定要比它所指向的包含更多字段的记录更小。也就是说，索引本身占用的磁盘空间比原来的表更少，因此需要遍历的数据块数也比搜索原来的表更少。以下是firstName字段索引的模式：123字段名 数据类型 在磁盘上的大小firstName Char(50) 50 字节（记录指针） Special 4 字节 注意：在MySQL中，根据表的大小，指针的大小可能是2、3、4或5字节。 示例分析二对于这个拥有r = 5 000 000条记录的示例数据库，每条索引记录要占用 R = 54字节磁盘空间，而且同样使用默认的数据块大小 B = 1024字节。那么索引的分块因数就是 bfr = (B/R) = 1024/54 = 18。最终这个表的索引需要占用 N = (r/bfr) = 5000000/18 = 277 778个数据块。 现在，再搜索firstName字段就可以使用索引来提高性能了。对索引使用二分查找，需要访问 log2 277778 = 18.09 = 19个数据块。再加上为找到实际记录的地址还要访问一个数据块，总共要访问 19 + 1 = 20个数据块，这与搜索未索引的表需要访问277 778个数据块相比，不啻于天壤之别。 什么时候用索引创建索引要额外占用磁盘空间（比如，上面例子中要额外占用277 778个数据块），建立的索引太多可能导致磁盘空间不足。因此，在建立索引时，一定要慎重选择正确的字段。 由于索引只能提高搜索记录中某个匹配字段的速度，因此在执行插入和删除操作的情况下，仅为输出结果而为字段建立索引，就纯粹是浪费磁盘空间和处理时间了；这种情况下不用建立索引。另外，由于二分查找的原因，数据的基数性（cardinality）或唯一性也非常重要。对基数性为2的字段建立索引，会将数据一分为二，而对基数性为1000的字段，则同样会返回大约1000条记录。在这么低的基数性下，索引的效率将减低至线性查找的水平，而查询优化器会在基数性小于记录数的30%时放弃索引，实际上等于索引纯粹只会浪费空间。 查询优化器的原理查询优化中最核心的问题就是精确估算不同查询计划的成本。优化器在估算查询计划的成本时，会使用一个数学模型，该模型又依赖于对每个查询计划中涉及的最大数据量的基数性（或者叫重数）的估算。而对基数性的估算又依赖于对查询中谓词选择因数（selection factor of predicates）的估算。过去，数据库系统在估算选择性时，要使用每个字段中值的分布情况的详尽统计信息，比如直方图。这种技术对于估算孤立谓词的选择符效果很好。然而，很多查询的谓词是相互关联的，例如 select count(*) from R where R.make=&#39;Honda&#39; and R.model=&#39;Accord&#39;。查询谓词经常会高度关联（比如，model=&#39;Accord&#39;的前提条件是make=&#39;Honda&#39;），而估计这种关联的选择性非常困难。查询优化器之所以会选择低劣的查询计划，一方面是因为对基数性估算不准，另一方面就是因为遗漏了很多关联性。而这也是为什么数据库管理员应该经常更新数据库统计信息（特别是在重要的数据加载和卸载之后）的原因。（译自维基百科：http://en.wikipedia.org/wiki/Query_optimizer。）]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]使用部分索引来加速PostgreSQL]]></title>
    <url>%2F2015%2F01%2F04%2F-%E7%BF%BB%E8%AF%91-%E4%BD%BF%E7%94%A8%E9%83%A8%E5%88%86%E7%B4%A2%E5%BC%95%E6%9D%A5%E5%8A%A0%E9%80%9FPostgreSQL%2F</url>
    <content type="text"><![CDATA[原文 本文经过原作者Dan Robinson同意翻译。（我在twitter发送推文和他互动） 你知道PostgreSQL支持表的部分索引吗？这使得读取部分索引是非常快速的，几乎没有什么索引开销。如果你想重复地分析那些匹配给定的 WHERE 子句的行数据，那部分索引是最好的索引数据的方式。这使得PostgreSQL非常适合于那种涉及预聚集额外的特别分析的工作流。在这一点上，我将通过一个非常适合使用部分索引的查询优化示例来实践下。 思考一下，具有以下模式的事件表：1234567CREATE TABLE event ( user_id BIGINT, event_id BIGINT, time BIGINT NOT NULL, data JSON NOT NULL, PRIMARY KEY (user_id, event_id)) 每一个事件都与用户关联，并且有一个ID，一个time，以及一个 JSON 表示事件。JSON包括页面路径，事件类型（例如：点击，查看页面，提交表单），以及其他任何描述事件的属性。 我们可以使用这张表来保存许多不同的事件，为了我们以后可以分析数据，让我们假设有许多自动跟踪并记录每次点击，查看页面以及表单提交的事件。我们可能想要一个内部的表盘可以显示一些高值指标，例如每周的注册数或者我们的每天收益数。与表盘相关的事件只是这个表的一个小的组成部分——在你的网站上最终购买的点击数占非常小的百分比。但它们被混合在表的其余部分，所以我们的“信噪比”比较低。 我们可能喜欢索引我们的数据来加快表盘的查询[1]。让我们从注册事件开始，我们定义一个表单提交到我们的 /signup 页面。获取9月份第一周的注册数可以这样子写：123456SELECT COUNT(*)FROM eventWHERE (data-&gt;&gt;&apos;type&apos;) = &apos;submit&apos; AND (data-&gt;&gt;&apos;path&apos;) = &apos;/signup/&apos; AND time BETWEEN 1409554800000 AND 1410159600000 在一个1000万个事件数据集里，有3000个是注册事件，并且没有任何索引，这条查询耗时45秒。 在每个单列里建立索引：混合一个天真地认为提高这个性能的方法是：为每个相关事件的特性：(data-&gt;&gt;&#39;type&#39;), (data-&gt;&gt;&#39;path&#39;), and time 都创建一个单列索引。 我们使用这三个索引的位图索引扫描得出结果，如果该查询是有选择性的并且相关的索引部分都在内存的这可能会比较快速。的确，这些索引在适当的位置时，该查询在初始化时耗时200ms，随后再耗时20ms在执行合并数据集上——这显著改善了耗时45秒的顺序扫描。 但是这种索引策略有一些非常大的缺点: 写开销. 我们需要在每个 插入/更新/删除 操作该表数据时都要写这三个索引的数据[2]。 对于在该例子里需要频繁写数据来说，这可能代价太高了。 限制查询结果集。这种策略约束了我们定义高值事件类型的能力。如果我们需要一些比在JSON里其中之一的字段的范围更复杂的查询就无法工作了。 假如我们想要匹配一个正则，或者查看所有以/signup/开头，后面可以接任何字符的页面路径？ 磁盘使用。在我们测试的数据集合里，该表的大小高达 6660 MB，并且这三个索引一总占用1026MB，为了支持该表，我们需要大幅增加硬盘空间。[3] 进入部分索引我们只是仅仅分析 0.03% 的组成注册事件的表数据，但是上面这种索引策略索引了所有行。我们希望能够高效地执行查询表的一小部分数据。类似像这种情况，最好的结果是使用部分索引。 如果我们索引一个不相关的列并且限制我们的索引是匹配注册定义事件的，PostgreSQL可以非常容易地确定注册事件的数据行在哪里，并且比在相关字段里建立完整的索引更高效地查询这些数据。特别注意，考虑索引time字段，但仅仅是匹配那些过滤好的注册事件的行。这是： 12CREATE INDEX event_signups ON event (time)WHERE (data-&gt;&gt;&apos;type&apos;) = &apos;submit&apos; AND (data-&gt;&gt;&apos;path&apos;) = &apos;/signup/&apos; 使用这个索引，我们的执行测试查询初始化耗时200ms，并且紧接耗费2ms来执行，因此，如果我们经常执行这种查询，这会提高性能。更重要的是，部分索引解决了上面提到的三个组合的索引的三个缺点。 它仅仅占用 96KB 空间， 这比完整索引所有这三个字段占用1026MB空间提升了10000 倍。 当新行匹配我们过滤好的注册事件时，我们才需要写部分索引。由于这里有 0.03% 的注册事件，这种数据分布显著提高了写性能：实际上这是由于部分索引而免费得到的。 PostgreSQL只是允许那些完全表达式过滤的部分加入。我们定义索引的 WHERE 子句可以使用我们可能在一条查询里使用的任何行过滤表达式。我们使用这方式来匹配更多复杂事件的定义，比如正则表达式，函数结果，或者上面提到的前缀匹配的例子。 避免索引那些谓词结果为布尔值的数据我见过的另一种方式是试图索引布尔表达式： 1(data-&gt;&gt;&apos;type&apos;) = &apos;submit&apos; AND (data-&gt;&gt;&apos;path&apos;) = &apos;/signup/&apos; 直接地，将time放在第二个字段，像这样： 12CREATE INDEX event_signup_time ON event(((data-&gt;&gt;&apos;type&apos;) = &apos;submit&apos; AND (data-&gt;&gt;&apos;path&apos;) = &apos;/signup/&apos;), time) 这比以上两种方式更加糟糕，它产生的结果是PostgreSQL的查询计划不会理解我们的查询例子来约束那些在索引里第一个字段为true的行。这是因为，查询计划不知道 WHERE 子句：1WHERE (data-&gt;&gt;&apos;type&apos;) = &apos;submit&apos; AND (data-&gt;&gt;&apos;path&apos;) = &apos;/signup/&apos; 是与下面我们索引的这个字段为必须为true的是相等的。 1((data-&gt;&gt;&apos;type&apos;) = &apos;submit&apos; AND (data-&gt;&gt;&apos;path&apos;) = &apos;/signup/&apos;) 因此， 在我们的扫描里，使用该索引来限制事件的时间范围，但是它无论这个正则表达式是true还是false都会读取所有事件(译者注：这里指的是通过时间范围查出来的所有事件)，加载完毕后才对每一行进行检查条件。[4] 因此，我们就会从磁盘里读取比实际需要的更加多的行，并且还要对每一个结果行执行重要的检查条件。在我们的数据集里，该查询开始执行时耗时25秒，之后再连续执行8秒。事实的真相是，这比仅索引time字段差一点，在执行上是等同的。 部分索引对于预先计算那些通过谓词来匹配表的子集来说是一个非常强大的方式。通过流量判断 #postgresql IRC 并没有被充分利用。相比完全索引，它们允许一个更好的谓词范围。它们明显地更加轻量级，需要更少地写操作以及更少的磁盘空间，特别是那些高选择性的过滤。如果你重复地查询一个表的一小部分行，那么部分索引应该是你的默认策略。 爱上PostgreSQL了吗？还有人可能知道更多关于部分索引的知识？发推给我 @danlovesproofs 对构建使强大的技术变得易用的系统感兴趣？向我们投递留言到 jobs@heapanalytics.com. [1] 我们可能使用分表来解决这种情况，将高值事件和低值事件分到不同的子表，但是如果有许多不同的高值事件时这种方式就比较笨拙了，并且我们想要添加一个新类型的高值事件时，每次都需要重新分表。 [2] 我们可能得到一些通过优化只在堆元组上的免更新，但是，至少在每次的插入和删除时将需要写这三个索引。 [3] 我们可以索引这三个字段为一个组合索引，例如在：((data-&gt;&gt;’type’), (data-&gt;&gt;’path’), time)。这占用 755MB 空间，节约了 26% ，但这仍然是非常大的，其他的缺点也一样有。更重要的是，在这些数据上，索引会更少地应用到其他的查询，因此，如果我们正支持一些不同的同值事件，这可能不会节约我们的任何空间。 [4] 相应的查询计划： 1234567 QUERY PLAN --------------------------------------------------------------------------------------------------------------- Aggregate (cost=820866.05..820866.06 rows=1 width=0) -&gt; Index Scan using event_signup_time on event (cost=0.43..820865.99 rows=27 width=0) Index Cond: ((&quot;time&quot; &gt;= 1409554800000::bigint) AND (&quot;time&quot; &lt;= 1410159600000::bigint)) Filter: (((data -&gt;&gt; &apos;type&apos;::text) = &apos;submit&apos;::text) AND ((data -&gt;&gt; &apos;path&apos;::text) = &apos;/signup/&apos;::text))(4 rows)]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL注意事项]]></title>
    <url>%2F2015%2F01%2F02%2FSQL%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[关于排序表是一个集合的概念，所以除非你显式地指定 order by 来排序，否则数据库是不保证每次返回的结果顺序是一样的。只是保证在没有修改的情况下，返回的数量是相同的。 关于大小写虽然SQL是不区分大小写的，但对于列名和表名和值可能在不同的数据库里有不同的对待（表名，列名值等可能是大小写敏感的）。 关于 select *除非你确实需要表中的每一列，否则最好别使用*通配符。虽然使用通配符能让你自己省事，不用明确列出所需列，但检索不需要的列通常会降低检索和应用程序的性能。 关于 distinctDISTINCT 关键字作用于所有列，不仅仅是跟在其后的那一列。 关于按列排序通常 order by 子句使用的列将是为显示而选择的列，但实际上并不一定要这样，用非检索的列排序数据是完全合法的。 关于按列排序的顺序order by 排序的顺序完全按规定进行。即按跟在 order by 后面的指定列顺序来排序，先排第一个列的数据，然后再排序第二个出现的列，第三个等等。 关于排序的位置order by 列的位置号[, 列的位置号2，列的位置号3 …]。这个列的位置是指select 后跟着的列的位号，数字从1开始，即第一个列的序号为1，以此类推。 注意，这种order by 排序，必须是出现在select 后指定的列的，而不能够是非select出来的列。 升序，降序ASC，DESC，这些关键字，只应用到直接按位于其前面的列名。默认情况下都是升序。 关于 between and它的范围是包括开始值，也包括结束值。 关于选择 NULL 值的数据不能用 where col = NULL，而要用 where col IS NULL 关于 and 和 or 的顺序and 的优先级高于 or，所以 col1 = 10 or col2 = 11 and col3 = 13，会被RDBMS理解成：col1 = 10 or （col2 = 11 and col3 = 13）。 自己可以显式加圆括号来按自己指定的逻辑进行。如 （col1 = 10 or col2 = 11） and col3 = 13，这样子括号里的就会优先进行。 所以，复杂点的SQL都建议显式地指定圆括号来指示逻辑顺序。 关于 IN 和 OR，IN的优点1）IN操作符一般比一组OR操作符执行得更快。2）IN的最大优点是可以包含其他的SELECT语句，更能动态建立WHERE子句3）IN比OR的执行顺序更明确（与其他AND等组合时） 关于AVG()函数AVG()函数只能用来确定特定数值列的平均值，而且列名必须作为函数参数给出。为了获得多个列的平均值，必须使用多个AVG()函数。而且 AVG() 函数忽略列值为NULL的行。 关于COUNT()函数使用COUNT(*)对表中行的数目进行计数，不管表列是否包含NULL都会统计。 使用COUNT(col)对表中特定值的行进行计数，但会忽略NULL值 。 关于MAX()，MIN()，SUM()MAX()函数和MIN()函数和SUM()函数，都会会忽略列值为NULL的行。 关于 COUNT 和 DISTINCT 混合如果指定列名，则DISTINCT只能用于COUNT(DISTINCT COL)。但是DISTINCT不能用于COUNT(*)。而且DISTINCT后只能跟列名，不能用于计算或表达式。 关于GROUP BY1）GROUP BY 子句可以包含任意数目的列，因而可以对分组进行嵌套，更细致地进行数据分组。 2）如果在GROUP BY子句中嵌套了分组，数据将在最后指定的分组上进行汇总。换句话说，在建立分组时，指定的所有列都一起计算（所以不能从个别的列取回数据） 3）GROUP BY子句中列出的每一列都必须是检索列或有效的表达式（但不能是聚集函数）。如果在SELECT中使用表达式，则必须在GROUP BY子句中指定相同的表达式。不能使用别名。 4）大多SQL实现不允许GROUP BY列带有长度可变的数据类型（如文本或备注型字段） 5）除聚集计算语句外，SELECT语句中的每一列都必须在GROUP BY子句中给出 6）如果分组中包含具有NULL值的行，则NULL将作为一个分组返回。如果列中有多行NULL值，它们将分为一组。 7）GROUP BY子句必须出现在WHERE子句之后，ORDER BY 子句之前。 ##关于 WHERE 和 HAVING 的区别 WHERE是分组之前过滤的，HAVING是分组之后过滤的。 关于SELECT语法顺序123456SELECTFROMWHEREGROUP BYHAVINGORDER BY 关于子查询作为子查询的SELECT语句只能查询单个列。企图检索多个列将返回错误。 关于SELECT子查询1select (select xxx from xx) , col from xx2 这种子查询对检索出的每一行都会执行一次。 关于连接表 笛卡儿积：如果两个连接的表，没有连接条件的话，检索出的行数，将是第一个表中的行数 x 第二个表中的行数。 公共点：所有的连接，第一步都是做笛卡儿积。 交叉连接（cross join）笛卡儿积的联结，也叫交叉连接(cross join) 等值连接（也叫内连接）两种方式123select a.col, b.col from a, b where a.pid = b.pid;select a.col, b.col from a inner join b on a.pid = b.pid 但是根据ANSI SQL规范，首选的是第二种。 内连接（基于连接谓词将两张表(如 A 和 B)的列组合在一起，产生新的结果表。） 等值连接 相等连接 (equi-join，或 equijoin)，是比较连接(θ连接)的一种特例，它的连接谓词只用了相等比较。使用其他比较操作符(如 &lt;)的不是相等连接 自然连接 自然连接比相等连接的进一步特例化。两表做自然连接时，两表中的所有名称相同的列都将被比较，这是隐式的。自然连接得到的结果表中，两表中名称相同的列只出现一次. 叉连接 交叉连接(cross join)，又称笛卡尔连接(cartesian join)或叉乘(Product)，它是所有类型的内连接的基础。把表视为行记录的集合，交叉连接即返回这两个集合的笛卡尔积。这其实等价于内连接的链接条件为”永真”，或连接条件不存在. 如果 A 和 B 是两个集合，它们的交叉连接就记为: A × B. 外连接外连接并不要求连接的两表的每一条记录在对方表中都一条匹配的记录. 连接表保留所有记录 – 甚至这条记录没有匹配的记录也要保留. 外连接可依据连接表保留左表, 右表或全部表的行而进一步分为左外连接, 右外连接和全连接. 左外连接 若 A 和 B 两表进行左外连接, 那么结果表中将包含”左表”(即表 A)的所有记录, 即使那些记录在”右表” B 没有符合连接条件的匹配. 这意味着即使 ON 语句在 B 中的匹配项是0条, 连接操作还是会返回一条记录, 只不过这条记录的中来自于 B 的每一列的值都为 NULL. 这意味着左外连接会返回左表的所有记录和右表中匹配记录的组合(如果右表中无匹配记录, 来自于右表的所有列的值设为 NULL). 如果左表的一行在右表中存在多个匹配行, 那么左表的行会复制和右表匹配行一样的数量, 并进行组合生成连接结果. 右外连接 右外连接, 亦简称右连接, 它与左外连接完全类似, 只不过是作连接的表的顺序相反而已. 如果 A 表右连接 B 表, 那么”右表” B 中的每一行在连接表中至少会出现一次. 如果 B 表的记录在”左表” A 中未找到匹配行, 连接表中来源于 A 的列的值设为 NULL. 其实可以通过变换表位置来使用左外连接。 全连接 全连接是左右外连接的并集. 连接表包含被连接的表的所有记录, 如果缺少匹配的记录, 即以 NULL 填充. 自连接自连接就是和自身连接. 优先使用自连接，而不是子查询一般来说，DBMS处理连接远比处理子查询快得多。但应该都试一下，以确定哪一种的性能更好。 ##连接算法 嵌套循环 合并连接 哈希连接 集合查询：并（union）在各个select语句之间加上关键字union就可以了。使用union时，默认情况下会自动去除重复的行。可以添加上 union all 来返回所有行，包括重复的。 限制 1）union中的每个查询必须包含相同的列、表达式或聚集函数（顺序并不要求） 2）列数据类型必须兼容：类型不必完全相同，但必须是DBMS可以隐含转换的类型 union中使用order by在union时，只能使用一条order by 子句，它必须位于最后一条select语句之后。因为，对于结果集来说，不存在用一种方式排序一部分，而又用另一种方式排序另一部分的情况，因此，不允许使用多条order by 。 关于insert没给出列名的情况如果没有显式给出列名，那么values后各列是对应它在表定义中出现的顺序的。 insert select 语句1insert into t (col1, col2) select col11, col2 from t2; 注意，是没有values的哦。 select into语句SQLite：1select * into totable from fromtable; PostgreSQL，MySQL，Oracle等的方式：1create table totable as select * from fromtable; 即，将fromtable表所有数据，复制到totable中。 关于视图 视图是不能索引的 视图是可以嵌套的（性能低） 视图包含的不是数据，而是根据需要检索数据的查询。视图提供了一种封装select语句的层次，可以用来简化数据处理，重新格式化或保护基础数据。 关于存储过程 简单（通过封装，将复杂逻辑放在一个单元中） 安全（简化表名，列名或业务逻辑等其他内容的变化时的管理） 高性能（存储过程是以编译后的形式存储的，所以DBMS处理命令的工作较少，从而提高性能） 关于游标它是一个存储在DBMS服务器上的数据库查询，它不是一条SELECT语句，而是被该语句检索出来的结果集。 关于主键 任意两行的主键值都不相同 每行都具有一个主键值（即不允许NULL值） 包含主键值的列从不修改或更新（允许DBMS允许，也不要这样子做） 主键仁政不能重用。如果从表中删除某一行，其主键值不分配给新行。 唯一约束 表可以包含多个唯一约束，但只允许一个主键 可以包含NULL值 可以修改或更新 唯一约束，不能用来定义外键 关于索引 索引改善检索的性能，但降低了数据插入、修改和删除的性能。 索引数据可能要占用大量存储空间 并非所有数据都适合做索引。取值不多的数据，不如具有更多可能值的数据，能通过索引得到那么多的好处。 索引用于数据过滤和数据排序。 可以在索引中定义多列。这样子使用索引的要求时，必须按定义出现的索的顺序为前缀。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL窗口函数中 ROWS 和 RANGE 模式的区别]]></title>
    <url>%2F2015%2F01%2F01%2FPostgreSQL%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E4%B8%AD-ROWS-%E5%92%8C-RANGE-%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[示例表数据如下：123456789101112131415test=# select * from tcost ; path | cost ------+------- 111 | 23.3 111 | 33.4 111 | 3.4 222 | 3.4 222 | 33.4 222 | 333.4 32 | 3.4 32 | 0.4 32 | 0.04(9 rows) test=# ROWS123456789101112131415test=# select path, cost, sum(cost) over (order by cost desc) as sum_cost, sum(cost) over (order by cost desc rows between current row and 2 following ) as row from tcost; path | cost | sum_cost | row ------+-------+----------+------- 222 | 333.4 | 333.4 | 400.2 111 | 33.4 | 400.2 | 90.1 222 | 33.4 | 400.2 | 60.1 111 | 23.3 | 423.5 | 30.1 111 | 3.4 | 433.7 | 10.2 32 | 3.4 | 433.7 | 7.2 222 | 3.4 | 433.7 | 3.84 32 | 0.4 | 434.1 | 0.44 32 | 0.04 | 434.14 | 0.04(9 rows) test=# 可以看到 max2 的值都是由 current row （当前行） and 2 following(紧接着2行）的sum()结果出来的。即400.2 = 333.4 + 33.4 + 33.4 得出的。90.1 = 33.4 + 33.4 + 23.3 得出的。 注意，上面那条SQL没有写 partition by ，那默认情况下就是以整个表来表示窗口化的，即只有一个窗口。现在试着，添加上partition by 语句的结果看看： 123456789101112131415test=# select path, cost, sum(cost) over (order by cost desc) as sum_cost, sum(cost) over (partition by path order by cost desc rows between current row and 2 following ) as row from tcost; path | cost | sum_cost | row ------+-------+----------+------- 32 | 3.4 | 433.7 | 3.84 32 | 0.4 | 434.1 | 0.44 32 | 0.04 | 434.14 | 0.04 111 | 33.4 | 400.2 | 60.1 111 | 23.3 | 423.5 | 26.7 111 | 3.4 | 433.7 | 3.4 222 | 333.4 | 333.4 | 370.2 222 | 33.4 | 400.2 | 36.8 222 | 3.4 | 433.7 | 3.4(9 rows) test=# 当 partition by path时，可以看到，这些ROWS 模式，都是在当前所在的窗口来进行的，并不会跨窗口来进行。所以，在这里强调一下，ROWS表示的是物理行。 RANGE看看，当是RANGE时的结果123456789101112131415test=# select path, cost, sum(cost) over (order by cost desc) as sum_cost, sum(cost) over (order by cost desc range between current row and UNBOUNDED following ) as range from tcost; path | cost | sum_cost | range ------+-------+----------+-------- 222 | 333.4 | 333.4 | 434.14 111 | 33.4 | 400.2 | 100.74 222 | 33.4 | 400.2 | 100.74 111 | 23.3 | 423.5 | 33.94 111 | 3.4 | 433.7 | 10.64 32 | 3.4 | 433.7 | 10.64 222 | 3.4 | 433.7 | 10.64 32 | 0.4 | 434.1 | 0.44 32 | 0.04 | 434.14 | 0.04(9 rows) test=# 可以看到，RANGE时，相同数据的会被合并到一起再来进行计算，也表明，列中具有相同值的range的值也是相同的，并且结果是它们合并后进行计算后的结果。 123456789101112131415test=# select path, cost, sum(cost) over (order by cost desc) as sum_cost, sum(cost) over (order by cost desc range between current row and UNBOUNDED following ) as range,sum(cost) over (order by cost desc rows between current row and UNBOUNDED following ) as row from tcost; path | cost | sum_cost | range | row ------+-------+----------+--------+-------- 222 | 333.4 | 333.4 | 434.14 | 434.14 111 | 33.4 | 400.2 | 100.74 | 100.74 222 | 33.4 | 400.2 | 100.74 | 67.34 111 | 23.3 | 423.5 | 33.94 | 33.94 111 | 3.4 | 433.7 | 10.64 | 10.64 32 | 3.4 | 433.7 | 10.64 | 7.24 222 | 3.4 | 433.7 | 10.64 | 3.84 32 | 0.4 | 434.1 | 0.44 | 0.44 32 | 0.04 | 434.14 | 0.04 | 0.04(9 rows) test=# 这里可以非常明显看到RANGE和ROWS的区别。ROWS：是按物理行来进行区分的RANGE：是按数值进行逻辑区分的 RANGE 和 ROWS 在PostgreSQL中的语法12[ RANGE | ROWS ] frame_start[ RANGE | ROWS ] BETWEEN frame_start AND frame_end frame_start 和 frame_end可以是：12345UNBOUNDED PRECEDINGvalue PRECEDINGCURRENT ROWvalue FOLLOWINGUNBOUNDED FOLLOWING 特别注意：value PRECEDING和value FOLLOWING 当前只允许ROWS模式。RANGE模式后面只能接 UNBOUNDED FOLLOWING。 默认的框架选项是RANGE UNBOUNDED PRECEDING，该选项与 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW相同。有ORDER BY， 它设置框架从分区的开始一直到与当前行相同的最后一行。没有ORDER BY， 那么就是当前分区的所有行都包含在框架中，因为所有行都会成为当前行的相同行。 RANGE时，请注意有没有 order by 的区别123456789101112131415test=# select path, cost, sum(cost) over (order by cost desc) as sum_cost, sum(cost) over (range between current row and UNBOUNDED following ) as no_order_by_range,sum(cost) over (order by cost desc range between current row and UNBOUNDED following ) as has_order_by_range from tcost; path | cost | sum_cost | no_order_by_range | has_order_by_range------+-------+----------+-------------------+-------------------- 222 | 333.4 | 333.4 | 434.14 | 434.14 111 | 33.4 | 400.2 | 434.14 | 100.74 222 | 33.4 | 400.2 | 434.14 | 100.74 111 | 23.3 | 423.5 | 434.14 | 33.94 111 | 3.4 | 433.7 | 434.14 | 10.64 32 | 3.4 | 433.7 | 434.14 | 10.64 222 | 3.4 | 433.7 | 434.14 | 10.64 32 | 0.4 | 434.1 | 434.14 | 0.44 32 | 0.04 | 434.14 | 434.14 | 0.04(9 rows) test=# 没有ORDER BY， 那么就是当前分区的所有行都包含在框架中，因为所有行都会成为当前行的相同行。ROWS时，请注意有没有 order by 的区别123456789101112131415test=# select path, cost, sum(cost) over (order by cost desc) as sum_cost, sum(cost) over (rows between current row and UNBOUNDED following ) as no_order_by_rows,sum(cost) over (order by cost desc rows between current row and UNBOUNDED following ) as has_order_by_rows from tcost; path | cost | sum_cost | no_order_by_rows | has_order_by_rows------+-------+----------+------------------+------------------- 222 | 333.4 | 333.4 | 434.14 | 434.14 111 | 33.4 | 400.2 | 100.74 | 100.74 222 | 33.4 | 400.2 | 67.34 | 67.34 111 | 23.3 | 423.5 | 33.94 | 33.94 111 | 3.4 | 433.7 | 10.64 | 10.64 32 | 3.4 | 433.7 | 7.24 | 7.24 222 | 3.4 | 433.7 | 3.84 | 3.84 32 | 0.4 | 434.1 | 0.44 | 0.44 32 | 0.04 | 434.14 | 0.04 | 0.04(9 rows) test=# 有没有ORDER BY，都是一样的，因为ROWS是按物理分行的，而不是按逻辑分行的。总结1234567ROWS：是按物理行来进行窗口级别里再次进行范围选择的。RANGE：是按逻辑行来进行窗口级别里再次进行范围选择的。RANGE时，相同行会被合并成同一条数据再进行计算，相同行窗口计算时的结果也是相同的。是否是相同行，是根据ORDER BY排序时的结果决定的。有ORDER BY时：同行是说在ORDER BY排序时不唯一的行。【即具有相同数值的行】 不同行是说ORDER BY排序时具有不同的数值的行。没有ORDER BY：那么就是当前分区的所有行都包含在框架中，因为所有行都会成为当前行的相同行。【特别要注意最后一句的意思】]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]为什么PostgreSQL的logo是一个大象？]]></title>
    <url>%2F2015%2F01%2F01%2F-%E7%BF%BB%E8%AF%91-%E4%B8%BA%E4%BB%80%E4%B9%88PostgreSQL%E7%9A%84logo%E6%98%AF%E4%B8%80%E4%B8%AA%E5%A4%A7%E8%B1%A1%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[原文地址 我也不知道，也不敢肯定为什么PostgreSQL的logo是一头大象 … 我正试着找出这个答案。 到现在为至，我最好的猜测是因为以下这个事实：在许多文化里，大象是众所周知的，具有非常好的记忆力的，或者至少是一个非常好记忆力的象征…因此，我们可以说：大象是可以非常棒地保存（数据库！）记忆（数据！）…或者换句话说：“大象是永不忘记的”… 这仅仅是我自己认为和大胆猜测的。 不过，我已经找到几个关于PostgreSQL logo原型的有趣的和确定的事情： PostgreSQL的logo的大象名字叫”Slonik” “Slonik”意思是”小象”并且名字来自”slony”(复数）或”slon”(单数）其中之一，分别来自俄罗斯单词“слоны”意思是“大象”（复数）或者“大象”（单数） 是不是很有趣？无论PostgreSQL的logo历史是如何的，它是一个非常棒的开源数据库。如果我发现更多关于”Slonik”的资料，我会再来更新的。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java乱码解决方案]]></title>
    <url>%2F2014%2F12%2F29%2FJava%E4%B9%B1%E7%A0%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 1.Tomcat配置： &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;UTF-8&quot; useBodyEncodingForURI=&quot;true&quot;/&gt; 2.文件：必须设置统一编码 JSP：&lt;%@ page language=&quot;java&quot; pageEncoding=&quot;UTF-8&quot;%&gt; HTML：&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=utf-8&quot;&gt; ServletRequest: request.setCharacterEncoding(&quot;UTF-8&quot;)是把提交内容的字符集设为UTF－8 ServletResponse: response.setCharacterEncoding(&quot;UTF-8&quot;) 3. MySQL default-character-set=utf-8 mysql里数据库和表也都设为utf8_unicode_ci jdbc:mysql://localhost/mydb?useUnicode=true&amp;characterEncoding=utf-8 4. PostgreSQL postgresql.conf文件中的client_encoding改成UTF-8, 5. 注意：使用 FileInputStream 读取文件时，使用的是系统默认的字符编码。如果用在UTF-8系统中，很容易出现问题。 这时，可以使用： FileInputStream in = new FileInputStream(&quot;g:\\yufa.txt&quot;); InputStreamReader reader = new InputStreamReader (in,&quot;GBK&quot;); // 用这个方法读取，并指定编码 6. Java中的 properties 文件，如果是使用 utf-8 文件格式的，这个格式是无 BOM 格式的UTF-8的。切记 7. Spring &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; ``` #response.setCharacterEncoding()，response.setContentType()区别 response.setContentType指定 HTTP 响应的编码,同时指定了浏览器显示的编码. response.setCharacterEncoding设置HTTP 响应的编码,如果之前使用response.setContentType设置了编码格式,则使用response.setCharacterEncoding指定的编码格式覆盖之前的设置.与response.setContentType相同的是,调用此方法,必须在getWriter执行之前或者response被提交之前. ```]]></content>
      <categories>
        <category>编程</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java 基础学习</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL查看及设置参数、单位、描述等信息]]></title>
    <url>%2F2014%2F12%2F26%2FPostgreSQL%E6%9F%A5%E7%9C%8B%E5%8F%8A%E8%AE%BE%E7%BD%AE%E5%8F%82%E6%95%B0%E3%80%81%E5%8D%95%E4%BD%8D%E3%80%81%E6%8F%8F%E8%BF%B0%E7%AD%89%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[注意123参数名：不区分大小写。参数值：布尔、整数、浮点数、字符串（大小写无关， 枚举参数值是不区分大小写的）布尔值可以是：on, off, true, false, yes, no, 1, 0 或这些东西的任意清晰无歧义的前缀。 123内存单位：kB(千字节), MB(兆字节), GB(吉字节)； 时间单位：ms(毫秒), s(秒), min(分钟), h(小时), d(天)。 内存单位中的&quot;千&quot;是1024， 不是1000。 查看参数的默认单位1select name, unit from pg_settings; 查看参数允许的枚举1select name, enumvals from pg_settings; 设置参数方式一：在 postgresql.conf设置 方式二：在启动时传递参数：postgres -c log_connections=yes -c log_destination=’syslog’ 在 psql 里查看及设置参数12查看：show postgresql.conf中的参数名;设置：set postgresql.conf中的参数名 TO 参数值 | set postgresql.conf中的参数名=参数值]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL删除表空间]]></title>
    <url>%2F2014%2F12%2F26%2FPostgreSQL%E5%88%A0%E9%99%A4%E8%A1%A8%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[昨天在群里看到有同鞋问：如何删除表空间？因为删除的时候，一直报123postgres=# drop tablespace mytmp;ERROR: tablespace &quot;mytmp&quot; is not emptypostgres=# 原因想要删除表空间，那么该表空间必须为空（即没有任何其他的对象会使用到该表空间）才能被删除。 找出有哪些对象使用到了表空间SQL语句：1234567891011121314postgres=# SELECT c.relname, t.spcnameFROM pg_class c JOIN pg_tablespace t ON c.reltablespace = t.oidWHERE t.spcname = &apos;mytmp&apos;;relname | spcname---------+--------- tsp | mytmp(1 row) postgres=# 删除找到表空间的使用对象时，这时如果确实要删除表空间，那就要将该表空间下的表对象都删除了最后才能删除表空间。 删除该表空间下的表123postgres=# drop table tsp;DROP TABLEpostgres=# 删除该表空间123postgres=# drop tablespace mytmp;DROP TABLESPACEpostgres=# 再检查一次看看1234567891011121314151617181920postgres=# select * from pg_tablespace where spcname = &apos;mytmp&apos;;spcname | spcowner | spcacl | spcoptions---------+----------+--------+------------(0 rows) postgres=# postgres=# SELECT postgres-# c.relname,postgres-# t.spcnamepostgres-# FROMpostgres-# pg_class cpostgres-# JOIN pg_tablespace t ON c.reltablespace = t.oidpostgres-# WHEREpostgres-# t.spcname = &apos;mytmp&apos;;relname | spcname---------+---------(0 rows) postgres=#]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL中 copy 和 \copy 的区别]]></title>
    <url>%2F2014%2F12%2F26%2FPostgreSQL%E4%B8%AD-copy-%E5%92%8C-copy-%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[权限123copy 必须要以超级用户来运行\copy 则不必 文件位置12345copy 的文件必须是在服务器端的位置\copy 的则是在客户端的位置。所以，文件的权限方面，copy是以服务器的为准，\copy 是以客户端的为准 例子DB服务器：10.0.0.101234567postgres=# \du yang; List of roles Role name | Attributes | Member of -----------+------------+----------- yang | | &#123;&#125;postgres=# 客户端（10.0.0.11）连接到DB服务器（10.0.0.10）客户端运行copy命令（11）： /tmp/tcopy.txt该文件是在客户端（10.0.0.11)的，DB服务器（10.0.0.10）并不存在该文件。 1234test=&gt; copy tcopy from &apos;/tmp/tcopy.txt&apos;;ERROR: must be superuser to COPY to or from a fileHINT: Anyone can COPY to stdout or from stdin. psql&apos;s \copy command also works for anyone.test=&gt; 它会报告必须要以数据库的超级用户身份才能运行copy命令。 客户端运行\copy命令（11）：123test=&gt; \copy tcopy from &apos;/tmp/tcopy.txt&apos;;COPY 3test=&gt; 它没有报告必须要以数据库的超级用户来运行，而且也没有报告文件或目录不存在的问题。 在DB（10.0.0.10）服务器端修改用户yang为超级用户:123postgres=# alter role yang superuser ;ALTER ROLEpostgres=# 然后在客户端再执行看看：123test=&gt; copy tcopy from &apos;/tmp/tcopy.txt&apos;;ERROR: could not open file &quot;/tmp/tcopy.txt&quot; for reading: No such file or directorytest=&gt; 它现在不报权限了，而是报告文件或目录不存在。这是因为该文件是在客户端的，而copy只会在服务器端定位。 在客户端换成\copy命令看看：123test=&gt; \copy tcopy from &apos;/tmp/tcopy.txt&apos;;COPY 3test=&gt; 可以发现COPY成功了。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Java中多线程造成的变量共享问题]]></title>
    <url>%2F2014%2F12%2F25%2F%E5%85%B3%E4%BA%8EJava%E4%B8%AD%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%80%A0%E6%88%90%E7%9A%84%E5%8F%98%E9%87%8F%E5%85%B1%E4%BA%AB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[起因在自己写的一段代码中，使用到了Redis。代码的逻辑是这样子的，先取出数据，然后判断，再然后将该数据进行自减。代码如下：123456789101112public boolean isOK(String invitationCode, boolean isSub) &#123; ValueOperations&lt;String, Object&gt; vo = redisTemplate.opsForValue(); Object count = vo.get(key + invitationCode); if (count != null &amp;&amp; Integer.parseInt(count.toString()) &gt;= 1) &#123; if (isSub) &#123; vo.increment(key + invitationCode, -1); &#125; return true; &#125; else &#123; return false; &#125; &#125; 分析在提交代码的时候，总监复查代码时，提出这段代码可能在并发的时候出现问题：比如有两条线程，都进入到了if(sub){xxx}这段代码，这个时候，就造成了重复多次自减的问题。比如，如果该value是5，那应该减到0就不会再减了，但是这段代码在高并发情况下，可能会出现减到-1的情况。这虽然对于现有的业务影响不大，但是，如果是对于其他的一些比较敏感并且需要精确的数据时，就需要特别注意了。 关键是之前一直没有怎么意识到这段代码可能会造成的问题。之前一直认为，对于局部变量是不会出现多线程问题的，这倒是没有错，但关键是如果是从其他地方传过来而且在多处地方允许被使用的情况下，就需要注意多线程问题。]]></content>
      <categories>
        <category>编程</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java 基础学习</tag>
        <tag>java 线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《麦兜，我和我妈妈》电影有感]]></title>
    <url>%2F2014%2F12%2F24%2F%E3%80%8A%E9%BA%A6%E5%85%9C%EF%BC%8C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88%E3%80%8B%E7%94%B5%E5%BD%B1%E6%9C%89%E6%84%9F%2F</url>
    <content type="text"><![CDATA[第一次看动画，看到也会莫名其妙地流泪，感触颇深，情到深处无言；爱到深处只能默默地在心里流泪。人生太多悲天悯人的事，许多时候真的只是只可意会，无法言语。父母之爱无言，只有自己默默体会，默默地感受了。 12345678910111213141516171819202122麦太：我的小傻猪，长大了，懂事了。麦太：你看....麦兜：啊？你买了我叫你不要买的那些号码啊？麦太：我只会买你选的号码麦太：你的手呀，从小就又厚，又软，不是霉猪手麦兜：妈妈！傍白：她说....麦太：全世界的人不信你，我也会信你；麦太：全世界的人不爱你，我也会爱你；麦太：我爱你爱到心肝里；麦太：我信你信到脚趾头。傍白：我说....傍白：我还能说什么？我爱我妈妈麦兜：妈妈！面对命运，妈妈可以输的，已经通通输光；面对命运，妈妈可以赢的，都赢了回来；她把赢的都给了我，把输了的留给自己。我没有离去只是换了个地方 活在爱我的人心里]]></content>
      <categories>
        <category>电影</category>
        <category>动画</category>
      </categories>
      <tags>
        <tag>电影</tag>
        <tag>动画</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL执行计划和成本因子详解]]></title>
    <url>%2F2014%2F12%2F23%2FPostgreSQL%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E5%92%8C%E6%88%90%E6%9C%AC%E5%9B%A0%E5%AD%90%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[PG对各表的统计信息：pg_stats资源来源：PostgreSQL 9.3.1 中文文档 —— Chapter 47. 系统表 —— 47.68. pg_stats 名字 类型 引用 描述 schemaname name pg_namespace.nspname 包含此表的模式名字 tablename name pg_class.relname 表的名字 attname name pg_attribute.attname 这一行描述的字段的名字 inherited bool 如果为真，那么这行包含继承的子字段，不只是指定表的值。 null_frac real 记录中字段为空的百分比 avg_width integer 字段记录以字节记的平均宽度 n_distinct real 如果大于零，就是在字段中独立数值的估计数目。如果小于零， 就是独立数值的数目被行数除的负数。用负数形式是因为ANALYZE 认为独立数值的数目是随着表增长而增长； 正数的形式用于在字段看上去好像有固定的可能值数目的情况下。比如， -1 表示一个唯一字段，独立数值的个数和行数相同。 most_common_vals anyarray 一个字段里最常用数值的列表。如果看上去没有啥数值比其它更常见，则为 null most_common_freqs real[] 一个最常用数值的频率的列表，也就是说，每个出现的次数除以行数。 如果most_common_vals是 null ，则为 null。 histogram_bounds anyarray 一个数值的列表，它把字段的数值分成几组大致相同热门的组。 如果在most_common_vals里有数值，则在这个饼图的计算中省略。 如果字段数据类型没有&lt;操作符或者most_common_vals 列表代表了整个分布性，则这个字段为 null。 correlation real 统计与字段值的物理行序和逻辑行序有关。它的范围从 -1 到 +1 。 在数值接近 -1 或者 +1 的时候，在字段上的索引扫描将被认为比它接近零的时候开销更少， 因为减少了对磁盘的随机访问。如果字段数据类型没有&lt;操作符，那么这个字段为null。 most_common_elems anyarray 经常在字段值中出现的非空元素值的列表。（标量类型为空。） most_common_elem_freqs real[] 最常见元素值的频率列表，也就是，至少包含一个给定值的实例的行的分数。 每个元素频率跟着两到三个附加的值；它们是在每个元素频率之前的最小和最大值， 还有可选择的null元素的频率。（当most_common_elems 为null时，为null） elem_count_histogram real[] 该字段中值的不同非空元素值的统计直方图，跟着不同非空元素的平均值。（标量类型为空。） 成本因子因为PostgreSQL是基于代价模型来选择最优的执行计划的，而成本因子则是计算代价模型的最重要参数。（代价=CPU代价+IO代价+数据传输[如网络]代价） 在PG9.4默认情况下的成本因子如下：（这些值可以在 postgresql.conf 文件里修改的） 12345678# - Planner Cost Constants -#seq_page_cost = 1.0 # measured on an arbitrary scale。扫描一个数据块（一页）的成本（IO成本）#random_page_cost = 4.0 # same scale as above。随机获取一个数据块（一页）的成本（IO成本）#cpu_tuple_cost = 0.01 # same scale as above。获取一行数据的CPU成本#cpu_index_tuple_cost = 0.005 # same scale as above。获取一个索引项的CPU成本#cpu_operator_cost = 0.0025 # same scale as above。每个操作符的CPU成本#effective_cache_size = 4GB #评估操作系统缓存可能使用的内存大小。用于评估索引扫描的开销，大的值倾向使用索引，小的值倾向使用全表扫描。一般设置为“物理内存 - shared buffers - 内核和其他软件占用的内存”。 注意：SSD的随机读和顺序读差别不是太大，这时可以缩小 seq_page_cost 和 random_page_cost 之间的大小。使random_page_cost趋向于seq_page_cost。 关于 effective_cache_size 特别说明一下资料来源 effective_cache_size用于在Linux操作系统上报告内核缓存的大小，我想强调一下它在postgresql.conf配置里的重要性。effective_cache_size 不像其他内存那样是设置已经分配好的控制内存，effective_cache_size用于告诉优化器在内核里有多少cache（读缓存）。这对于决定代价高的索引扫描方式是非常重要的。优化器知道 shared_buffers 大小，但是不知道内核缓存大小，从而影响到代价非常高的磁盘访问。 内核缓存大小改变比较频繁，所以，正常地运行一段时间的系统负载，然后使用该内存值去设置 effective_cache_size。这个值不必是非常完美的，仅仅只是粗略地估计还有多少内核内存，相当于是shared buffers的二级缓存。 explain 输出及详解explain 语法： 123456789101112131415test=# \h explain;Command: EXPLAINDescription: show the execution plan of a statementSyntax:EXPLAIN [ ( option [, ...] ) ] statementEXPLAIN [ ANALYZE ] [ VERBOSE ] statement where option can be one of: ANALYZE [ boolean ] 是否真正执行 VERBOSE [ boolean ] 显示详细信息 COSTS [ boolean ] 显示代价信息 BUFFERS [ boolean ] 显示缓存信息 TIMING [ boolean ] 显示时间信息 FORMAT &#123; TEXT | XML | JSON | YAML &#125; 输出格式，默认为 text 图解： 注意看执行计划，是从最底层开始往后看的。即先从 节点1，再到节点2，最后到节点3。而且，上一级节点的成本，是包含了下一级的成本的。比如：节点2的启动成本和结束成本是已经包含了节点1的启动成本和结束成本的，由此可以得出一个结论：就是上一级节点的启动成本和结束成本永远不会比下一级的小。 再次强调一下，每个节点的估算的总启动或结束成本只是平均每次loops的平均成本，所以最后的总成本还要乘以loops次数。 12345678910111213141516171819test=# explain(analyze, timing, verbose, buffers,costs) select max(sum) from ( select count(*) as sum from tgroup group by point) as t; QUERY PLAN ----------------------------------------------------------------------------------------------------------------------------------------- Aggregate (cost=235363.15..235363.16 rows=1 width=8) (actual time=4898.900..4898.900 rows=1 loops=1) Output: max((count(*))) Buffers: shared hit=12770 read=49578 -&gt; HashAggregate (cost=235363.04..235363.09 rows=5 width=4) (actual time=4898.890..4898.891 rows=5 loops=1) Output: count(*), tgroup.point Group Key: tgroup.point Buffers: shared hit=12770 read=49578 -&gt; Seq Scan on public.tgroup (cost=0.00..177691.36 rows=11534336 width=4) (actual time=0.045..1643.984 rows=11534336 loops=1) Output: tgroup.id, tgroup.age, tgroup.point Buffers: shared hit=12770 read=49578 Planning time: 0.170 ms Execution time: 4898.982 ms(12 rows)Time: 4899.758 mstest=# 估算成本的计算公式全表扫描时计算：公式：total cost = relpages * seq_page_cost + reltuples * cpu_tuple_cost。 123456test=# select relpages, reltuples from pg_class where relname = &apos;tgroup&apos;;-[ RECORD 1 ]----------relpages | 62348reltuples | 1.15343e+07Time: 0.751 ms 12345test=# show seq_page_cost ;-[ RECORD 1 ]-+--seq_page_cost | 1Time: 28.848 ms 12345test=# show cpu_tuple_cost;-[ RECORD 1 ]--+-----cpu_tuple_cost | 0.01Time: 0.460 ms 如上节点1执行计划，是全表扫描：177691.36 = 62348 * 1 + 1.15343e+07 * 0.01123456test=# select 62348 * 1 + 1.15343e+07 * 0.01;-[ RECORD 1 ]-------?column? | 177691.00Time: 39.815 mstest=# 这个与结果相符。 全表顺序扫描并过滤，代价公式为:Cost = seq_scan_cost*relpages + cpu_tuple_cost*reltuples + cpu_operator_cost*reltuples 扫描的方式1234567891011enable_bitmapscan = onenable_hashagg = onenable_hashjoin = onenable_indexscan = on #索引扫描enable_indexonlyscan = on #只读索引扫描enable_material = on #物化视图enable_mergejoin = onenable_nestloop = onenable_seqscan = onenable_sort = onenable_tidscan = on 虽然我们不能强制指定PostgreSQL按我们写的SQL来执行（无视优化器），但是可以通过改变某些的查询方式代价从而影响PostgreSQL的查询优化器的选择。这时，我们可以从上面的扫描方式中将其修改为 off（其实不是强制不能以某种方式扫描，将其设置为 off时，只是将该项的扫描代价提高到非常大的值，从而让PostgreSQL尽可能避免使用该方式来进行扫描，但不是绝对的，如果其他的方式比off的代价更大，那PostgreSQL还是会选择代价最小的来执行的），这就为我们提供了非常好的控制我们SQL的扫描方式。 补充如果explain，执行计划在同一层级，则是由上到下执行的的. 参考资料: understanding_explain.pdf]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL上选择MAX（COUNT）的数据出来]]></title>
    <url>%2F2014%2F12%2F23%2FPostgreSQL%E4%B8%8A%E9%80%89%E6%8B%A9MAX%EF%BC%88COUNT%EF%BC%89%E7%9A%84%E6%95%B0%E6%8D%AE%E5%87%BA%E6%9D%A5%2F</url>
    <content type="text"><![CDATA[昨天晚上，和同事讨论了一个SQL的问题，是如何选择根据某字段分组，然后取出MAX COUNT(XX) 值的数据出来。例如数据是： 1234567891011121314151617test=# select * from tgroup;id | age | point----+-----+------- 1 | 1 | 11 2 | 1 | 32 3 | 2 | 32 4 | 2 | 13 5 | 2 | 33 6 | 2 | 38 7 | 3 | 38 8 | 2 | 38 9 | 2 | 38 10 | 2 | 38 11 | 2 | 38(11 rows) test=# 现在要选择出根据 POINT 分组里包含个数最大的值。大概意思是：MAX(COUNT(*)) FROM tgroup GROUP BY POINT;所以，一开始，我们的SQL语句是（失败）： 1select MAX(COUNT(*)) FROM tgroup group by point; 然而，我们得出的错误是：1aggregate function calls cannot be nested 原来，聚集函数是不能嵌套调用的。 然后又想到能不能使用子查询来完成。SQL如下（成功） ： 1select max(sum) from ( select count(*) as sum from tgroup group by point) as t; 再来一条，不使用子查询，而是使用ORDER BY 结合 LIMIT 来完成，SQL语句如下（成功):1select count(*) as sum from tgroup group by point order by sum desc limit 1; 最后使用PG里的CTE表达式最容易理解（成功）：1with cte as (select count(*) over (partition by point) from tgroup) select max(count) from cte; 那他们的性能是何呢？测试了一千一百五十多万的数据。每条SQL性能如何？1234567test=# select count(*) from tgroup; count ----------11534336(1 row) test=# 使用子查询的性能（POINT没有索引）1234567test=# select max(sum) from ( select count(*) as sum from tgroup group by point) as t; max ---------6291456(1 row) Time: 3055.716 ms ORDER BY 结合 LIMIT（POINT没有索引）12345678test=# select count(*) as sum from tgroup group by point order by sum desc limit 1; sum ---------6291456(1 row) Time: 3047.152 mstest=# 使用CTE表达式（POINT没有索引）1234567test=# with cte as (select count(*) over (partition by point) from tgroup) select max(count) from cte; max ---------6291456(1 row) Time: 25675.005 ms 后面为POINT添加索引，速度只有CTE表达式的加快了一倍（添加索引其实也不太科学，POINT的数据分布不均匀，重复的数据比较多，因为是通过 insert into select 的方式来生成大量数据的，只是想看一下添加索引后的效果）: 12345678test=# with cte as (select count(*) over (partition by point) from tgroup) select max(count) from cte; max ---------6291456(1 row) Time: 11735.775 mstest=# 其他两种方式，并没有什么变化。看执行计划，其他两种依然是使用Seq Scan的方式，而添加了索引后，CTE的方式使用了 CTE Scan + IndexOnlyScan的方式。1234567891011test=# explain with cte as (select count(*) over (partition by point) from tgroup) select max(count) from cte; QUERY PLAN ---------------------------------------------------------------------------------------------------------- Aggregate (cost=955503.54..955503.55 rows=1 width=8) CTE cte -&gt; WindowAgg (cost=0.43..695980.98 rows=11534336 width=4) -&gt; Index Only Scan using tgroup_point on tgroup (cost=0.43..522965.94 rows=11534336 width=4) -&gt; CTE Scan on cte (cost=0.00..230686.72 rows=11534336 width=8)(5 rows) Time: 0.909 ms 总结看来没有 WHERE 或其他条件过滤数据而且数据量非常大的情况下，不适宜使用CTE表达式，因为它本质是一个一次性视图，生成一张这么大的视图，性能也快不到哪里去(可能使用物化视图会好点,不过没有测试过）。在大量数据情况下，还是使用普通的全表扫描比使用生成CTE再全表扫描来得快。这也应验了之前翻译篇文章的强调：CTE表达式的作用，真的不是为了加快查询速度，而仅仅是为了方便。冏 ~~。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]为什么在Java里不能将Integer强制转换成String]]></title>
    <url>%2F2014%2F12%2F22%2F-%E7%BF%BB%E8%AF%91-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9C%A8Java%E9%87%8C%E4%B8%8D%E8%83%BD%E5%B0%86Integer%E5%BC%BA%E5%88%B6%E8%BD%AC%E6%8D%A2%E6%88%90String%2F</url>
    <content type="text"><![CDATA[为何Integer不能转换为String原文 因为 String 和 Integer 不是在同一个对象阶层。 1234 Object / \ / \String Integer 当你尝试强制转换时，仅仅会在同一个对象阶层转换。比如： 1234567 Object / / A //B 在这种情况，(A)objB 或者 (Object)objB 或者 (Object)objA 可以进行转换。 正如其他人已经提到，将integer转换成String可以使用以下方法： 基本类型的整型时使用：String.valueOf(integer)或者Integer.toString(integer) 来转换成String。Integer对象型时使用：Integer.toString()转换成String 写代码过程中，居然遇到这种错误（在使用Spring 来操作 Redis 经常出现，但百思不得其姐。和同事讨论时才发现，原来Redis在底层永远是保存String的，即使在写代码的时候是写成 set(String, Object)。这时，如果get这个缓存出来，而且想要的是整型时，就会报java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String错误。），出来工作差不多2年了，这种错误的本质原因，直到今天才明白。实在是太惭愧了。很可能是被所有对象可以以字符串的形式表示而导致的，以为所有的对象在使用 (String)obj时，会使用 obj.toString()，所以才造成这种认为理所当然的错觉。]]></content>
      <categories>
        <category>编程</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java 基础学习</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cookie 的 HttpOnly 和 Secure 属性作用]]></title>
    <url>%2F2014%2F12%2F22%2FCookie-%E7%9A%84-HttpOnly-%E5%92%8C-Secure-%E5%B1%9E%E6%80%A7%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[今天和总监、同事又讨论起关于Session共享的解决方案问题，讨论到因为Tomcat自带的Session机制在集群时难以做到真正的集群。因为使用Tomcat自带的Session机制，难以做到在集群中节点共享，一般是通过Nginx反向代理使用Hash、固定IP等解决方案，并不能避免单节点崩溃时不能继续提供服务的问题。虽然这种可以解决压力的问题，但是当一直为某IP或通过Hash来分配服务的某台服务器挂了，则它负责服务的客户就都访问不了了（Session失效，只能重新调度分配到其他服务器，这时要重新生成会话）。讨论到的可用的解决方案是Cookie + Redis，然后又讨论了Cookie的安全性问题。然后同事问了下HttpOnly这个在浏览器里打勾的作用，然后自己按以前了解到的资料来回答了一下，大概是说：不能通过Javascript来修改带有HttpOnly属性的Cookie，只能通过服务器来修改。但是看到总监却可以通过JS来修改带有HttpOnly属性的Cookie，这让我产生了怀疑自己的正确性。 不过还好，事后向总监确认了一下，原来他是通过删除旧的带有HttpOnly属性的Cookie，然后才用JS添加一个同名同值没有HttpOnly属性来测试。所以，我之前说的大概是对的，但是不够系统，所以再次查了下资料来系统整理一下，与君分享。 下面两个属性都属于Cookie安全方面考虑的。这要视浏览器或服务端有没有支持。 SecureCookie的Secure属性，意味着保持Cookie通信只限于加密传输，指示浏览器仅仅在通过安全/加密连接才能使用该Cookie。如果一个Web服务器从一个非安全连接里设置了一个带有secure属性的Cookie，当Cookie被发送到客户端时，它仍然能通过中间人攻击来拦截。 HttpOnlyCookie的HttpOnly属性，指示浏览器不要在除HTTP（和 HTTPS)请求之外暴露Cookie。一个有HttpOnly属性的Cookie，不能通过非HTTP方式来访问，例如通过调用JavaScript(例如，引用 document.cookie），因此，不可能通过跨域脚本（一种非常普通的攻击技术）来偷走这种Cookie。尤其是Facebook 和 Google 正在广泛地使用HttpOnly属性。]]></content>
      <categories>
        <category>HTTP</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>Cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]PostgreSQL版本策略]]></title>
    <url>%2F2014%2F12%2F22%2F-%E7%BF%BB%E8%AF%91-PostgreSQL%E7%89%88%E6%9C%AC%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[原文 版本策略我们始终建议所有用户都运行最新可用的次版本号的发行版，无论你正在使用哪个主版本的PostgreSQL。 PostgreSQL主版本包含新特性并且大概一年发行一次。主版本是通过增加第一个或第二个版本数字来标识的，例如：9.1 到 9.2 主版本通常改变内部系统表和数据文件的格式。这些改变通常是非常复杂的，所以，我们不保证所有存储数据会向后兼容。主版本一般使用 备份/恢复 数据库或者使用 pg_upgrade模块来升级。 次版本是版本号的第三部分的数字。例如：9.2.3 到 9.2.4。PostgreSQL团队仅在修复bugs时才会增加次版本号。所有用户都尽可能应该升级到最新的次版本号。虽然升级总是会有风险，PostgreSQL次版本升级仅修复那些经常遇到、安全性以及数据崩溃的bugs，以减少升级的风险。社区认为，不升级比升级更危险。 升级次版本，不要求备份和恢复数据；仅仅只需停止数据库服务器，安装更新的二进制文件，然后重新启动服务器即可。对于某些发行版本，可能需要手工升级，所以，在升级之前，请必须阅读发行版的提示。 PostgreSQL发行版支持策略PostgreSQL目的是对主版本号完整地支持5年。 当一个发行版不再受支持时，我们可能（这取决于我们提交者的决定）会继续为源代码进行打上关键的补丁。但项目不会产生正式发行或者二进制包，但是更新后的源代码可以从我们的代码控制系统里获取。 该策略会在尽最大努力的基础上实行。在极端情况下，它可能在计划的生命周期内就不再被支持了；例如，如果在给定的主版本上发现有一个严重的bug超出了代码稳定性或者要牺牲程序序兼容性来解决的。在这种情况下，该主要版本就要提前退休了。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL最可靠的升级方案[实践]]]></title>
    <url>%2F2014%2F12%2F20%2FPostgreSQL%E6%9C%80%E5%8F%AF%E9%9D%A0%E7%9A%84%E5%8D%87%E7%BA%A7%E6%96%B9%E6%A1%88-%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[注意事项121. 如果原先的数据库安装了第三方的扩展，请在升级的新版本服务器上也先安装好这些第三方扩展(contrib)2. 相应的表空间配置也要与原先的一致 升级步骤123451. 以PG管理员的身份运行以下命令来备份所有数据库信息（包括用户，角色，等） pg_dumpall &gt; outfile2. 恢复DB（记得将最新版本的DB服务器运行起来先），运行以下命令 psql -f outfile postgres 打完收工。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]在Ubuntu服务器上将PostgreSQL从9.1升级到9.3]]></title>
    <url>%2F2014%2F12%2F20%2F-%E7%BF%BB%E8%AF%91-%E5%9C%A8Ubuntu%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%B0%86PostgreSQL%E4%BB%8E9-1%E5%8D%87%E7%BA%A7%E5%88%B09-3%2F</url>
    <content type="text"><![CDATA[原文地址 从不同的重大版本升级PostgreSQL（例如，从9.1升级到9.3），基本上有三种方法： 用 pg_dump 升级如果可以的话，首先推荐的方法是使用新版本（9.3）进行二进制备份一个老（9.1）版本数据，然后在新版本创建的集群中恢复数据。 这种途径，通常，是比较慢的，但是也是最实用的。使它进行得更加快的方法之一是，使用并发。为了并行备份任务，你可以这样子做： 1$ pg_dump --format=directory --jobs=4 --no-synchronized-snapshots --file=/path/to/mydump mydatabase 你可以为每个数据库进行这样子的备份，并调整 --jobs=4 参数值到任何值（测试从2到CPU核心数，并看看哪个更快）。当然，在备份期间，没人应该连接到数据库，任何的修改将会导致备份中断（因为非安全选项 --no-synchronized-snapshots） 之后，你可以使用pg_restore来恢复到新的实例中： 12$ createdb &lt;options&gt; -T template0 mydatabase$ pg_restore --exit-on-error --jobs=4 --dbname=mydatabase /path/to/mydump 之后, 建议在数据库上执行ANALYZE命令： 1$ vacuumdb --analyze-only mydatabase （如果你可以等待时间的话，仅仅运行 --analyze 来同时进行 VACUUM 数据库并更新可视数据字典） 使用 pg_upgrade 升级另一种方法，是使用扩展包中的 pg_upgrade。它提供了一个非常快速的方法来升级PostgreSQL，就是使用 --link 方法。使用之前，你必须备份整个数据目录，因为在 --link 模式下，如果出错，你可能丢失所有数据（包括新旧数据）。并且，请完整地阅读文档，特别是底部的提示（pg_upgrade有许多限制） ##使用基于复制工具的触发器来升级 另一种升级版本的选项，是使用基于触发器的复制工具 。比如Slony, Bucardo和Londiste。 这个选项可能用于最少停机时间，但是也是最难操作的。 这样做的话，需要建立一个 master-slave，主库是你当前版本（9.1），从库是新版本（9.3）。之后，等待第一次同步（系统仍然在生产环境），之后你关闭所有连接到数据库（停机时间从这里开始），等待从库赶上，然后提升（从库）到主库，然后重定向所有客户/应用程序到新版本数据库。打完收工。 Slony文档提供了一步一步地教你使用Slony来升级PostgreSQL. 应该选择哪个？Well, as always depends, resuming:好了，这要取决于什么，总结一下： dump+restore是最可靠的，但通常也是最慢的一种（尽管，并行性可以带来更好的结果） pg_upgrade是对于比较少的停机时间来说是最好的选择之一（如果你能使用的话，看看它的限制）。它通常只需要花数分钟的时间，甚至对于大的数据库也是这样。 触发器复制，毫无疑问是最少停机时间（几乎为0）的做法，但是它真的好难实行，并且我仅仅建议专家（PostgreSQL和复制工具二者都非常熟悉的专家） 希望我可以帮到你。祝你好运。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语句各部分的执行顺序]]></title>
    <url>%2F2014%2F12%2F15%2FSQL%E8%AF%AD%E5%8F%A5%E5%90%84%E9%83%A8%E5%88%86%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[上星期请教了条SQL为什么没有使用到索引的问题，引起了我对SQL执行顺序的疑惑，查了不少资料，收集到比较认可的答案如下，引用资料也在后面标识了。有什么不同的见解，还请大牛指出。 ##各部分的执行顺序12345678910111. FROM2. ON3. OUTER4. WHERE5. GROUP BY6. CUBE | ROLLUP7. HAVING8. SELECT9. DISTINCT10. ORDER BY11. TOP(LIMIT) 来源资料：Stackoverflow whats-the-execute-order-of-the-different-parts-of-a-sql-select-statement Stackoverflow order-of-execution-of-the-query MSDN order-of-execution-of-sql-queries]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]CTE表达式和临时表的区别]]></title>
    <url>%2F2014%2F12%2F12%2F-%E7%BF%BB%E8%AF%91-CTE%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E4%B8%B4%E6%97%B6%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[翻译于dba.stackexchange.com版权归原作者所有，本人只是业余爱好翻译。 这个问题是相当广泛的，但尽我所能给你一个普通的回答。 CTEs 不可以建索引（但可以使用引用到的对象的索引） 不能有约束 本质上是一个一次性视图 只在下一个执行查询时存在 可以递归 没有专门的统计状态数据（只依赖于底层对象） 临时表 是存在于临时数据库的真正物化的表 可以建索引 可以有约束 在当前连接的会话中会一直存在 可以被其他查询或子查询引用 引擎可以有专门为它准备的统计数据 至于何时使用哪个，他们有不同的应用场景。如果你会有一个非常大的结果集，或者需要不上一次地引用它，那请使用临时表。如果需要使用递归，一次性，或者做一些简单的逻辑计算，那就使用CTE。 注意，CTE永远不应该用于性能。使用CTE并不会提高你的性能，因为，它仅仅是个一次性视图。你可以用它做一些其他的事，但是为了加快查询真的并不是它的用途。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>CTE表达式</tag>
        <tag>临时表</tag>
        <tag>postgresql</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java HashSet HashMap 原理]]></title>
    <url>%2F2014%2F12%2F11%2FJava-HashSet-%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[HashSet看其源码java.util.HashSet，它的构造函数内部，是使用java.util.HashMap来实现的. 默认的容量大小，以及扩容因子大小分别为: Initial Capacity： 16Load Factor: 0.75 HashSet 实现集合的原理123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 可以看到，它的add的方法里，是通过HashMap的key唯一性来实现的，而内部的HashMap的value，是一个固定的值private static final Object PRESENT = new Object(); HashMap看其构造函数，默认容量大小，以及扩容因子大小分别为 Initial Capacity：1 &lt;&lt; 4，即16Load Factor： 0.75 HashMap 中的实体类Node它实现了Map接口Map.Entry，它代表HashMap中的抽象实体类.它的属性有 int hash：哈唏码K key：键V value：值Node&lt;K,V&gt; next：下一个map的节点 它的Node的hashCode实现逻辑: 123public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value);&#125; 即key的hashCode 异或 value的hashCode Node 判断相等1234567891011public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false;&#125; 可以看出，只有同一对象，或者key.equals(key1) 并且 value.equals(value1)才会为真. Node的 key的 hashCode计算1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>hashset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]MySQL与PostgreSQL9.0的复制功能对比]]></title>
    <url>%2F2014%2F12%2F09%2F-%E7%BF%BB%E8%AF%91-MySQL%E4%B8%8EPostgreSQL9-0%E7%9A%84%E5%A4%8D%E5%88%B6%E5%8A%9F%E8%83%BD%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[源文地址 作者:Robin Schumacher 和 Gary Carter,EnterpriseDB 公司 原文:Replication is one of the most popular features used in RDBMS’s today. Replication is used for disaster recovery purposes (i.e. backup or warm stand-by servers), reporting systems where query activity is offloaded onto another machine to conserve resources on the transactional server, and scale-out architectures that use sharding or other methods to increase overall query performance and data throughput. 翻译:今天，“复制”是关系数据库的最受欢迎的功能之一。复制的目的是用于灾难恢复（也就是备份或者叫“热”备用服务器），用于在事务服务器上报告系统，将查询活动转移到其他机器，以节约资源。并且这种分区或其他方法的横向扩展构架将会提升整体的查询性能以及数据的吞吐率。 原文:Replication is not restricted to only the major proprietary databases; open source databases such as MySQL and PostgreSQL also offer replication as a feature. While MySQL has offered built-in replication for a number of years, PostgreSQL replication used to be accomplished via community software that was an add-on to the core Postgres Server. That all changed with the release of version 9.0 of PostgreSQL, which now offers built-in streaming replication that is based on its proven write ahead log technology. 翻译:复制功能，并不仅仅限制在专利的商业数据库，一些开源的比如：MySQL 和 PostgreSQL 也提供复制的功能。当MySQL已经内建提供复制功能好几年时，PostgreSQL的复制功能还只是社区通过附加组件形式被添加到核心PostgreSQL服务器。但是，直到PostgreSQL9.0版本时，一切都发生改变了，PostgreSQL现在提供内建一种基于WAL(预写日志）技术的流复制功能。 原文:With the two most popular open source databases now providing built-in replication, questions are being asked about how they differ in their replication technologies. What follows is a brief overview of both MySQL and PostgreSQL replication, with a brief compare and contrast of the implementations being performed immediately afterwards. 翻译:现在，这两个最流行的开源数据库都已经提供了内建的复制功能，那么问题来了：他们两者之间的复制功能有什么区别？下面对MySQL和PostgreSQL作一些简要概述，作一个简单的比较和它们的实现区别之后来简单实践一下。 原文：An Overview of MySQL Replication Asynchronous replication was introduced into Oracle’s MySQL with version 3.23 and today it remains the primary feature employed by many MySQL users to create scale-out architectures, standby servers, read-only data marts, and more. The various supported MySQL replication topologies include: • Single master to one slave • Single master to multiple slaves • Single master to one slave to one or more slaves • Circular replication (A to B to C and back to A) • Master to master The major replication topology not currently supported in Oracle’s MySQL today is multi-source replication: having one or more master servers feed a single slave. A graphical view of how MySQL replication functions can be represented as follows: 翻译:MySQL的复制功能概要 异步复制在MySQL的3.23版本时就被引入了。今天，异步复制仍然是许多MySQL用户用于横向扩展、备库、只读数据等等的主要功能。MySQL支持的各种拓扑结构包括： • 单主，一从 • 单主，多从 • 单主一从到多从 • 环形复制（A - B - C - A） • 主对主 对于现在的MySQL主要不支持的拓扑结构是“多源复制”，也就是：拥有一个或多个主服务器，但只有一个从库。 MySQL复制功能的图形化表示如下： 原文：Object, data, and security operations run on the master are copied to the master server’s binary log. A user has the option of replicating an entire server, one or more databases, or just selected tables (although filtering by table is only done on the slave). The slave server obtains information from the master’s binary log over the network , copies the commands and/or data, and first applies them to the slave’s relay binary log. That log is then read by another process – the SQL thread – that applies the replicated operations/data to the slave database and its binary log. 翻译：在主库上，对象、数据和安全的操作全部都会被复制到主库服务器的二进制日志。用户可以选择复制整个服务器、一个或多个数据库、或仅仅选择某些表来进行复制（尽管表过滤只是在从库完成）。从库通过网络传输从主库获取二进制日志信息，复制的命令或数据会首先应用到从库的 relay 二进制日志里。这个 relay 二进制日志，会被其他工具处理 —— SQL 线程，SQL线程会将replay二进制日志里复制的操作命令和数据应用到从库自己的二进制日志里。 原文：Prior to release 5.1, MySQL replication was statement-based, meaning that the actual SQL commands were replicated from the master to one or more slaves. However, certain use cases did not lend themselves to statement-based replication (e.g. non-deterministic function calls) so in MySQL 5.1 row-based replication was introduced. A user now has the option of setting a configuration parameter to use either statement or row-based replication. 翻译：在5.1版本之前，MySQL 复制是基于语句的，意味着实际的SQL命令是通过复制从主库到一个或多个备库中的。然而，某些使用情况不能让它们基于语句复制（例如，非确定函数调用）。所以，在MySQL 5.1版本提供了基于行复制功能。用户现在可以通过配置相应的参数来决定是使用基于语句还是基于行复制。 原文：The primary bottleneck for busy MySQL replication configurations is the single-threaded nature of its design: replication operations are not multi-threaded at the moment, although MySQL has declared it is coming in a future release. This limitation can cause some slave servers under heavy load to get far behind the master in regards to applying binary log information. 翻译：在繁忙时的MySQL复制配置里，主要的瓶颈是由于它自身的单线程设计性质：复制操作都不是多线程的，尽管MySQL已经声称将来会将这个多线程特性添加到未来的版本中。这个限制可能导致从库在高负载情况下应用执行二进制日志将会远远落后于主库的日志信息。 原文：Setting up MySQL replication is a fairly painless process. Although various setup procedures exist, in general, the following is a basic outline of how it is done: • The master and slave servers are identified • The master server is modified to include a replication security account • The master server’s MySQL configuration file is modified to enable binary logging. A few other parameters are included as well (e.g. a unique server ID, type of replication such as statement or row-based, etc.) • The slave server’s MySQL configuration file is modified to include a unique server ID • The master server is restarted • The master server’s log file position is recorded • The master’s data is copied to the slave to initially seed the slave server. This can be done via a cold backup/restore, using the mysqldump utility, locking the master tables and doing a file copy, etc. • The slave server is restarted • The MySQL CHANGE MASTER command is executed on the slave server to set the master host name on the slave server as well as other parameters such as the master account username and password, the log file name, and beginning log file position 翻译：设置MySQL的复制功能是一个非常痛苦的过程。尽管有许多种设置规则存在，但通常，以下是一些通常的步骤： • 主库和从库都要标识 • 主库添加一个用于安全复制的账号 • 在主库中修改配置文件以开启二进制日志功能，还有一些其他的参数也要开启。 （比如：唯一的服务器ID， 复制的类型，等等） • 在从库中修改配置文件，添加一个唯一的服务器ID。 • 重启主服务器 • 主库的日志文件位置被记录。 • 主库的数据将被初始化到从库中。这是通过冷备份/恢复完成的，例如使用：mysqldump 工具，锁住主库的表然后完成文件复制，等等。 • 重启从库 • MySQL CHANGE MASTER 命令是在从库服务器上执行设置将主库的主机名以及其他的参数如：主库的用户名，密码，日志文件名以及日志文件起始位置设置到从库。 原文：Once set up, MySQL replication is quite reliable. Being asynchronous in nature, however, there are use cases that could result in data loss between a master and slave. To help combat these situations, MySQL 5.5 introduced semi-synchronous replication where a pending transaction is sent from a master to a slave, but not committed on the slave; it merely ‘lands’ safely on the slave to be run as soon as possible. Once the master is notified that the transaction is safely recorded on the slave, then the transaction is committed on the master. 翻译：一旦设置完毕，MySQL复制是相当可靠的。因为本质上是异步的，所以有一些使用情况下还是会导致在主库和从库之间丢失数据。为了帮助解决这个问题，MySQL 5.5 提供了“半同步”复制，它会将事务从主库发送到从库，但在从库并未提交（只是记录到relay二进制日志）。它仅仅是尽可能快速地被安全送到从库。一旦主库收到事务已经被安全地记录在从库上，然后主库才会正式提交事务。 原文：In terms of MySQL replication limitations and missing features, besides the already mentioned single threaded nature of the implementation and the inability to perform multi-source replication, other wish-list items include a full synchronous option, conflict detection and resolution, time-delayed replication, changing the binary log to a storage engine, better replication filtering on the master, global statement ID’s, and graphical tools to manage replication functions. 翻译：MySQL在复制功能方面有许多限制以及不足，除了之前已经提过的单线程性质，还有不能进行多源进制，其他的希望加入的特性包括：完全同步选项，冲突检测及解决办法，延时复制，更改二进制日志的存储引擎，在主库上更好的复制过滤功能，全局语句的ID标识以及管理复制函数的图形化工具。 原文：There are third-party providers of MySQL replication solutions that overcome some of the current shortcomings in what is provided out-of-the-box with MySQL. One example is Continuent’s Tungsten product. For more information about Oracle’s MySQL replication, see: http://dev.mysql.com/doc/refman/5.5/en/replication.html. 翻译：有许多第三方提供即开即用的MySQL复制解决方案来克服当前MySQL内建复制功能的缺点。一个例子是：Continuent’s Tungsten 的数据库产品。更多关于MySQL复制功能，请看：MySQL5.5复制 原文：An Overview of PostgreSQL Replication PostgreSQL replication is based on a mature and long used technology called write ahead log (WAL) archiving. WAL technology has been in use since version 7.1 and has been used in features such as backup and restore and warm standby servers (i.e. slave servers offline kept in synch with the master to step in during crash recovery) for high availability. PostgreSQL 9.0 introduced significant enhancements producing extremely fast WAL processing that results in near real-time replication and hot standby capabilities for slave servers. The supported PostgreSQL replication topologies include: • Single master to one slave • Single master to multiple slaves A graphical view of how PostgreSQL replication functions can be represented as follows: 翻译：PostgreSQL的复制功能概要 PostgreSQL 复制功能是基于一个成熟并且被长时间使用的技术，叫WAL（预写日志）归档。WAL技术已经在PostgreSQL 7.0版本被使用，并且是用在备份/恢复和热备用服务器的高可用中。（比如，从库离线【注，这里我认为是作者写错了，应该是online在线，而不是offline离线】保持与主库同步，并且在主库崩溃时介入以进行恢复）。 PostgreSQL9.0 版本显著地改进以产生极快的WAL日志处理，结果就是一个几乎是近实时复制并且是双机（主从）热备功能的从库。PostgreSQL支持的复制拓扑结构包括： • 单主单从 • 单主多从 A graphical view of how PostgreSQL replication functions can be represented as follows: PostgreSQL复制功能的图形化表示如下： 原文： All objects and data (including schema) and security operation executed on the master are written to the WAL log directly on the slave machine for safety (avoiding complete data loss in the event of a catastrophic master failure). WAL also ensures that no transaction is committed on the master until a successful write of the WAL log has occurred. No filtering is currently possible (although replication with filtering is possible with the xDB Replication Server from EnterpriseDB) so a complete copy of the master is replicated on the slave. 翻译：所有的对象和数据（包括模式）和在主库安全的操作都被写到WAL日志会立即安全地同步地从库(完全避免了在主库发生灾难时导致的数据丢失)。WAL也会确保在主库上不会有事务被提交，直到该事务已经成功地写到入WAL日志。当前版本并没有选择性复制功能（尽管选择性复制功能可能在 EnterpriseDB 的 xDB复制服务器提供了），所以主库会完整地被复制到从库。 原文：The slave then applies the WAL log by directly rewriting the raw table data on disk, which is much faster than statement based replication. It is also safer since statements such as: INSERT INTO table (column) VALUES (SELECT function()); may have unexpected and inconsistent results if the function returns different values on different servers - perhaps because it involves a generated timestamp or uuid. 翻译：从库然后直接应用磁盘上的WAL日志来重写元数据，这点比基于语句复制更加快速。并且，遇到以下这种SQL时都是安全的： INSERT INTO table (column) VALUES (SELECT function()); 如果这个function函数在主从两个不同的服务器之间产生不同的值，这可能有意想不到和不一致的结果。比如可能它调用一个产生UUID或Timestamp的函数。 原文：The primary limitations of PostgreSQL replication are topology based. It cannot currently do cascading replication or filter tables by rows for replication. Again, these are capabilities available in a separate replication solution from EnterpriseDB called xDB Replication Server. 翻译：PostgreSQL复制的主要限制是它的拓扑结构。它目前不能进行联级复制，也不能通过行来过滤表进行复制。同样，这些功能可以通过 EnterpriseDB 里单独提供一种叫 xDB 复制服务器来解决。 原文：Setting up PostgreSQL replication is very straightforward. WAL logging is always enabled with minimal configuration needed by the user to utilize replication. The basic process to get replication going is: • The master and slave servers are identified • The postgresql.conf file on the master is edited to turn on streaming replication • The pg_hba.conf file on the master is edited in order to let the slave connect • The recovery.conf and postgresql.conf files on the slave are edited to start up replication and hot standby • The master is shutdown and the data files are copied to the slave • The slave is started first • The master is started 翻译：设置PostgreSQL复制是非常简单的。开启WAL日志是用户使用复制的最小化配置。使用复制的基本流程如下： • 主库和从库都要标识 • 编辑在主库的postgresql.conf 配置文件里，以开启流复制 • 编辑在主库的pg_hba.conf 配置文件，以让从库连接到主库 • 编辑在从库的 recovery.conf 配置文件和postgresql.conf 配置文件，以开始复制和热备用 • 关闭主库，并且复制data目录所有文件到从库 • 先启动从库 • 再启动从库 原文：The secret sauce to PostgreSQL 9.0’s extremely reliable WAL based replication is a set of enhancements to efficiently stream very small WAL segments compared to earlier versions. Like MySQL there are cases where data loss could occur – however, depending on how you configure the system, your hardware architecture, and load, its possible the data loss could be as small as a single transaction. PostgreSQL does not currently have native synchronous replication. However, there are multiple replication options available from other community and third-party software providers. PostgreSQL offers multiple solutions for multi-master replication, including solutions based on two phase commit. Offerings include Bucardo, rubyrep, PgPool and PgPool-II and Tungsten Replicator as well as some proprietary solutions. Another promising approach, implementing eager (synchronous) replication is Postgres-R, however it is still in development. Yet another project implementing synchronous replication is Postgres-XC, which is a shared-nothing, transactional scale-out solution that is still under development. For more information on PostgreSQL replication see: PostgreSQL Documentation: http://www.enterprisedb.com/docs/en/9.0/pg/high-availability.html Bucardo: http://bucardo.org/wiki/Bucardo PgPool-II: http://pgpool.projects.postgresql.org/ Tungsten Replication: http://www.continuent.com/community/tungsten-replicator 翻译：PostgreSQL9.0非常可靠的秘密武器在于基于WAL日志复制，它是一套增强的高效流，利用非常小的一段WAL来进行早期版本的比较。像MySQL在有些情况下可能会导致数据丢失，然而，这取决于你的系统、你的硬件构架以及负载如何，它丢失的数据可能非常小，如：一个事务的数据。 PostgreSQL目前还没有本地同步复制。然而，有许多种通过社区和第三方软件提供商提供的可用复制方案。PostgreSQL 提供许多“多主复制”的解决方案，包括基于两阶段提交的解决方案。包括：Bucardo, rubyrep, PgPool and PgPool-II and Tungsten Replicator 以及其他一些专有的解决方案。另一种非常有前景的解决办法，实现 饥饿（同步）复制的Postgres-R产品，然而，它目前还在开发中。还有另一个项目实现同步复制的是Postgres-XC，它是一个无共享、事务横向扩展的解决方案，目前也是处于开发中。 更多关于PostgreSQL复制，请看：PostgreSQL 文档: http://www.enterprisedb.com/docs/en/9.0/pg/high-availability.html Bucardo: http://bucardo.org/wiki/Bucardo PgPool-II: http://pgpool.projects.postgresql.org/ Tungsten Replication: http://www.continuent.com/community/tungsten-replicator 原文：A Brief Compare and Contrast of MySQL and PostgreSQL Replication Those wanting to use an open source database for a particular application project that requires replication have two good choices in MySQL and PostgreSQL. But, the question naturally arises, which should be used? Is one just as good as the other? As demonstrated above, there are both feature and functional differences between how MySQL and PostgreSQL implement replication. However, for many general application use cases, either MySQL or PostgreSQL replication will serve just fine; technically speaking, from a functional and performance perspective, it won’t matter which solution is chosen. That said, there still are some considerations to keep in mind in deciding between the different offerings. Some of these include the following: • Oracle’s MySQL offers both statement and row-based replication, whereas PostgreSQL only uses the latter based on write ahead log information. There are pro’s and con’s to using statement-based replication, which MySQL has documented here: http://dev.mysql.com/doc/refman/5.5/en/replication-sbr-rbr.html. It is generally acknowledged that row or WAL-based replication is the safest and most reliable form of replication. It does, however, result in larger log files for MySQL than the statement-based option does. • MySQL currently supports more replication topologies than PostgreSQL (e.g. ring, etc.). However PostgreSQL does have a number of community supported replication offerings that help close this gap (e.g. Bucardo’s master-to-master solution). • In regard to data loss, MySQL 5.5 offers the semi-synchronous option, which helps minimize the risk of master-slave synchronization problems due to a master server going down. For PostgreSQL, a full synchronous replication option is in development and scheduled for release sometime in 2011. • As to replication filtering, MySQL provides filtering on the slave server, whereas with PostgreSQL, no filtering is available; in other worlds, the entire database from the master is replicated to the slave. With MySQL, all the information is sent, but then options exist to selectively apply the replicated events on the slave. However, as the MySQL binary log is not used for crash recovery purposes in the same way as PostgreSQL’s WAL is, a user can configure a MySQL master so only certain databases are logged and, in that sense, a filter for the master server is available. • Both MySQL and PostgreSQL replication are single-threaded at the current time. • With respect to monitoring replication, MySQL provides a number of SHOW commands to understand the state of replication between a master and slave. To date, PostgreSQL offers functions to compute the differences in log positions between the master and slave servers, but that is all that is currently provided in 9.0. • For failover and load balancing, the PostgreSQL community provides pgPool, which is middleware that provides connection pooling, load balancing, failover, and more between replicated servers. MySQL 5.5 supports connection pooling in the Enterprise edition, but failover and load balancing must be handled via a third-party product or custom development. 翻译：简单对比一下MySQL和PostgreSQL复制 那些想为一个需要复制功能的特定应用的项目使用开源数据库的人，MySQL和PostgreSQL是两个很好的选择。但是，问题自然而然产生了，我们应该使用哪个？还是说这两个一样好？ 综上所述，MySQL和PostgreSQL都有复制功能，但是有不同的实现。然而，对于一般的应用来说，无论是MySQL还是PostgreSQL复制功能会工作得挺好；从技术上说，以及从功能和性能来看，它不会不管要选哪个数据库。这意味着，在不同产品之间还有一些值得注意的事项，其中包括以下内容： • MySQL提供基于语句和基于行的复制，而PostgreSQL只有基于WAL日志信息。有赞成也有反对使用基于语句复制的，MySQL有文档介绍：http://dev.mysql.com/doc/refman/5.5/en/replication-sbr-rbr.html 。一般认为，基于行或基于WAL 复制是最安全和最可靠的复制形式。的确如此，然而，这会导致比基于语句复制的形式产生更大的日志文件。 • MySQL目前比PostgreSQL支持更加多的复制拓扑结构（比如：环形等）。然而，PostgreSQL有许多种社区支持的复制选项，这就缩小了这个因拓扑结构种类而导致的距离（比如 Bucardo 的 主-主解决方案） • 考虑到数据丢失，MySQL 5.5 提供了半同步选项，这有助于减小因主库崩溃而导致主从同步问题的风险。对于PostgreSQL，完全同步复制特性正在开发，并且计划于2011年正式可用。 • 对于过滤复制，MySQL 提供了在从库过滤，而在PostgreSQL，并不能使用过滤，换句话说，就是完整地将数据库从主库复制到从库。对于MySQL，所有信息都会被发送到从库，但如果开启过滤复制，从库会有选择地将事件应用到从库。然而，对于MySQL二进制日志并不是用于灾难恢复的，但PostgreSQL的WAL是可以用于灾难恢复的，用户可以配置MySQL主库指定哪些数据库会被记录到日志，在这种意义上，过滤器对于主库是可用的。 • 目前，MySQL和PostgreSQL复制都是单线程的 • 对于复制的监控，MySQL提供了许多 SHOW 命令去了解主从复制的状态。至今，PostgreSQL提供一些函数去计算主从日志位置的区别，但是当前只是在PostgreSQL9.0版本才提供的。 • 对于故障切换和负载均衡，PostgreSQL社区提供pgPool的中间件，pgPool提供连接池，负载均衡，故障切换和更多种复制形式。MySQL 5.5 在企业版里提供连接池，但是对于故障切换和负载均衡必须通过第三方产品或定制开发。 原文：Conclusions As was previously stated, for many application use cases, both Oracle’s MySQL and PostgreSQL replication will be an equally good choice. The best way to determine which is right for you is to download both and put each through a comprehensive evaluation. You can download Oracle’s MySQL at http://www.mysql.com/downloads/, while both community and EnterpriseDB’s offerings of PostgreSQL can be found at: http://www.enterprisedb.com/products/download.do. By Robin Schumacher and Gary Carter, www.enterprisedb.com 18 Nov 2010 翻译：结论 正如前面所指出一样，对于许多应用程序的用例，MySQL和PostgreSQL都是非常好的选择。要决定哪一个最适合你，最好的办法就是同时下载它们两个，然后使用进行综合评估。 你可以在 http://www.mysql.com/downloads/ 下载MySQL，PostgreSQL的社区版和EnterpriseDB提供的PostgreSQL版本都可以在这个地址里找到：http://www.enterprisedb.com/products/download.do 作者：Robin Schumacher and Gary Carter, www.enterprisedb.com18 Nov 2010 注：版权是原作者所有，我只是出于业余爱好进行翻译。 这也是我的处女版翻译文章，有许多不足或表达不清晰的地方，恳请各位指出，我会加以修改，一起为开源、为PostgreSQL作出一份力量。于2014年12月9号星期二晚，广州]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL窗口函数]]></title>
    <url>%2F2014%2F12%2F08%2FPostgreSQL%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[什么是窗口函数PostgreSQL窗口函数 窗口函数提供跨行相关的当前查询行集执行计算的能力。仅当调用跟着OVER子句的聚集函数，作为窗口函数；否则它们作为常规的聚合函数。 我个人的理解：窗口也是一种分组，但和 group by 的分组不同。窗口，可以提供分组之外，还可以执行对每个窗口进行计算。可以相像成是group by 后，然后对每个分组进行计算，而不像Group by ，只是单纯地分组。 窗口函数的语法1234function_name ([expression [, expression ... ]]) OVER window_namefunction_name ([expression [, expression ... ]]) OVER ( window_definition )function_name ( * ) OVER window_namefunction_name ( * ) OVER ( window_definition ) 窗口函数的调用总是包含一个OVER子句，即窗口函数的名称和参数。 该语法区别于普通函数或聚合功能。OVER子句决定究竟将 查询的行如何通过窗口函数拆分处理。OVER子句内的PARTITION BY分区指定 行划分成组，或分区，共享相同的PARTITION BY值。 对于每一行，窗口函数通过同一个分区作为当前行的行进行计算 如果OVER不使用PARTITION BY时即代表整个表。 典型的窗口函数用法1select path, cost, sum(cost) over (partition by path ) as sum_cost from tcost; 内置的窗口函数 Function Return Type Description row_number() 行号 bigint number of the current row within its partition, counting from 1 。返回当前窗口的行数，计数从1开始。主要就是遇到相同排名时的区别，即相同的数值，排名是不同的，而且也不是确定的。 rank() 排名（保持间隔） bigint rank of the current row with gaps; same as row_number of its first peer。当前窗口中，相同的数值排名是相同的，但是还是会保留间隔的。比如：1，1，3。如果是 row_number 会是 1，2，3。也可能是：1，2，3这样子下去，这个看数据是否有相同。 dense_rank() 排名（不保持间隔） bigint rank of the current row without gaps; this function counts peer groups。这个函数与 rank() 一样，只是它不会保持间隔的，相同的数据在同一排名，然后会是下一个排名。如：1,1,2,3,3,4等。 percent_rank() 排名的百分比 double precision relative rank of the current row: (rank - 1) / (total rows - 1)。这条是得出结果的公式。可知相同的排名，结果是一样的。 cume_dist() double precision relative rank of the current row: (number of rows preceding or peer with current row) / (total rows)。即小于等于当前行值的行数/总行数。结果为 0&lt;结果&lt;=1 ntile(num_buckets integer) 可以将结果集放到我们指定数目的组中 integer integer ranging from 1 to the argument value, dividing the partition as equally as possible。组的数目从1开始计。分组的依据：1,每组的记录数不能大于它上一组的记录数。2,所有组中的记录要么都相同，要么从某组开始后面所有组的记录数都与该组的记录数相同 lag(value any [, offset integer [, default any ]]) same type as value returns value evaluated at the row that is offset rows before the current row within the partition; if there is no such row, instead return default. Both offset and default are evaluated with respect to the current row. If omitted, offset defaults to 1 and default to null 。向前获得相对于当前记录指定距离的那条记录的数据 lead(value any [, offset integer [, default any ]]) same type as value returns value evaluated at the row that is offset rows after the current row within the partition; if there is no such row, instead return default. Both offset and default are evaluated with respect to the current row. If omitted, offset defaults to 1 and default to null。向后获得相对于当前记录指定距离的那条记录的数据 first_value(value any) same type as value returns value evaluated at the row that is the first row of the window frame。获取当前窗口的第一个值。 last_value(value any) same type as value returns value evaluated at the row that is the last row of the window frame 。获取当前窗口的最后一个值。 nth_value(value any, nth integer) same type as value returns value evaluated at the row that is the nth row of the window frame (counting from 1); null if no such row。获取窗口中第N个值。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL选择某组sum结果最小的所有数据]]></title>
    <url>%2F2014%2F12%2F05%2FPostgreSQL%E9%80%89%E6%8B%A9%E6%9F%90%E7%BB%84sum%E7%BB%93%E6%9E%9C%E6%9C%80%E5%B0%8F%E7%9A%84%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[在 PostgreSQL 技术群里，今天发现有个人在群里“求救”，说想要执行一条SQL语句，获取某表中以某字段为组，并且sum（其他字段）结果最小的，所有结果。 比如，有张表如下： 1path(int) cost(decimal) 想要的结果是，以path所有相同的字段分组，并且 sum(cost)字段，选择出sum(cost)值最小的，所有path字段。如： 我写的SQL：12with cte as (select path, cost, sum(cost) over (partition by path ) as sum_cost from tcost)select path , cost from cte where sum_cost = (select min(sum_cost) from cte); 我的解题思路在没有接触到PostgreSQL之前，我一直使用MySQL，每次想到“组”这个字，总会想到 group by 。虽然可能使用group by 也可能实现相同的结果，但是经常需要表自身join表，所以性能方面对于数据量大的表话，是满足不了要求的，即使是有索引。因为索引最适合于那种存在索引，而且选择率低的表，否则的话，索引的优势其实和全表扫描差不多，甚至有时候，常常是全表扫描比索引的全表扫描性能还要好。（当然，在PostgreSQL中，如果是只读索引来扫描的话，性能是最好的）。因为MySQL的 InnoDB 是索引组织表，所以索引全表和普通的全表扫描，性能几乎是没有差别。但是在PostgreSQL中，这种差别就很明显了，选择率大的索引全表扫描，比顺序全表扫描SeqScan慢好多。 说远了，回到题目上来。这思路虽然也是要分组，但这种分组跟group by 的分组差得比较远，这种需要一种“窗口函数”（Window Function，在Oracle里叫分析函数）来处理这钟需求，而且这种窗口函数的性能是比那种需要自表连接的性能快好多的，即使是没有索引情况下。之前在群里也遇到这种情况，利用窗口函数几秒钟就可以出结果，但那种自连接的（特别在数据量大的情况下）要几十分钟。这种窗口分组来处理数据，可以避免好多性能问题，而且非常易于理解。 所以，对于PostgreSQL，一有那种需要那种类似窗口的分组操作，首先要想到 Window Function，真的是非常好用。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]PostgreSQL 进程构架]]></title>
    <url>%2F2014%2F12%2F04%2F-%E7%BF%BB%E8%AF%91-PostgreSQL-%E8%BF%9B%E7%A8%8B%E6%9E%84%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[ps aux | grep postgres123456postgres 31964 0.0 0.3 162180 12436 pts/0 S 18:09 0:00 /usr/local/pg/bin/postgres -D /usr/local/pg/datapostgres 31966 0.0 0.0 162312 2192 ? Ss 18:09 0:00 postgres: checkpointer process postgres 31967 0.0 0.0 162180 1820 ? Ss 18:09 0:00 postgres: writer process postgres 31968 0.0 0.0 162180 960 ? Ss 18:09 0:00 postgres: wal writer process postgres 31969 0.0 0.0 163032 2064 ? Ss 18:09 0:00 postgres: autovacuum launcher process postgres 31970 0.0 0.0 18000 948 ? Ss 18:09 0:00 postgres: stats collector process 1234567postgres: logger process: 在PostgreSQL中称为SysLogger(8.0)，用于整个系统的日志输出；postgres: checkpointer process: 在PostgreSQL中称为Checkpointer(9.2），用于处理checkpoints；postgres: writer process: 在PostgreSQL中称为BgWriter，用于将脏页刷出到磁盘；postgres: wal writer process: 在PostgreSQL中称为WalWriter(8.3)，处理预写日志输出；postgres: autovacuum launcher process: 在PostgreSQL中称为AutoVacuum(8.1)，用于系统的自动清理；postgres: archiver process: 在PostgreSQL中称为PgArch，用于预写日志归档；postgres: stats collector process: 在PostgreSQL中称为PgStat，用于统计数据收集。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL基础学习（一）]]></title>
    <url>%2F2014%2F12%2F03%2FPostgreSQL%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介PostgreSQL官网 PostgreSQL 官网号称：它是最世界最先进的开源数据库（顺便说一下，MySQL官网说它自己是最流行的开源数据库）。我觉得这一句话，也已经非常足够概括 PostgreSQL 了（MySQL 官网的那句话，也概括了它自己的特点，一个是最先进，一个是最流行）。也有号称是 Oracle 的开源版，因为PostgreSQL被经常拿来与Oracle这个重量级的商业数据库比较。的确，PostgreSQL 与 Oracle 兼容性非常强，Oracle 的 DBA 可以非常快地上手 PostgreSQL。在 PostgreSQL 技术群里的大牛大多都是从 Oracle 转到 PostgreSQL，使我印象非常深刻就是 @德哥，绝对是PostgreSQL的大神级别。我也是跟着德哥的视频一边看，一边学习的。 安装（以 Ubuntu 下源码安装 PostgreSQL 9.3.5 为例）下载PostgreSQL 源码下载地址 安装与使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#安装必要的编译环境sudo apt-get install build-essential libreadline-dev#解压tar -xvjf postgresql-9.3.5.tar.bz2#创建一个目录，将PostgreSQL安装到这个目录sudo mkdir /usr/local/pg#配置cd postgresql-9.3.5./configure --prefix=/usr/local/pg#开始编译make -j-j：开启多核编译如果有：All of PostgreSQL successfully made. Ready to install. 表示编译成功#安装sudo make install如果出现：PostgreSQL installation complete. 表示安装成功#添加 PostgreSQL 用户sudo useradd -s /bin/bash -d /home/postgres postgres#创建 PostgreSQL 的 data 数据目录sudo mkdir /usr/local/pg/data -p#修改拥有者身份sudo chown postgres:postgres /usr/local/pg/ -R#初始化数据库su - postgres/usr/local/pg/bin/initdb -D /usr/local/pg/data#启动数据库/usr/local/pg/bin/postgres -D /usr/local/pg/data &gt;logfile 2&gt;&amp;1 &amp;或者/usr/local/pg/bin/pg_ctl -D /usr/local/pg/data -l logfile start#创建数据库/usr/local/pg/bin/createdb test#连接数据库/usr/local/pg/bin/psql test 配置环境变量 为了避免每次使用绝对路径以及一些参数问题，可以使用一些环境变量来代替，PostgreSQL 在没有指定参数时，就会读取这些环境变量的值 123456789101112131415161718192021222324252627282930313233vi /home/postgres/.bash_profile#这个是默认的PostgreSQL端口export PGPORT=5432#这个是PostgreSQL数据目录export PGDATA=/usr/local/pg/data#所使用的语言export LANG=en_US.utf8#PostgreSQL 安装目录export PGHOME=/usr/local/pg#PostgreSQL 连接库文件export LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/lib:$LD_LIBRARY_PATHexport DATE=`date +"%Y%m%d%H%M"`#将PostgreSQL的命令行工具添加到 PATH 环境变量 ，这样子就不用每次使用绝对路径了export PATH=$PGHOME/bin:$PATH#PostgreSQL的 man 手册export MANPATH=$PGHOME/share/man:$MANPATH#PostgreSQL的默认用户export PGUSER=postgres#这个是PostgreSQL默认主机地址export PGHOST=127.0.0.1#连接数据库时默认的数据库名export PGDATABASE=postgre PostgreSQL所有环境变量 PostgreSQL 的 bin 目录常用工具说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#clusterdb — 对一个PostgreSQL数据库进行建簇 #createdb — 创建一个新的 PostgreSQL 数据库 #createlang — 定义一种新的 PostgreSQL 过程语言 #createuser — 定义一个新的 PostgreSQL 用户帐户 #dropdb — 删除一个现有 PostgreSQL 数据库 #droplang — 删除一种 PostgreSQL 过程语言 #dropuser — 删除一个 PostgreSQL 用户帐户 #ecpg — 嵌入的 SQL C 预处理器 #pg_basebackup -- 做一个PostgreSQL集群的基础备份 #pg_config — 检索已安装版本的 PostgreSQL 的信息 #pg_dump — 将一个PostgreSQL数据库抽出到一个脚本文件或者其它归档文件中 #pg_dumpall — 抽出一个 PostgreSQL 数据库集群到脚本文件中 #pg_restore — 从一个由 pg_dump 创建的备份文件中恢复 PostgreSQL 数据库。 #psql — PostgreSQL 交互终端 #reindexdb -- 重新建立一个数据库索引 #vacuumdb — 收集垃圾并且分析一个PostgreSQL 数据库 #pg_receivexlog 从另一台运行PG的数据库里接收 wal 日志 #pg_resetxlog 重置一个 PostgreSQL 数据库集群的预写日志以及其它控制内容 PostgreSQL 的 data 目录说明]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《数据库查询优化器的艺术》第三章物理查询优化学习笔记]]></title>
    <url>%2F2014%2F12%2F03%2F%E3%80%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%E7%AC%AC%E4%B8%89%E7%AB%A0%E7%89%A9%E7%90%86%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[代价模型总代价 = IO 代价 + CPU 代价 COST = P * a_page_cpu_time + W * T P：计划运行时访问的页数，a_page_cpu_time 是每个页读取的时间花费，其积反映了IO代价 T：访问的元组。反映了CPU花费。（存储层是以页面为单位，数据以页面的形式读入内存，每个页面上可能有多个元组，访问元组需要解析元组结构，才能把元组上的字段读出，这消耗的是CPU）。如果是索引扫描，则还会包括索引读取的花费。 W：权重因子。表明IO到CPU的相关性，又称选择率（selectivity）。选择率用于表示在关系R中，满足条件“A&lt;op&gt;a”的元组数与R的所有元组N的比值。 单表扫描算法全表扫描，局部扫描。单表扫描与IO操作密切相关。 1）顺序扫描（SeqScan）。当无索引可用，或访问表中的大部分数据，或表的数据量很小时，使用顺序扫描效果较好。 2）索引扫描（IndexScan）。根据索引键读索引，找出物理元组的位置。【如果选择率很高，不适宜使用索引扫描】 3）只读索引扫描（IndexOnlyScan）。根据索引键读索引，索引中的数据能够满足条件判断，不需要读取数据页面。比索引扫描少了读取数据的IO花费。 4）行扫描（RowIdScan）。用于直接定位表中的某一行。对于元组，通常为元组增加特殊的列，通过特殊的列计算出元组r物理位置，然后直接读取元组对应的页面，获取元组。在PostgreSQL中称为【Tid】扫描，此种方式是在元组头上增加名为【CTID】的列，用这列的值可直接计算本条元组的物理存储位置。 5）并行表扫描（ParallelTableScan）。对同一个表，并行地、通过顺序的方式获取表的数据，结果是得到一个完整的表数据。 6）并行索引扫描（ParallelIndexScan）。对同一个表，并行地、通过索引的方式获取表的数据，将结果合并在一起。 7）组合多个索引扫描（MultipleIndexScan）。 扫描代价估算公式COST = N_page * a_tuple_IO_time + N_tuple * a_tuple_CPU_time 索引扫描代价估算公式COST = C_index + N_page_index * a_tuple_IO_time C_index：索引的IO花费。C_index = N_page_index * a_page_IO_time N_page_index：索引作用下的可用元组数。N_page_index = N_tuple * 索引选择率 索引本质上是通过索引直接定位表的物理元组，加快数据获取的方式，所以索引优化的手段是物理查询优化。 如何利用索引1）索引列作为条件出现在 WHERE，HAVING， ON 子句中。 2）索引列是被连接的表（内表）对象的列且存在于连接条件中 除了上述两种情况，还有一些特殊情况可以使用索引，如：排序操作、在索引列上求MIN、MAX值等。 （1）对表做查询，没有列对应作为过滤条件（如出现在WHERE子句中），只能做顺序扫描。 （2）对表做查询，有列对象且索引列作为过滤条件，可做索引扫描。 （3）对表做查询，有列对象作为过滤条件，但索引列被运算符“-”处理，查询优化器不能在执行前进行取反运算，这时不可利用索引扫描，只能做顺序扫描。 （4）对表做查询，有列对象作为过滤条件，且目标列没有超出索引列，可做只读索引扫描，这种扫描方式比单纯的索引扫描的效率更高。 （5）对表做查询，有索引存在，但选择条件不包括索引列对象，只能使用顺序扫描。 （6）对表做查询，有索引存在，选择条件包括索引列对象，可使用索引扫描，对选择条件中不存在索引的列作为过滤器被使用。 （7）对表做查询，有索引存在，选择条件包括索引列对象，但索引列对象位于一个表达式中，参与了运算，不是“key=常量”格式，则索引不可使用，只能是顺序扫描。如： select a. from a where a.a1 + a.a3 = 2；（a1列是索引），这时只能做顺序扫描。 或 select a. from a where a.a1 = 2 - a.a3 ；（a1列是索引），这时只能做顺序扫描。 （8）对表做查询，有索引列对象作为过滤条件，操作符是范围操作符 &gt; 或 &lt; ，可做索引扫描。 （9）对表做查询，有索引列对象作为过滤条件，操作符是范围操作符 &lt;&gt; ，不可做索引扫描。 （10）对表做查询，有索引列对象作为过滤条件，操作符是范围操作符BETWEEN-AND ，可做索引扫描。 索引列的位置对使用索引的影响（1）索引列出现在目标列，通常不可使用索引（但不是全部情况下不能使用索引） （2）聚集函数MIN / MAX用在索引列上，出现在目标列，可使用索引。 （3）索引列出现在WHERE子句中，可使用索引。 （4）索引列出现在 JOIN / ON 子句中，作为连接条件，有时不可使用索引。（这取决于代价估算模型） （5）索引列出现在 JOIN / ON 子句中，作为限制条件满足“key &lt;op&gt; 常量 ”格式可用索引。 （6）（5）索引列出现在 WHERE子句中，但与子查询比较，格式上不满足&quot;key &lt;op&gt; 常量&quot;，不可用索引。 索引列对GROUP BY子句的影响（1）索引列出现在 group by 子句中，不触发索引扫描。 （2）WHERE子句出现索引列，【且】GROUP BY 子句出现索引列，索引扫描被使用。 （3）WHERE子句中出现非索引列，且GROUP BY子句出现索引列，索引扫描不被使用。 索引列对HAVING子句的影响（1）WHERE子句出现非索引列，且GROUP BY和HAVING子句出现索引列，索引扫描被使用。 索引列对ORDER BY子句的影响（1）ORDER BY子句出现索引列，可使用索引。 （2）ORDER BY子句使用非索引列，不可使用索引扫描。 索引列对 DISTINCT 的影响（1）DISTINCT 子句管辖范围内出现索引列，不可使用索引。 联合索引对索引使用的影响（1）使用联合索引的全部索引键，可触发索引的使用。 （2）使用联合索引的前缀部分索引键。如：key_part_1 &lt;op&gt; 常量。可触发索引的使用。 （3）使用部分索引，但不是联合索引的前缀部分，如“key_part_2 &lt;op&gt; 常量&quot;，不可触发索引的使用。 （4）使用索引索引的全部索引键，但索引键不是AND操作，不可触发索引的使用。 多个索引对索引使用的影响（1）WHERE子句出现两个可利用的索引，优选最简单的索引。（但这也是要根据代价估算模型来决定的） （2）WHERE子句出现两个可利用的索引且索引键有重叠部分，优选最简单的索引。 聚簇索引 是指表的一个或多个列作为索引的关键字，以关键字的具体值为依据，把所有具有相同值的元组连续放在外存上。当从磁盘扫描读取的块进入内存时，相同值的其他元组在内存中的概率增大，能有效减少IO。即：聚簇索引确定表中数据的物理顺序。聚簇索引对于那些经常要搜索范围值的列特别有效。使用聚簇索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《数据库查询优化器的艺术》第二章逻辑查询优化学习笔记]]></title>
    <url>%2F2014%2F12%2F03%2F%E3%80%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0%E9%80%BB%E8%BE%91%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[主要解决的问题如何找出SQL语句等价的变换形式，使得SQL执行更高效。 #可优化的思路 （1）子句局部优化。 如等价谓词重写，WHERE和HAVING条件化简中的大部分情况。 （2）子句间关联优化。 子句与子句之间关联的语义存在优化的可能，如外连接消除、连接消除、子查询优化、视图重写等。 （3）局部与整体的优化。 协同局部与整体。如OR重写并集规则需要考虑UNION操作（UNION是变换后的整体形式）的花费和OR操作（OR是局部表达式）的花费。 （4）形式变化优化 多个子句存在嵌套，可能通过形式的变化完成优化。如：嵌套连接消除。 （5）语义优化 根据完整性约束，SQL表达的含义等信息对语句进行语义优化 （6）其他优化 根据一些规则对非SPJ做的其他优化，根据硬件环境进行的并行查询优化。 它们都是依据关系代数和启发式规则进行。 #关系模型 关系数据结构即二维结构，二维表。即数据库中的表。 关系是一种对象 关系即是表 关系的元数据，即表结构，通常称为列或属性。 关系的数据，即表的行数据，通常称为元组（tuple），也称为记录(record)。 关系操作集合并，交，差，积，选择，投影，连接，除。。 选择：单个关系中筛选元组。 投影：单个关系中筛选列。 连接：多个关系中根据列间的逻辑运算筛选元组（自然连接，等值连接） 除：多个关系中根据条件筛选元组（NOT EXISTS 的子查询实现除） 并：多个关系合并元组（用UNION实现并） 交：多个关系中根据条件筛选元组（用两次NOT IN 实现交） 差：多个关系中根据条件筛选元组（NOT IN 子查询实现差） 积：无连接条件。N*M条元组 关系类型R &lt;op&gt; S 自然连接：R和S中“公共属性”，结果包括公共属性名字上相等的所有元组的组合，在结果中把重复的列去掉。（是同时从列和行的角度进行去重） @-连接：R和S中没有公共属性，结果包括在R和S中满足操作符@的所有组合。@通常包括：&lt; &lt;=, =, =, &gt;=。即从关系R和S的广义笛卡儿积中选取A，B属性相等的那些元组，是从“行”的角度进行运算。 等值连接：操作符是 = 的@-连接。 半连接：结果包括在S中公共属性名字上相等的元组的所有的R中的元组。即结果包括R的部分元组，而R中的部分元组的公共属性的值在S中同样存在。SQL中没有自己的连接操作符，使用EXISTS， IN 关键字做子句的子查询常被查询优化器转换为半连接。 反连接：结果是在S中没有在公共属性名字上相等的元组的R的元组。即为半连接的补集，反连接有时称为反半连接。在SQL中没有自己的连接操作符，使用了 NOT EXISTS 则被查询优化器转换为反半连接。 外连接（左外连接）：结果包括R中的所有元组。若在S中有在公共属性名字上相等的元组，则正常连接；若在S中没有公共属性名字上相等的元组，则依旧保留此元组，并将对应的其他列设为NULL 外连接（右外连接）：结果包括S中的所有元组。若在R中有在公共属性名字上相等的元组，则正常连接；若在R中没有公共属性名字上相等的元组，则依旧保留此元组，并将对应的其他列设为NULL 外连接（全外连接）：结果包括S和R中的所有元组。对于每个元组，若在另一个关系中有在公共属性名字上相等的元组，则正常连接；若在另一人关系中没有公共属性名字上相等的元组，则依旧保留此元组，并将对应的其他列设为NULL 关系完整性约束查询句与二叉树叶子是关系（表） 内部结点是运算符（或称算子，操作符，如 LEFT OUT JOIN，表示左右子树的运算方式） 子树是子表达式或SQL片段 根结点是最后运算符的操作符 根结点运算后，得到的是SQL查询优化后的结果 这样一棵树就是一个查询的路径 多个关系连接，连接顺序不同，可以得出多个类似的二叉树 查询优化就是找出代价最小的二叉树，即最优的查询路径。 基于代价估算的查询优化就是通过计算和比较，找出花费最少的是优二叉树。 从运算符的角度考虑优化不同的运算符优化可c减少中间生成物的大小和数量，节约IO和内存CPU等，从而提高执行速度。前提是优化前和优化后是等价的。 选择 —— 基本选择性质对同一个表的同样选择条件，作一次即可。 可优化的原因： 幂等性：多次应用同一个选择有同样的效果 交换性：应用选择的次序在最终结果中没有影响 选择可有效减少在它的操作数中的元组数的运算（元组数减少） 选择 —— 分解有复杂条件的选择合取：合并多个选择为更少的需求值的选择，多个等式可以合并。它等价于针对这些单独的一系列选择。 析取：分解它们使得其成员选择可被移动或单独优化。它等价于选择的并集。 选择 —— 和叉积尽可能选做选择：关系有N和M行，先做积运算将包含N*M行。先做选择运算，减少N和M，则可避免不满足条件的条件参与积的运算，节约时间减少结果的大小。 尽可能下推选择：如果积不跟随着选择运算，可尝试使用其他规则从表达式树更高层下推选择。 选择 —— 和集合运算选择下推到的集合运算中：选择在差集，交集和并集算子上满足分配律。 选择 —— 和投影在投影之前进行选择：如果选择条件中引用的字段是投影中的字段的子集，则选择与投影满足交换性。 投影 —— 和基本投影性质尽可能先做投影：投影是幂等性的；投影可以减少元组大小。 投影 —— 和集合运算。投影下推到集合运算中：投影在差集，交集和并集运算上满足分配律。 运算规则主导的优化连接、笛卡儿积 交换律做连接、做积运算，可交换前后位置，其结果不变。如两表连接算法中嵌套连接算法，对外表和内表有要求，外表尽可能小则有利于做“基于块的嵌套循环连接“，所以，通过交换律可以把元组少的表作为外表。 连接、笛卡儿积 结合律做连接、做积运算，如果新的结合有利于减少中间关系的大小，则可优先处理。 投影的串接定律在同一个关系上，只需要做一次投影运算，且一次投影时选择多列同时完成。所以许多数据库优化引擎为同一个关系收集齐本关系上的所有列（目标列和 WHERE， GROUP BY 等子句的本关系的列） 选择的串接定律选择条件可以合并，使得可一次就检查全部条件，不必多次过滤元组，所以可以把同层的合取条件收集在一起，统一判断。 选择与投影的交换律（1）先投影后选择，可以改为先选择后投影，这对于以行为存储格式的主流数据库而言，很有优化意义。存储方式总是在先获得元组后才能解析得到其中的列。 （2）先择选后投影，可以改为带有选择条件中列的投影后再选择，最后完成最外层的投影，这样，使得内层的选择和投影可以同时进行。 选择与笛卡儿积的分配律条件下推到相关的关系上，先做选择后做积运算，这样可以减小中间结果的大小。 选择与并的分配律条件下推到相关的关系上，先做选择后做并运算，可以减小每个关系输出结果的大小。 选择与差的分配律条件下推到相关的关系上，先做选择后做差运算，可以减小每个关系输出结果的大小。 投影与笛卡儿积的分配律先做投影后做积，可减少做积前每个元组的长度，使得再做积后得到新元组的长度变短。 投影与并的分配律先做投影后做并，可减少做并前每个元组的长度。 OLTPOn-line Transaction Processing, OLTP。 SPJSELECT， 投影（PROJECT）， 连接（JOIN） 查询优化对SPJ的优化方式如下：1）选择操作。对应的是限制条件（格式类似 field&lt;op&gt;consant）优化方式是选择操作下推，目的是尽量减少连接操作前的元组数，使得中间临时关系尽量少。这可减少IO和CPU等的消耗。 2）投影操作：对应SELECT查询的目的的列对象。优化方式是投影操作下推。目的是尽量减少连接操作前的列数，使得中间临时关系尽量小（选择操作是使元组个数”尽量少“，投影操作，是使一条元组”尽量小“）。这样，虽然不能减少IO（多数数据库存储方式是行存储，元组是读取的最基本单位，所以想要操作列必须读取一行数据）。但可以减少连接后的中间关系的元组大小，节约内存。 3）连接操作：对应的是连接条件。（格式为field1&lt;op&gt;field2, field1和field表示”不同表“上的列对象。表示两个表连接条件。（1）”多表连接中每个表被连接的顺序决定着效率。“，即如果ABC三个表，ABC， ACB， CBA， BCA等不同的连接后结果一样的话，则要计算哪种效率最高。（2）多表连接每个表被连接的顺序由用户语义决定，这决定着表之间的前后连接次序是不能随意更换的。 4）非SPJ（在SPJ的基础上存在 GROUP BY 操作的查询，这是一种复杂的查询）。 子查询优化它是一种比较耗时的操作，优化子查询对查询效率的提升有着直接的影响。 子查询可出现的位置及对优化的影响1）目标列 这时，只能是标量子查询，否则数据库可能返回类似”错误：子查询必须只能返回一个字段“的提示。 2）FROM子句 相关子查询不能出现在FROM子句中；非相关子查询出现在FROM子句中，可上拉子查询到父层，在多表连接时统一考虑连接代价后择优。 3）WHERE子句 4）JOIN/ON子句 它们处理方式同FROM子句和WHERE子句 5）GROUP BY子句 目标列必须和 GROUP BY 关联。可将子查询写在GROUP BY位置，但没有什么实用意义。 6）HAVING子句 7）ORDER BY 子句 子查询优化技术1）子查询合并 等价的情况下。多个子查询能够合并成一个子查询。这样可以把多次表扫描，多次连接减少为单次表扫描和单次连接。如： select * from t1 where a1 &lt; 10 and (exists (select a2 from t2 where t2.a2 &lt; 5 and t2.b2 = 1) or exists (select a2 from t2 where t2.a2 &lt; 5 and t2.b2 = 2) 可优化为 select * from t1 where a1 &lt; 10 and ( exists (select a2 from t2 where t2.a2 &lt; 5 and ( t2.b2 = 1 or t2.b2 = 2)); 2）子查询展开 又称子查询反嵌套，又称为子查询上拉。把一些子查询置于外层的父查询中，作为连接关系与外层父查询并列。实质上是把某些子查询重写为等价的多表连接操作。如： select * from t1, ( select * from t2 where t2.a2 &gt; 10) v_t2 where t1.a1 &lt; 10 and v_t2.a2 &lt; 20 可优化为 select * from t1, t2 where t1.a1 &lt; 10 and t2.a2 &lt; 20 and t2.a2 &gt; 10 3）聚集子查询消除 将聚集函数上推，将子查询转变为一个新的不包含聚集函数的子查询，并与父查询的部分或者全部表做左外连接。 4）其他 利用窗口函数消除子查询的技术。子查询推进等技术 子查询展开1）如果子查询出现了聚集、GROUP BY， DISTINCT 子句，则子查询只能单独求解，不可以上拉到上层。 2）如果子查询只是一个简单格式（SPJ）的查询语句，则可以上拉到上层，这样往往能提高查询效率。 子查询展开的规则1）如果上层查询的结果没有重复（即SELECT子句中包含主键），则可以展开其子查询，并且展开后的查询的SELECT 子句前就回上 DISTINCT 标志。 2）如果上层有 DISTINCT 标志，则可以直接展开子查询 3）如果内层查询结果没有重复元组，则可以展开。 子查询展开的步骤1）将子查询和上层查询的FROM子句连接，为同一个FROM子句，并修改相应的运行参数 2）将子查询的谓词符号进行相应修改。如 IN修改为=ANY 3）将子查询的WHERE条件作为一个整体与上层查询的WHERE条件合并，并用AND条件连接词连接。 子查询优化说明子查询类似： 10 IN (select ...）这不能做上拉操作，所以不能优化 子查询类似：出现 random()等易失函数，子查询结果不能确定，所以查询优化器就不能对子查询优化。 ALL/SOME/ANY类型如果子查询没有 GROUP BY 子句，也没有聚集函数。则可以使用如下表达式做等价转换： val &gt; ALL (select ...) 等价为 val &gt; MAX(select ...) val &lt; ALL (select ...) 等价为 val &lt; min( select ...) val &gt; any (select ...) 等价为 val &gt; min(select ....） val &lt; any (select ...) 等价为 val&lt;max(select ....) val &gt;= ALL 同上 val &lt;= ALL val &gt;= ANY val &lt;= ANY 视图重写就是将视图的引用重写为对基本表的引用。如： create table t_a ( a int , b int ); create view v_a as select * from t_a; 基于视图的命令： select col_a from v_a where col_b &gt; 100; 经过视图重写后： select col_a from ( select col_a , col_b from t_a) where col_b &gt; 100; 再经过优化后，则是： select col_a from t_a where col_b &gt; 100; 简单的视图（SPJ）可以被查询优化器较好地处理。 但复杂视图则不能被查询优化器很好地处理。 等价谓词重写1）LIKE规则 如：name like &apos;abc%&apos; 重写为 name &gt;= &apos;abc&apos; and name &lt; &apos;abd&apos;; 应用like规则的好处：转换前针对 like 谓词只能进行全表扫描。如果name列上存在索引，则转换后可以进行索引范围扫描。 如果没有通配符（%或_）。则是与 = 等价 name like &apos;abc&apos; 重写为 name = &apos;abc&apos; 2） BETWEEN-AND规则 sno BETWEEN 10 AND 20 重写为 sno &gt;= 10 and sno &lt;=20 好处：如果sno建立了索引，则可以用索引扫描代替原来的BETWEEN-AND谓词限定的全表扫描，从而提高了查询的效率。 3）IN转换OR规则 IN只是IN操作符，而不是IN子查询。改为OR可以更好地利用索引进行优化。将IN改为若干个OR可能会提高效率。 age IN （8, 12, 21） 重写为 age = 8 or age = 12 or age = 21 效率是否提高，需要看数据库对IN谓词是否只支持全表扫描。如果数据库对IN谓词只支持全表扫描且OR谓词中表的age列存在索引，则转换后的查询效率会更好。 4）IN转换ANY规则 因为IN可以转换为OR，而OR可转换为ANY，所以可以直接把IN转换为ANY。这可能会提高效率。 age IN (8, 12, 21) 重写为 age any (8, 12, 21) 效率是否提高，依赖于数据库对ANY操作的支持情况。 如：PostgreSQL没有显式支持 ANY 操作，但在内部实现时把IN操作转换为了ANY操作。（通过 explain 知道） 5）OR转换为ANY规则 这样可以更好地利用 MIN/MAX 操作进行优化。但（PG9.2.3 和 MySQL 5.6.10 目前都还没有支持） 6）ALL/ANT 转换为集函数规则 这样可以更好地利用 MIN/MAX 操作进行优化。如： sno &gt; ANY (10, 2*5+3, sqrt(9)) 重写为 sno &gt; sqrt(9) 通常，聚集函数MAX(), MIN()等的效率比ANY， ALL谓词的执行效率高。 7）NOT规则 NOT (col_1 != 2) 重写为 col_1 = 2 其他类似 好处：如果 col_1 上建立了索引，则可以用索引扫描代替原来的全表扫描。 8）OR重写并集规则 如： select * from student where ( sex = &apos;f&apos; and sno &gt; 15 ) or age &gt; 18； 这条SQL会强迫查询优化器使用顺序存取，因为这个语句要检索的是OR操作的集合。假设，sex, age 上有索引，则可优化为： select * from student where sex = &apos;f&apos; and sno &gt; 15 union select * from student where age &gt; 18； 条件简化1）把HAVING条件并入WHERE条件。（只有SQL语句不存在 GROUP BY 条件 或聚集函数的情况下才可以使用） 2）去除表达式中冗余的括号。这样子可以减少语法分析时产生的AND和OR树的层次。 3）常量传递。如：col_1 = col_2 and col_2 = 3 。改为：col_1 = 3 and col_2 = 3; 4）消除死码。如：永恒为假的条件。 5）表达式计算：如：where col_1 = 1 + 2 ，改为 where col_1 = 3 6）等式变换：化简条件（如反转关系操作符的操作数顺序）。如： -a = 3; 简化为 a = -3； 7）不等式变换。化简条件。如：a &gt; 10 and b = 6 and a &gt; 2 ，简化为 b = 6 and a &gt; 10 8）布尔表达式变换。 9）谓词传递闭包。 10）任何一个布尔表达式都能被转换为一个等价的合取范式（CNF）。如：and 操作符是可交换的，所以优化器可以按先易后难的顺序计算表达式。 11）索引的利用。 外连接消除外连接的左右子树不能互换。 查询重写的一项技术就是把外连接，转换为内连接。意义： 1）查询优化器在处理外连接操作时所需要的时间多于内连接 2）优化器在选择表连接顺序时，可以有更多更灵活的选择，从而sk以选择更好的表连接顺序。 3）表的一些连接算法，将规模小的或筛选严格的条件的作为外表，可以减少不必要的IO开销，极大地加快算法执行的速度。 嵌套连接消除嵌套连接是指：当执行连接操作的次序不是从左到右逐个进行时，就说明这样的连接表达式存在嵌套。 1）如果连接表达式只包括内连接（JOIN ON），括号可以去掉，这意味着表之间的次序可以交换。 2）如果连接表达式包括外连接，括号不可以去掉，意味着表之间的次序只能按原语义进行，至多能执行的就是外连接向内连接转换。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自行测试的1亿条数据中PostgreSQL性能]]></title>
    <url>%2F2014%2F12%2F02%2F%E8%87%AA%E8%A1%8C%E6%B5%8B%E8%AF%95%E7%9A%841%E4%BA%BF%E6%9D%A1%E6%95%B0%E6%8D%AE%E4%B8%ADPostgreSQL%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[插入一亿条数据12345test=# insert into tbl_time1 select generate_series(1,100000000),clock_timestamp(),now();INSERT 0 100000000Time: 525833.218 ms约:8.7分钟 COUNT，没有索引，1亿条数据。123456789test=# select count(1) from tbl_time1; count ----------- 100000000(1 row)Time: 3070658.058 ms约:51.2分钟 添加主键索引耗时12345test=# alter table tbl_time1 add primary key (id);ALTER TABLETime: 981276.804 ms约：16.4分钟 再 explain 一下看看123456test=# explain select count(id) from tbl_time1; QUERY PLAN ----------------------------------------------------------------------------- Aggregate (cost=7770150.00..7770150.01 rows=1 width=4) -&gt; Seq Scan on tbl_time1 (cost=0.00..7520150.00 rows=100000000 width=4)(2 rows) 虽然 id 上有索引，但是依然是使用顺序扫描。 #COUNT，有索引(主键），1亿条数据，还要注意有没有 where id &gt; 0 的条件的差别 1234567891011121314151617181920212223242526272829303132333435363738394041这个有 where id &gt; 0test=# select count(id) from tbl_time1 where id &gt; 0; count ----------- 100000000(1 row)Time: 244243.112 ms约：4.071分钟test=# explain select count(id) from tbl_time1 where id &gt; 0; QUERY PLAN ----------------------------------------------------------------------------------------------- Aggregate (cost=7644075.89..7644075.90 rows=1 width=4) -&gt; Bitmap Heap Scan on tbl_time1 (cost=623925.90..7560742.56 rows=33333333 width=4) Recheck Cond: (id &gt; 0) -&gt; Bitmap Index Scan on tbl_time1_pkey (cost=0.00..615592.57 rows=33333333 width=0) Index Cond: (id &gt; 0)(5 rows) Time: 0.767 ms这个无 where id &gt; 0test=# select count(id) from tbl_time1; count ----------- 100000000(1 row)Time: 548650.606 ms约：9.144分钟test=# explain select count(id) from tbl_time1; QUERY PLAN ----------------------------------------------------------------------------- Aggregate (cost=7770150.00..7770150.01 rows=1 width=4) -&gt; Seq Scan on tbl_time1 (cost=0.00..7520150.00 rows=100000000 width=4)(2 rows) Time: 1.253 ms COUNT 结论：（9.3.5的版本，默认配置）无论你的数据有没有索引，COUNT都只会进行全表扫描。（条件是没有where， 或有where，但经过查询计划估算代价时，还是决定使用顺序全表扫描）。比如在上面的表，id 有索引。大概原因是说：因为MVCC的影响。 select count(id) from tbl_time1 where id &gt; 0; 经过PG的查询优化器估算时，它最后还是决定使用 Seq Scan 扫描。 123456789test=# explain select count(id) from tbl_time2 where id &gt; 0; QUERY PLAN ------------------------------------------------------------------------- Aggregate (cost=21370.00..21370.01 rows=1 width=4) -&gt; Seq Scan on tbl_time2 (cost=0.00..18870.00 rows=1000000 width=4) Filter: (id &gt; 0)(3 rows) Time: 0.872 ms Postgres中通过需要扫描来计数count(*)的成本比较高. 没有别的办法来来对行数计数并返回结果除了扫描全部数据. 通过修改配置文件调优，时间从 ：51.2分钟–&gt;9.144分钟–&gt;4.071分钟–&gt;1.456分钟1234567891011121314enable_bitmapscan = offenable_hashagg = onenable_hashjoin = onenable_indexscan = onenable_indexonlyscan = on#enable_material = on#enable_mergejoin = on#enable_nestloop = onenable_seqscan = off#enable_sort = onenable_tidscan = off实测在如此配置的情况下，indexonlyscan优先!所谓的 IndexOnlyScan，表示只在索引取数据，不用再定位物理位置后再取数据。性能最快。 通过以上的配置，重启下服务器。再执行查询计划时可以看到： 12345678910111213141516171819202122test=# explain select count(id) from tbl_time1 where id &gt; 0; QUERY PLAN ---------------------------------------------------------------------------------------------------------- Aggregate (cost=118803211.23..118803211.24 rows=1 width=4) -&gt; Index Only Scan using tbl_time1_pkey on tbl_time1 (cost=0.57..118719877.89 rows=33333333 width=4) Index Cond: (id &gt; 0)(3 rows)Time: 16.033 ms这时变成了：Index Only Scan 了。不过耗时还是需要 test=# select count(id) from tbl_time1 where id &gt; 0; count -----------100000000(1 row) Time: 87501.151 ms约：1.456分钟 估算表大小SELECT reltuples FROM pg_class WHERE relname = &apos;tb_name&apos;; 并发方式建立索引当Postgres建立你的索引的时候， 和其他数据库一样, 在建立索引的时候是会锁表的. 对于小数据量来说没什么关系， 但是通常可能是我们对一个大数据量的表加索引, 这意味着要获得性能改进应用必须收到停机一段时间. 至少那一张表会受影响. Postgres有能力在创建索引的时候不锁表, 通过使用 CREATE INDEX CONCURRENTLY , 例如: CREATE INDEX CONCURRENTLY idx_salary ON employees(last_name, salary); 当你的索引比你聪明的时候在所有索引没有被Postgres使用的情况, 大多数情况下你应该相信Postgres, 例如当你查询的结果占所有数据的大部分时候, 它可能不使用索引，因为只扫描全表一次最简单,而不是使用索引做额外的查找.]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《数据库查询优化器的艺术》第一章学习笔记]]></title>
    <url>%2F2014%2F12%2F02%2F%E3%80%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[数据库管理系统数据定义 数据操纵 数据库的运行管理 数据库的建立和维护等 查询优化的目标使查询优化引擎生成一个执行策略的过程，尽量使查询的总开销（IO，CPU，网络传输等）达到最小。 查询优化技术（广义）查询重用技术 查询重写规则 查询算法优化技术 并行查询优化技术 分布式查询优化技术 其他方面（如框架结构）的优化技术 查询优化技术（狭义）查询重写规则 查询算法优化 代数优化（逻辑优化）主要依据关系代数的等价变换做一些逻辑变换。查询重写规则属于逻辑优化。 非代数优化（物理优化）主要根据数据读取，表连接方式，表连接顺序，排序等技术对查询进行优化。查询算法优化，属于物理优化。运用了基于代价估算的多表连接算法求解最小花费的技术。 数据库调优目标是使数据库有更高的吞吐量以及更短的响应时间。它是全局的。而查询优化技术是SQL层面的，局部的优化。 查询重用指尽可能利用先前的执行结果，以达到节约查询计算全过程的时间并减少资源消耗的目的。 （1）查询结果的重用 在缓冲区分配一块缓冲块，存放该SQL语句文本和最后的结果集，当遇到同样的SQL输入时，可直接把结果返回。它节约了查询计划生成时间和查询执行过程的时间，减少了查询执行全过程的资源消耗。 （2）查询计划的重用 缓存一条查询语句的执行计划及其相应语法树结构。查询计划的重用技术减少了查询计划生成的时间和资源消耗 查询重写规则它是一种等价转换。即对于任何相关模式的任意状态都会产生相同的结果。目标： （1）将查询转换为等价的，效率更高的形式。 （2）尽量将查询重写为等价，简单且不受表顺序限制的形式，为物理查询优化阶段提供更多的选择。如：视图的重写，子查询的合并转换等。 重写的主要依据是关系代数。它是查询重写规则的理论支持。 它有3个角度，第4个是物理优化。 （1）语法级 （2）代数级 （3）语义级 （4）物理级：即基于代价估算模型，比较得出代价最小的，是从连接路径中选择代价最小的路径的过程。 主要思路： 1）将过程性查询转换为描述性的查询，如视图重写 2）将复杂的查询（嵌套子查询，外连接，嵌套连接）尽可能转换为多表连接查询 3）将效率低的谓词转换为等价的效率高的谓词（如等价谓词重写） 4）利用等式和不等式的性质，简化 WHERE， HAVING 和 ON 条件 核心是：等价转换，只有等价才能转换。 查询算法优化查询优化即求解给定查询语句的高效执行计划的过程。 单表结点获取数据的方式有： （1）直接通过IO获取 （2）通过索引获取数据 （3）通过索引定位数据的位置再经IO到数据块中获取数据 这是从物理存储到内存解析成逻辑字段的过程。 查询计划的策略： （1）基于规则优化 （2）基于代价优化。 PG和MySQL采取了基于规则和代价估算的查询优化策略。 多表连接优化算法SYSTEM-R算法 启发式搜索算法 贪婪算法 动态规划算法 遗传算法 并行查询优化单机：找到查询的一个具有最小执行花费的执行计划 并行：寻找具有最小响应时间的查询执行计划 并行查询： （1）操作内并行：将同一操作，如单表扫描操作，两表连接操作，排序操作等分解成多个独立的子操作，由不同的CPU同时执行。 （2）操作间并行：一条SQL查询语句可以分解成多个子操作，由多个CPU执行。 分布式查询优化查询策略优化（主要是数据传输策略）和局部处理优化（传统的单结点数据库的查询优化技术）是查询优化的重点。 主要目标： 减少传输的次数和数据量 分布式代价估算模型 总代价 = IO代价 + CPU代价 + 通信代价]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]PostgreSQL中的死锁]]></title>
    <url>%2F2014%2F12%2F01%2F%E7%BF%BB%E8%AF%91-PostgreSQL%E4%B8%AD%E7%9A%84%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[原文 在讨论死锁之前，让我们看一下锁的类型以及它们在PostgreSQL中的获取方法。 锁的类型： 表级锁 以及 行级锁 表级锁： AcessShareLock（访问共享锁）：通过在一张表或多张表一条 SELECT 语句检索数据时就会自动获取。这个模式会阻塞在同一张表下的 ALTER TABLE，DROP TABLE 以及 VACUUM (AccessExclusiveLock，访问排他锁)操作。 RowShareLock （行共享锁）：通过一条SELECT...FOR UPDATE子句自动获取。它会在同一张表上阻塞并发的ExclusiveLock(排他锁）以及AccessExclusiveLock(访问排他锁）。 RowExclusiveLock （行排他锁）：通过UPDATE，INSERT，或者 DELETE命令自动获取。它会在同一张表上阻塞ALTER TABLE，DROP TABLE,VACUUM 和 CREATE INDEX命令。（ShareLock[共享锁]，ShareRowExclusiveLock[共享行排他锁]，ExclusiveLock[排他锁]，AccessExclusiveLock[访问排他锁]）。 ShareLock（共享锁）: 通过CREATE INDEX命令自动获取。它会在同一张表上阻塞INSERT, UPDATE, DELETE, ALTER TABLE, DROP TABLE, 以及 VACUUM命令.(RowExclusiveLock[行排他锁], ShareRowExclusiveLock[共享行排他锁], ExclusiveLock[排他锁], 以及 AccessExclusiveLock[访问排他锁]) ShareRowExclusiveLock（共享行排他锁）：这个锁模式与ExclusiveLock（排他锁）是一样的，但是它允许获取并发的 RowShareLock（行共享锁） ExclusiveLock（排他锁）：”每个事务在它的事务ID的整个时间里都会持有一个Exclusive Lock（排他锁）”。如果一个事务发现它需要特别地等待另一个事务，它就会尝试地在另一个事务ID上获取 Share Lock（共享锁）。这仅当另一个事务结束并释放它自己的锁时才会成功。（注意，冲突）。Exclusive Lock（排他锁）会在同一张表上阻塞INSERT, UPDATE, DELETE,CREATE INDEX, ALTER TABLE,DROP TABLE, SELECT...FOR UPDATE 以及 VACUUM命令。 AccessExclusiveLock（访问排他锁）：通过ALTER TABLE, DROP TABLE, 或者 VACUUM命令来修改表时自动获取。从开始在表上获取锁时，会阻塞任何并发命令或者其他锁模式。 行级锁：行级锁有两种类型：共享锁和排他锁。不要混淆锁的命名，你可以通过在视图pg_locks中的列lock_type来区分是表级锁，还是行级锁。 Exclusive lock（排他锁）：当通过UPDATE或DELETE命中行时就会自动获取该锁。锁会一直被持有，直到一个事务提交或回滚了。为了手动获取exclusive-lock（排他锁），可以使用SELECT FOR UPDATE。 Share-Lock（共享锁）：当通过SELECT...FOR SHARE命中行时就会自动获取该锁。 注意：在这两种情况下的行级锁，数据检索是一点也不会影响的。行级锁会阻塞“写”（即，“写”会阻塞“写”）。 死锁:现在到死锁了，你已经知道锁的模式以及获取这些锁的方法，有些情况下事务会陷入死锁中。我相信应用程序设计是导致死锁的罪魁祸首。死锁大多数是由于ExclusiveLock（排他锁）例如UPDATE或DELETE操作导致的。 ##什么是死锁？ 进程A持有对象X的锁，并且正等待对象Y的锁。进程B持有对象Y的锁，并且正等待对象X的锁。在这时，这两个进程就会进入所谓的“死锁”，每个进程都想获取另一个进程持有的锁。在这个状态下，他们都在永远等待对方释放锁。他们之一必须放弃并释放自己拥有的锁。现在，死锁检测器就会检测到并且允许一个进程成功提交事务，而另一个则进行回滚。 为了解决死锁，要用这样一个方法来设计应用程序——任何事务“UPDATE”或“DELETE”都应该成功地取得表的所有权。通过SHARE UPDATE EXCLUSIVE 模式或者SELECT...FOR UPDATE，又或者ACCESS EXCLUSIVE 模式来锁表并且完成事务。在这个模型下，死锁检测器永远不会抛出它已经检测到一个EXCLUSIVE LOCK（排他锁）。 你可通过这个办法来解决上面的图的情况，你会看到死锁检测器永远不会抛出错误。 锁查询语句1\set locks &apos;SELECT w.locktype AS waiting_locktype,w.relation::regclass AS waiting_table,w.transactionid, substr(w_stm.current_query,1,20) AS waiting_query,w.mode AS waiting_mode,w.pid AS waiting_pid,other.locktype AS other_locktype,other.relation::regclass AS other_table,other_stm.current_query AS other_query,other.mode AS other_mode,other.pid AS other_pid,other.granted AS other_granted FROM pg_catalog.pg_locks AS w JOIN pg_catalog.pg_stat_activity AS w_stm ON (w_stm.procpid = w.pid) JOIN pg_catalog.pg_locks AS other ON ((w.\&quot;database\&quot; = other.\&quot;database\&quot; AND w.relation = other.relation) OR w.transactionid = other.transactionid) JOIN pg_catalog.pg_stat_activity AS other_stm ON (other_stm.procpid = other.pid) WHERE NOT w.granted AND w.pid &lt;&gt; other.pid;;&apos; 关于锁的信息链接 http://www.postgresql.org/docs/9.0/static/sql-lock.htmlhttp://developer.postgresql.org/pgdocs/postgres/explicit-locking.html 希望你有一个关于PostgreSQL锁的概念了。 希望在之后的博文中可以再次见到你。:) –Raghav By Raghavendra 我附：现在的PG有8种表级锁了，除了上面作者提到的7种，还有一种是： SHARE UPDATE EXCLUSIVE 锁 与”Share update exclusive,Share,Share row ,exclusive,exclusive,Access exclusive”模式冲突，这种模式保护一张表不被并发的模式更改和VACUUM; “Vacuum(without full), Analyze ”和 “Create index concurrently”命令会获得这种类型锁。 资料： http://www.postgresql.org/docs/9.0/static/explicit-locking.html]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]高效使用PostgreSQL索引]]></title>
    <url>%2F2014%2F12%2F01%2F%E7%BF%BB%E8%AF%91-%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8PostgreSQL%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[原文 在Postgres里有许多种索引类型，也有不同的方式来使用它们。在本文中,我们概述一下可用的索引类型，并解释不同的使用和维护最常见的索引类型的方式:B树。 索引是一种从表中检索的行数相对较小的有效方式。如果从一个表中检索的行数相对较小时索引是非常有用的（例如：按条件来检索行——WHERE子句选择）。对于免排序的，B树索引也是非常有用的。 索引类型Postgres支持许多不同的索引类型： B树对于当你执行CREATE INDEX时是默认的索引类型。实际上，所有数据库都有一些B树索引。字母B代表是Balanced（平衡），这个大意是,两边的树的数据量是大致相同的。因此，必须遍历去找行的层次数总是在相同的范围内。B树索引可以有效地用于等值和范围查询，并且也可以用于检索NULL值。B树的设计与缓存可以很好地工作，即使只是缓存部分。 哈希索引只在等值比较时才有用，但是你几乎从来没有想使用它们，因为它们不是事务安全的，崩溃后需要手工重建，并且是不会被复制到从库的，因此，比B树索引的优势是相当小的。 当一个索引必须映射多个值到一行时通用反转索引（GIN，Generalized Inverted Indexes）（通用逆向索引、广义倒排索引）是非常有用的，然而当一行有一个单键值时，B树索引会做一些优化。GIN对于索引数组值以及实现全文搜索是比较好的。 通用搜索树（广义搜索树）（GiST，Generalized Search Tree）索引允许你建立普通平衡树结构，也能用于等值和范围比较之外的操作。它们用于索引几何数据类型，也可用于全文搜索。 本文是关于如何最有效地使用默认的B树索引。GIN和GiST索引使用例子，请参考扩展包说明。 ##为什么我的查询没有用上索引？ 有许多原因导致为什么Postgres查询计划没有选择使用索引。大多数的时候，查询计划器是正确的，即使它不是那么明显地为什么会这样。如果相同的查询有几次会使用索引扫描，但其他时候不使用索引扫描，这是没问题的。从表中检索到的行数可以基于特定的常数值的查询检索而变化。（我注：即不同的常量值，会导致不同的结果行数）。因此，例如，查询计划器对于查询select * from foo where bar = 1使用索引可能是正确的，但对于查询select * from foo where bar = 2却可能不使用索引，这发生于对于bar值为2的行有比较多的话。发生这种情况时，顺序扫描实际上是最有可能比索引扫描快得多，因此，查询计划器实际上是判断正确的，这时顺序扫描的性能代价相比索引扫描更低。 部分索引部分索引包含表数据的一个子集。它是一个带有WHERE子句的索引。这个概念是为了提高索引的效率,减少索引的大小。小的索引占更少的存储空间，易于维护，扫描更快。 例如，假设你允许用户评论你的网站，从而设置标记布尔值为真（true）。然后你批量处理标标记的评论。你可能想创建一个类似这样子的索引：1CREATE INDEX articles_flagged_created_at_index ON articles(created_at) WHERE flagged IS TRUE; 这个索引将会是相当小的， 在复杂查询中也能使用其他索引来结合它一起使用。 表达式索引表达式索引对于匹配一些函数或修改的数据是有用的。Postgres允许你索引函数结果，以便搜索变得像通过原始数据值搜索一样有效。例如，你可能要求用户保存他们的邮箱登录地址，但你想大小写不敏感的认证。在这种情况下可以保存邮件地址，但是搜索上使用WHERE lower(email) = &#39;&lt;lowercased-email&gt;&#39;。在这种查询下，唯一使用索引的方式是通过表达式索引，例如这样：1CREATE INDEX users_lower_email ON users(lower(email)); 另一个常见例子是，查找给定日期的行，这里我们已经保存时间戳在一个datatime字段，但是想通过转换的date值来查找他们。一个像这样子的索引：1CREATE INDEX articles_day ON articles ( date(published_at) ) 可以用在包含WHERE date(articles.created_at) = date(&#39;2011-03-07&#39;)的查询中使用。 唯一索引唯一索引保证表不会有超过1行的相同值的行。创建唯一索引的有利的两个原因：数据完整和性能。在唯一索引上查找通常是非常快的。在数据完整性方面，使用模型类的validates_uniqueness_of并不是真正保证唯一的，因为这可能在并发用户时会创建无效的记录。因此，你应该问题在数据库级别创建约束——通过索引或者唯一约束。 唯一索引和唯一约束之间有点差别。唯一索引可以想成是更低级别，因为表达式索引和部分索引不能创建唯一约束。表达式上的部分唯一索引就有可能。 多列索引虽然Postgres已经能够创建多列索引，重要的是要理解这样子做的意义。Postgres查询计划器通过位图索引扫描（bitmap index scan）在一条多列查询中有能力结合和使用多个单列索引。通常，你可以在覆盖查询条件的每个列上创建索引并且大部分情况下Postgres将会使用到它们，所以在你创建一个多列索引之前做一个基准测试并证明创建一个多列索引是有效的。正如之前一样，索引是有代价的，并且一个多列索引仅能在查询引用的列是与创建索引时的列的顺序是一样的才会被优化，虽然多个单列索引提供大量的查询的性能改进。 然而在某些情况下,一个多列索引显然是有意义的。一个在列（a,b）上的索引能够用在查询包含WHERE a = x AND b = y，或者查询仅使用WHERE a = x的情况，但是不会用于查询使用WHERE b = y的情况。所以，如果这匹配到你的应用程序的查询模式，多列索引就是值得考虑的。也要注意在本例中创建一个独立的索引（我注：我理解是在这种情况下，创建多个单列索引）是多余的。 B树和排序B树索引项默认按升序排序保存的。在某些情况下,它可以为索引提供一个不同的排序顺序。比如当你正分页显示文章的情况，首先按最近发布的来排序。我们在articles表上可能有一列published_at。对于未发表的文章，published_at的值是NULL。在这种情况下，我们可以创建一个这样子的索引：1CREATE INDEX articles_published_at_index ON articles(published_at DESC NULLS LAST); 在Postgre 9.2及之后版本，值得注意的是索引并不总是需要去查找表的，我们可以提供一切需要从索引得到的数据。（也就是，没有索引的列是不感兴趣的）。这个特性叫“只读索引扫描”。 由于我们会按published_at排序以及限制结果数来查询表，我们可以从创建同样的顺序的索引中得到一些好处。Postgres会以正确的顺序在索引中找到这些行，然后去数据块里检索数据。如果索引不是排序的，Postgres就有一个好机会来顺序读取数据块并且排序结果。 这种技巧主要是当你要求相关的单列索引并且“null在排序的最后”的行为上，否则的话顺序已经是可用的，索引扫描可以在任何方向扫描。当用一个多列索引时来对付一个当查询要求一个混合排序时，例如：a ASC, b DESC，它会变得更加的相关。 管理和维护索引在Postgres里索引并不拥有所有的行数据。即使使用索引来查询和匹配查找到的行，Postgres还会到磁盘中去取行数据。另外，行可见性信息（在MVCC文章中讨论）是不保存到索引的，因此，Postgres必须去磁盘取到这些信息。有了这一点，您可以看到在某些情况下如何使用索引并没有真正意义。索引必须足够选择性地减少磁盘的查找,这才是值得的使用索引的。例如，在一个足够大的表里按一个主键查找，这就很好地利用索引：代替匹配查询条件的顺序扫描，Postgres能够在索引里查找到目标行，然后从磁盘里选择性地取出它们。对于非常小的表，例如，一张查找城市的表，索引可能是不可取，即使你是通过城市名来搜索。在那种情况下，Postgres可能决定忽略索引而支持顺序扫描。Postgres在一些会命中很大一部分表数据的查询上将决定执行顺序扫描。如果你在那些列上有索引，它将会是一个永不被使用的死索引——并且 索引并不是“免费”的：他们在存储和维护方面是有代价的。 当调优一条查询并且了解索引是非常有意义的，从没有在你的开发机上尝试过的话。是否使用索引决定于许多因素，包括Postgres服务器配置、表的数据、索引和查询。例如，在你的开发机上带有一小部分的测试数据的表上尝试使一条查询用上索引是会令你挫败的：Postgres会决定数据集是如此小以致不值得使用索引的额外的“读”开销，然后从磁盘取数据。随机 I/O 比顺序 I/O 是非常慢的，所以，顺序扫描的代价比通过索引读取然后从磁盘查找数据的随机I/O更少。进行索引调优应该在生产或在暂存环境中完成，尽可能在生产环境中。在Heroku 的Postgres数据库平台，可以很容易地复制你的生产数据库到一个不同的环境。 当你准备在你的生产数据库上应用一个索引时，请记住创建索引会锁表并阻塞写操作。对于大表，这可能意味着你的网站是停机几个小时。幸运的是，Postgres允许你CREATE INDEX CONCURRENTLY（并发创建索引），这会导致花更多的时间来建索引，但是不要求锁住写锁。正常的CREATE INDEX命令要求一个锁来锁住写操作，但允许读。最终，在之后一段时间，索引会变得碎片和未优化，如果在表中的行经常更新或删除就特别容易这样。在这种情况下，就可能需要执行一个REINDEX命令来平衡及优化你的索引了。然而，要谨慎重建索引会在父表中获得写锁。有个策略在在线的网站来实现相同的结果就是并发地在相同的表和列但有一个不同的名称的索引，然后，删除旧的索引并且重新命名新的索引。这个过程可能持续比较久，但不要求在在线的(活跃）表有任何长久执行的锁。当准备创建B树索引时Postgres提供了许多灵活性来优化你特定的使用情况，也有许多选项来管理你应用程序不断增长的数据库。这些建议应该会帮你保持你的数据库健康，以及你的查询非常爽快。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译]PostgreSQL中的log, xlog和clog]]></title>
    <url>%2F2014%2F12%2F01%2F%E7%BF%BB%E8%AF%91-PostgreSQL%E4%B8%AD%E7%9A%84log-xlog%E5%92%8Cclog%2F</url>
    <content type="text"><![CDATA[[翻译]PostgreSQL中的log, xlog和clog原文 译记：该文章开头还有一段内容就不翻译了。主要翻译这些log的主要内容。 pg_log$PGDATA/pg_log是数据库运行活动日志的默认保存目录，它包括错误信息，查询日志以及启动/关闭数据库的信息。当PostgreSQL启动失败时，这里应该是你第一个应该查看的信息。一些Linux发行版以及其他的软件包管理系统会将这个日志目录移到某些地方，比如：/var/log/postgresql 你可以在pg_log目录里自由地删除、重命名、压缩或者移动文件而不会有什么不好的结果，只要Postgres用户仍然有权限写该目录。如果pg_log随着许多大文件而膨胀，你可能需要在postgresql.conf里减小你想记录日志的事件。 pg_xlog$PGDATA/pg_xlog是PostgreSQL的事务日志。 这是一些二进制日志文件的集合，文件名类似00000001000000000000008E，它包含最近事务的一些描述数据。这些日志也被用于二进制复制。如果复制、归档或者PITR失败了，当归档正在恢复时，这个目录保存的数据库日志可能会膨胀数GB。这可能会导致你用完你的磁盘空间。不像pg_log，你不能自由地删除、移动或者压缩这个目录的文件。你甚至不能在没有符号链接到该目录的情况下移动这个目录。删除pg_xlog的文件可能会导致不可恢复的数据库损坏。 如果你发现自己处在这样的情况：你发现有100G大小的文件在pg_xlog目录并且数据也启动不了，并且你已经禁止归档/复制并且尝试清理磁盘空间等任何其他的方式，请做以下两个步骤： 从pg_xlog目录里移动文件到一个备份磁盘或者共享网络驱动器中，也不要删除它们，并且 移动一些最老的文件，直到足够允许PostgreSQL启动起来。 pg_clog$PGDATA/pg_clog包含了事务的元数据。这种日志用于告诉PostgreSQL哪个事务已经完成、哪个还没有完成。clog是比较小的并且没有任何理由会膨胀，所以，你应该没有任何理由去碰触它。在任何时候你都不应该从pg_clog里删除文件，如果你这样子做，还不如完全地删除整个数据库目录。缺少clog是不可恢复的。请注意，这意味着，如果你在$PGDATA目录里备份文件，你应该确定同时包含pg_clog和pg_xlog，否则你可能会发现你的备份是不可用的。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>翻译</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL中代替MySQL的内存表方法]]></title>
    <url>%2F2014%2F10%2F01%2FPostgreSQL%E4%B8%AD%E4%BB%A3%E6%9B%BFMySQL%E7%9A%84%E5%86%85%E5%AD%98%E8%A1%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[今天在群里发现有人问PostgreSQL里，有没有类似MySQL的内存表（Memory引擎）。 其实在PostgreSQL里，就只有一种表：堆表。不像MySQL那种提供那么多种的表类型（这个是由引擎来决定的，比如InnoDB的是索引组织表等）。​ 替代方法1） 使用RAM Disk。创建一个表空间到Ram Disk上，然后建表的时候指定表空间到该 Ram Disk即可。 2） 如果需要创建那种全局可见的临时表，建表时可以使用UNLOGGED选项来创建表。这种表性能比一般的快。 实战使用 Ram Disk 作为“临时表”步骤1：创建一个Ram Disk1sudo mount tmpfs /home/postgres/ramdisk/ -t tmpfs 步骤2：更改拥有者为Postgres1sudo chown postgres:postgres /home/postgres/ -R 步骤3：创建Ram的表空间1create tablespace ramdis location &apos;/home/postgres/ramdisk&apos;; 步骤4：创建一个表，并指定表空间到Ram Disk的表空间123test=# create table ram (id serial, name varchar(40), age int) TABLESPACE ramdis;CREATE TABLEtest=# 注意有人担心重启电脑后，Ram disk 的表空间不存在了，会不会影响PostgreSQL服务器的启动。这其实是不用担心的，本人测试过，关闭PostgreSQL，然后删除Ram Disk 的表空间目录，然后再启动PostgreSQL，完全是没问题的。 不过，创建在该表空间的表就不能操作了。典型的错误提示如下：123test=# select * from ram;ERROR: could not open file &quot;pg_tblspc/16718/PG_9.4_201409291/16389/16729&quot;: No such file or directorytest=# 删除该表就OK了。]]></content>
      <categories>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>database</tag>
      </tags>
  </entry>
</search>